## Классическое машинное обучение

### **1. Подготовка данных**
1. Предобработка данных (Preprocessing)
1. Обработка пропущенных значений
1. Обработка выбросов
1. Кодирование категориальных признаков
1. Масштабирование и нормализация
1. Feature Engineering
1. Выбор признаков (Feature Selection)
1. Снижение размерности (Dimensionality Reduction)
1. Балансировка классов

### **2. Классификация**
1. Логистическая регрессия
1. Метод опорных векторов (SVM)
1. Наивный Байес (Naive Bayes)
1. k-ближайших соседей (k-NN)
1. Деревья решений для классификации
1. Случайный лес для классификации
1. Градиентный бустинг для классификации
1. XGBoost / LightGBM / CatBoost
1. Ансамбли методов (Voting, Stacking)

### **3. Регрессия**
1. Линейная регрессия
1. Полиномиальная регрессия
1. Ридж, Лассо, ElasticNet
1. Деревья решений для регрессии
1. Случайный лес для регрессии
1. Градиентный бустинг для регрессии
1. Методы регуляризации
1. Непараметрическая регрессия

### **4. Кластеризация**
1. K-means и K-means++
1. Иерархическая кластеризация
1. DBSCAN
1. OPTICS
1. Gaussian Mixture Models
1. Метрики оценки кластеризации
1. Выбор числа кластеров

### **5. Понижение размерности**
1. PCA (Principal Component Analysis)
1. t-SNE
1. UMAP
1. LDA (Linear Discriminant Analysis)
1. SVD (Singular Value Decomposition)
1. Автоэнкодеры (линейные)

### **6. Оценка моделей и валидация**
1. Метрики классификации
1. Метрики регрессии
1. Кросс-валидация
1. Кривые обучения
1. Калибровка моделей
1. Статистические тесты для сравнения моделей

### **7. Поиск гиперпараметров**
1. Grid Search
1. Random Search
1. Bayesian Optimization
1. Optuna / Hyperopt
1. Стратегии поиска гиперпараметров

### **8. Работа с временными рядами (классические методы)**
1. ARIMA / SARIMA
1. Экспоненциальное сглаживание
1. Методы на основе скользящих средних
1. Feature Engineering для временных рядов
1. Валидация временных рядов

### **9. Обнаружение аномалий**
1. Isolation Forest
1. One-Class SVM
1. Local Outlier Factor
1. Elliptic Envelope
1. Статистические методы

### **10. Рекомендательные системы (классические)**
1. Коллаборативная фильтрация
1. Контентная фильтрация
1. Матричная факторизация (SVD)
1. ALS (Alternating Least Squares)

### **11. Градиентный бустинг**
1. XGBoost
1. LightGBM
1. CatBoost
1. Гиперпараметры градиентного бустинга
1. Особенности и тонкости настройки

### **12. Статистические методы**
1. Линейные модели (GLM)
1. Множественная регрессия
1. Дисперсионный анализ (ANOVA)
1. Bootstrap
1. Статистическая проверка гипотез

### **13. Проектирование признаков**
1. Создание полиномиальных признаков
1. Взаимодействия признаков
1. Биннинг (дискретизация)
1. Target Encoding
1. Дата-специфичные признаки (временные, текстовые)

### **14. Работа с несбалансированными данными**
1. Методы семплирования
1. Веса классов
1. Метрики для несбалансированных данных
1. Алгоритмические подходы

### **15. Интерпретация моделей**
1. Важность признаков
1. SHAP значения
1. LIME
1. Частичные зависимости
1. Surrogate models

### **16. Производственные аспекты**
1. Сериализация моделей
1. Мониторинг дрейфа данных
1. Концептуальный дрейф
1. Пайплайны ML

### **17. Специальные алгоритмы**
1. Метод главных компонент (PCA)
1. Линейный дискриминантный анализ (LDA)
1. Канонический корреляционный анализ
1. Скрытые марковские модели
1. EM-алгоритм

### **18. Визуализация в ML**
1. Визуализация данных
1. Визуализация кластеров
1. Визуализация деревьев
1. Визуализация метрик

### **19. Основы теории**
1. Смещение-дисперсия
1. Переобучение/недообучение
1. Регуляризация
1. Байесовский подход
1. Теория информации в ML

### **20. Инструменты и библиотеки**
1. Scikit-learn полный обзор
1. Pandas для ML
1. NumPy для ML
1. Matplotlib/Seaborn для визуализации
1. ML-пайплайны

### **21. Дополнительные темы**
1. Active Learning
1. Transfer Learning (классические подходы)
1. Multi-task Learning
1. Multi-output модели
1. Квантильная регрессия

