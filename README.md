* [Классическое машинное обучение](https://github.com/gurovic/MLCheatSheets/blob/main/README.md#%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5-%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5-%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5)
* [Глубокое обучение](https://github.com/gurovic/MLCheatSheets/blob/main/README.md#%D0%B3%D0%BB%D1%83%D0%B1%D0%BE%D0%BA%D0%BE%D0%B5-%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5)
* [Разные темы машинного обучения]()

## Классическое машинное обучение

### **1. Подготовка данных**
1. Предобработка данных (Preprocessing)
1. Обработка пропущенных значений
1. Обработка выбросов
1. Кодирование категориальных признаков
1. Масштабирование и нормализация
1. Feature Engineering
1. Выбор признаков (Feature Selection)
1. Снижение размерности (Dimensionality Reduction)
1. Балансировка классов

### **2. Классификация**
1. Логистическая регрессия
1. Метод опорных векторов (SVM)
1. Наивный Байес (Naive Bayes)
1. k-ближайших соседей (k-NN)
1. Деревья решений для классификации
1. Случайный лес для классификации
1. Градиентный бустинг для классификации
1. XGBoost / LightGBM / CatBoost
1. Ансамбли методов (Voting, Stacking)

### **3. Регрессия**
1. Линейная регрессия
1. Полиномиальная регрессия
1. Ридж, Лассо, ElasticNet
1. Деревья решений для регрессии
1. Случайный лес для регрессии
1. Градиентный бустинг для регрессии
1. Методы регуляризации
1. Непараметрическая регрессия

### **4. Кластеризация**
1. K-means и K-means++
1. Иерархическая кластеризация
1. DBSCAN
1. OPTICS
1. Gaussian Mixture Models
1. Метрики оценки кластеризации
1. Выбор числа кластеров

### **5. Понижение размерности**
1. PCA (Principal Component Analysis)
1. t-SNE
1. UMAP
1. LDA (Linear Discriminant Analysis)
1. SVD (Singular Value Decomposition)
1. Автоэнкодеры (линейные)

### **6. Оценка моделей и валидация**
1. Метрики классификации
1. Метрики регрессии
1. Кросс-валидация
1. Кривые обучения
1. Калибровка моделей
1. Статистические тесты для сравнения моделей

### **7. Поиск гиперпараметров**
1. Grid Search
1. Random Search
1. Bayesian Optimization
1. Optuna / Hyperopt
1. Стратегии поиска гиперпараметров

### **8. Работа с временными рядами (классические методы)**
1. ARIMA / SARIMA
1. Экспоненциальное сглаживание
1. Методы на основе скользящих средних
1. Feature Engineering для временных рядов
1. Валидация временных рядов

### **9. Обнаружение аномалий**
1. Isolation Forest
1. One-Class SVM
1. Local Outlier Factor
1. Elliptic Envelope
1. Статистические методы

### **10. Рекомендательные системы (классические)**
1. Коллаборативная фильтрация
1. Контентная фильтрация
1. Матричная факторизация (SVD)
1. ALS (Alternating Least Squares)

### **11. Градиентный бустинг**
1. XGBoost
1. LightGBM
1. CatBoost
1. Гиперпараметры градиентного бустинга
1. Особенности и тонкости настройки

### **12. Статистические методы**
1. Линейные модели (GLM)
1. Множественная регрессия
1. Дисперсионный анализ (ANOVA)
1. Bootstrap
1. Статистическая проверка гипотез

### **13. Проектирование признаков**
1. Создание полиномиальных признаков
1. Взаимодействия признаков
1. Биннинг (дискретизация)
1. Target Encoding
1. Дата-специфичные признаки (временные, текстовые)

### **14. Работа с несбалансированными данными**
1. Методы семплирования
1. Веса классов
1. Метрики для несбалансированных данных
1. Алгоритмические подходы

### **15. Интерпретация моделей**
1. Важность признаков
1. SHAP значения
1. LIME
1. Частичные зависимости
1. Surrogate models

### **16. Производственные аспекты**
1. Сериализация моделей
1. Мониторинг дрейфа данных
1. Концептуальный дрейф
1. Пайплайны ML

### **17. Специальные алгоритмы**
1. Метод главных компонент (PCA)
1. Линейный дискриминантный анализ (LDA)
1. Канонический корреляционный анализ
1. Скрытые марковские модели
1. EM-алгоритм

### **18. Визуализация в ML**
1. Визуализация данных
1. Визуализация кластеров
1. Визуализация деревьев
1. Визуализация метрик

### **19. Основы теории**
1. Смещение-дисперсия
1. Переобучение/недообучение
1. Регуляризация
1. Байесовский подход
1. Теория информации в ML

### **20. Инструменты и библиотеки**
1. Scikit-learn полный обзор
1. Pandas для ML
1. NumPy для ML
1. Matplotlib/Seaborn для визуализации
1. ML-пайплайны

### **21. Дополнительные темы**
1. Active Learning
1. Transfer Learning (классические подходы)
1. Multi-task Learning
1. Multi-output модели
1. Квантильная регрессия

## Глубокое обучение

### **1. Основы нейронных сетей**
1. Искусственный нейрон (перцептрон)
1. Архитектура MLP (многослойный перцептрон)
1. Функции активации (ReLU, Sigmoid, Tanh, Softmax)
1. Функции потерь для классификации и регрессии
1. Алгоритм обратного распространения ошибки
1. Оптимизаторы (SGD, Momentum, Adam, RMSProp)
1. Инициализация весов
1. Регуляризация нейронных сетей

### **2. Сверточные нейронные сети (CNN)**
1. Основы свертки
1. Пулинг-слои (Max, Average, Global)
1. Архитектуры CNN (LeNet, AlexNet, VGG)
1. Современные архитектуры (ResNet, Inception, EfficientNet)
1. Transfer learning для CNN
1. Data augmentation для изображений
1. Визуализация CNN
1. 1D-CNN и 3D-CNN

### **3. Рекуррентные нейронные сети (RNN)**
1. Основы RNN
1. Проблема исчезающего градиента
1. LSTM (Long Short-Term Memory)
1. GRU (Gated Recurrent Units)
1. Двунаправленные RNN
1. Рекуррентная регуляризация
1. Архитектуры encoder-decoder

### **4. Трансформеры и механизмы внимания**
1. Механизм внимания (attention)
1. Self-attention
1. Multi-head attention
1. Архитектура Transformer
1. Positional encoding
1. BERT и языковые модели
1. Vision Transformers (ViT)
1. Efficient Transformers

### **5. Генеративные модели**
1. Автоэнкодеры
1. Вариационные автоэнкодеры (VAE)
1. Генеративно-состязательные сети (GAN)
1. DCGAN, Conditional GAN
1. StyleGAN
1. Diffusion модели
1. Нормализующие потоки (Normalizing Flows)

### **6. Обучение с подкреплением (Deep RL)**
1. Deep Q-Networks (DQN)
1. Policy Gradient методы
1. Actor-Critic методы
1. PPO (Proximal Policy Optimization)
1. Многозадачное RL
1. Иерархическое RL
1. Имитационное обучение

### **7. Обработка естественного языка (NLP)**
1. Векторные представления слов (Word2Vec, GloVe, FastText)
1. RNN/LSTM для NLP
1. Transformer для NLP
1. BERT и его вариации
1. GPT-архитектуры
1. Токенизация (BPE, WordPiece, SentencePiece)
1. Задачи NLP (NER, классификация, суммаризация)

### **8. Компьютерное зрение (Computer Vision)**
1. Классификация изображений
1. Детекция объектов (YOLO, SSD, Faster R-CNN)
1. Сегментация (Semantic, Instance, Panoptic)
1. Детекция ключевых точек
1. Слежение за объектами
1. Оценка позы человека
1. 3D Computer Vision

### **9. Обработка аудио и речь**
1. Спектрограммы и MFCC
1. Модели для распознавания речи (ASR)
1. Модели для синтеза речи (TTS)
1. Классификация звуков
1. Source separation
1. Audio generation

### **10. Мультимодальное обучение**
11. Модели для изображений и текста
11. CLIP и похожие архитектуры
11. Видео-аудио модели
11. Cross-modal retrieval
11. Мультимодальные трансформеры

### **11. Малоресурсное обучение**
11. Few-shot learning
11. Zero-shot learning
11. Transfer learning
11. Meta-learning (MAML, Prototypical Networks)
11. Domain adaptation

### **12. Объяснимость и интерпретируемость**
11. CAM и Grad-CAM
11. Saliency maps
11. Integrated gradients
11. LIME для нейросетей
11. SHAP для нейросетей
11. Concept activation vectors

### **13. Оптимизация и ускорение**
11. Mixed precision training
11. Gradient checkpointing
11. Distributed training
11. Квантизация (quantization)
11. Прунинг (pruning)
11. Дистилляция знаний (knowledge distillation)
11. Neural Architecture Search (NAS)

### **14. Графовые нейронные сети (GNN)**
11. Основы GNN
11. Graph Convolutional Networks (GCN)
11. Graph Attention Networks (GAT)
11. Message Passing Networks
11. Применения GNN

### **15. Временные ряды и прогнозирование**
11. RNN/LSTM для временных рядов
11. CNN для временных рядов (TCN)
11. Transformers для временных рядов
11. Многомерные временные ряды
11. Аномалии во временных рядах
11. Прогнозирование спроса и трафика

### **16. Нейросети для табличных данных**
11. MLP для табличных данных
11. TabNet
11. Neural Oblivious Decision Ensembles
11. AutoML для нейросетей
11. Сравнение с классическими методами

### **17. Этичные аспекты и безопасность**
11. Adversarial attacks
11. Defensive distillation
11. Adversarial training
11. Bias в нейросетях
11. Fairness в ML
11. Federated learning
11. Differential privacy

### **18. Производство и MLOps**
11. Сериализация нейросетей
11. ONNX формат
11. TensorFlow Serving
11. TorchServe
11. Мониторинг моделей
11. CI/CD для ML
11. Feature stores

### **19. Фреймворки и библиотеки**
11. PyTorch полный гайд
11. TensorFlow/Keras полный гайд
11. JAX и Flax
11. Hugging Face Transformers
11. PyTorch Lightning
11. FastAI

### **20. Теория глубокого обучения**
21. Теорема универсальной аппроксимации
21. Теория обобщения для нейросетей
21. Динамика обучения нейросетей
21. Neural tangent kernel
21. Information bottleneck theory

### **21. Специальные архитектуры**
21. Capsule networks
21. Spiking neural networks
21. Neural ODEs
21. Differentiable programming
21. Memory networks
21. Hypernetworks

### **22. Нейронаука и биологически правдоподобные модели**
21. Биологически вдохновленные архитектуры
21. Нейроморфные вычисления
21. Связь нейросетей и мозга

### **23. Креативные приложения**
21. Neural style transfer
21. Image-to-image translation
21. Text-to-image generation
21. Музыкальные нейросети
21. Генерация видео

### **24. Научные применения**
21. Нейросети в физике
21. Нейросети в химии
21. Нейросети в биологии
21. Нейросети в медицине
21. Нейросети в астрономии

### **25. История и эволюция**
21. Хронология глубокого обучения
21. Ключевые прорывы
21. Современные тенденции
21. Будущее глубокого обучения

