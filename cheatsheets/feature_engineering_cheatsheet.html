<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Feature Engineering Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      
        min-width: 900px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

        .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 600;
    }

    .good p, .bad p {
      margin: 0;
      font-size: 0.88em;
    }

    em {
      color: #d32f2f;
      font-style: normal;
      font-weight: 600;
    }

    strong {
      color: #1a5fb4;
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üõ†Ô∏è Feature Engineering</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –ß—Ç–æ —Ç–∞–∫–æ–µ Feature Engineering?</h2>
    <ul>
      <li><strong>–¶–µ–ª—å</strong>: —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö</li>
      <li><strong>–ó–∞—á–µ–º</strong>: —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏</li>
      <li><strong>–ö–æ–≥–¥–∞</strong>: –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–∏</li>
      <li><strong>–ò—Å–∫—É—Å—Å—Ç–≤–æ –∏ –Ω–∞—É–∫–∞</strong>: —Ç—Ä–µ–±—É–µ—Ç –∑–Ω–∞–Ω–∏—è –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏</li>
      <li><strong>–ö–ª—é—á –∫ —É—Å–ø–µ—Ö—É</strong>: —á–∞—Å—Ç–æ –≤–∞–∂–Ω–µ–µ –≤—ã–±–æ—Ä–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–∞!</li>
    </ul>

    </div>
<div class="block">
    <h2>üî∑ 2. –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏</h2>
    <table>
      <tr><th>–¢–µ—Ö–Ω–∏–∫–∞</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th></tr>
      <tr><td><strong>–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ</strong></td><td>–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏–π</td></tr>
      <tr><td><strong>–ë–∏–Ω–Ω–∏–Ω–≥</strong></td><td>–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –≤ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã</td></tr>
      <tr><td><strong>–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è</strong></td><td>Log, sqrt, Box-Cox</td></tr>
      <tr><td><strong>–ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ</strong></td><td>–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ ‚Üí —á–∏—Å–ª–æ–≤—ã–µ</td></tr>
      <tr><td><strong>–í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è</strong></td><td>–ö–æ–º–±–∏–Ω–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</td></tr>
      <tr><td><strong>–ê–≥—Ä–µ–≥–∞—Ü–∏–∏</strong></td><td>–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏</td></tr>
      <tr><td><strong>–í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏</strong></td><td>–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑ –¥–∞—Ç</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 3. –ß–∏—Å–ª–µ–Ω–Ω—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è</h2>
    <pre><code>import numpy as np
import pandas as pd

df = pd.DataFrame({'value': [1, 10, 100, 1000]})

# –õ–æ–≥–∞—Ä–∏—Ñ–º (–¥–ª—è —Å–∫–æ—à–µ–Ω–Ω—ã—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π)
df['log_value'] = np.log1p(df['value'])

# –ö–≤–∞–¥—Ä–∞—Ç–Ω—ã–π –∫–æ—Ä–µ–Ω—å
df['sqrt_value'] = np.sqrt(df['value'])

# –°—Ç–µ–ø–µ–Ω—å
df['squared'] = df['value'] ** 2

# –û–±—Ä–∞—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
df['inverse'] = 1 / (df['value'] + 1)

# Box-Cox (–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è)
from scipy.stats import boxcox
df['boxcox'], lambda_param = boxcox(df['value'])</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. –ë–∏–Ω–Ω–∏–Ω–≥ (–¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏—è)</h2>
    <pre><code>import pandas as pd

df = pd.DataFrame({'age': [5, 15, 25, 35, 45, 55, 65]})

# –†–∞–≤–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
df['age_binned'] = pd.cut(
    df['age'], 
    bins=3, 
    labels=['young', 'middle', 'old']
)

# –†–∞–≤–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤ –∫–∞–∂–¥–æ–º –±–∏–Ω–µ
df['age_qbinned'] = pd.qcut(
    df['age'], 
    q=3, 
    labels=['Q1', 'Q2', 'Q3']
)

# –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –≥—Ä–∞–Ω–∏—Ü—ã
df['age_custom'] = pd.cut(
    df['age'], 
    bins=[0, 18, 40, 100],
    labels=['child', 'adult', 'senior']
)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. One-Hot Encoding</h2>
    <pre><code>import pandas as pd

df = pd.DataFrame({
    'color': ['red', 'blue', 'green', 'red']
})

# pandas get_dummies
encoded = pd.get_dummies(df, columns=['color'])

# sklearn OneHotEncoder
from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(sparse_output=False)
encoded = encoder.fit_transform(df[['color']])

# –ü–æ–ª—É—á–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
feature_names = encoder.get_feature_names_out(['color'])

# –ò–∑–±–µ–∂–∞—Ç—å dummy variable trap
encoded_df = pd.get_dummies(df, columns=['color'], 
                            drop_first=True)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. Label Encoding</h2>
    <pre><code>from sklearn.preprocessing import LabelEncoder

df = pd.DataFrame({
    'size': ['S', 'M', 'L', 'XL', 'M']
})

# LabelEncoder
le = LabelEncoder()
df['size_encoded'] = le.fit_transform(df['size'])
# Result: [2, 1, 0, 3, 1]

# –û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
original = le.inverse_transform(df['size_encoded'])

# –ü–æ—Ä—è–¥–∫–æ–≤–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ (ordinal)
from sklearn.preprocessing import OrdinalEncoder

oe = OrdinalEncoder(categories=[['S', 'M', 'L', 'XL']])
df['size_ordinal'] = oe.fit_transform(df[['size']])
# Result: [0, 1, 2, 3, 1] - —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ—Ä—è–¥–æ–∫!</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. Target Encoding</h2>
    <pre><code>import pandas as pd

df = pd.DataFrame({
    'category': ['A', 'B', 'A', 'C', 'B', 'A'],
    'target': [1, 0, 1, 1, 0, 0]
})

# –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ target –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
target_mean = df.groupby('category')['target'].mean()
df['category_encoded'] = df['category'].map(target_mean)

# –° —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π (smoothing)
def target_encode_smooth(df, col, target, alpha=5):
    global_mean = df[target].mean()
    agg = df.groupby(col)[target].agg(['mean', 'count'])
    
    # Smoothed mean
    smooth = (agg['mean'] * agg['count'] + 
              global_mean * alpha) / (agg['count'] + alpha)
    
    return df[col].map(smooth)

df['category_smooth'] = target_encode_smooth(
    df, 'category', 'target'
)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</h2>
    <pre><code>import pandas as pd
import numpy as np

df = pd.DataFrame({
    'x1': [1, 2, 3, 4],
    'x2': [2, 4, 6, 8]
})

# –£–º–Ω–æ–∂–µ–Ω–∏–µ
df['x1_x2'] = df['x1'] * df['x2']

# –î–µ–ª–µ–Ω–∏–µ
df['x1_div_x2'] = df['x1'] / (df['x2'] + 1e-8)

# –°–ª–æ–∂–µ–Ω–∏–µ
df['x1_plus_x2'] = df['x1'] + df['x2']

# –†–∞–∑–Ω–æ—Å—Ç—å
df['x1_minus_x2'] = df['x1'] - df['x2']

# –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
from sklearn.preprocessing import PolynomialFeatures

poly = PolynomialFeatures(degree=2, 
                          interaction_only=True,
                          include_bias=False)
interactions = poly.fit_transform(df[['x1', 'x2']])
print(poly.get_feature_names_out())</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏</h2>
    <pre><code>import pandas as pd

df = pd.DataFrame({
    'date': pd.date_range('2024-01-01', periods=365)
})

# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
df['year'] = df['date'].dt.year
df['month'] = df['date'].dt.month
df['day'] = df['date'].dt.day
df['dayofweek'] = df['date'].dt.dayofweek
df['quarter'] = df['date'].dt.quarter
df['week'] = df['date'].dt.isocalendar().week

# –í—ã—Ö–æ–¥–Ω—ã–µ
df['is_weekend'] = df['dayofweek'].isin([5, 6]).astype(int)

# –¶–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
df['day_sin'] = np.sin(2 * np.pi * df['day'] / 31)
df['day_cos'] = np.cos(2 * np.pi * df['day'] / 31)

# –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ª–∞–≥–∏
df['value'] = np.random.randn(365)
df['lag_1'] = df['value'].shift(1)
df['lag_7'] = df['value'].shift(7)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. –ê–≥—Ä–µ–≥–∞—Ü–∏–∏</h2>
    <pre><code>import pandas as pd

df = pd.DataFrame({
    'user_id': [1, 1, 1, 2, 2, 3],
    'amount': [100, 150, 200, 50, 75, 300],
    'category': ['A', 'B', 'A', 'A', 'B', 'C']
})

# –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
user_stats = df.groupby('user_id')['amount'].agg([
    ('total', 'sum'),
    ('mean', 'mean'),
    ('std', 'std'),
    ('count', 'count'),
    ('min', 'min'),
    ('max', 'max')
])

# –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
df = df.merge(user_stats, on='user_id', how='left')

# Rolling —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
df = df.sort_values('user_id')
df['rolling_mean_3'] = df.groupby('user_id')['amount'] \
                         .rolling(3, min_periods=1) \
                         .mean().reset_index(drop=True)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. –¢–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏</h2>
    <pre><code>import pandas as pd

df = pd.DataFrame({
    'text': ['Hello World', 'Python ML', 'Data Science!']
})

# –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞
df['text_length'] = df['text'].str.len()

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤
df['word_count'] = df['text'].str.split().str.len()

# –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ –≤ —Å–ª–æ–≤–µ
df['avg_word_len'] = df['text_length'] / df['word_count']

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≥–ª–∞–≤–Ω—ã—Ö –±—É–∫–≤
df['upper_count'] = df['text'].str.count(r'[A-Z]')

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏—Ñ—Ä
df['digit_count'] = df['text'].str.count(r'\d')

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
df['special_count'] = df['text'].str.count(r'[^a-zA-Z0-9\s]')

# TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer(max_features=100)
tfidf_features = tfidf.fit_transform(df['text'])</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 12. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π</h2>
    <pre><code>import pandas as pd
import numpy as np

df = pd.DataFrame({
    'age': [25, np.nan, 35, np.nan, 45],
    'income': [50000, 60000, np.nan, 70000, np.nan]
})

# –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø—Ä–æ–ø—É—Å–∫–∞
df['age_missing'] = df['age'].isna().astype(int)

# –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –º–µ–¥–∏–∞–Ω–æ–π
df['age_filled'] = df['age'].fillna(df['age'].median())

# –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–∏–º
df['income_filled'] = df['income'].fillna(df['income'].mean())

# Forward fill
df['age_ffill'] = df['age'].ffill()

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
from sklearn.impute import KNNImputer
imputer = KNNImputer(n_neighbors=2)
df_imputed = pd.DataFrame(
    imputer.fit_transform(df[['age', 'income']]),
    columns=['age', 'income']
)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 13. –í—ã–±—Ä–æ—Å—ã –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è</h2>
    <pre><code>import numpy as np
import pandas as pd

df = pd.DataFrame({'value': [1, 2, 3, 100, 4, 5, 200]})

# Winsorization (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤)
lower = df['value'].quantile(0.05)
upper = df['value'].quantile(0.95)
df['value_winsorized'] = df['value'].clip(lower, upper)

# Z-score —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
z_scores = np.abs((df['value'] - df['value'].mean()) / 
                   df['value'].std())
df['is_outlier'] = (z_scores > 3).astype(int)

# IQR –º–µ—Ç–æ–¥
Q1 = df['value'].quantile(0.25)
Q3 = df['value'].quantile(0.75)
IQR = Q3 - Q1
df['is_outlier_iqr'] = (
    (df['value'] < Q1 - 1.5*IQR) | 
    (df['value'] > Q3 + 1.5*IQR)
).astype(int)

# Robust–Ω—ã–π –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤—â–∏–∫
from sklearn.preprocessing import RobustScaler
scaler = RobustScaler()
df['value_robust'] = scaler.fit_transform(df[['value']])</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 14. –ß–∞—Å—Ç–æ—Ç–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ</h2>
    <pre><code>import pandas as pd

df = pd.DataFrame({
    'category': ['A', 'B', 'A', 'C', 'B', 'A', 'D']
})

# –ü–æ–¥—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç
freq_map = df['category'].value_counts()
df['category_freq'] = df['category'].map(freq_map)

# –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞
freq_norm = df['category'].value_counts(normalize=True)
df['category_freq_norm'] = df['category'].map(freq_norm)

# Rank (—Ä–∞–Ω–≥ –ø–æ —á–∞—Å—Ç–æ—Ç–µ)
freq_rank = df['category'].value_counts().rank(
    ascending=False
)
df['category_rank'] = df['category'].map(freq_rank)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 15. –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π</h2>
    <pre><code>import pandas as pd

df = pd.DataFrame({
    'city': ['Moscow', 'SPb', 'Moscow', 'Kazan', 
             'Moscow', 'SPb', 'Other'],
    'region': ['Central', 'Northwest', 'Central', 
               'Volga', 'Central', 'Northwest', 'South']
})

# –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–¥–∫–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
freq = df['city'].value_counts()
threshold = 2
df['city_grouped'] = df['city'].apply(
    lambda x: x if freq[x] >= threshold else 'Other'
)

# –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ—Å—Ç–∞–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
df['city_region'] = df['city'] + '_' + df['region']

# –•–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ (–¥–ª—è –º–Ω–æ–≥–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π)
from sklearn.feature_extraction import FeatureHasher
hasher = FeatureHasher(n_features=10, input_type='string')
hashed = hasher.transform(df['city'].values.reshape(-1, 1))</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 16. –ì–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏</h2>
    <pre><code>import numpy as np
import pandas as pd

df = pd.DataFrame({
    'lat': [55.75, 59.93, 51.51],
    'lon': [37.62, 30.36, -0.13]
})

# –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç —Ü–µ–Ω—Ç—Ä–∞
center_lat, center_lon = 55.75, 37.62

# Haversine —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
def haversine(lat1, lon1, lat2, lon2):
    R = 6371  # –†–∞–¥–∏—É—Å –ó–µ–º–ª–∏ –≤ –∫–º
    
    lat1, lon1, lat2, lon2 = map(np.radians, 
                                  [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    
    a = np.sin(dlat/2)**2 + np.cos(lat1) * \
        np.cos(lat2) * np.sin(dlon/2)**2
    c = 2 * np.arcsin(np.sqrt(a))
    
    return R * c

df['distance_to_center'] = haversine(
    df['lat'], df['lon'], center_lat, center_lon
)

# –°–µ—Ç–∫–∞ (grid)
df['lat_grid'] = (df['lat'] // 0.1).astype(int)
df['lon_grid'] = (df['lon'] // 0.1).astype(int)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 17. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π Feature Engineering</h2>
    <pre><code># Featuretools
import featuretools as ft
import pandas as pd

# –°–æ–∑–¥–∞–Ω–∏–µ EntitySet
es = ft.EntitySet(id='data')

df = pd.DataFrame({
    'id': [1, 2, 3, 4],
    'value': [10, 20, 30, 40],
    'category': ['A', 'B', 'A', 'B']
})

es = es.add_dataframe(
    dataframe_name='main',
    dataframe=df,
    index='id'
)

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
feature_matrix, feature_defs = ft.dfs(
    entityset=es,
    target_dataframe_name='main',
    max_depth=2
)

print(feature_matrix.columns)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 18. –ü—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–π</h2>
    <pre><code>import pandas as pd

df = pd.DataFrame({
    'total_price': [100, 200, 300],
    'quantity': [2, 5, 10],
    'area': [50, 100, 150]
})

# –¶–µ–Ω–∞ –∑–∞ –µ–¥–∏–Ω–∏—Ü—É
df['price_per_unit'] = df['total_price'] / df['quantity']

# –¶–µ–Ω–∞ –∑–∞ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–π –º–µ—Ç—Ä
df['price_per_sqm'] = df['total_price'] / df['area']

# –ü–ª–æ—Ç–Ω–æ—Å—Ç—å
df['density'] = df['quantity'] / df['area']

# –î–æ–ª—è –æ—Ç –º–∞–∫—Å–∏–º—É–º–∞
df['price_ratio'] = df['total_price'] / df['total_price'].max()

# –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ
df['price_deviation'] = (df['total_price'] - 
                          df['total_price'].mean())

# –ü—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å
df['price_percentile'] = df['total_price'].rank(pct=True)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 19. –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è Feature Engineering</h2>
    <pre><code>from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
import pandas as pd

# –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å
base_score = cross_val_score(
    RandomForestClassifier(random_state=42),
    X_base, y, cv=5, scoring='accuracy'
).mean()

# –° –Ω–æ–≤—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
enhanced_score = cross_val_score(
    RandomForestClassifier(random_state=42),
    X_enhanced, y, cv=5, scoring='accuracy'
).mean()

print(f"Base accuracy: {base_score:.4f}")
print(f"Enhanced accuracy: {enhanced_score:.4f}")
print(f"Improvement: {enhanced_score - base_score:.4f}")

# –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
rf = RandomForestClassifier(random_state=42)
rf.fit(X_enhanced, y)
importance = pd.DataFrame({
    'feature': X_enhanced.columns,
    'importance': rf.feature_importances_
}).sort_values('importance', ascending=False)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 20. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –î–µ–ª–∞—Ç—å</h3>
        <p>‚Ä¢ –ù–∞—á–∏–Ω–∞—Ç—å —Å –ø—Ä–æ—Å—Ç—ã—Ö –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π<br>
        ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–Ω–∞–Ω–∏—è –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏<br>
        ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—è—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤<br>
        ‚Ä¢ –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏<br>
        ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é</p>
      </div>
      <div class="bad">
        <h3>‚ùå –ù–µ –¥–µ–ª–∞—Ç—å</h3>
        <p>‚Ä¢ –°–æ–∑–¥–∞–≤–∞—Ç—å —Å–æ—Ç–Ω–∏ —Å–ª—É—á–∞–π–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤<br>
        ‚Ä¢ –ó–∞–±—ã–≤–∞—Ç—å –ø—Ä–æ —É—Ç–µ—á–∫—É –¥–∞–Ω–Ω—ã—Ö (data leakage)<br>
        ‚Ä¢ –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤<br>
        ‚Ä¢ –ü—Ä–∏–º–µ–Ω—è—Ç—å —Å–ª–æ–∂–Ω—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –±–µ–∑ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è<br>
        ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å target encoding –±–µ–∑ CV</p>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 21. –¢–∏–ø–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏</h2>
    <table>
      <tr><th>–û—à–∏–±–∫–∞</th><th>–†–µ—à–µ–Ω–∏–µ</th></tr>
      <tr><td>Data leakage</td><td>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Pipeline –∏ CV</td></tr>
      <tr><td>–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</td><td>Feature selection</td></tr>
      <tr><td>–ú—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å</td><td>–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏</td></tr>
      <tr><td>–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ</td><td>–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –∏ CV</td></tr>
      <tr><td>–ù–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å</td><td>StandardScaler –ø–æ—Å–ª–µ FE</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 22. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ data leakage</h2>
    <pre><code>from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# ‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û - leakage!
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2
)

# ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û - –±–µ–∑ leakage
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2
)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ‚úÖ –ï–©–ï –õ–£–ß–®–ï - Pipeline
from sklearn.pipeline import Pipeline

pipeline = Pipeline([
    ('feature_eng', CustomTransformer()),
    ('scaler', StandardScaler()),
    ('model', RandomForestClassifier())
])

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑–±–µ–≥–∞–µ—Ç leakage!
pipeline.fit(X_train, y_train)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 23. –†–µ—Å—É—Ä—Å—ã</h2>
    <ul>
      <li><strong>–ö–Ω–∏–≥–∞</strong>: "Feature Engineering for Machine Learning"</li>
      <li><strong>Kaggle</strong>: Feature Engineering tutorials</li>
      <li><strong>–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞</strong>: Featuretools –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏</li>
      <li><strong>–°—Ç–∞—Ç—å—è</strong>: "Feature Engineering Techniques" –Ω–∞ Medium</li>
      <li><strong>–ö—É—Ä—Å</strong>: Fast.ai - Practical Deep Learning</li>
    </ul>
  </div>



</div>
</body>
</html>
