<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>–ù–∞–∏–≤–Ω—ã–π –ë–∞–π–µ—Å (–∫–∞–∫ –±–∞–π–µ—Å–æ–≤—Å–∫–∏–π –º–µ—Ç–æ–¥) Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      
        min-width: 900px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

        .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.88em;
      margin: 6px 0;
    }

    th, td {
      padding: 6px 8px;
      text-align: left;
      border: 1px solid #e0e7ff;
    }

    th {
      background-color: #1a5fb4;
      color: white;
      font-weight: 700;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üìö –ù–∞–∏–≤–Ω—ã–π –ë–∞–π–µ—Å (–∫–∞–∫ –±–∞–π–µ—Å–æ–≤—Å–∫–∏–π –º–µ—Ç–æ–¥)</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –°—É—Ç—å –±–∞–π–µ—Å–æ–≤—Å–∫–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞</h2>
    <p><strong>–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ beliefs –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π: P(Œ∏|D) ‚àù P(D|Œ∏)P(Œ∏)</strong></p>
    <ul>
      <li><strong>–ê–ø—Ä–∏–æ—Ä–Ω–æ–µ –∑–Ω–∞–Ω–∏–µ</strong>: –Ω–∞—á–∏–Ω–∞–µ–º —Å –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏—è P(Œ∏) –æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö</li>
      <li><strong>–ù–∞–±–ª—é–¥–µ–Ω–∏—è</strong>: –ø–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ D –∏ –≤—ã—á–∏—Å–ª—è–µ–º likelihood P(D|Œ∏)</li>
      <li><strong>–ê–ø–æ—Å—Ç–µ—Ä–∏–æ—Ä–Ω–æ–µ</strong>: –æ–±–Ω–æ–≤–ª—è–µ–º belief —á–µ—Ä–µ–∑ P(Œ∏|D)</li>
      <li><strong>–ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ—Å—Ç—å</strong>: –∫–∞–∂–¥–æ–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ —É–ª—É—á—à–∞–µ—Ç –æ—Ü–µ–Ω–∫—É</li>
      <li><strong>Uncertainty</strong>: –ø–æ–ª—É—á–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, –∞ –Ω–µ —Ç–æ—á–µ—á–Ω—É—é –æ—Ü–µ–Ω–∫—É</li>
    </ul>
    <blockquote>
      üí° –ë–∞–π–µ—Å–æ–≤—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ñ–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–Ω–∞–Ω–∏–π –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 2. –¢–µ–æ—Ä–µ–º–∞ –ë–∞–π–µ—Å–∞</h2>
    <p><strong>P(A|B) = P(B|A)P(A)/P(B)</strong></p>
    <ul>
      <li><strong>P(A|B)</strong> ‚Äî –∞–ø–æ—Å—Ç–µ—Ä–∏–æ—Ä–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å (posterior)</li>
      <li><strong>P(B|A)</strong> ‚Äî –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏–µ (likelihood)</li>
      <li><strong>P(A)</strong> ‚Äî –∞–ø—Ä–∏–æ—Ä–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å (prior)</li>
      <li><strong>P(B)</strong> ‚Äî –Ω–æ—Ä–º–∞–ª–∏–∑—É—é—â–∞—è –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞ (evidence)</li>
      <li><strong>–§–æ—Ä–º—É–ª–∞</strong>: –ø–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞–µ—Ç —É—Å–ª–æ–≤–Ω—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å</li>
      <li><strong>–î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏</strong>: P(–∫–ª–∞—Å—Å|–ø—Ä–∏–∑–Ω–∞–∫–∏) ‚àù P(–ø—Ä–∏–∑–Ω–∞–∫–∏|–∫–ª–∞—Å—Å)P(–∫–ª–∞—Å—Å)</li>
    </ul>
    <blockquote>
      üí° –¢–µ–æ—Ä–µ–º–∞ –ë–∞–π–µ—Å–∞ ‚Äî –æ—Å–Ω–æ–≤–∞ –≤—Å–µ—Ö –±–∞–π–µ—Å–æ–≤—Å–∫–∏—Ö –º–µ—Ç–æ–¥–æ–≤ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 3. –ù–∞–∏–≤–Ω—ã–π –ë–∞–π–µ—Å –∫–∞–∫ –±–∞–π–µ—Å–æ–≤—Å–∫–∏–π –º–µ—Ç–æ–¥</h2>
    <p><strong>MAP –æ—Ü–µ–Ω–∫–∞ —Å –Ω–∞–∏–≤–Ω—ã–º –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ–º –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</strong></p>
    <ul>
      <li><strong>MAP</strong>: Maximum A Posteriori ‚Äî –∏—â–µ–º –∫–ª–∞—Å—Å —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π P(y|X)</li>
      <li><strong>Naive assumption</strong>: –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã ‚Üí P(X|y) = ‚àèP(x·µ¢|y)</li>
      <li><strong>Prior P(y)</strong>: —á–∞—Å—Ç–æ—Ç–∞ –∫–ª–∞—Å—Å–æ–≤ –≤ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ</li>
      <li><strong>Likelihood P(X|y)</strong>: –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ P(x·µ¢|y) –¥–ª—è –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</li>
      <li><strong>–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ</strong>: ≈∑ = argmax_y P(y)‚àèP(x·µ¢|y)</li>
      <li><strong>–ü—Ä–æ—Å—Ç–æ—Ç–∞</strong>: –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —É–ø—Ä–æ—â–∞–µ—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∏—è</li>
    </ul>
    <blockquote>
      üí° "–ù–∞–∏–≤–Ω–æ–µ" –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–∫–ª—è—Ç–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ P(X|y)
    </blockquote>
    <pre><code>from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ Naive Bayes
nb = GaussianNB()
nb.fit(X_train, y_train)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ (MAP estimate)
y_pred = nb.predict(X_test)

# –ê–ø–æ—Å—Ç–µ—Ä–∏–æ—Ä–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ P(y|X)
y_proba = nb.predict_proba(X_test)

# –û—Ü–µ–Ω–∫–∞
print(f"Accuracy: {accuracy_score(y_test, y_pred):.3f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. Prior, Likelihood, Posterior</h2>
    <p><strong>–ê–ø—Ä–∏–æ—Ä–Ω–æ–µ, –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏–µ, –∞–ø–æ—Å—Ç–µ—Ä–∏–æ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ</strong></p>
    <ul>
      <li><strong>Prior P(y)</strong>: —á–∞—Å—Ç–æ—Ç–∞ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –≤ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö</li>
      <li><strong>Likelihood P(X|y)</strong>: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–∞–±–ª—é–¥–∞—Ç—å X –¥–ª—è –∫–ª–∞—Å—Å–∞ y</li>
      <li><strong>Posterior P(y|X)</strong>: –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞ –ø–æ—Å–ª–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è X</li>
      <li><strong>Evidence P(X)</strong>: –Ω–æ—Ä–º–∞–ª–∏–∑—É—é—â–∏–π –º–Ω–æ–∂–∏—Ç–µ–ª—å, –æ–¥–∏–Ω–∞–∫–æ–≤ –¥–ª—è –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤</li>
      <li><strong>–í Naive Bayes</strong>: prior –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç—Å—è –∏–∑ –¥–∞–Ω–Ω—ã—Ö, likelihood —á–µ—Ä–µ–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è</li>
      <li><strong>–î–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è</strong>: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–∏—Ç–µ–ª—å P(X|y)P(y)</li>
    </ul>
    <blockquote>
      üí° Prior –º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å —è–≤–Ω–æ —á–µ—Ä–µ–∑ class_prior –≤ sklearn, –µ—Å–ª–∏ –µ—Å—Ç—å —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–µ –∑–Ω–∞–Ω–∏—è
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 5. –¢–∏–ø—ã Naive Bayes</h2>
    <p><strong>Gaussian NB, Multinomial NB, Bernoulli NB</strong></p>
    <ul>
      <li><strong>GaussianNB</strong>: –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ</li>
      <li><strong>MultinomialNB</strong>: –¥–ª—è –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö —á–∞—Å—Ç–æ—Ç (—Ç–µ–∫—Å—Ç, bag-of-words)</li>
      <li><strong>BernoulliNB</strong>: –¥–ª—è –±–∏–Ω–∞—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–µ—Å—Ç—å/–Ω–µ—Ç —Å–ª–æ–≤–∞ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ)</li>
      <li><strong>ComplementNB</strong>: –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤</li>
      <li><strong>CategoricalNB</strong>: –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–Ω–æ–≤–æ–µ –≤ sklearn)</li>
      <li><strong>–í—ã–±–æ—Ä —Ç–∏–ø–∞</strong>: –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –ø—Ä–∏—Ä–æ–¥—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –Ω–µ –æ—Ç –∑–∞–¥–∞—á–∏</li>
    </ul>
    <blockquote>
      üí° GaussianNB –≤—ã—á–∏—Å–ª—è–µ—Ç —Å—Ä–µ–¥–Ω–µ–µ Œº –∏ –¥–∏—Å–ø–µ—Ä—Å–∏—é œÉ¬≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ –≤ –∫–∞–∂–¥–æ–º –∫–ª–∞—Å—Å–µ
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 6. –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ (smoothing)</h2>
    <p><strong>Laplace smoothing, Lidstone smoothing</strong></p>
    <ul>
      <li><strong>–ü—Ä–æ–±–ª–µ–º–∞ –Ω—É–ª–µ–π</strong>: –µ—Å–ª–∏ P(x·µ¢|y) = 0, —Ç–æ –≤–µ—Å—å posterior = 0</li>
      <li><strong>Laplace (alpha=1)</strong>: –¥–æ–±–∞–≤–ª—è–µ—Ç 1 –∫ –∫–∞–∂–¥–æ–º—É —Å—á–µ—Ç—á–∏–∫—É</li>
      <li><strong>Lidstone (alpha‚â†1)</strong>: –¥–æ–±–∞–≤–ª—è–µ—Ç alpha –∫ –∫–∞–∂–¥–æ–º—É —Å—á–µ—Ç—á–∏–∫—É</li>
      <li><strong>–í sklearn</strong>: –ø–∞—Ä–∞–º–µ—Ç—Ä alpha –≤ MultinomialNB –∏ BernoulliNB</li>
      <li><strong>–≠—Ñ—Ñ–µ–∫—Ç</strong>: –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –æ–±–Ω—É–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –Ω–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏—è—Ö</li>
      <li><strong>–ù–∞—Å—Ç—Ä–æ–π–∫–∞</strong>: alpha –º–æ–∂–Ω–æ –ø–æ–¥–æ–±—Ä–∞—Ç—å —á–µ—Ä–µ–∑ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é</li>
    </ul>
    <blockquote>
      üí° –ë–µ–∑ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è –Ω–æ–≤–æ–µ —Å–ª–æ–≤–æ –≤ —Ç–µ—Å—Ç–æ–≤–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ –æ–±–Ω—É–ª–∏—Ç –≤—Å—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞
    </blockquote>
    <pre><code>from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import CountVectorizer

# –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
vectorizer = CountVectorizer()
X_train_counts = vectorizer.fit_transform(texts_train)
X_test_counts = vectorizer.transform(texts_test)

# Naive Bayes —Å Laplace smoothing
nb = MultinomialNB(alpha=1.0)  # alpha=1 ‚Üí Laplace
nb.fit(X_train_counts, y_train)

# –ü–æ–ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ alpha
for alpha in [0.01, 0.1, 1.0, 10.0]:
    nb = MultinomialNB(alpha=alpha)
    nb.fit(X_train_counts, y_train)
    score = nb.score(X_test_counts, y_test)
    print(f"Alpha={alpha}: {score:.3f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. –ë–∞–π–µ—Å–æ–≤—Å–∫–∏–π –≤—ã–≤–æ–¥</h2>
    <p><strong>–û—Ç —Ç–æ—á–µ—á–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫ –∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è–º</strong></p>
    <ul>
      <li><strong>–¢–æ—á–µ—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞</strong>: Naive Bayes –¥–∞–µ—Ç MAP (–æ–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ)</li>
      <li><strong>–ü–æ–ª–Ω—ã–π –±–∞–π–µ—Å–æ–≤—Å–∫–∏–π</strong>: –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç –ø–æ –≤—Å–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º</li>
      <li><strong>Posterior predictive</strong>: P(y_new|X_new, D) = ‚à´P(y_new|X_new,Œ∏)P(Œ∏|D)dŒ∏</li>
      <li><strong>Uncertainty</strong>: –ø–æ–ª–Ω—ã–π –±–∞–π–µ—Å–æ–≤—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥ –¥–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏</li>
      <li><strong>Naive Bayes —É–ø—Ä–æ—â–µ–Ω–∏–µ</strong>: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ—á–µ—á–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</li>
      <li><strong>–î–ª—è –ø–æ–ª–Ω–æ–≥–æ</strong>: –Ω—É–∂–Ω—ã –º–µ—Ç–æ–¥—ã —Ç–∏–ø–∞ MCMC (PyMC, Stan)</li>
    </ul>
    <blockquote>
      üí° Naive Bayes –≤ sklearn ‚Äî —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –±–∞–π–µ—Å–æ–≤—Å–∫–∏–π –º–µ—Ç–æ–¥, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–æ–ª–Ω—ã–π –±–∞–π–µ—Å–æ–≤—Å–∫–∏–π –≤—ã–≤–æ–¥
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 8. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å MLE</h2>
    <p><strong>Maximum Likelihood vs Maximum A Posteriori</strong></p>
    <ul>
      <li><strong>MLE</strong>: Œ∏_MLE = argmax_Œ∏ P(D|Œ∏) ‚Äî –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç prior</li>
      <li><strong>MAP</strong>: Œ∏_MAP = argmax_Œ∏ P(D|Œ∏)P(Œ∏) ‚Äî —É—á–∏—Ç—ã–≤–∞–µ—Ç prior</li>
      <li><strong>Naive Bayes</strong>: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç MAP –¥–ª—è –≤—ã–±–æ—Ä–∞ –∫–ª–∞—Å—Å–∞</li>
      <li><strong>Prior —ç—Ñ—Ñ–µ–∫—Ç</strong>: MAP –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ—Ç –±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã–µ –∞–ø—Ä–∏–æ—Ä–∏ –∫–ª–∞—Å—Å—ã</li>
      <li><strong>–ú–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö</strong>: –ø—Ä–∏ –±–æ–ª—å—à–æ–º D, MAP ‚âà MLE (prior –º–µ–Ω–µ–µ –≤–∞–∂–µ–Ω)</li>
      <li><strong>–ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö</strong>: MAP –ª—É—á—à–µ, —Ç–∞–∫ –∫–∞–∫ prior —Ä–µ–≥—É–ª—è—Ä–∏–∑—É–µ—Ç</li>
    </ul>
    <blockquote>
      üí° –ü–∞—Ä–∞–º–µ—Ç—Ä class_prior –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–¥–∞—Ç—å —Å–≤–æ–π prior –≤–º–µ—Å—Ç–æ —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏—Ö —á–∞—Å—Ç–æ—Ç
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 9. Conjugate priors</h2>
    <p><strong>–°–æ–ø—Ä—è–∂–µ–Ω–Ω—ã–µ –∞–ø—Ä–∏–æ—Ä–Ω—ã–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è</strong></p>
    <ul>
      <li><strong>–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ</strong>: prior –∏ posterior –∏–∑ –æ–¥–Ω–æ–≥–æ —Å–µ–º–µ–π—Å—Ç–≤–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π</li>
      <li><strong>Gaussian-Gaussian</strong>: prior Gaussian + Gaussian likelihood ‚Üí posterior Gaussian</li>
      <li><strong>Beta-Bernoulli</strong>: Beta prior + Bernoulli likelihood ‚Üí Beta posterior</li>
      <li><strong>Dirichlet-Multinomial</strong>: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ MultinomialNB</li>
      <li><strong>–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ</strong>: –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–µ —Ä–µ—à–µ–Ω–∏–µ, –Ω–µ –Ω—É–∂–Ω–æ —á–∏—Å–ª–µ–Ω–Ω–æ–µ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ</li>
      <li><strong>–í Naive Bayes</strong>: –≤—ã–±–æ—Ä —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —á–∞—Å—Ç–æ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ conjugacy</li>
    </ul>
    <blockquote>
      üí° Conjugate priors –ø–æ–∑–≤–æ–ª—è—é—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –æ–±–Ω–æ–≤–ª—è—Ç—å beliefs –ø—Ä–∏ –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–∏ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    </blockquote>
    <pre><code>from sklearn.naive_bayes import GaussianNB
import numpy as np

# GaussianNB –∏—Å–ø–æ–ª—å–∑—É–µ—Ç conjugate prior –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
nb = GaussianNB(
    priors=None,       # –µ—Å–ª–∏ None, –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç—Å—è –∏–∑ –¥–∞–Ω–Ω—ã—Ö
    var_smoothing=1e-9 # —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –¥–∏—Å–ø–µ—Ä—Å–∏–∏
)

nb.fit(X_train, y_train)

# –ò–∑—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (MLE –æ—Ü–µ–Ω–∫–∏)
print("–°—Ä–µ–¥–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞:")
print(nb.theta_)  # Œº –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ –≤ –∫–∞–∂–¥–æ–º –∫–ª–∞—Å—Å–µ

print("\n–î–∏—Å–ø–µ—Ä—Å–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞:")
print(nb.var_)    # œÉ¬≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ –≤ –∫–∞–∂–¥–æ–º –∫–ª–∞—Å—Å–µ

print("\n–ê–ø—Ä–∏–æ—Ä–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤:")
print(nb.class_prior_)  # P(y)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã</h2>
    <p><strong>Spam filtering, document classification</strong></p>
    <ul>
      <li><strong>Spam filtering</strong>: –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è MultinomialNB</li>
      <li><strong>Sentiment analysis</strong>: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ/–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ</li>
      <li><strong>News categorization</strong>: —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π –ø–æ —Ç–µ–º–∞–º</li>
      <li><strong>Medical diagnosis</strong>: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∏–º–ø—Ç–æ–º–æ–≤ (GaussianNB)</li>
      <li><strong>Real-time classification</strong>: –±—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ</li>
      <li><strong>Baseline –º–æ–¥–µ–ª—å</strong>: —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ –±—ã—Å—Ç—Ä—ã–π –±–µ–π–∑–ª–∞–π–Ω</li>
    </ul>
    <blockquote>
      üí° Naive Bayes –±—ã–ª –æ–¥–Ω–∏–º –∏–∑ –ø–µ—Ä–≤—ã—Ö —É—Å–ø–µ—à–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å–ø–∞–º–∞ –≤ 90-—Ö
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 11. –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –±–∞–π–µ—Å–æ–≤—Å–∫–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞</h2>
    <p><strong>Uncertainty quantification, prior knowledge</strong></p>
    <ul>
      <li><strong>Prior knowledge</strong>: –º–æ–∂–Ω–æ –≤–∫–ª—é—á–∏—Ç—å —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–µ –∑–Ω–∞–Ω–∏–µ —á–µ—Ä–µ–∑ prior</li>
      <li><strong>–ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö</strong>: —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–∞–∂–µ –ø—Ä–∏ –º–∞–ª–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤</li>
      <li><strong>Probabilistic output</strong>: predict_proba –¥–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏, –Ω–µ –ø—Ä–æ—Å—Ç–æ –∫–ª–∞—Å—Å</li>
      <li><strong>Online learning</strong>: –ª–µ–≥–∫–æ –æ–±–Ω–æ–≤–ª—è—Ç—å –º–æ–¥–µ–ª—å –ø—Ä–∏ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö</li>
      <li><strong>–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å</strong>: –º–æ–∂–Ω–æ –ø–æ–Ω—è—Ç—å, –ø–æ—á–µ–º—É –º–æ–¥–µ–ª—å –≤—ã–±—Ä–∞–ª–∞ –∫–ª–∞—Å—Å</li>
      <li><strong>Theoretical foundation</strong>: —Å—Ç—Ä–æ–≥–∞—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Å–Ω–æ–≤–∞</li>
    </ul>
    <blockquote>
      üí° Naive Bayes –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å partial_fit() –¥–ª—è –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    </blockquote>
  </div>

</div>

  <div class="block">
    <h2>üî∑ 12. –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è</h2>
    <p><strong>–ù–∞–∏–≤–Ω–æ–µ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏, –≤—ã–±–æ—Ä prior</strong></p>
    <ul>
      <li><strong>–ù–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</strong>: —Ä–µ–¥–∫–æ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ</li>
      <li><strong>–ö–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏</strong>: –ø–µ—Ä–µ–æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –≤–ª–∏—è–Ω–∏–µ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</li>
      <li><strong>Zero frequency</strong>: –Ω—É–∂–Ω–æ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –¥–ª—è –Ω–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π</li>
      <li><strong>Continuous features</strong>: GaussianNB –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å</li>
      <li><strong>Prior sensitivity</strong>: –º–æ–∂–µ—Ç –±—ã—Ç—å —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ –≤—ã–±–æ—Ä—É prior –ø—Ä–∏ –º–∞–ª—ã—Ö –¥–∞–Ω–Ω—ã—Ö</li>
      <li><strong>–ù–µ –ª—É—á—à–∏–π –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á</strong>: —É—Å—Ç—É–ø–∞–µ—Ç –¥–µ—Ä–µ–≤—å—è–º –∏ –Ω–µ–π—Ä–æ—Å–µ—Ç—è–º</li>
    </ul>
    <blockquote>
      üí° –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ "–Ω–∞–∏–≤–Ω–æ—Å—Ç—å", —á–∞—Å—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —É–¥–∏–≤–∏—Ç–µ–ª—å–Ω–æ —Ö–æ—Ä–æ—à–æ –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö
    </blockquote>
    <pre><code>from sklearn.naive_bayes import GaussianNB, MultinomialNB
from sklearn.datasets import make_classification
from sklearn.model_selection import cross_val_score

# –ü—Ä–∏–º–µ—Ä —Å —Ä–∞–∑–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ Naive Bayes
X, y = make_classification(n_samples=1000, n_features=20, 
                          n_informative=15, random_state=42)

# –ü–æ–ø—Ä–æ–±—É–µ–º GaussianNB
gnb = GaussianNB()
scores_gnb = cross_val_score(gnb, X, y, cv=5)
print(f"GaussianNB: {scores_gnb.mean():.3f} ¬± {scores_gnb.std():.3f}")

# –ó–∞–¥–∞—Ç—å —Å–≤–æ–π prior –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤
gnb_custom = GaussianNB(priors=[0.3, 0.7])
gnb_custom.fit(X, y)

# Incremental learning
gnb_incremental = GaussianNB()
for i in range(0, len(X), 100):
    gnb_incremental.partial_fit(X[i:i+100], y[i:i+100], 
                                 classes=np.unique(y))</code></pre>
  </div>

</body>
</html>
