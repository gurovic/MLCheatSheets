<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>–ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ –±—É—Å—Ç–∏–Ω–≥–∞ Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      
        min-width: 900px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

        .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üéõÔ∏è –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ –±—É—Å—Ç–∏–Ω–≥–∞</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã</h2>
    <ul>
      <li><strong>n_estimators</strong>: —á–∏—Å–ª–æ –¥–µ—Ä–µ–≤—å–µ–≤</li>
      <li><strong>learning_rate</strong>: —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (0.01-0.3)</li>
      <li><strong>max_depth</strong>: –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤—å–µ–≤</li>
      <li><strong>subsample</strong>: –¥–æ–ª—è –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –¥–µ—Ä–µ–≤–∞</li>
      <li><strong>colsample_bytree</strong>: –¥–æ–ª—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</li>
    </ul>
    <p><strong>–ü—Ä–∞–≤–∏–ª–æ</strong>: –º–∞–ª–µ–Ω—å–∫–∏–π learning_rate ‚Üí –±–æ–ª—å—à–µ n_estimators</p>

    </div>
<div class="block">
    <h2>üî∑ 2. XGBoost –ø–∞—Ä–∞–º–µ—Ç—Ä—ã</h2>
    <table>
      <tr><th>–ü–∞—Ä–∞–º–µ—Ç—Ä</th><th>–î–∏–∞–ø–∞–∑–æ–Ω</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th></tr>
      <tr><td><code>n_estimators</code></td><td>100-1000</td><td>–ß–∏—Å–ª–æ –¥–µ—Ä–µ–≤—å–µ–≤</td></tr>
      <tr><td><code>learning_rate</code></td><td>0.01-0.3</td><td>Œ∑ (eta)</td></tr>
      <tr><td><code>max_depth</code></td><td>3-10</td><td>–ì–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞</td></tr>
      <tr><td><code>subsample</code></td><td>0.5-1.0</td><td>–°–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–æ–∫</td></tr>
      <tr><td><code>colsample_bytree</code></td><td>0.5-1.0</td><td>–°–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</td></tr>
      <tr><td><code>gamma</code></td><td>0-5</td><td>–ú–∏–Ω. –ø–æ—Ç–µ—Ä—è –¥–ª—è split</td></tr>
      <tr><td><code>min_child_weight</code></td><td>1-10</td><td>–ú–∏–Ω. –≤–µ—Å –≤ –ª–∏—Å—Ç–µ</td></tr>
      <tr><td><code>reg_alpha</code></td><td>0-1</td><td>L1 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è</td></tr>
      <tr><td><code>reg_lambda</code></td><td>0-10</td><td>L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 3. XGBoost –±–∞–∑–æ–≤—ã–π</h2>
    <pre><code>import xgboost as xgb
from sklearn.model_selection import train_test_split

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å
model = xgb.XGBClassifier(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=5,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)

model.fit(X_train, y_train)

# –û—Ü–µ–Ω–∫–∞
train_score = model.score(X_train, y_train)
test_score = model.score(X_test, y_test)

print(f"Train: {train_score:.4f}")
print(f"Test: {test_score:.4f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. LightGBM –ø–∞—Ä–∞–º–µ—Ç—Ä—ã</h2>
    <table>
      <tr><th>–ü–∞—Ä–∞–º–µ—Ç—Ä</th><th>–î–∏–∞–ø–∞–∑–æ–Ω</th><th>–û—Ç–ª–∏—á–∏—è –æ—Ç XGBoost</th></tr>
      <tr><td><code>num_leaves</code></td><td>31-255</td><td>–í–º–µ—Å—Ç–æ max_depth</td></tr>
      <tr><td><code>learning_rate</code></td><td>0.01-0.3</td><td>-</td></tr>
      <tr><td><code>n_estimators</code></td><td>100-1000</td><td>-</td></tr>
      <tr><td><code>min_child_samples</code></td><td>20-100</td><td>–ú–∏–Ω. –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –ª–∏—Å—Ç–µ</td></tr>
      <tr><td><code>feature_fraction</code></td><td>0.5-1.0</td><td>=colsample_bytree</td></tr>
      <tr><td><code>bagging_fraction</code></td><td>0.5-1.0</td><td>=subsample</td></tr>
      <tr><td><code>reg_alpha</code></td><td>0-1</td><td>L1 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è</td></tr>
      <tr><td><code>reg_lambda</code></td><td>0-10</td><td>L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 5. LightGBM –±–∞–∑–æ–≤—ã–π</h2>
    <pre><code>import lightgbm as lgb

# DMatrix —Ñ–æ—Ä–º–∞—Ç
train_data = lgb.Dataset(X_train, label=y_train)
test_data = lgb.Dataset(X_test, label=y_test, 
                       reference=train_data)

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
params = {
    'objective': 'binary',
    'metric': 'auc',
    'num_leaves': 31,
    'learning_rate': 0.05,
    'feature_fraction': 0.9,
    'bagging_fraction': 0.8,
    'bagging_freq': 5,
    'verbose': 0
}

# –û–±—É—á–µ–Ω–∏–µ
model = lgb.train(
    params,
    train_data,
    num_boost_round=100,
    valid_sets=[test_data],
    early_stopping_rounds=10
)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
y_pred = model.predict(X_test)

# –° sklearn API
lgb_clf = lgb.LGBMClassifier(
    num_leaves=31,
    learning_rate=0.05,
    n_estimators=100
)
lgb_clf.fit(X_train, y_train)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. CatBoost –ø–∞—Ä–∞–º–µ—Ç—Ä—ã</h2>
    <table>
      <tr><th>–ü–∞—Ä–∞–º–µ—Ç—Ä</th><th>–î–∏–∞–ø–∞–∑–æ–Ω</th><th>–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å</th></tr>
      <tr><td><code>iterations</code></td><td>100-1000</td><td>=n_estimators</td></tr>
      <tr><td><code>learning_rate</code></td><td>0.01-0.3</td><td>-</td></tr>
      <tr><td><code>depth</code></td><td>4-10</td><td>=max_depth</td></tr>
      <tr><td><code>l2_leaf_reg</code></td><td>1-10</td><td>L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è</td></tr>
      <tr><td><code>border_count</code></td><td>32-255</td><td>–ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</td></tr>
      <tr><td><code>bagging_temperature</code></td><td>0-1</td><td>Bayesian bootstrap</td></tr>
      <tr><td><code>random_strength</code></td><td>0-10</td><td>–°–ª—É—á–∞–π–Ω–æ—Å—Ç—å splits</td></tr>
    </table>
    <p><strong>–§–∏—à–∫–∞</strong>: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–∞–±–æ—Ç–∞ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º–∏</p>
  </div>

  <div class="block">
    <h2>üî∑ 7. CatBoost –±–∞–∑–æ–≤—ã–π</h2>
    <pre><code>from catboost import CatBoostClassifier, Pool

# –£–∫–∞–∑—ã–≤–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
cat_features = [0, 2]  # –∏–Ω–¥–µ–∫—Å—ã

# Pool –æ–±—ä–µ–∫—Ç
train_pool = Pool(X_train, y_train, 
                 cat_features=cat_features)
test_pool = Pool(X_test, y_test,
                cat_features=cat_features)

# –ú–æ–¥–µ–ª—å
model = CatBoostClassifier(
    iterations=100,
    learning_rate=0.1,
    depth=6,
    l2_leaf_reg=3,
    verbose=False
)

# –û–±—É—á–µ–Ω–∏–µ
model.fit(train_pool, eval_set=test_pool)

# Feature importance
feature_importance = model.get_feature_importance()
print(feature_importance)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. Grid Search</h2>
    <pre><code>from sklearn.model_selection import GridSearchCV

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞
param_grid = {
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.3],
    'n_estimators': [100, 300, 500],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0]
}

# XGBoost –º–æ–¥–µ–ª—å
xgb_model = xgb.XGBClassifier(random_state=42)

# Grid Search
grid_search = GridSearchCV(
    xgb_model,
    param_grid,
    cv=5,
    scoring='roc_auc',
    n_jobs=-1,
    verbose=1
)

grid_search.fit(X_train, y_train)

print(f"Best params: {grid_search.best_params_}")
print(f"Best score: {grid_search.best_score_:.4f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. Optuna –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</h2>
    <pre><code>import optuna

def objective(trial):
    param = {
        'max_depth': trial.suggest_int('max_depth', 3, 9),
        'learning_rate': trial.suggest_float('learning_rate', 
                                            0.01, 0.3, log=True),
        'n_estimators': trial.suggest_int('n_estimators', 
                                         50, 500),
        'min_child_weight': trial.suggest_int('min_child_weight', 
                                              1, 7),
        'gamma': trial.suggest_float('gamma', 0, 5),
        'subsample': trial.suggest_float('subsample', 0.5, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 
                                                0.5, 1.0),
        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),
        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10)
    }
    
    model = xgb.XGBClassifier(**param, random_state=42)
    model.fit(X_train, y_train)
    
    return model.score(X_test, y_test)

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=50)

print(f"Best trial: {study.best_trial.value:.4f}")
print(f"Best params: {study.best_params}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. Early Stopping</h2>
    <pre><code># XGBoost
model = xgb.XGBClassifier(
    n_estimators=1000,
    learning_rate=0.01,
    early_stopping_rounds=10
)

model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    verbose=False
)

print(f"Best iteration: {model.best_iteration}")

# LightGBM
evals_result = {}
lgb_model = lgb.train(
    params,
    train_data,
    num_boost_round=1000,
    valid_sets=[test_data],
    early_stopping_rounds=10,
    evals_result=evals_result
)

# CatBoost (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å eval_set)
cb_model = CatBoostClassifier(
    iterations=1000,
    learning_rate=0.01,
    early_stopping_rounds=10
)
cb_model.fit(train_pool, eval_set=test_pool)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏</h2>
    <p><strong>–ü–æ—ç—Ç–∞–ø–Ω—ã–π –ø–æ–¥—Ö–æ–¥:</strong></p>
    <ol>
      <li><strong>–®–∞–≥ 1</strong>: –§–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å learning_rate=0.1, –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å max_depth –∏ min_child_weight</li>
      <li><strong>–®–∞–≥ 2</strong>: –ù–∞—Å—Ç—Ä–æ–∏—Ç—å subsample –∏ colsample_bytree</li>
      <li><strong>–®–∞–≥ 3</strong>: –î–æ–±–∞–≤–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é (gamma, reg_alpha, reg_lambda)</li>
      <li><strong>–®–∞–≥ 4</strong>: –£–º–µ–Ω—å—à–∏—Ç—å learning_rate, —É–≤–µ–ª–∏—á–∏—Ç—å n_estimators</li>
      <li><strong>–®–∞–≥ 5</strong>: Fine-tuning —Å early stopping</li>
    </ol>
  </div>

  <div class="block">
    <h2>üî∑ 12. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π</h2>
    <table>
      <tr><th>–ê—Å–ø–µ–∫—Ç</th><th>XGBoost</th><th>LightGBM</th><th>CatBoost</th></tr>
      <tr><td>–°–∫–æ—Ä–æ—Å—Ç—å</td><td>–°—Ä–µ–¥–Ω—è—è</td><td>–ë—ã—Å—Ç—Ä–∞—è</td><td>–ú–µ–¥–ª–µ–Ω–Ω–∞—è</td></tr>
      <tr><td>–ü–∞–º—è—Ç—å</td><td>–°—Ä–µ–¥–Ω—è—è</td><td>–ù–∏–∑–∫–∞—è</td><td>–í—ã—Å–æ–∫–∞—è</td></tr>
      <tr><td>–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ</td><td>–ù—É–∂–Ω–æ –∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å</td><td>–ù—É–∂–Ω–æ –∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å</td><td>–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏</td></tr>
      <tr><td>–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ</td><td>–£–º–µ—Ä–µ–Ω–Ω–æ–µ</td><td>–†–∏—Å–∫ –≤—ã—à–µ</td><td>–†–∏—Å–∫ –Ω–∏–∂–µ</td></tr>
      <tr><td>GPU</td><td>–î–∞</td><td>–î–∞</td><td>–î–∞</td></tr>
      <tr><td>–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è</td><td>–û—Ç–ª–∏—á–Ω–∞—è</td><td>–•–æ—Ä–æ—à–∞—è</td><td>–•–æ—Ä–æ—à–∞—è</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 13. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –ù–∞—á–∞—Ç—å —Å –±–∞–∑–æ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</li>
      <li>[ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å max_depth / num_leaves</li>
      <li>[ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å learning_rate –∏ n_estimators</li>
      <li>[ ] –î–æ–±–∞–≤–∏—Ç—å subsample / bagging</li>
      <li>[ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é</li>
      <li>[ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å early stopping</li>
      <li>[ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ (train vs test)</li>
      <li>[ ] –û—Ü–µ–Ω–∏—Ç—å feature importance</li>
      <li>[ ] –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´–ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ –±—É—Å—Ç–∏–Ω–≥–∞ ‚Äî —ç—Ç–æ "—Ä—É—á–∫–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏" –∞–ª–≥–æ—Ä–∏—Ç–º–∞. –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–∂–µ—Ç —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ –Ω–∞ 5-15%, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç –≤—Ä–µ–º–µ–Ω–∏. –ú—ã –Ω–∞—á–∏–Ω–∞–µ–º —Å —Ä–∞–∑—É–º–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π, –∑–∞—Ç–µ–º —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º, –±–∞–ª–∞–Ω—Å–∏—Ä—É—è –º–µ–∂–¥—É —Ç–æ—á–Ω–æ—Å—Ç—å—é –∏ —Å–∫–æ—Ä–æ—Å—Ç—å—é –æ–±—É—á–µ–Ω–∏—è¬ª.
    </blockquote>
  </div>



</div>
</body>
</html>
