<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –∏ —Ç–æ–Ω–∫–æ—Å—Ç–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω—Å–∞–º–±–ª–µ–π ‚Äî Cheatsheet</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

    .container {
      column-count: 3;
      column-gap: 20px;
      max-width: 100%;
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      font-size: 0.9em;
      color: #666;
      text-align: center;
      margin-bottom: 20px;
      column-span: all;
    }

    h2 {
      font-size: 1.1em;
      font-weight: 700;
      margin-top: 0;
      color: #1a5fb4;
      border-bottom: 2px solid #e0e8f5;
      padding-bottom: 4px;
    }

    h3 {
      font-size: 0.95em;
      font-weight: 600;
      margin: 8px 0 4px;
      color: #26a269;
    }

    p, ul, ol {
      margin: 6px 0;
      font-size: 0.88em;
      line-height: 1.5;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 3px;
    }

    code {
      background: #f6f8fa;
      padding: 1px 4px;
      border-radius: 3px;
      font-family: 'Consolas', 'Monaco', monospace;
      font-size: 0.9em;
      color: #c7254e;
    }

    pre {
      background: #282c34;
      color: #abb2bf;
      padding: 10px;
      border-radius: 6px;
      overflow-x: auto;
      font-size: 0.8em;
      line-height: 1.4;
      margin: 8px 0;
    }

    pre code {
      background: transparent;
      color: inherit;
      padding: 0;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      margin: 8px 0;
      font-size: 0.85em;
    }

    th, td {
      border: 1px solid #ddd;
      padding: 6px 8px;
      text-align: left;
    }

    th {
      background: #e0e8f5;
      font-weight: 600;
      color: #1a5fb4;
    }

    tr:nth-child(even) {
      background: #f9fbff;
    }

    blockquote {
      background: #fff9e6;
      border-left: 4px solid #f6d32d;
      padding: 8px 12px;
      margin: 8px 0;
      font-size: 0.88em;
      font-style: italic;
    }

    .formula {
      background: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      margin: 8px 0;
      font-family: 'Cambria', 'Times New Roman', serif;
      font-size: 0.9em;
      text-align: center;
    }
  </style>
</head>
<body>

<h1>üéØ –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –∏ —Ç–æ–Ω–∫–æ—Å—Ç–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω—Å–∞–º–±–ª–µ–π</h1>
<div class="subtitle">Advanced Ensemble Tuning: Techniques, Tricks, and Best Practices</div>

<div class="container">

  <div class="block">
    <h2>üî∑ 1. –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã</h2>
    <p><strong>–ê–Ω—Å–∞–º–±–ª—å</strong> ‚Äî —ç—Ç–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π.</p>
    
    <h3>–£—Å–ª–æ–≤–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∞–Ω—Å–∞–º–±–ª—è:</h3>
    <ul>
      <li><strong>–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ</strong> ‚Äî –º–æ–¥–µ–ª–∏ –¥–æ–ª–∂–Ω—ã –æ—à–∏–±–∞—Ç—å—Å—è –ø–æ-—Ä–∞–∑–Ω–æ–º—É</li>
      <li><strong>–ö–∞—á–µ—Å—Ç–≤–æ</strong> ‚Äî –∫–∞–∂–¥–∞—è –º–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª—É—á—à–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –≥–∞–¥–∞–Ω–∏—è</li>
      <li><strong>–ù–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å</strong> ‚Äî –æ—à–∏–±–∫–∏ –º–æ–¥–µ–ª–µ–π –Ω–µ –¥–æ–ª–∂–Ω—ã –∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞—Ç—å</li>
    </ul>

    <h3>–¢–∏–ø—ã –∞–Ω—Å–∞–º–±–ª–µ–π:</h3>
    <ul>
      <li><strong>Bagging</strong> ‚Äî –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –ø–æ–¥–≤—ã–±–æ—Ä–∫–∞—Ö</li>
      <li><strong>Boosting</strong> ‚Äî –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ –æ—à–∏–±–∫–∏</li>
      <li><strong>Stacking</strong> ‚Äî –æ–±—É—á–µ–Ω–∏–µ –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏ –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö</li>
      <li><strong>Voting</strong> ‚Äî –ø—Ä–æ—Å—Ç–æ–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ –∏–ª–∏ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 2. –í—ã–±–æ—Ä –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π</h2>
    <h3>–°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –†–∞–∑–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã</h3>
    <pre><code>from sklearn.ensemble import VotingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB

ensemble = VotingClassifier(
    estimators=[
        ('dt', DecisionTreeClassifier()),
        ('lr', LogisticRegression()),
        ('svc', SVC(probability=True)),
        ('nb', GaussianNB())
    ],
    voting='soft',  # –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
    weights=[2, 1, 2, 1]  # —Ä–∞–∑–Ω—ã–µ –≤–µ—Å–∞
)</code></pre>

    <h3>–°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –û–¥–∏–Ω –∞–ª–≥–æ—Ä–∏—Ç–º —Å —Ä–∞–∑–Ω—ã–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏</h3>
    <pre><code>from sklearn.ensemble import RandomForestClassifier

models = [
    RandomForestClassifier(max_depth=5, n_estimators=50),
    RandomForestClassifier(max_depth=10, n_estimators=100),
    RandomForestClassifier(max_depth=20, n_estimators=200)
]</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 3. –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π</h2>
    <p>–ë–æ–ª—å—à–µ –º–æ–¥–µ–ª–µ–π ‚â† –ª—É—á—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç. –ï—Å—Ç—å —Ç–æ—á–∫–∞ –Ω–∞—Å—ã—â–µ–Ω–∏—è!</p>

    <h3>–≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–µ –ø—Ä–∞–≤–∏–ª–∞:</h3>
    <ul>
      <li><strong>Voting/Bagging</strong>: 5-20 –º–æ–¥–µ–ª–µ–π</li>
      <li><strong>Stacking</strong>: 3-7 –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π</li>
      <li><strong>Boosting</strong>: 50-1000 –∏—Ç–µ—Ä–∞—Ü–∏–π (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç learning_rate)</li>
    </ul>

    <h3>–ö–∞–∫ –Ω–∞–π—Ç–∏ –æ–ø—Ç–∏–º—É–º:</h3>
    <pre><code>import numpy as np
from sklearn.model_selection import cross_val_score

# –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π
results = []
for n_models in range(3, 21):
    ensemble = create_ensemble(n_models)
    score = cross_val_score(ensemble, X, y, cv=5).mean()
    results.append((n_models, score))

# –ù–∞—Ö–æ–¥–∏–º —Ç–æ—á–∫—É –Ω–∞—Å—ã—â–µ–Ω–∏—è (–∫–æ–≥–¥–∞ –ø—Ä–∏—Ä–æ—Å—Ç < 0.001)
optimal_n = find_saturation_point(results, threshold=0.001)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–µ–π</h2>
    <h3>–ú–µ—Ç–æ–¥ 1: –ü—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –∫–∞—á–µ—Å—Ç–≤—É</h3>
    <pre><code>from sklearn.model_selection import cross_val_score

models = [model1, model2, model3]
scores = [cross_val_score(m, X, y, cv=5).mean() 
          for m in models]

# –í–µ—Å–∞ –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω—ã –∫–∞—á–µ—Å—Ç–≤—É
weights = np.array(scores) / sum(scores)

ensemble = VotingClassifier(
    estimators=list(zip(['m1','m2','m3'], models)),
    voting='soft',
    weights=weights
)</code></pre>

    <h3>–ú–µ—Ç–æ–¥ 2: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤</h3>
    <pre><code>from scipy.optimize import minimize

def objective(weights):
    ensemble.weights = weights
    return -cross_val_score(ensemble, X, y, cv=5).mean()

# –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –≤–µ—Å–æ–≤
result = minimize(
    objective, 
    x0=np.ones(n_models)/n_models,
    bounds=[(0,1)]*n_models,
    constraints={'type':'eq', 'fun':lambda w: sum(w)-1}
)
optimal_weights = result.x</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è</h2>
    <h3>–¢–µ—Ö–Ω–∏–∫–∞ 1: –†–∞–∑–Ω—ã–µ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</h3>
    <pre><code>from sklearn.ensemble import BaggingClassifier

bagging = BaggingClassifier(
    base_estimator=DecisionTreeClassifier(),
    n_estimators=10,
    max_features=0.7,  # –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 70% –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    max_samples=0.8,   # –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 80% –æ–±—ä–µ–∫—Ç–æ–≤
    bootstrap=True,
    bootstrap_features=True  # —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
)</code></pre>

    <h3>–¢–µ—Ö–Ω–∏–∫–∞ 2: –†–∞–∑–Ω—ã–µ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∏</h3>
    <pre><code>from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.pipeline import Pipeline

pipelines = [
    Pipeline([
        ('scaler', StandardScaler()),
        ('model', LogisticRegression())
    ]),
    Pipeline([
        ('scaler', MinMaxScaler()),
        ('model', LogisticRegression())
    ]),
    # –ë–µ–∑ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
    Pipeline([
        ('model', RandomForestClassifier())
    ])
]</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. Stacking: –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–µ –∞–Ω—Å–∞–º–±–ª–∏</h2>
    <h3>–ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è Stacking</h3>
    <pre><code>from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression

# –ë–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
base_models = [
    ('rf', RandomForestClassifier(n_estimators=100)),
    ('gb', GradientBoostingClassifier(n_estimators=100)),
    ('svc', SVC(probability=True))
]

# –ú–µ—Ç–∞-–º–æ–¥–µ–ª—å
meta_model = LogisticRegression()

stacking = StackingClassifier(
    estimators=base_models,
    final_estimator=meta_model,
    cv=5,  # –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û! –ò–∑–±–µ–≥–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
    stack_method='predict_proba'  # –¥–ª—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
)</code></pre>

    <h3>–í—ã–±–æ—Ä –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏:</h3>
    <ul>
      <li><strong>–õ–∏–Ω–µ–π–Ω—ã–µ –º–æ–¥–µ–ª–∏</strong> (Ridge, Lasso) ‚Äî –µ—Å–ª–∏ –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ</li>
      <li><strong>Gradient Boosting</strong> ‚Äî –µ—Å–ª–∏ –Ω—É–∂–Ω–∞ —Å–ª–æ–∂–Ω–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è</li>
      <li><strong>Neural Network</strong> ‚Äî –¥–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 7. Boosting: —Ç–æ–Ω–∫–æ—Å—Ç–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏</h2>
    <h3>Learning rate vs n_estimators</h3>
    <table>
      <tr><th>Learning Rate</th><th>N Estimators</th><th>–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å</th></tr>
      <tr><td>0.01-0.03</td><td>500-1000</td><td>–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ</td></tr>
      <tr><td>0.05-0.1</td><td>100-300</td><td>–ë–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç—å/–∫–∞—á–µ—Å—Ç–≤–æ</td></tr>
      <tr><td>0.2-0.3</td><td>50-100</td><td>–ë—ã—Å—Ç—Ä–æ–µ –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏–µ</td></tr>
    </table>

    <h3>–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –≤ boosting:</h3>
    <pre><code>from xgboost import XGBClassifier

xgb = XGBClassifier(
    learning_rate=0.01,
    n_estimators=1000,
    max_depth=3,           # –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤—å–µ–≤
    subsample=0.8,         # –¥–æ–ª—è –æ–±—ä–µ–∫—Ç–æ–≤
    colsample_bytree=0.8,  # –¥–æ–ª—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    reg_alpha=0.1,         # L1 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
    reg_lambda=1.0,        # L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
    early_stopping_rounds=50  # —Ä–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞
)

xgb.fit(X_train, y_train, 
        eval_set=[(X_val, y_val)],
        verbose=False)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π</h2>
    <p>–ê–Ω—Å–∞–º–±–ª–∏ —á–∞—Å—Ç–æ –≤—ã–¥–∞—é—Ç –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏!</p>

    <h3>–ü—Ä–æ–±–ª–µ–º–∞:</h3>
    <p>–ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Ç–æ–ª—å–∫–æ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0.3, 0.7], –∞ –Ω–µ [0, 1].</p>

    <h3>–†–µ—à–µ–Ω–∏–µ ‚Äî –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞:</h3>
    <pre><code>from sklearn.calibration import CalibratedClassifierCV

ensemble = VotingClassifier(...)

# –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –º–µ—Ç–æ–¥–æ–º Platt scaling
calibrated = CalibratedClassifierCV(
    ensemble,
    method='sigmoid',  # –∏–ª–∏ 'isotonic'
    cv=5
)

calibrated.fit(X_train, y_train)

# –¢–µ–ø–µ—Ä—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
proba = calibrated.predict_proba(X_test)</code></pre>

    <h3>–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <ul>
      <li>–ö–æ–≥–¥–∞ –≤–∞–∂–Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π (–º–µ–¥–∏—Ü–∏–Ω–∞, —Ñ–∏–Ω–∞–Ω—Å—ã)</li>
      <li>–ü–æ—Å–ª–µ Voting/Stacking –∞–Ω—Å–∞–º–±–ª–µ–π</li>
      <li>–ö–æ–≥–¥–∞ ROC-AUC —Ö–æ—Ä–æ—à–∏–π, –Ω–æ Brier score –ø–ª–æ—Ö–æ–π</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 9. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π</h2>
    <h3>–ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏—è:</h3>
    <pre><code># Bagging - –ª–µ–≥–∫–æ –ø–∞—Ä–∞–ª–ª–µ–ª–∏—Ç—Å—è
rf = RandomForestClassifier(
    n_estimators=100,
    n_jobs=-1  # –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å–µ —è–¥—Ä–∞
)

# Voting - –ø–∞—Ä–∞–ª–ª–µ–ª–∏–º –æ–±—É—á–µ–Ω–∏–µ
voting = VotingClassifier(
    estimators=[...],
    n_jobs=-1
)

# Boosting - –ù–ï –ø–∞—Ä–∞–ª–ª–µ–ª–∏—Ç—Å—è!
# –ò—Å–ø–æ–ª—å–∑—É–µ–º GPU –≤–µ—Ä—Å–∏–∏
from xgboost import XGBClassifier
xgb = XGBClassifier(tree_method='gpu_hist')</code></pre>

    <h3>–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:</h3>
    <pre><code># –î–ª—è stacking - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
import joblib

# –û–±—É—á–∞–µ–º –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –æ–¥–∏–Ω —Ä–∞–∑
for i, (name, model) in enumerate(base_models):
    model.fit(X_train, y_train)
    preds = model.predict_proba(X_val)
    joblib.dump(preds, f'cache_{name}.pkl')

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è</h2>
    <h3>–ú–µ—Ç—Ä–∏–∫–∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è:</h3>
    <pre><code>from scipy.stats import pearsonr
import numpy as np

def diversity_score(predictions):
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ä–µ–¥–Ω—é—é –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é –º–µ–∂–¥—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
    –ß–µ–º –±–ª–∏–∂–µ –∫ 0, —Ç–µ–º –±–æ–ª—å—à–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ
    """
    n_models = len(predictions)
    correlations = []
    
    for i in range(n_models):
        for j in range(i+1, n_models):
            corr, _ = pearsonr(predictions[i], predictions[j])
            correlations.append(abs(corr))
    
    return np.mean(correlations)

# –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
predictions = [model.predict(X_val) for model in models]
div_score = diversity_score(predictions)

print(f"Diversity Score: {div_score:.3f}")
# < 0.5 - —Ö–æ—Ä–æ—à–µ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ
# > 0.8 - –º–æ–¥–µ–ª–∏ —Å–ª–∏—à–∫–æ–º –ø–æ—Ö–æ–∂–∏</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. –†–∞–±–æ—Ç–∞ —Å –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏</h2>
    <h3>–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤:</h3>
    <pre><code>from sklearn.utils.class_weight import compute_class_weight

# –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤
class_weights = compute_class_weight(
    'balanced',
    classes=np.unique(y_train),
    y=y_train
)

# –î–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ –≤ –∞–Ω—Å–∞–º–±–ª–µ
models = [
    RandomForestClassifier(class_weight='balanced'),
    LogisticRegression(class_weight='balanced'),
    SVC(class_weight='balanced')
]</code></pre>

    <h3>–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –ø–æ—Ä–æ–≥–∞ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è:</h3>
    <pre><code>from sklearn.metrics import f1_score

# –ü–æ–¥–±–∏—Ä–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
thresholds = np.arange(0.1, 0.9, 0.05)
scores = []

for threshold in thresholds:
    y_pred = (ensemble.predict_proba(X_val)[:,1] > threshold).astype(int)
    score = f1_score(y_val, y_pred)
    scores.append(score)

optimal_threshold = thresholds[np.argmax(scores)]</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 12. –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤ –≤ –∞–Ω—Å–∞–º–±–ª—è—Ö</h2>
    <h3>–ú–µ—Ç–æ–¥ 1: Trimmed mean (—É—Å–µ—á—ë–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ)</h3>
    <pre><code>from scipy.stats import trim_mean

def robust_ensemble_predict(models, X, trim_percent=0.1):
    """
    –£–±–∏—Ä–∞–µ–º –∫—Ä–∞–π–Ω–∏–µ 10% –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Å –∫–∞–∂–¥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã
    """
    predictions = np.array([m.predict_proba(X)[:,1] 
                           for m in models])
    
    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ —É—Å–µ—á—ë–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ
    result = np.apply_along_axis(
        lambda x: trim_mean(x, trim_percent),
        axis=0,
        arr=predictions
    )
    return result</code></pre>

    <h3>–ú–µ—Ç–æ–¥ 2: –ú–µ–¥–∏–∞–Ω–∞ –≤–º–µ—Å—Ç–æ —Å—Ä–µ–¥–Ω–µ–≥–æ</h3>
    <pre><code>from sklearn.ensemble import VotingClassifier

# –ö–∞—Å—Ç–æ–º–Ω—ã–π VotingClassifier —Å –º–µ–¥–∏–∞–Ω–æ–π
class MedianVoting(VotingClassifier):
    def predict_proba(self, X):
        predictions = np.array([
            est.predict_proba(X) 
            for est in self.estimators_
        ])
        return np.median(predictions, axis=0)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 13. –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏ —É–¥–∞–ª–µ–Ω–∏–µ —Å–ª–∞–±—ã—Ö –º–æ–¥–µ–ª–µ–π</h2>
    <pre><code>from sklearn.model_selection import cross_val_score

def prune_ensemble(models, X, y, threshold=0.6):
    """
    –£–¥–∞–ª—è–µ—Ç –º–æ–¥–µ–ª–∏ —Å –∫–∞—á–µ—Å—Ç–≤–æ–º –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞
    """
    scores = []
    for model in models:
        score = cross_val_score(model, X, y, cv=5).mean()
        scores.append(score)
    
    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª–∏ –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞
    pruned = [m for m, s in zip(models, scores) 
              if s >= threshold]
    
    # –ï—Å–ª–∏ —É–¥–∞–ª–∏–ª–∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ, –±–µ—Ä—ë–º —Ç–æ–ø-5
    if len(pruned) < 3:
        indices = np.argsort(scores)[-5:]
        pruned = [models[i] for i in indices]
    
    return pruned

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
models = train_many_models(X, y)
good_models = prune_ensemble(models, X_val, y_val)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 14. –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ</h2>
    <p>–†–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞—é—Ç –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–∞—Ö –¥–∞–Ω–Ω—ã—Ö.</p>

    <h3>Instance-based weighting:</h3>
    <pre><code>from sklearn.neighbors import KNeighborsClassifier

def dynamic_ensemble(models, X_train, y_train, X_test):
    """
    –î–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –ø–æ–¥–±–∏—Ä–∞–µ–º –≤–µ—Å–∞ –º–æ–¥–µ–ª–µ–π
    –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ –ø–æ—Ö–æ–∂–∏—Ö –æ–±—ä–µ–∫—Ç–∞—Ö
    """
    # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Ö–æ–∂–∏–µ –æ–±—ä–µ–∫—Ç—ã
    knn = KNeighborsClassifier(n_neighbors=50)
    knn.fit(X_train, y_train)
    
    results = []
    for x in X_test:
        # –ù–∞—Ö–æ–¥–∏–º –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π
        neighbors = knn.kneighbors([x], return_distance=False)[0]
        X_neighbors = X_train[neighbors]
        y_neighbors = y_train[neighbors]
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Å–æ—Å–µ–¥—è—Ö
        weights = []
        for model in models:
            score = (model.predict(X_neighbors) == y_neighbors).mean()
            weights.append(score)
        
        weights = np.array(weights) / sum(weights)
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ
        predictions = [m.predict_proba([x])[0,1] for m in models]
        result = np.dot(weights, predictions)
        results.append(result)
    
    return np.array(results)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 15. –ß–µ–∫-–ª–∏—Å—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏</h2>
    <ul>
      <li>[ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –º–æ–¥–µ–ª–µ–π (correlation < 0.7)</li>
      <li>[ ] –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∫–∞–∂–¥–∞—è –º–æ–¥–µ–ª—å –ª—É—á—à–µ baseline</li>
      <li>[ ] –ù–∞–π—Ç–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π (—Ç–æ—á–∫–∞ –Ω–∞—Å—ã—â–µ–Ω–∏—è)</li>
      <li>[ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –≤–µ—Å–∞ –º–æ–¥–µ–ª–µ–π (–∏–ª–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å)</li>
      <li>[ ] –î–ª—è Stacking –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CV –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏</li>
      <li>[ ] –ö–∞–ª–∏–±—Ä–æ–≤–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏, –µ—Å–ª–∏ –æ–Ω–∏ –≤–∞–∂–Ω—ã</li>
      <li>[ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å early stopping –¥–ª—è boosting</li>
      <li>[ ] –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≥–¥–µ –≤–æ–∑–º–æ–∂–Ω–æ</li>
      <li>[ ] –£–¥–∞–ª–∏—Ç—å —Å–ª–∞–±—ã–µ –º–æ–¥–µ–ª–∏ –∏–∑ –∞–Ω—Å–∞–º–±–ª—è</li>
      <li>[ ] –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏, –Ω–µ –Ω–∞ —Ç—Ä–µ–π–Ω–µ!</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´–ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ –∫–æ–Ω—Å–∏–ª–∏—É–º –≤—Ä–∞—á–µ–π: –∫–∞–∂–¥—ã–π —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –¥–∞—ë—Ç —Å–≤–æ—ë –º–Ω–µ–Ω–∏–µ, –Ω–æ –∏—Ç–æ–≥–æ–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç—Å—è —Å —É—á—ë—Ç–æ–º —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã –∫–∞–∂–¥–æ–≥–æ. –¢–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∞–Ω—Å–∞–º–±–ª—å –º–æ–¥–µ–ª–µ–π ‚Äî –æ–±—ä–µ–¥–∏–Ω—è—è —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã —Ä–∞–∑–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤, –º—ã –ø–æ–ª—É—á–∞–µ–º –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π –∏ –Ω–∞–¥—ë–∂–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç¬ª.
    </blockquote>
  </div>

</div>

</body>
</html>
