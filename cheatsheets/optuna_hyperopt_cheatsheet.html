<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>Optuna / Hyperopt Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

    .container {
      column-count: 3;
      column-gap: 20px;
      max-width: 100%;
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üéØ Optuna / Hyperopt</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. Optuna: –û—Å–Ω–æ–≤—ã</h2>
    <ul>
      <li><strong>–ò–¥–µ—è</strong>: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</li>
      <li><strong>–ú–µ—Ç–æ–¥</strong>: –±–∞–π–µ—Å–æ–≤—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (TPE)</li>
      <li><strong>–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞</strong>: pruning, –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏—è, –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è</li>
      <li><strong>–ì–∏–±–∫–æ—Å—Ç—å</strong>: –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏</li>
    </ul>
    <pre><code># –£—Å—Ç–∞–Ω–æ–≤–∫–∞
pip install optuna

import optuna
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

# –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ü–µ–ª–µ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é
def objective(trial):
    # –ü—Ä–µ–¥–ª–æ–∂–∏—Ç—å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    n_estimators = trial.suggest_int('n_estimators', 50, 300)
    max_depth = trial.suggest_int('max_depth', 2, 32, log=True)
    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)
    
    # –°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å
    clf = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        min_samples_split=min_samples_split,
        random_state=42
    )
    
    # –û—Ü–µ–Ω–∏—Ç—å
    score = cross_val_score(clf, X_train, y_train, cv=3).mean()
    
    return score

# –°–æ–∑–¥–∞—Ç—å study –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)

# –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
print("–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:", study.best_params)
print("–õ—É—á—à–∏–π score:", study.best_value)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 2. –¢–∏–ø—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ Optuna</h2>
    <pre><code># –¶–µ–ª—ã–µ —á–∏—Å–ª–∞
n_estimators = trial.suggest_int('n_estimators', 10, 100)

# –° –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–π —à–∫–∞–ª–æ–π
max_depth = trial.suggest_int('max_depth', 2, 32, log=True)

# –í–µ—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —á–∏—Å–ª–∞
learning_rate = trial.suggest_float('lr', 0.001, 0.1, log=True)

# –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ
optimizer = trial.suggest_categorical('optimizer', 
                                     ['adam', 'sgd', 'rmsprop'])

# –î–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
dropout = trial.suggest_float('dropout', 0.1, 0.5, step=0.1)

# –£—Å–ª–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
if optimizer == 'adam':
    beta1 = trial.suggest_float('beta1', 0.8, 0.99)
    beta2 = trial.suggest_float('beta2', 0.9, 0.999)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 3. Optuna: Pruning</h2>
    <p>–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ–ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö –∏—Å–ø—ã—Ç–∞–Ω–∏–π</p>
    <pre><code>import optuna
from optuna.pruners import MedianPruner

def objective_with_pruning(trial):
    n_estimators = trial.suggest_int('n_estimators', 10, 100)
    max_depth = trial.suggest_int('max_depth', 2, 20)
    
    clf = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth
    )
    
    # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å pruning
    for step in range(10):
        # –û–±—É—á–∏—Ç—å –Ω–∞ –ø–æ–¥–≤—ã–±–æ—Ä–∫–µ
        subset_size = (step + 1) * len(X_train) // 10
        X_subset = X_train[:subset_size]
        y_subset = y_train[:subset_size]
        
        clf.fit(X_subset, y_subset)
        score = clf.score(X_val, y_val)
        
        # –°–æ–æ–±—â–∏—Ç—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        trial.report(score, step)
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω—É–∂–Ω–æ –ª–∏ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è
        if trial.should_prune():
            raise optuna.TrialPruned()
    
    return score

# Study —Å pruner
study = optuna.create_study(
    direction='maximize',
    pruner=MedianPruner(n_startup_trials=5, n_warmup_steps=3)
)

study.optimize(objective_with_pruning, n_trials=50)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. Optuna: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è</h2>
    <pre><code>import optuna.visualization as vis

# –ò—Å—Ç–æ—Ä–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
fig = vis.plot_optimization_history(study)
fig.show()

# –í–∞–∂–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
fig = vis.plot_param_importances(study)
fig.show()

# –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
fig = vis.plot_parallel_coordinate(study)
fig.show()

# Contour plot –¥–ª—è 2D
fig = vis.plot_contour(study, params=['n_estimators', 'max_depth'])
fig.show()

# Slice plot
fig = vis.plot_slice(study)
fig.show()

# EDF (Empirical Distribution Function)
fig = vis.plot_edf(study)
fig.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. Hyperopt: –û—Å–Ω–æ–≤—ã</h2>
    <pre><code># –£—Å—Ç–∞–Ω–æ–≤–∫–∞
pip install hyperopt

from hyperopt import hp, fmin, tpe, Trials, STATUS_OK
from sklearn.ensemble import RandomForestClassifier

# –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞
space = {
    'n_estimators': hp.quniform('n_estimators', 50, 300, 10),
    'max_depth': hp.quniform('max_depth', 2, 32, 1),
    'min_samples_split': hp.quniform('min_samples_split', 2, 20, 1),
    'criterion': hp.choice('criterion', ['gini', 'entropy'])
}

# –¶–µ–ª–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è
def objective(params):
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ int
    params['n_estimators'] = int(params['n_estimators'])
    params['max_depth'] = int(params['max_depth'])
    params['min_samples_split'] = int(params['min_samples_split'])
    
    clf = RandomForestClassifier(**params, random_state=42)
    
    # Cross-validation
    score = cross_val_score(clf, X_train, y_train, cv=3).mean()
    
    # Hyperopt –º–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ—Ç, –ø–æ—ç—Ç–æ–º—É –∏–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
    return {'loss': -score, 'status': STATUS_OK}

# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å
trials = Trials()
best = fmin(
    fn=objective,
    space=space,
    algo=tpe.suggest,  # Tree-structured Parzen Estimator
    max_evals=100,
    trials=trials
)

print("–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:", best)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. Hyperopt: –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞</h2>
    <pre><code>from hyperopt import hp

# Uniform (—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ)
lr = hp.uniform('lr', 0.001, 0.1)

# Log-uniform (–ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ)
lr_log = hp.loguniform('lr', np.log(0.001), np.log(0.1))

# Quantized uniform (–¥–∏—Å–∫—Ä–µ—Ç–Ω–æ–µ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ)
n_estimators = hp.quniform('n_estimators', 10, 100, 5)

# Normal (–Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ)
dropout = hp.normal('dropout', 0.5, 0.1)

# Choice (–∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–æ–µ)
optimizer = hp.choice('optimizer', ['adam', 'sgd', 'rmsprop'])

# Lognormal
learning_rate = hp.lognormal('lr', -5, 1)

# Conditional spaces
space = {
    'optimizer': hp.choice('optimizer', [
        {
            'type': 'adam',
            'lr': hp.loguniform('adam_lr', np.log(0.0001), np.log(0.1))
        },
        {
            'type': 'sgd',
            'lr': hp.loguniform('sgd_lr', np.log(0.001), np.log(0.1)),
            'momentum': hp.uniform('momentum', 0.5, 0.99)
        }
    ])
}</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ Optuna vs Hyperopt</h2>
    <table>
      <tr><th>–ê—Å–ø–µ–∫—Ç</th><th>Optuna</th><th>Hyperopt</th></tr>
      <tr><td>–°–∏–Ω—Ç–∞–∫—Å–∏—Å</td><td>–ü—Ä–æ—â–µ, pythonic</td><td>–°–ª–æ–∂–Ω–µ–µ</td></tr>
      <tr><td>Pruning</td><td>–í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π</td><td>–ù–µ—Ç</td></tr>
      <tr><td>–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è</td><td>–ë–æ–≥–∞—Ç–∞—è</td><td>–ë–∞–∑–æ–≤–∞—è</td></tr>
      <tr><td>–ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏—è</td><td>–ü—Ä–æ—Å—Ç–∞—è</td><td>–°–ª–æ–∂–Ω–µ–µ</td></tr>
      <tr><td>Storage</td><td>SQL, Redis</td><td>MongoDB</td></tr>
      <tr><td>–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å</td><td>–í—ã—Å–æ–∫–∞—è</td><td>–°—Ä–µ–¥–Ω—è—è</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 8. XGBoost —Å Optuna</h2>
    <pre><code>import optuna
import xgboost as xgb
from sklearn.model_selection import cross_val_score

def objective(trial):
    param = {
        'objective': 'binary:logistic',
        'eval_metric': 'logloss',
        'booster': trial.suggest_categorical('booster', ['gbtree', 'dart']),
        'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),
        'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),
    }
    
    if param['booster'] == 'gbtree' or param['booster'] == 'dart':
        param['max_depth'] = trial.suggest_int('max_depth', 1, 9)
        param['eta'] = trial.suggest_float('eta', 1e-8, 1.0, log=True)
        param['gamma'] = trial.suggest_float('gamma', 1e-8, 1.0, log=True)
        param['grow_policy'] = trial.suggest_categorical(
            'grow_policy', ['depthwise', 'lossguide']
        )
    
    if param['booster'] == 'dart':
        param['sample_type'] = trial.suggest_categorical(
            'sample_type', ['uniform', 'weighted']
        )
        param['normalize_type'] = trial.suggest_categorical(
            'normalize_type', ['tree', 'forest']
        )
        param['rate_drop'] = trial.suggest_float('rate_drop', 1e-8, 1.0, log=True)
        param['skip_drop'] = trial.suggest_float('skip_drop', 1e-8, 1.0, log=True)
    
    # Train
    model = xgb.XGBClassifier(**param, random_state=42)
    score = cross_val_score(model, X_train, y_train, cv=3).mean()
    
    return score

study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. LightGBM —Å Optuna</h2>
    <pre><code>import lightgbm as lgb

def objective(trial):
    param = {
        'objective': 'binary',
        'metric': 'binary_logloss',
        'verbosity': -1,
        'boosting_type': 'gbdt',
        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),
        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),
        'num_leaves': trial.suggest_int('num_leaves', 2, 256),
        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),
        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),
        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),
        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),
    }
    
    model = lgb.LGBMClassifier(**param, random_state=42)
    score = cross_val_score(model, X_train, y_train, cv=3).mean()
    
    return score

study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. –ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ —Å Optuna</h2>
    <pre><code>import optuna
import torch
import torch.nn as nn
import torch.optim as optim

def objective(trial):
    # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
    n_layers = trial.suggest_int('n_layers', 1, 3)
    layers = []
    in_features = X_train.shape[1]
    
    for i in range(n_layers):
        out_features = trial.suggest_int(f'n_units_l{i}', 4, 128, log=True)
        layers.append(nn.Linear(in_features, out_features))
        layers.append(nn.ReLU())
        
        dropout = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)
        layers.append(nn.Dropout(dropout))
        
        in_features = out_features
    
    layers.append(nn.Linear(in_features, 1))
    layers.append(nn.Sigmoid())
    
    model = nn.Sequential(*layers)
    
    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'SGD'])
    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)
    
    if optimizer_name == 'Adam':
        optimizer = optim.Adam(model.parameters(), lr=lr)
    else:
        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)
    
    # –û–±—É—á–µ–Ω–∏–µ
    criterion = nn.BCELoss()
    
    for epoch in range(10):
        model.train()
        optimizer.zero_grad()
        outputs = model(X_train_tensor)
        loss = criterion(outputs, y_train_tensor)
        loss.backward()
        optimizer.step()
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        model.eval()
        with torch.no_grad():
            val_outputs = model(X_val_tensor)
            val_loss = criterion(val_outputs, y_val_tensor)
        
        trial.report(val_loss.item(), epoch)
        
        if trial.should_prune():
            raise optuna.TrialPruned()
    
    return val_loss.item()

study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</h2>
    <pre><code># Optuna —Å SQL storage (–¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏–∏)
import optuna

# –°–æ–∑–¥–∞—Ç—å storage
storage = optuna.storages.RDBStorage(
    url='sqlite:///optuna.db',
    engine_kwargs={'connect_args': {'timeout': 10}}
)

# –°–æ–∑–¥–∞—Ç—å study
study = optuna.create_study(
    study_name='distributed_optimization',
    storage=storage,
    load_if_exists=True,
    direction='maximize'
)

# –ó–∞–ø—É—Å—Ç–∏—Ç—å –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–∞—Ö/–º–∞—à–∏–Ω–∞—Ö
study.optimize(objective, n_trials=100)

# –ù–∞ –¥—Ä—É–≥–æ–π –º–∞—à–∏–Ω–µ/–ø—Ä–æ—Ü–µ—Å—Å–µ
# study = optuna.load_study(
#     study_name='distributed_optimization',
#     storage=storage
# )
# study.optimize(objective, n_trials=100)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 12. Multi-objective –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</h2>
    <p>–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–µ—Ç—Ä–∏–∫ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ</p>
    <pre><code>def objective_multi(trial):
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
    n_estimators = trial.suggest_int('n_estimators', 50, 300)
    max_depth = trial.suggest_int('max_depth', 2, 32)
    
    clf = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth
    )
    
    clf.fit(X_train, y_train)
    
    # Accuracy
    accuracy = clf.score(X_test, y_test)
    
    # –í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    import time
    start = time.time()
    _ = clf.predict(X_test)
    inference_time = time.time() - start
    
    # –í–µ—Ä–Ω—É—Ç—å –æ–±–µ –º–µ—Ç—Ä–∏–∫–∏
    return accuracy, inference_time

# Study —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Ü–µ–ª—è–º–∏
study = optuna.create_study(
    directions=['maximize', 'minimize']  # max accuracy, min time
)

study.optimize(objective_multi, n_trials=100)

# –ü–æ–ª—É—á–∏—Ç—å Pareto front
best_trials = study.best_trials

for trial in best_trials:
    print(f"Trial {trial.number}: Accuracy={trial.values[0]:.3f}, Time={trial.values[1]:.3f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 13. Callbacks –≤ Optuna</h2>
    <pre><code># Early stopping
from optuna.study import MaxTrialsCallback

max_trials = MaxTrialsCallback(100, states=(optuna.trial.TrialState.COMPLETE,))

# Custom callback
class MetricCallback:
    def __init__(self, threshold):
        self.threshold = threshold
    
    def __call__(self, study, trial):
        if trial.value > self.threshold:
            print(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ø–æ—Ä–æ–≥ {self.threshold}!")
            study.stop()

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
study = optuna.create_study(direction='maximize')
study.optimize(
    objective,
    n_trials=100,
    callbacks=[MetricCallback(0.95), max_trials]
)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 14. Sampler –≤ Optuna</h2>
    <pre><code>import optuna
from optuna.samplers import (
    TPESampler, RandomSampler, GridSampler, 
    CmaEsSampler, NSGAIISampler
)

# TPE (Tree-structured Parzen Estimator) - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
study = optuna.create_study(sampler=TPESampler())

# Random Search
study = optuna.create_study(sampler=RandomSampler())

# Grid Search
search_space = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 15]
}
study = optuna.create_study(sampler=GridSampler(search_space))

# CMA-ES (–¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
study = optuna.create_study(sampler=CmaEsSampler())

# NSGA-II (–¥–ª—è multi-objective)
study = optuna.create_study(
    directions=['maximize', 'minimize'],
    sampler=NSGAIISampler()
)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 15. –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏</h2>
    <ul>
      <li>–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ <code>log=True</code> –¥–ª—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å —à–∏—Ä–æ–∫–∏–º –¥–∏–∞–ø–∞–∑–æ–Ω–æ–º</li>
      <li>–ù–∞—á–Ω–∏—Ç–µ —Å Random Search (20-50 trials), –∑–∞—Ç–µ–º TPE</li>
      <li>–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ pruning –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è</li>
      <li>–°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ study –≤ –ë–î –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å</li>
      <li>–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è insights</li>
      <li>–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é, –Ω–µ holdout</li>
      <li>–õ–æ–≥–∏—Ä—É–π—Ç–µ –≤—Å–µ trials –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞</li>
      <li>–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ timeout –∏–ª–∏ max_trials</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 16. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</li>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å –º–µ—Ç—Ä–∏–∫—É –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (accuracy, F1, AUC –∏ —Ç.–¥.)</li>
      <li>[ ] –ù–∞–ø–∏—Å–∞—Ç—å objective function</li>
      <li>[ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é –≤ objective</li>
      <li>[ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å pruning –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è</li>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å sampler (TPE —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)</li>
      <li>[ ] –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é (50-200 trials)</li>
      <li>[ ] –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã</li>
      <li>[ ] –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</li>
      <li>[ ] –û–±—É—á–∏—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏</li>
      <li>[ ] –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ test set</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´Optuna –∏ Hyperopt ‚Äî —ç—Ç–æ –∫–∞–∫ —É–º–Ω—ã–µ –ø–æ–º–æ—â–Ω–∏–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥–±–∏—Ä–∞—é—Ç –ª—É—á—à–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –í–º–µ—Å—Ç–æ —Ä—É—á–Ω–æ–≥–æ –ø–µ—Ä–µ–±–æ—Ä–∞ —Ç—ã—Å—è—á –∫–æ–º–±–∏–Ω–∞—Ü–∏–π, —ç—Ç–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç —É–º–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏, —á—Ç–æ–±—ã –±—ã—Å—Ç—Ä–æ –Ω–∞–π—Ç–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –ø–æ–≤—ã—à–∞—é—â–∏–µ —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏¬ª.
    </blockquote>
  </div>

</div>

</body>
</html>
