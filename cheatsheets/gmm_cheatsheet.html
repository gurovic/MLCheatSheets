<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>Gaussian Mixture Models (GMM) Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

    .container {
      column-count: 3;
      column-gap: 20px;
      max-width: 100%;
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    .formula {
      text-align: center;
      font-family: 'Cambria Math', serif;
      font-size: 1em;
      margin: 10px 0;
      padding: 8px;
      background: #f8fbff;
      border-radius: 4px;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üéØ Gaussian Mixture Models (GMM) Cheatsheet</h1>
  <div class="subtitle">–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è ‚Ä¢ EM-–∞–ª–≥–æ—Ä–∏—Ç–º ‚Ä¢ –ú—è–≥–∫–∏–µ –∫–ª–∞—Å—Ç–µ—Ä—ã<br>üìÖ 3 —è–Ω–≤–∞—Ä—è 2026</div>

  <div class="block">
    <h2>üî∑ 1. –°—É—Ç—å</h2>
    <ul>
      <li><strong>–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥</strong>: –∫–∞–∂–¥–∞—è —Ç–æ—á–∫–∞ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –∫–ª–∞—Å—Ç–µ—Ä—É —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é</li>
      <li><strong>–ì–∞—É—Å—Å–æ–≤—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è</strong>: —Å–º–µ—Å—å –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π</li>
      <li><strong>–ú—è–≥–∫–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è</strong>: –≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç K-means (–∂–µ—Å—Ç–∫–∞—è)</li>
      <li><strong>EM-–∞–ª–≥–æ—Ä–∏—Ç–º</strong>: Expectation-Maximization –¥–ª—è –æ–±—É—á–µ–Ω–∏—è</li>
    </ul>
    <div class="formula">
      P(x) = Œ£ œÄ‚Çñ ¬∑ N(x | Œº‚Çñ, Œ£‚Çñ)
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 2. –ë–∞–∑–æ–≤—ã–π –∫–æ–¥</h2>
    <pre><code>from sklearn.mixture import GaussianMixture
import numpy as np

# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
gmm = GaussianMixture(
    n_components=3,
    covariance_type='full',
    random_state=42
)

# –û–±—É—á–µ–Ω–∏–µ
gmm.fit(X)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
labels = gmm.predict(X)

# –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏
proba = gmm.predict_proba(X)
print(proba[:5])  # –ø–µ—Ä–≤—ã–µ 5 —Ç–æ—á–µ–∫</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 3. –¢–∏–ø—ã –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω—ã—Ö –º–∞—Ç—Ä–∏—Ü</h2>
    <table>
      <tr><th>–¢–∏–ø</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th><th>–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å</th></tr>
      <tr><td><code>full</code></td><td>–ü–æ–ª–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞</td><td>–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–∏–±–∫–æ—Å—Ç—å</td></tr>
      <tr><td><code>tied</code></td><td>–û–±—â–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –¥–ª—è –≤—Å–µ—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤</td><td>–û–¥–∏–Ω–∞–∫–æ–≤–∞—è —Ñ–æ—Ä–º–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤</td></tr>
      <tr><td><code>diag</code></td><td>–î–∏–∞–≥–æ–Ω–∞–ª—å–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞</td><td>–ü—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã</td></tr>
      <tr><td><code>spherical</code></td><td>–û–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–∏—Å–ø–µ—Ä—Å–∏–∏</td><td>–°—Ñ–µ—Ä–∏—á–µ—Å–∫–∏–µ –∫–ª–∞—Å—Ç–µ—Ä—ã</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 4. –ö–ª—é—á–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã</h2>
    <table>
      <tr><th>–ü–∞—Ä–∞–º–µ—Ç—Ä</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th><th>–°–æ–≤–µ—Ç</th></tr>
      <tr><td><code>n_components</code></td><td>–ß–∏—Å–ª–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç (–∫–ª–∞—Å—Ç–µ—Ä–æ–≤)</td><td>–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ BIC/AIC –¥–ª—è –≤—ã–±–æ—Ä–∞</td></tr>
      <tr><td><code>covariance_type</code></td><td>–¢–∏–ø –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã</td><td>'full' –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é</td></tr>
      <tr><td><code>max_iter</code></td><td>–ú–∞–∫—Å. –∏—Ç–µ—Ä–∞—Ü–∏–π EM</td><td>100 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é</td></tr>
      <tr><td><code>n_init</code></td><td>–ß–∏—Å–ª–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–π</td><td>1 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, —É–≤–µ–ª–∏—á–∏—Ç—å –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏</td></tr>
      <tr><td><code>init_params</code></td><td>–ú–µ—Ç–æ–¥ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏</td><td>'kmeans' –∏–ª–∏ 'random'</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 5. –í—ã–±–æ—Ä —á–∏—Å–ª–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤</h2>
    <pre><code># –ú–µ—Ç–æ–¥ 1: BIC (Bayesian Information Criterion)
bic_scores = []
aic_scores = []
K_range = range(2, 11)

for k in K_range:
    gmm = GaussianMixture(n_components=k, random_state=42)
    gmm.fit(X)
    bic_scores.append(gmm.bic(X))
    aic_scores.append(gmm.aic(X))

# –õ—É—á—à–µ–µ k - –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π BIC –∏–ª–∏ AIC
best_k = K_range[np.argmin(bic_scores)]
print(f"–û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ k: {best_k}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è BIC/AIC</h2>
    <pre><code>import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
plt.plot(K_range, bic_scores, 'o-', label='BIC')
plt.plot(K_range, aic_scores, 's-', label='AIC')
plt.xlabel('–ß–∏—Å–ª–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç')
plt.ylabel('–ö—Ä–∏—Ç–µ—Ä–∏–π')
plt.legend()
plt.title('–í—ã–±–æ—Ä —á–∏—Å–ª–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. –ú—è–≥–∫–∞—è vs –∂–µ—Å—Ç–∫–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è</h2>
    <pre><code># –ñ–µ—Å—Ç–∫–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è (–∫–∞–∫ K-means)
hard_labels = gmm.predict(X)

# –ú—è–≥–∫–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏)
soft_labels = gmm.predict_proba(X)

# –ü—Ä–∏–º–µ—Ä: —Ç–æ—á–∫–∞ –Ω–∞ –≥—Ä–∞–Ω–∏—Ü–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
print(f"–ñ–µ—Å—Ç–∫–∞—è –º–µ—Ç–∫–∞: {hard_labels[0]}")
print(f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏: {soft_labels[0]}")
# –í—ã–≤–æ–¥: [0.2, 0.6, 0.2] - –±–æ–ª—å—à–µ –≤–æ 2-–º –∫–ª–∞—Å—Ç–µ—Ä–µ</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö —Ç–æ—á–µ–∫</h2>
    <pre><code># GMM –º–æ–∂–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
new_samples, labels = gmm.sample(n_samples=100)

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
import matplotlib.pyplot as plt
plt.scatter(new_samples[:, 0], new_samples[:, 1], 
            c=labels, alpha=0.5)
plt.title('–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ')
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. GMM vs K-Means</h2>
    <table>
      <tr><th>–ê—Å–ø–µ–∫—Ç</th><th>K-Means</th><th>GMM</th></tr>
      <tr><td>–¢–∏–ø –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏</td><td>–ñ–µ—Å—Ç–∫–∞—è</td><td>–ú—è–≥–∫–∞—è</td></tr>
      <tr><td>–§–æ—Ä–º–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤</td><td>–°—Ñ–µ—Ä–∏—á–µ—Å–∫–∞—è</td><td>–≠–ª–ª–∏–ø—Å–æ–∏–¥–∞–ª—å–Ω–∞—è</td></tr>
      <tr><td>–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏</td><td>–ù–µ—Ç</td><td>–î–∞</td></tr>
      <tr><td>–°–∫–æ—Ä–æ—Å—Ç—å</td><td>–ë—ã—Å—Ç—Ä–µ–µ</td><td>–ú–µ–¥–ª–µ–Ω–Ω–µ–µ</td></tr>
      <tr><td>–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö</td><td>–ù–µ—Ç</td><td>–î–∞</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 10. –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞</h3>
        <ul>
          <li>–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è</li>
          <li>–ö–ª–∞—Å—Ç–µ—Ä—ã –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–π —Ñ–æ—Ä–º—ã</li>
          <li>–ú—è–≥–∫–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è</li>
          <li>–ú–æ–∂–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ</li>
          <li>–ö—Ä–∏—Ç–µ—Ä–∏–∏ –≤—ã–±–æ—Ä–∞ —á–∏—Å–ª–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (BIC/AIC)</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏</h3>
        <ul>
          <li>–ú–µ–¥–ª–µ–Ω–Ω–µ–µ K-means</li>
          <li>–ú–æ–∂–µ—Ç –∑–∞—Å—Ç—Ä—è—Ç—å –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º –º–∏–Ω–∏–º—É–º–µ</li>
          <li>–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏</li>
          <li>–ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç –≥–∞—É—Å—Å–æ–≤—É —Ñ–æ—Ä–º—É –∫–ª–∞—Å—Ç–µ—Ä–æ–≤</li>
          <li>–ë–æ–ª—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 11. –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –•–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç</h3>
        <ul>
          <li>–ù—É–∂–Ω—ã –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏</li>
          <li>–ö–ª–∞—Å—Ç–µ—Ä—ã —ç–ª–ª–∏–ø—Å–æ–∏–¥–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º—ã</li>
          <li>–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö</li>
          <li>–ú—è–≥–∫–∏–µ –≥—Ä–∞–Ω–∏—Ü—ã –º–µ–∂–¥—É –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ùå –ü–ª–æ—Ö–æ –ø–æ–¥—Ö–æ–¥–∏—Ç</h3>
        <ul>
          <li>–û—á–µ–Ω—å –±–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ</li>
          <li>–ö–ª–∞—Å—Ç–µ—Ä—ã –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–π —Ñ–æ—Ä–º—ã (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ DBSCAN)</li>
          <li>–ù—É–∂–Ω–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 12. –û—Ü–µ–Ω–∫–∞ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏</h2>
    <pre><code># –û—Ü–µ–Ω–∫–∞ log-likelihood –¥–ª—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
log_likelihood = gmm.score_samples(X_new)

# –û–±—â–∏–π score
total_score = gmm.score(X_test)
print(f"Log-likelihood: {total_score:.2f}")

# –í—ã—è–≤–ª–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π
threshold = np.percentile(log_likelihood, 5)
anomalies = X_new[log_likelihood < threshold]</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 13. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö</h2>
    <pre><code>from sklearn.preprocessing import StandardScaler

# –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# –ó–∞—Ç–µ–º GMM
gmm = GaussianMixture(n_components=3)
gmm.fit(X_scaled)</code></pre>
    <p><strong>–í–∞–∂–Ω–æ:</strong> GMM —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ –º–∞—Å—à—Ç–∞–±—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤!</p>
  </div>

  <div class="block">
    <h2>üî∑ 14. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏</h2>
    <pre><code># –í–µ—Å–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç (œÄ‚Çñ)
weights = gmm.weights_
print(f"–í–µ—Å–∞: {weights}")

# –°—Ä–µ–¥–Ω–∏–µ (Œº‚Çñ)
means = gmm.means_
print(f"–°—Ä–µ–¥–Ω–∏–µ:\n{means}")

# –ö–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–∞—Ç—Ä–∏—Ü—ã (Œ£‚Çñ)
covariances = gmm.covariances_
print(f"–ö–æ–≤–∞—Ä–∏–∞—Ü–∏–∏:\n{covariances}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 15. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã</h2>
    <ul>
      <li><strong>–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è</strong>: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–ø—É—Å–∫–æ–≤ (n_init>1)</li>
      <li><strong>–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ</strong>: –≤—Å–µ–≥–¥–∞ –ø—Ä–∏–º–µ–Ω—è–π—Ç–µ StandardScaler</li>
      <li><strong>–í—ã–±–æ—Ä k</strong>: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ BIC/AIC, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ –≤–∏–∑—É–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É</li>
      <li><strong>–ö–æ–≤–∞—Ä–∏–∞—Ü–∏–∏</strong>: –Ω–∞—á–Ω–∏—Ç–µ —Å 'full', –∑–∞—Ç–µ–º —É–ø—Ä–æ—â–∞–π—Ç–µ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏</li>
      <li><strong>–°—Ö–æ–¥–∏–º–æ—Å—Ç—å</strong>: —É–≤–µ–ª–∏—á—å—Ç–µ max_iter –µ—Å–ª–∏ –Ω–µ —Å—Ö–æ–¥–∏—Ç—Å—è</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 16. –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏</h2>
    <pre><code># –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏
print(f"–°–æ—à–ª–æ—Å—å: {gmm.converged_}")
print(f"–ò—Ç–µ—Ä–∞—Ü–∏–π: {gmm.n_iter_}")

# –ï—Å–ª–∏ –Ω–µ —Å–æ—à–ª–æ—Å—å
if not gmm.converged_:
    gmm = GaussianMixture(
        n_components=3,
        max_iter=200,  # —É–≤–µ–ª–∏—á–∏—Ç—å
        random_state=42
    )
    gmm.fit(X)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 17. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ (StandardScaler)</li>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç (BIC/AIC)</li>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å —Ç–∏–ø –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã</li>
      <li>[ ] –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å n_init ‚â• 5 –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏</li>
      <li>[ ] –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å</li>
      <li>[ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å</li>
      <li>[ ] –û—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ</li>
      <li>[ ] –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã</li>
    </ul>
    <blockquote>
      ¬´GMM ‚Äî –º–æ—â–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –≥–æ—Ä–∞–∑–¥–æ –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, —á–µ–º –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π K-means, –∑–∞ —Å—á–µ—Ç –Ω–µ–±–æ–ª—å—à–æ–≥–æ —É–≤–µ–ª–∏—á–µ–Ω–∏—è –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏¬ª.
    </blockquote>
  </div>

  <div class="block">
    <h2>üîó –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏</h2>
    <ul>
      <li><a href="https://scikit-learn.org/stable/modules/mixture.html" target="_blank">üìö Scikit-learn: Gaussian Mixture Models</a></li>
      <li><a href="https://en.wikipedia.org/wiki/Mixture_model" target="_blank">üìù Wikipedia: Mixture model</a></li>
      <li><a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.12-gaussian-mixtures.html" target="_blank">üìñ Python Data Science Handbook: GMM</a></li>
    </ul>
  </div>

</div>
</body>
</html>
