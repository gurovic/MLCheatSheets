<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Curriculum Learning Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      
        min-width: 900px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

        .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üìö Curriculum Learning</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>


  <div class="block">
    <h2>üî∑ 1. –ß—Ç–æ —Ç–∞–∫–æ–µ Curriculum Learning</h2>
    <ul>
      <li><strong>–¶–µ–ª—å</strong>: –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å –æ—Ç –ø—Ä–æ—Å—Ç—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –∫ —Å–ª–æ–∂–Ω—ã–º</li>
      <li><strong>–ò–¥–µ—è</strong>: –∏–º–∏—Ç–∞—Ü–∏—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è</li>
      <li><strong>–†–µ–∑—É–ª—å—Ç–∞—Ç</strong>: –±—ã—Å—Ç—Ä–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å, –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ</li>
      <li><strong>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</strong>: CV, NLP, RL</li>
      <li><strong>–ö–ª—é—á–µ–≤—ã–µ –∞—Å–ø–µ–∫—Ç—ã</strong>: –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏, —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ</li>
    </ul>

  <div class="block">
    <h2>üî∑ 2. –û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏</h2>
    <p><strong>1. Predefined Curriculum</strong>:</p>
    <ul>
      <li>–ó–∞—Ä–∞–Ω–µ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫</li>
      <li>–û—Å–Ω–æ–≤–∞–Ω –Ω–∞ —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã—Ö –∑–Ω–∞–Ω–∏—è—Ö</li>
      <li>–ü—Ä–æ—Å—Ç–æ–π –≤ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏</li>
    </ul>
    <p><strong>2. Self-Paced Learning</strong>:</p>
    <ul>
      <li>–ú–æ–¥–µ–ª—å —Å–∞–º–∞ –≤—ã–±–∏—Ä–∞–µ—Ç –ø—Ä–∏–º–µ—Ä—ã</li>
      <li>–ù–∞ –æ—Å–Ω–æ–≤–µ loss –∏–ª–∏ confidence</li>
      <li>–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥</li>
    </ul>
    <p><strong>3. Transfer Teacher</strong>:</p>
    <ul>
      <li>–£—á–∏—Ç–µ–ª—å—Å–∫–∞—è –º–æ–¥–µ–ª—å –≤—ã–±–∏—Ä–∞–µ—Ç –ø—Ä–∏–º–µ—Ä—ã</li>
      <li>–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 3. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏</h2>
    <pre><code>import torch
import numpy as np

class CurriculumDataset(torch.utils.data.Dataset):
    def __init__(self, X, y, difficulty_fn):
        self.X = X
        self.y = y
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞
        self.difficulties = difficulty_fn(X, y)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        self.sorted_indices = np.argsort(self.difficulties)
        
        self.current_size = len(X) // 10  # –ù–∞—á–∏–Ω–∞–µ–º —Å 10%
    
    def set_curriculum_stage(self, stage):
        """–£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        max_size = len(self.X)
        self.current_size = min(
            int(max_size * (stage + 1) / 10), 
            max_size
        )
    
    def __len__(self):
        return self.current_size
    
    def __getitem__(self, idx):
        real_idx = self.sorted_indices[idx]
        return self.X[real_idx], self.y[real_idx]


# –ü—Ä–∏–º–µ—Ä—ã —Ñ—É–Ω–∫—Ü–∏–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
def difficulty_by_label_noise(X, y):
    """–°–ª–æ–∂–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —à—É–º–∞ –≤ –º–µ—Ç–∫–∞—Ö"""
    # –ë–æ–ª—å—à–µ —à—É–º–∞ = –≤—ã—à–µ —Å–ª–æ–∂–Ω–æ—Å—Ç—å
    return np.random.rand(len(X))

def difficulty_by_feature_variance(X, y):
    """–°–ª–æ–∂–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    return np.var(X, axis=1)

def difficulty_by_class_rarity(X, y):
    """–°–ª–æ–∂–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–¥–∫–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–∞"""
    unique, counts = np.unique(y, return_counts=True)
    class_difficulty = {
        cls: 1.0 / count 
        for cls, count in zip(unique, counts)
    }
    return np.array([class_difficulty[label] for label in y])</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. Baby Step Curriculum</h2>
    <pre><code>class BabyStepCurriculum:
    def __init__(self, model, train_loader, epochs_per_stage=10):
        self.model = model
        self.train_loader = train_loader
        self.epochs_per_stage = epochs_per_stage
        self.num_stages = 10
    
    def train(self):
        optimizer = torch.optim.Adam(
            self.model.parameters(), 
            lr=0.001
        )
        criterion = torch.nn.CrossEntropyLoss()
        
        for stage in range(self.num_stages):
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞
            self.train_loader.dataset.set_curriculum_stage(stage)
            
            print(f"Stage {stage+1}/{self.num_stages}")
            print(f"Training on {len(self.train_loader.dataset)} samples")
            
            # –û–±—É—á–∞–µ–º –Ω–∞ —Ç–µ–∫—É—â–µ–º —ç—Ç–∞–ø–µ
            for epoch in range(self.epochs_per_stage):
                self.model.train()
                total_loss = 0
                
                for batch_X, batch_y in self.train_loader:
                    optimizer.zero_grad()
                    outputs = self.model(batch_X)
                    loss = criterion(outputs, batch_y)
                    loss.backward()
                    optimizer.step()
                    
                    total_loss += loss.item()
                
                avg_loss = total_loss / len(self.train_loader)
                print(f"  Epoch {epoch+1}, Loss: {avg_loss:.4f}")


# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
dataset = CurriculumDataset(
    X_train, y_train, 
    difficulty_fn=difficulty_by_feature_variance
)
dataloader = torch.utils.data.DataLoader(
    dataset, batch_size=32, shuffle=True
)

curriculum = BabyStepCurriculum(model, dataloader)
curriculum.train()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. Self-Paced Learning</h2>
    <pre><code>class SelfPacedLearning:
    def __init__(self, model, train_data, lambda_init=1.0):
        self.model = model
        self.X, self.y = train_data
        self.lambda_param = lambda_init
        self.weights = np.ones(len(self.X))
    
    def update_weights(self, losses):
        """–û–±–Ω–æ–≤–ª—è–µ–º –≤–µ—Å–∞ –ø—Ä–∏–º–µ—Ä–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ loss"""
        # –í–µ—Å–∞ –±–æ–ª—å—à–µ –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ (–º–∞–ª—ã–π loss)
        self.weights = (losses < self.lambda_param).astype(float)
        
        # –ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º lambda
        # (–≤–∫–ª—é—á–∞–µ–º –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã)
        self.lambda_param *= 1.1
    
    def train_epoch(self):
        optimizer = torch.optim.Adam(
            self.model.parameters(), 
            lr=0.001
        )
        criterion = torch.nn.CrossEntropyLoss(reduction='none')
        
        self.model.train()
        losses = []
        
        for i in range(len(self.X)):
            if self.weights[i] > 0:  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ
                x = torch.FloatTensor(self.X[i]).unsqueeze(0)
                y = torch.LongTensor([self.y[i]])
                
                optimizer.zero_grad()
                output = self.model(x)
                loss = criterion(output, y)
                
                # –í–∑–≤–µ—à–µ–Ω–Ω—ã–π loss
                weighted_loss = loss * self.weights[i]
                weighted_loss.backward()
                optimizer.step()
                
                losses.append(loss.item())
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –≤–µ—Å–∞ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π —ç–ø–æ—Ö–∏
        self.update_weights(np.array(losses))
        
        return np.mean(losses)
    
    def train(self, num_epochs=50):
        for epoch in range(num_epochs):
            avg_loss = self.train_epoch()
            num_selected = np.sum(self.weights > 0)
            
            print(f"Epoch {epoch+1}: Loss={avg_loss:.4f}, "
                  f"Selected={num_selected}/{len(self.X)}, "
                  f"Lambda={self.lambda_param:.2f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. Curriculum –¥–ª—è NLP</h2>
    <pre><code># –°–ª–æ–∂–Ω–æ—Å—Ç—å –ø–æ –¥–ª–∏–Ω–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
def text_difficulty_by_length(texts):
    return np.array([len(text.split()) for text in texts])

# –°–ª–æ–∂–Ω–æ—Å—Ç—å –ø–æ —Ä–µ–¥–∫–æ—Å—Ç–∏ —Å–ª–æ–≤
def text_difficulty_by_vocabulary(texts, vocab_freq):
    difficulties = []
    for text in texts:
        words = text.split()
        # –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª-–≤–æ —Ä–µ–¥–∫–∏—Ö —Å–ª–æ–≤
        rare_count = sum(
            1 for w in words if vocab_freq.get(w, 0) < 100
        )
        difficulties.append(rare_count / len(words))
    return np.array(difficulties)

# –°–ª–æ–∂–Ω–æ—Å—Ç—å –ø–æ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
def text_difficulty_by_syntax(texts):
    """–ò—Å–ø–æ–ª—å–∑—É–µ–º spacy –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    import spacy
    nlp = spacy.load('en_core_web_sm')
    
    difficulties = []
    for text in texts:
        doc = nlp(text)
        # –ì–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        max_depth = max(
            len(list(token.ancestors)) for token in doc
        )
        difficulties.append(max_depth)
    
    return np.array(difficulties)


# Curriculum –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
class TextCurriculumDataset(torch.utils.data.Dataset):
    def __init__(self, texts, labels, tokenizer, difficulty='length'):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        
        # –í—ã–±–∏—Ä–∞–µ–º –º–µ—Ç—Ä–∏–∫—É —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        if difficulty == 'length':
            self.difficulties = text_difficulty_by_length(texts)
        # ... –¥—Ä—É–≥–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        
        self.sorted_indices = np.argsort(self.difficulties)
        self.current_size = len(texts) // 5
    
    def set_stage(self, stage):
        self.current_size = min(
            len(self.texts) * (stage + 1) // 5,
            len(self.texts)
        )
    
    def __getitem__(self, idx):
        real_idx = self.sorted_indices[idx]
        text = self.texts[real_idx]
        label = self.labels[real_idx]
        
        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=128,
            return_tensors='pt'
        )
        
        return {
            'input_ids': encoding['input_ids'].squeeze(),
            'attention_mask': encoding['attention_mask'].squeeze(),
            'labels': torch.tensor(label)
        }</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. Curriculum –¥–ª—è Computer Vision</h2>
    <pre><code>from PIL import Image, ImageFilter

# –°–ª–æ–∂–Ω–æ—Å—Ç—å –ø–æ —Ä–∞–∑–º—ã—Ç–æ—Å—Ç–∏
def image_difficulty_by_blur(images):
    difficulties = []
    for img in images:
        # –í–∞—Ä–∏–∞—Ü–∏—è –ª–∞–ø–ª–∞—Å–∏–∞–Ω–∞ (—Ä–∞–∑–º—ã—Ç–æ—Å—Ç—å)
        gray = img.convert('L')
        laplacian_var = np.array(
            gray.filter(ImageFilter.FIND_EDGES)
        ).var()
        difficulties.append(1.0 / (laplacian_var + 1))
    return np.array(difficulties)

# –°–ª–æ–∂–Ω–æ—Å—Ç—å –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –æ–±—ä–µ–∫—Ç–æ–≤
def image_difficulty_by_object_count(images, detector):
    """–ò—Å–ø–æ–ª—å–∑—É–µ–º object detector –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ –æ–±—ä–µ–∫—Ç–æ–≤"""
    difficulties = []
    for img in images:
        detections = detector(img)
        num_objects = len(detections)
        difficulties.append(num_objects)
    return np.array(difficulties)

# –°–ª–æ–∂–Ω–æ—Å—Ç—å –ø–æ —Ä–∞–∑–º–µ—Ä—É –æ–±—ä–µ–∫—Ç–æ–≤
def image_difficulty_by_object_size(images, bboxes):
    """–ú–µ–Ω—å—à–∏–π –æ–±—ä–µ–∫—Ç = –≤—ã—à–µ —Å–ª–æ–∂–Ω–æ—Å—Ç—å"""
    difficulties = []
    for bbox_list in bboxes:
        if len(bbox_list) == 0:
            difficulties.append(0)
        else:
            min_size = min(
                (x2-x1) * (y2-y1) 
                for x1, y1, x2, y2 in bbox_list
            )
            difficulties.append(1.0 / (min_size + 1))
    return np.array(difficulties)


# Progressive resizing - –ø–æ–ø—É–ª—è—Ä–Ω–∞—è —Ç–µ—Ö–Ω–∏–∫–∞
class ProgressiveResizeCurriculum:
    def __init__(self, model, start_size=64, end_size=224, stages=4):
        self.model = model
        self.sizes = np.linspace(start_size, end_size, stages).astype(int)
        self.current_stage = 0
    
    def get_transform(self):
        size = self.sizes[self.current_stage]
        return transforms.Compose([
            transforms.Resize(size),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])
    
    def next_stage(self):
        self.current_stage = min(
            self.current_stage + 1,
            len(self.sizes) - 1
        )
        print(f"Moving to stage {self.current_stage+1}, "
              f"size={self.sizes[self.current_stage]}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. Curriculum –¥–ª—è RL</h2>
    <pre><code>class CurriculumRL:
    """Curriculum –¥–ª—è Reinforcement Learning"""
    
    def __init__(self, env, agent, stages):
        self.env = env
        self.agent = agent
        self.stages = stages  # –°–ø–∏—Å–æ–∫ –Ω–∞—Å—Ç—Ä–æ–µ–∫ —Å—Ä–µ–¥—ã
        self.current_stage = 0
    
    def get_stage_env(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ä–µ–¥—É —Ç–µ–∫—É—â–µ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏"""
        stage_config = self.stages[self.current_stage]
        
        # –ü—Ä–∏–º–µ—Ä: –∏–∑–º–µ–Ω–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å—Ä–µ–¥—ã
        self.env.set_difficulty(stage_config['difficulty'])
        self.env.set_reward_shaping(stage_config['reward_scale'])
        
        return self.env
    
    def should_advance(self, performance_history):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —ç—Ç–∞–ø—É"""
        if len(performance_history) < 100:
            return False
        
        recent_performance = np.mean(performance_history[-100:])
        threshold = self.stages[self.current_stage]['threshold']
        
        return recent_performance >= threshold
    
    def train(self, num_episodes=10000):
        episode_rewards = []
        
        for episode in range(num_episodes):
            env = self.get_stage_env()
            state = env.reset()
            episode_reward = 0
            done = False
            
            while not done:
                action = self.agent.select_action(state)
                next_state, reward, done, _ = env.step(action)
                
                self.agent.update(state, action, reward, next_state, done)
                
                state = next_state
                episode_reward += reward
            
            episode_rewards.append(episode_reward)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —ç—Ç–∞–ø—É
            if self.should_advance(episode_rewards):
                if self.current_stage < len(self.stages) - 1:
                    self.current_stage += 1
                    print(f"Advanced to stage {self.current_stage+1}")
            
            if episode % 100 == 0:
                avg_reward = np.mean(episode_rewards[-100:])
                print(f"Episode {episode}, "
                      f"Avg Reward: {avg_reward:.2f}, "
                      f"Stage: {self.current_stage+1}")


# –ü—Ä–∏–º–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –∏–≥—Ä—ã
stages = [
    {'difficulty': 0.2, 'reward_scale': 1.5, 'threshold': 100},
    {'difficulty': 0.4, 'reward_scale': 1.2, 'threshold': 200},
    {'difficulty': 0.6, 'reward_scale': 1.0, 'threshold': 300},
    {'difficulty': 0.8, 'reward_scale': 1.0, 'threshold': 400},
    {'difficulty': 1.0, 'reward_scale': 1.0, 'threshold': 500}
]</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. Teacher-Student Curriculum</h2>
    <pre><code>class TeacherStudentCurriculum:
    """–£—á–∏—Ç–µ–ª—å –≤—ã–±–∏—Ä–∞–µ—Ç –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è —É—á–µ–Ω–∏–∫–∞"""
    
    def __init__(self, teacher_model, student_model, train_data):
        self.teacher = teacher_model
        self.student = student_model
        self.X, self.y = train_data
        
        # –£—á–∏—Ç–µ–ª—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω –Ω–∞ –ø–æ–ª–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self.teacher.eval()
    
    def select_samples(self, batch_size, difficulty_threshold):
        """–£—á–∏—Ç–µ–ª—å –≤—ã–±–∏—Ä–∞–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –ø—Ä–∏–º–µ—Ä—ã"""
        with torch.no_grad():
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —É—á–∏—Ç–µ–ª—è
            X_tensor = torch.FloatTensor(self.X)
            teacher_logits = self.teacher(X_tensor)
            teacher_probs = torch.softmax(teacher_logits, dim=1)
            
            # Confidence —É—á–∏—Ç–µ–ª—è
            confidences, _ = teacher_probs.max(dim=1)
            
            # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã —Å –ø–æ–¥—Ö–æ–¥—è—â–µ–π —Å–ª–æ–∂–Ω–æ—Å—Ç—å—é
            # –í—ã—Å–æ–∫–∏–π confidence = –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–º–µ—Ä
            mask = (confidences >= difficulty_threshold) &                    (confidences <= difficulty_threshold + 0.2)
            
            selected_indices = torch.where(mask)[0]
            
            if len(selected_indices) < batch_size:
                selected_indices = torch.randperm(len(self.X))[:batch_size]
            else:
                selected_indices = selected_indices[
                    torch.randperm(len(selected_indices))[:batch_size]
                ]
        
        return self.X[selected_indices], self.y[selected_indices]
    
    def train_student(self, num_epochs=50):
        optimizer = torch.optim.Adam(
            self.student.parameters(),
            lr=0.001
        )
        criterion = torch.nn.CrossEntropyLoss()
        
        # –ù–∞—á–∏–Ω–∞–µ–º —Å –≤—ã—Å–æ–∫–æ–≥–æ –ø–æ—Ä–æ–≥–∞ (–ø—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏–º–µ—Ä—ã)
        difficulty_threshold = 0.8
        
        for epoch in range(num_epochs):
            # –ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —Å–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ (–¥–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–∂–Ω—ã–µ)
            difficulty_threshold = max(0.3, 0.8 - epoch * 0.01)
            
            batch_X, batch_y = self.select_samples(
                batch_size=32,
                difficulty_threshold=difficulty_threshold
            )
            
            self.student.train()
            optimizer.zero_grad()
            
            outputs = self.student(torch.FloatTensor(batch_X))
            loss = criterion(outputs, torch.LongTensor(batch_y))
            
            loss.backward()
            optimizer.step()
            
            if epoch % 10 == 0:
                print(f"Epoch {epoch}, Loss: {loss.item():.4f}, "
                      f"Difficulty: {difficulty_threshold:.2f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã</h2>
    <ul>
      <li><strong>–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏</strong>: domain-specific –º–µ—Ç—Ä–∏–∫–∏</li>
      <li><strong>–°–∫–æ—Ä–æ—Å—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å–∞</strong>: –Ω–µ —Å–ª–∏—à–∫–æ–º –±—ã—Å—Ç—Ä–æ/–º–µ–¥–ª–µ–Ω–Ω–æ</li>
      <li><strong>–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥</strong>: –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ</li>
      <li><strong>–ê–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—å</strong>: self-paced –ª—É—á—à–µ fixed curriculum</li>
      <li><strong>Transfer</strong>: curriculum –ø–æ–º–æ–≥–∞–µ—Ç transfer learning</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 11. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–æ–≤</h2>
    <table>
      <tr><th>–ú–µ—Ç–æ–¥</th><th>–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è</th><th>–°–ª–æ–∂–Ω–æ—Å—Ç—å</th><th>–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å</th></tr>
      <tr><td><strong>Predefined</strong></td><td>‚ùå</td><td>–ù–∏–∑–∫–∞—è</td><td>–°—Ä–µ–¥–Ω—è—è</td></tr>
      <tr><td><strong>Self-Paced</strong></td><td>‚úÖ</td><td>–°—Ä–µ–¥–Ω—è—è</td><td>–í—ã—Å–æ–∫–∞—è</td></tr>
      <tr><td><strong>Teacher-Student</strong></td><td>‚úÖ</td><td>–í—ã—Å–æ–∫–∞—è</td><td>–û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è</td></tr>
      <tr><td><strong>RL Curriculum</strong></td><td>‚ö†Ô∏è</td><td>–í—ã—Å–æ–∫–∞—è</td><td>–í—ã—Å–æ–∫–∞—è</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 12. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –•–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç</h3>
        <ul>
          <li>–°–ª–æ–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏ —Å —á–µ—Ç–∫–æ–π –≥—Ä–∞–¥–∞—Ü–∏–µ–π</li>
          <li>Reinforcement Learning</li>
          <li>Few-shot learning</li>
          <li>Domain adaptation</li>
          <li>Noisy labels</li>
          <li>Imbalanced datasets</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ùå –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è</h3>
        <ul>
          <li>–°–ª–æ–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–µ—Ç—Ä–∏–∫—É —Å–ª–æ–∂–Ω–æ—Å—Ç–∏</li>
          <li>–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã</li>
          <li>–ú–æ–∂–µ—Ç –∑–∞–º–µ–¥–ª–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ</li>
          <li>–¢—Ä–µ–±—É–µ—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 13. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–µ—Ç—Ä–∏–∫—É —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–º–µ—Ä–æ–≤</li>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é curriculum (predefined/self-paced)</li>
      <li>[ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏</li>
      <li>[ ] –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ</li>
      <li>[ ] –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å —Å–∫–æ—Ä–æ—Å—Ç—å—é –ø—Ä–æ–≥—Ä–µ—Å—Å–∞</li>
      <li>[ ] –°—Ä–∞–≤–Ω–∏—Ç—å —Å baseline –±–µ–∑ curriculum</li>
      <li>[ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ validation set</li>
      <li>[ ] –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è</li>
      <li>[ ] –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´Curriculum Learning ‚Äî —ç—Ç–æ –∫–∞–∫ –æ–±—É—á–µ–Ω–∏–µ –≤ —à–∫–æ–ª–µ: —Å–Ω–∞—á–∞–ª–∞ –∏–∑—É—á–∞–µ–º –ø—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏–º–µ—Ä—ã, –ø–æ—Ç–æ–º –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–º. –≠—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç –º–æ–¥–µ–ª–∏ –±—ã—Å—Ç—Ä–µ–µ —É—á–∏—Ç—å—Å—è –∏ –¥–æ—Å—Ç–∏–≥–∞—Ç—å –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤¬ª.
    </blockquote>
  </div>


</div>

</div>
</body>
</html>
