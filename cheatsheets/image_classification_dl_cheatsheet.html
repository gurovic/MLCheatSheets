<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (Deep Learning) Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen { body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif; color: #333; background: #fafcff; padding: 10px; } }
    @media print { body { background: white; padding: 0; } @page { size: A4 landscape; margin: 10mm; } }
    .container { column-count: 3; column-gap: 20px; max-width: 100%; }
    .block { break-inside: avoid; margin-bottom: 1.2em; padding: 12px; background: white; border-radius: 6px; box-shadow: 0 1px 3px rgba(0,0,0,0.05); }
    h1 { font-size: 1.6em; font-weight: 700; color: #1a5fb4; text-align: center; margin: 0 0 8px; column-span: all; }
    .subtitle { text-align: center; color: #666; font-size: 0.9em; margin-bottom: 12px; column-span: all; }
    h2 { font-size: 1.15em; font-weight: 700; color: #1a5fb4; margin: 0 0 8px; padding-bottom: 4px; border-bottom: 1px solid #e0e7ff; }
    p, ul, ol { font-size: 0.92em; margin: 0.6em 0; }
    ul, ol { padding-left: 18px; }
    li { margin-bottom: 4px; }
    code { font-family: 'Consolas', 'Courier New', monospace; background-color: #f0f4ff; padding: 1px 4px; border-radius: 3px; font-size: 0.88em; }
    pre { background-color: #f0f4ff; padding: 8px; border-radius: 4px; overflow-x: auto; font-size: 0.84em; margin: 6px 0; }
    pre code { padding: 0; background: none; white-space: pre-wrap; }
    table { width: 100%; border-collapse: collapse; font-size: 0.82em; margin: 6px 0; }
    th { background-color: #e6f0ff; text-align: left; padding: 4px 6px; font-weight: 600; }
    td { padding: 4px 6px; border-bottom: 1px solid #f0f4ff; }
    tr:nth-child(even) { background-color: #f8fbff; }
    blockquote { font-style: italic; margin: 8px 0; padding: 6px 10px; background: #f8fbff; border-left: 2px solid #1a5fb4; font-size: 0.88em; }
  </style>
</head>
<body>
<div class="container">
  <h1>üñºÔ∏è –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (Deep Learning)</h1>
  <div class="subtitle"></div>
  
  <div class="block">
    <h2>üî∑ 1. –ë–∞–∑–æ–≤–∞—è CNN –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞</h2>
    <pre><code>import tensorflow as tf
from tensorflow.keras import layers, models

model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', 
                  input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(num_classes, activation='softmax')
])

model.compile(optimizer='adam',
             loss='categorical_crossentropy',
             metrics=['accuracy'])</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 2. Data Augmentation</h2>
    <pre><code>from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    zoom_range=0.2,
    fill_mode='nearest'
)

# Augmentation –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
train_generator = datagen.flow_from_directory(
    'train/',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 3. Transfer Learning</h2>
    <pre><code>from tensorflow.keras.applications import ResNet50

# –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
base_model = ResNet50(weights='imagenet',
                     include_top=False,
                     input_shape=(224, 224, 3))

# –ó–∞–º–æ—Ä–æ–∑–∏—Ç—å –≤–µ—Å–∞ base model
base_model.trainable = False

# –î–æ–±–∞–≤–∏—Ç—å —Å–≤–æ–∏ —Å–ª–æ–∏
model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(num_classes, activation='softmax')
])

model.compile(optimizer='adam',
             loss='categorical_crossentropy',
             metrics=['accuracy'])</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. Fine-tuning</h2>
    <pre><code># –ü–æ—Å–ª–µ initial training
# –†–∞–∑–º–æ—Ä–æ–∑–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–ª–æ–∏
base_model.trainable = True

# –ó–∞–º–æ—Ä–æ–∑–∏—Ç—å —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ —Å–ª–æ–∏
for layer in base_model.layers[:-20]:
    layer.trainable = False

# –ü–µ—Ä–µ–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞—Ç—å —Å –Ω–∏–∑–∫–∏–º learning rate
model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),
             loss='categorical_crossentropy',
             metrics=['accuracy'])

# Fine-tune
model.fit(train_ds, epochs=10, validation_data=val_ds)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã</h2>
    <table>
      <tr><th>–ú–æ–¥–µ–ª—å</th><th>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã</th><th>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</th></tr>
      <tr><td>ResNet50</td><td>25M</td><td>General purpose</td></tr>
      <tr><td>MobileNetV2</td><td>3.5M</td><td>Mobile, edge</td></tr>
      <tr><td>EfficientNetB0</td><td>5.3M</td><td>–õ—É—á—à–∏–π –±–∞–ª–∞–Ω—Å</td></tr>
      <tr><td>VGG16</td><td>138M</td><td>Feature extraction</td></tr>
      <tr><td>InceptionV3</td><td>24M</td><td>Multi-scale</td></tr>
    </table>
    <pre><code>from tensorflow.keras.applications import (
    ResNet50, MobileNetV2, EfficientNetB0
)

# –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
base = EfficientNetB0(weights='imagenet', include_top=False)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. Callbacks</h2>
    <pre><code>from tensorflow.keras.callbacks import (
    ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
)

callbacks = [
    ModelCheckpoint('best_model.h5', save_best_only=True),
    EarlyStopping(patience=10, restore_best_weights=True),
    ReduceLROnPlateau(factor=0.5, patience=5)
]

model.fit(train_ds, epochs=100, 
         validation_data=val_ds,
         callbacks=callbacks)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. Preprocessing</h2>
    <pre><code>from tensorflow.keras.applications.resnet50 import preprocess_input

# –î–ª—è –∫–∞–∂–¥–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å–≤–æ–π preprocessing
# ResNet: scale to [-1, 1]
# Inception: scale to [-1, 1]
# VGG: subtract mean RGB

img = tf.keras.preprocessing.image.load_img('image.jpg',
                                            target_size=(224, 224))
img_array = tf.keras.preprocessing.image.img_to_array(img)
img_array = tf.expand_dims(img_array, 0)
img_array = preprocess_input(img_array)

predictions = model.predict(img_array)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (Grad-CAM)</h2>
    <pre><code>import numpy as np

def grad_cam(model, img_array, layer_name):
    grad_model = tf.keras.models.Model(
        [model.inputs],
        [model.get_layer(layer_name).output, model.output]
    )
    
    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_array)
        loss = predictions[:, np.argmax(predictions[0])]
    
    grads = tape.gradient(loss, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    
    heatmap = conv_outputs[0] @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    
    return heatmap.numpy()

heatmap = grad_cam(model, img_array, 'conv5_block3_out')</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏</h2>
    <pre><code>from sklearn.metrics import classification_report, confusion_matrix

y_pred = model.predict(test_ds)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = test_ds.classes

print(classification_report(y_true, y_pred_classes))

# Top-k accuracy
top_5_acc = tf.keras.metrics.TopKCategoricalAccuracy(k=5)
top_5_acc.update_state(y_true_onehot, y_pred)
print(f"Top-5 Accuracy: {top_5_acc.result().numpy():.3f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ</li>
      <li>[ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å data augmentation</li>
      <li>[ ] Transfer learning —Å pretrained –º–æ–¥–µ–ª—å—é</li>
      <li>[ ] Fine-tuning —Å –Ω–∏–∑–∫–∏–º LR</li>
      <li>[ ] Early stopping –∏ checkpointing</li>
      <li>[ ] –ü—Ä–æ–≤–µ—Ä—è—Ç—å –Ω–∞ test set</li>
      <li>[ ] –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è</li>
      <li>[ ] Grad-CAM –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏</li>
      <li>[ ] –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å val_accuracy</li>
      <li>[ ] –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è deployment</li>
    </ul>
    <blockquote>
      ¬´Transfer learning ‚Äî –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∑–Ω–∞–Ω–∏–π, –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –Ω–∞ ImageNet (–º–∏–ª–ª–∏–æ–Ω—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π), –¥–ª—è –≤–∞—à–µ–π –∑–∞–¥–∞—á–∏. –≠—Ç–æ –∫–∞–∫ –Ω–∞–Ω—è—Ç—å —ç–∫—Å–ø–µ—Ä—Ç–∞ –≤–º–µ—Å—Ç–æ –æ–±—É—á–µ–Ω–∏—è –Ω–æ–≤–∏—á–∫–∞ —Å –Ω—É–ª—è¬ª.
    </blockquote>
  </div>


</div>
</body>
</html>
