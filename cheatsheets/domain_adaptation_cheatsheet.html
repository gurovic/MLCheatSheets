<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>Domain Adaptation Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen { body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif; color: #333; background: #fafcff; padding: 10px; } }
    @media print { body { background: white; padding: 0; } @page { size: A4 landscape; margin: 10mm; } }
    .container { column-count: 3; column-gap: 20px; max-width: 100%; }
    .block { break-inside: avoid; margin-bottom: 1.2em; padding: 12px; background: white; border-radius: 6px; box-shadow: 0 1px 3px rgba(0,0,0,0.05); }
    h1 { font-size: 1.6em; font-weight: 700; color: #1a5fb4; text-align: center; margin: 0 0 8px; column-span: all; }
    .subtitle { text-align: center; color: #666; font-size: 0.9em; margin-bottom: 12px; column-span: all; }
    h2 { font-size: 1.15em; font-weight: 700; color: #1a5fb4; margin: 0 0 8px; padding-bottom: 4px; border-bottom: 1px solid #e0e7ff; }
    p, ul, ol { font-size: 0.92em; margin: 0.6em 0; }
    ul, ol { padding-left: 18px; }
    li { margin-bottom: 4px; }
    code { font-family: 'Consolas', 'Courier New', monospace; background-color: #f0f4ff; padding: 1px 4px; border-radius: 3px; font-size: 0.88em; }
    pre { background-color: #f0f4ff; padding: 8px; border-radius: 4px; overflow-x: auto; font-size: 0.84em; margin: 6px 0; }
    pre code { padding: 0; background: none; white-space: pre-wrap; }
    table { width: 100%; border-collapse: collapse; font-size: 0.82em; margin: 6px 0; }
    th { background-color: #e6f0ff; text-align: left; padding: 4px 6px; font-weight: 600; }
    td { padding: 4px 6px; border-bottom: 1px solid #f0f4ff; }
    tr:nth-child(even) { background-color: #f8fbff; }
    .good-vs-bad { display: flex; flex-direction: column; gap: 8px; }
    .good-vs-bad div { flex: 1; padding: 6px 8px; border-radius: 4px; }
    .good { background-color: #f0f9f4; border-left: 3px solid #2e8b57; }
    .bad { background-color: #fdf0f2; border-left: 3px solid #d32f2f; }
    .good h3, .bad h3 { margin: 0 0 4px; font-size: 1em; font-weight: 700; }
    .good ul, .bad ul { padding-left: 20px; margin: 0; }
    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }
    blockquote { font-style: italic; margin: 8px 0; padding: 6px 10px; background: #f8fbff; border-left: 2px solid #1a5fb4; font-size: 0.88em; }
    @media print { .container { column-gap: 12px; } .block { box-shadow: none; } code, pre, table { font-size: 0.78em; } h1 { font-size: 1.4em; } h2 { font-size: 1em; } }
  </style>
</head>
<body>
<div class="container">
  <h1>Domain Adaptation</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>
  <div class="block">
    <h2>üî∑ 1. –°—É—Ç—å</h2>
    <ul>
      <li><strong>–ü—Ä–æ–±–ª–µ–º–∞</strong>: –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ source –¥–æ–º–µ–Ω–µ, –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ target</li>
      <li><strong>Domain shift</strong>: P_source(X) ‚â† P_target(X)</li>
      <li><strong>–¶–µ–ª—å</strong>: –∞–¥–∞–ø—Ç–∞—Ü–∏—è –±–µ–∑ –º–µ—Ç–æ–∫ (–∏–ª–∏ —Å –º–∏–Ω–∏–º—É–º–æ–º) –≤ target</li>
      <li><strong>–ü–æ–¥—Ö–æ–¥—ã</strong>: feature alignment, adversarial methods, self-training</li>
    </ul>  </div>

  <div class="block">
    <h2>üî∑ 2. –¢–∏–ø—ã –∑–∞–¥–∞—á</h2>
    <table>
      <tr><th>–¢–∏–ø</th><th>–î–∞–Ω–Ω—ã–µ target</th><th>–ú–µ—Ç–æ–¥—ã</th></tr>
      <tr><td><strong>Unsupervised DA</strong></td><td>–ù–µ—Ç –º–µ—Ç–æ–∫</td><td>DANN, ADDA, CORAL</td></tr>
      <tr><td><strong>Semi-supervised DA</strong></td><td>–ù–µ–º–Ω–æ–≥–æ –º–µ—Ç–æ–∫</td><td>MME, CDAC</td></tr>
      <tr><td><strong>Open-set DA</strong></td><td>–ù–æ–≤—ã–µ –∫–ª–∞—Å—Å—ã</td><td>OSBP, STA</td></tr>
      <tr><td><strong>Multi-source DA</strong></td><td>–ú–Ω–æ–≥–æ source</td><td>MDAN, M3SDA</td></tr>
    </table>  </div>

  <div class="block">
    <h2>üî∑ 3. DANN (Domain Adversarial NN)</h2>
    <pre><code>import torch.nn as nn

class DANN(nn.Module):
    def __init__(self):
        super().__init__()
        self.feature_extractor = nn.Sequential(...)
        self.classifier = nn.Linear(256, num_classes)
        self.domain_classifier = nn.Sequential(
            nn.Linear(256, 100),
            nn.ReLU(),
            nn.Linear(100, 1)
        )
    
    def forward(self, x, alpha=1.0):
        features = self.feature_extractor(x)
        # Gradient reversal layer
        features_reversed = GradientReversalLayer.apply(features, alpha)
        class_pred = self.classifier(features)
        domain_pred = self.domain_classifier(features_reversed)
        return class_pred, domain_pred</code></pre>  </div>

  <div class="block">
    <h2>üî∑ 4. CORAL (Correlation Alignment)</h2>
    <p><strong>–ò–¥–µ—è</strong>: –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π source –∏ target</p>
    <pre><code>def coral_loss(source_features, target_features):
    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω—ã—Ö –º–∞—Ç—Ä–∏—Ü
    source_cov = torch.cov(source_features.T)
    target_cov = torch.cov(target_features.T)
    
    # CORAL loss = Frobenius norm —Ä–∞–∑–Ω–æ—Å—Ç–∏
    loss = torch.norm(source_cov - target_cov, p="fro")
    return loss

# –í –æ–±—É—á–µ–Ω–∏–∏
loss = classification_loss + lambda_coral * coral_loss(src_feat, tgt_feat)</code></pre>  </div>

  <div class="block">
    <h2>üî∑ 5. Self-training</h2>
    <p><strong>–ü—Å–µ–≤–¥–æ-–º–µ—Ç–∫–∏ –¥–ª—è target –¥–æ–º–µ–Ω–∞</strong></p>
    <pre><code># –®–∞–≥ 1: –æ–±—É—á–∏—Ç—å –Ω–∞ source
model.train_on_source(source_data, source_labels)

# –®–∞–≥ 2: –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –Ω–∞ target —Å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
model.eval()
with torch.no_grad():
    preds = model(target_data)
    probs = F.softmax(preds, dim=1)
    confidence, pseudo_labels = probs.max(dim=1)
    
# –®–∞–≥ 3: –æ—Ç–æ–±—Ä–∞—Ç—å —É–≤–µ—Ä–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
mask = confidence > 0.95
target_confident = target_data[mask]
pseudo_labels_confident = pseudo_labels[mask]

# –®–∞–≥ 4: –¥–æ–æ–±—É—á–∏—Ç—å –Ω–∞ target —Å –ø—Å–µ–≤–¥–æ-–º–µ—Ç–∫–∞–º–∏
model.train_on_target(target_confident, pseudo_labels_confident)</code></pre>  </div>

  <div class="block">
    <h2>üî∑ 6. MMD (Maximum Mean Discrepancy)</h2>
    <p><strong>–ú–µ—Ç—Ä–∏–∫–∞ —Ä–∞–∑–ª–∏—á–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π</strong></p>
    <pre><code>def mmd_loss(source_features, target_features):
    # Kernel Mean Embedding
    xx = torch.mm(source_features, source_features.t())
    yy = torch.mm(target_features, target_features.t())
    xy = torch.mm(source_features, target_features.t())
    
    # RBF kernel
    def rbf_kernel(x, sigma=1.0):
        return torch.exp(-x / (2 * sigma**2))
    
    K_xx = rbf_kernel(xx)
    K_yy = rbf_kernel(yy)
    K_xy = rbf_kernel(xy)
    
    # MMD^2
    mmd = K_xx.mean() + K_yy.mean() - 2 * K_xy.mean()
    return mmd</code></pre>  </div>

  <div class="block">
    <h2>üî∑ 7. –î–∞—Ç–∞—Å–µ—Ç—ã</h2>
    <table>
      <tr><th>–î–∞—Ç–∞—Å–µ—Ç</th><th>–î–æ–º–µ–Ω—ã</th><th>–ó–∞–¥–∞—á–∞</th></tr>
      <tr><td><strong>Office-31</strong></td><td>Amazon, DSLR, Webcam</td><td>–û–±—ä–µ–∫—Ç—ã –æ—Ñ–∏—Å–∞</td></tr>
      <tr><td><strong>VisDA</strong></td><td>Synthetic ‚Üí Real</td><td>–í–∏–∑—É–∞–ª—å–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è</td></tr>
      <tr><td><strong>DomainNet</strong></td><td>6 –¥–æ–º–µ–Ω–æ–≤</td><td>–ë–æ–ª—å—à–æ–π multi-domain</td></tr>
      <tr><td><strong>PACS</strong></td><td>Photo, Art, Cartoon, Sketch</td><td>Domain generalization</td></tr>
    </table>  </div>

  <div class="block">
    <h2>üî∑ 8. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è</h3>
        <ul>
          <li>–í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å feature distributions (t-SNE)</li>
          <li>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å pre-trained —ç–Ω–∫–æ–¥–µ—Ä—ã</li>
          <li>–ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å –≤–µ—Å domain loss</li>
          <li>–í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ target domain</li>
          <li>Self-training —Å –≤—ã—Å–æ–∫–∏–º –ø–æ—Ä–æ–≥–æ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ùå –ò–∑–±–µ–≥–∞—Ç—å</h3>
        <ul>
          <li>–ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ label shift</li>
          <li>–°–ª–∏—à–∫–æ–º –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è</li>
          <li>–í–∞–ª–∏–¥–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –Ω–∞ source</li>
          <li>–ù–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –ø—Å–µ–≤–¥–æ-–º–µ—Ç–æ–∫</li>
        </ul>
      </div>
    </div>  </div>

  <div class="block">
    <h2>üî∑ 9. –ú–µ—Ç—Ä–∏–∫–∏ –∏ –æ—Ü–µ–Ω–∫–∞</h2>
    <ul>
      <li><strong>Target accuracy</strong>: –≥–ª–∞–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞</li>
      <li><strong>A-distance</strong>: –∏–∑–º–µ—Ä–µ–Ω–∏–µ domain shift</li>
      <li><strong>Feature visualization</strong>: t-SNE, UMAP –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏</li>
      <li><strong>Per-class analysis</strong>: –∫–∞–∫–∏–µ –∫–ª–∞—Å—Å—ã —Ö—É–∂–µ –∞–¥–∞–ø—Ç–∏—Ä—É—é—Ç—Å—è</li>
    </ul>
    <pre><code># A-distance –º–µ–∂–¥—É –¥–æ–º–µ–Ω–∞–º–∏
def compute_a_distance(source_feat, target_feat):
    # –û–±—É—á–∏—Ç—å –±–∏–Ω–∞—Ä–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ä–∞–∑–ª–∏—á–∞—Ç—å –¥–æ–º–µ–Ω—ã
    X = torch.cat([source_feat, target_feat])
    y = torch.cat([torch.zeros(len(source_feat)), 
                   torch.ones(len(target_feat))])
    
    from sklearn.linear_model import LogisticRegression
    clf = LogisticRegression().fit(X.cpu(), y.cpu())
    acc = clf.score(X.cpu(), y.cpu())
    
    # A-distance = 2(1 - 2*error)
    a_dist = 2 * (1 - 2 * (1 - acc))
    return a_dist</code></pre>  </div>

  <div class="block">
    <h2>üî∑ 10. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å domain shift (–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è)</li>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å –º–µ—Ç–æ–¥ (unsupervised/semi-supervised)</li>
      <li>[ ] –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å source –∏ target –¥–∞–Ω–Ω—ã–µ</li>
      <li>[ ] –û–±—É—á–∏—Ç—å baseline (—Ç–æ–ª—å–∫–æ –Ω–∞ source)</li>
      <li>[ ] –ü—Ä–∏–º–µ–Ω–∏—Ç—å domain adaptation</li>
      <li>[ ] –û—Ü–µ–Ω–∏—Ç—å –Ω–∞ target test set</li>
      <li>[ ] –ü—Ä–æ–≤–µ—Å—Ç–∏ ablation studies</li>
      <li>[ ] –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (t-SNE)</li>
      <li>[ ] –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ –∫–ª–∞—Å—Å–∞–º</li>
    </ul>
    <blockquote>
      üí° <strong>–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</strong> "–ú–æ–¥–µ–ª—å —É—á–∏–ª–∞—Å—å –Ω–∞ –æ–¥–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–∞—Ä—Ç–∏–Ω–∫–∞—Ö —Å Amazon), –Ω–æ –Ω—É–∂–Ω–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –Ω–∞ –¥—Ä—É–≥–∏—Ö (—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ —Å –∫–∞–º–µ—Ä—ã). Domain adaptation –ø–æ–º–æ–≥–∞–µ—Ç –º–æ–¥–µ–ª–∏ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è –∫ –Ω–æ–≤—ã–º —É—Å–ª–æ–≤–∏—è–º –±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è".
    </blockquote>  </div>

</div>
</body>
</html>