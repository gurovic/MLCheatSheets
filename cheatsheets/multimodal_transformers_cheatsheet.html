<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

    .container {
      column-count: 3;
      column-gap: 20px;
      max-width: 100%;
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üîÑ –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã Cheatsheet</h1>
  <div class="subtitle">Multi-modal Transformers ‚Ä¢ Cross-attention ‚Ä¢ Unified models<br>üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –°—É—Ç—å</h2>
    <ul>
      <li><strong>–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞</strong>: Transformer –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π</li>
      <li><strong>–ö–ª—é—á</strong>: cross-attention –º–µ–∂–¥—É –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—è–º–∏</li>
      <li><strong>–¶–µ–ª—å</strong>: –µ–¥–∏–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è vision + language + audio</li>
      <li><strong>–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ</strong>: –æ–±—â–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è, transfer learning</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 2. –ö–ª—é—á–µ–≤—ã–µ –º–æ–¥–µ–ª–∏</h2>
    <table>
      <tr><th>–ú–æ–¥–µ–ª—å</th><th>–ú–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏</th><th>–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏</th></tr>
      <tr><td><strong>ViLT</strong></td><td>Vision+Text</td><td>Single-stream –±–µ–∑ CNN</td></tr>
      <tr><td><strong>ViLBERT</strong></td><td>Vision+Text</td><td>Dual-stream —Å cross-attention</td></tr>
      <tr><td><strong>UNITER</strong></td><td>Vision+Text</td><td>Universal image-text representation</td></tr>
      <tr><td><strong>Flamingo</strong></td><td>Vision+Text</td><td>Few-shot learning (DeepMind)</td></tr>
      <tr><td><strong>BLIP-2</strong></td><td>Vision+Text</td><td>Q-Former architecture</td></tr>
      <tr><td><strong>ImageBind</strong></td><td>6 –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π</td><td>Unified embedding (Meta)</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 3. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã</h2>
    <p><strong>Single-stream (ViLT)</strong></p>
    <ul>
      <li>–í—Å–µ –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏ –≤ –æ–¥–Ω–æ–º Transformer</li>
      <li>–ü—Ä–æ—Å—Ç–æ—Ç–∞, –º–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</li>
      <li>–õ–∏–Ω–µ–π–Ω—ã–µ –ø—Ä–æ–µ–∫—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏</li>
    </ul>
    <p><strong>Dual-stream (ViLBERT)</strong></p>
    <ul>
      <li>–û—Ç–¥–µ–ª—å–Ω—ã–µ —ç–Ω–∫–æ–¥–µ—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏</li>
      <li>Cross-attention –º–µ–∂–¥—É –ø–æ—Ç–æ–∫–∞–º–∏</li>
      <li>–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∏ –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π</li>
    </ul>
    <p><strong>Fusion Transformer</strong></p>
    <ul>
      <li>–ü–æ–∑–¥–Ω–∏–π fusion —á–µ—Ä–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π Transformer</li>
      <li>–ì–∏–±–∫–æ—Å—Ç—å –≤ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 4. ViLT ‚Äî –ø—Ä–∏–º–µ—Ä –∫–æ–¥–∞</h2>
    <pre><code>from transformers import ViltProcessor, ViltModel
from PIL import Image

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
processor = ViltProcessor.from_pretrained("dandelin/vilt-b32-mlm")
model = ViltModel.from_pretrained("dandelin/vilt-b32-mlm")

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
image = Image.open("photo.jpg")
text = "a photo of a cat"

inputs = processor(image, text, return_tensors="pt")

# Forward pass
outputs = model(**inputs)

# Pooled output (–¥–ª—è –∑–∞–¥–∞—á –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏)
pooled_output = outputs.pooler_output  # [batch, hidden_dim]

# –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–¥–ª—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á)
sequence_output = outputs.last_hidden_state  # [batch, seq_len, hidden_dim]</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. Cross-modal Attention</h2>
    <pre><code>import torch
import torch.nn as nn

class CrossModalAttention(nn.Module):
    def __init__(self, dim, num_heads=8):
        super().__init__()
        self.multihead_attn = nn.MultiheadAttention(
            dim, num_heads, batch_first=True
        )
        self.norm1 = nn.LayerNorm(dim)
        self.norm2 = nn.LayerNorm(dim)
        self.ffn = nn.Sequential(
            nn.Linear(dim, dim * 4),
            nn.GELU(),
            nn.Linear(dim * 4, dim)
        )
    
    def forward(self, query_modal, key_value_modal):
        # Query –∏–∑ –æ–¥–Ω–æ–π –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏, K,V –∏–∑ –¥—Ä—É–≥–æ–π
        attn_out, _ = self.multihead_attn(
            query_modal, 
            key_value_modal, 
            key_value_modal
        )
        x = self.norm1(query_modal + attn_out)
        
        # Feed-forward
        ffn_out = self.ffn(x)
        x = self.norm2(x + ffn_out)
        
        return x</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. Tokenization —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏</h2>
    <p><strong>Vision tokens</strong></p>
    <ul>
      <li><strong>Patch embedding</strong>: —Ä–∞–∑–±–∏–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –ø–∞—Ç—á–∏ (ViT-style)</li>
      <li><strong>ROI features</strong>: —Ä–µ–≥–∏–æ–Ω—ã –∏–Ω—Ç–µ—Ä–µ—Å–∞ (Faster R-CNN)</li>
      <li><strong>Grid features</strong>: —Å–µ—Ç–∫–∞ —Ñ–∏—á–µ–π –∏–∑ CNN</li>
    </ul>
    <p><strong>Text tokens</strong></p>
    <ul>
      <li><strong>WordPiece/BPE</strong>: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è</li>
      <li><strong>Special tokens</strong>: [CLS], [SEP], [MASK]</li>
    </ul>
    <pre><code># –ü—Ä–∏–º–µ—Ä –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤
def create_multimodal_input(image_patches, text_tokens):
    # [CLS] + image_patches + [SEP] + text_tokens + [SEP]
    cls_token = torch.tensor([[CLS_ID]])
    sep_token = torch.tensor([[SEP_ID]])
    
    combined = torch.cat([
        cls_token,
        image_patches,
        sep_token,
        text_tokens,
        sep_token
    ], dim=1)
    
    return combined</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. Positional Encoding</h2>
    <p><strong>–î–ª—è —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π</strong></p>
    <pre><code>class MultiModalPositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=512):
        super().__init__()
        # –û—Ç–¥–µ–ª—å–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Ç–∏–ø–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤
        self.text_pos_emb = nn.Embedding(max_len, d_model)
        self.image_pos_emb = nn.Embedding(max_len, d_model)
        # Type embeddings
        self.type_emb = nn.Embedding(3, d_model)  # 0:text, 1:image, 2:cls
    
    def forward(self, tokens, token_types):
        positions = torch.arange(len(tokens))
        
        # –ü–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–µ + type —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        pos_embed = self.text_pos_emb(positions) * (token_types == 0).float() + \
                    self.image_pos_emb(positions) * (token_types == 1).float()
        
        type_embed = self.type_emb(token_types)
        
        return tokens + pos_embed + type_embed</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. Pre-training –∑–∞–¥–∞—á–∏</h2>
    <table>
      <tr><th>–ó–∞–¥–∞—á–∞</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th></tr>
      <tr><td><strong>MLM</strong></td><td>Masked Language Modeling (—Ç–µ–∫—Å—Ç)</td></tr>
      <tr><td><strong>MIM</strong></td><td>Masked Image Modeling (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)</td></tr>
      <tr><td><strong>ITM</strong></td><td>Image-Text Matching (—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ)</td></tr>
      <tr><td><strong>WPA</strong></td><td>Word-Patch Alignment</td></tr>
      <tr><td><strong>Contrastive</strong></td><td>CLIP-style contrastive learning</td></tr>
    </table>
    <pre><code># Image-Text Matching loss
def itm_loss(pooled_output, labels):
    """
    labels: 1 –µ—Å–ª–∏ –ø–∞—Ä–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç, 0 –µ—Å–ª–∏ –Ω–µ—Ç
    """
    classifier = nn.Linear(pooled_output.size(-1), 2)
    logits = classifier(pooled_output)
    loss = F.cross_entropy(logits, labels)
    return loss</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. BLIP-2 Q-Former</h2>
    <p><strong>–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± —Å–≤—è–∑–∞—Ç—å frozen —ç–Ω–∫–æ–¥–µ—Ä—ã</strong></p>
    <ul>
      <li>Learnable query tokens –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É—é—Ç —Å image features</li>
      <li>–ù–µ –Ω—É–∂–Ω–æ fine-tuning —Ç—è–∂–µ–ª—ã—Ö —ç–Ω–∫–æ–¥–µ—Ä–æ–≤</li>
      <li>–õ–µ–≥–∫–æ –ø–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ —Ä–∞–∑–Ω—ã–º LLM</li>
    </ul>
    <pre><code>class QFormer(nn.Module):
    def __init__(self, num_queries=32, dim=768):
        super().__init__()
        self.queries = nn.Parameter(torch.randn(1, num_queries, dim))
        self.cross_attn_layers = nn.ModuleList([
            CrossAttentionLayer(dim) for _ in range(6)
        ])
    
    def forward(self, image_features):
        # Queries –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É—é—Ç —Å image features
        queries = self.queries.expand(image_features.size(0), -1, -1)
        
        for layer in self.cross_attn_layers:
            queries = layer(queries, image_features)
        
        return queries  # –°–∂–∞—Ç–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. Fine-tuning —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏</h2>
    <p><strong>–ü–æ–ª–Ω–æ–µ fine-tuning</strong></p>
    <ul>
      <li>–û–±—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</li>
      <li>–õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –Ω–æ –¥–æ—Ä–æ–≥–æ</li>
    </ul>
    <p><strong>LoRA (Low-Rank Adaptation)</strong></p>
    <ul>
      <li>–û–±—É—á–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ low-rank –º–∞—Ç—Ä–∏—Ü</li>
      <li>–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –ø–æ –ø–∞–º—è—Ç–∏</li>
    </ul>
    <p><strong>Prompt tuning</strong></p>
    <ul>
      <li>–û–±—É—á–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø—Ä–æ–º–ø—Ç–æ–≤</li>
      <li>–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏</li>
    </ul>
    <pre><code>from peft import get_peft_model, LoraConfig

# LoRA –¥–ª—è efficient fine-tuning
lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=["query", "value"],
    lora_dropout=0.1
)

model = get_peft_model(base_model, lora_config)
# –¢–æ–ª—å–∫–æ LoRA –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–∞—é—Ç—Å—è
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. Attention –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ</h2>
    <p><strong>–ü—Ä–æ–±–ª–µ–º–∞</strong>: –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å attention</p>
    <p><strong>–†–µ—à–µ–Ω–∏—è</strong>:</p>
    <ul>
      <li><strong>Sparse attention</strong>: –Ω–µ –≤—Å–µ —Ç–æ–∫–µ–Ω—ã attend –¥—Ä—É–≥ –∫ –¥—Ä—É–≥—É</li>
      <li><strong>Linear attention</strong>: –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è softmax</li>
      <li><strong>Flash Attention</strong>: –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–∞ —É—Ä–æ–≤–Ω–µ GPU</li>
    </ul>
    <pre><code># –ü—Ä–∏–º–µ—Ä sparse attention –ø–∞—Ç—Ç–µ—Ä–Ω–∞
def get_sparse_attention_mask(seq_len, window_size=128):
    """–õ–æ–∫–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ + global tokens"""
    mask = torch.zeros(seq_len, seq_len)
    
    # –õ–æ–∫–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ
    for i in range(seq_len):
        start = max(0, i - window_size)
        end = min(seq_len, i + window_size)
        mask[i, start:end] = 1
    
    # Global tokens ([CLS] –≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω)
    mask[:, 0] = 1
    mask[0, :] = 1
    
    return mask</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 12. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è</h3>
        <ul>
          <li>Pre-trained –±–∞–∑—ã (BERT, ViT)</li>
          <li>Gradient checkpointing –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏</li>
          <li>Mixed precision training (fp16)</li>
          <li>LoRA –¥–ª—è efficient fine-tuning</li>
          <li>Flash Attention –≥–¥–µ –≤–æ–∑–º–æ–∂–Ω–æ</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ùå –ò–∑–±–µ–≥–∞—Ç—å</h3>
        <ul>
          <li>–û–±—É—á–µ–Ω–∏–µ —Å –Ω—É–ª—è –±–µ–∑ –æ–≥—Ä–æ–º–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞</li>
          <li>–ü–æ–ª–Ω–æ–µ fine-tuning –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏</li>
          <li>–ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ positional encodings</li>
          <li>–°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –±–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 13. –î–∞—Ç–∞—Å–µ—Ç—ã –¥–ª—è pre-training</h2>
    <table>
      <tr><th>–î–∞—Ç–∞—Å–µ—Ç</th><th>–†–∞–∑–º–µ—Ä</th><th>–ú–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏</th></tr>
      <tr><td><strong>LAION-5B</strong></td><td>5.85B –ø–∞—Ä</td><td>Image-Text</td></tr>
      <tr><td><strong>Conceptual Captions</strong></td><td>15M –ø–∞—Ä</td><td>Image-Text</td></tr>
      <tr><td><strong>WebVid</strong></td><td>10M –≤–∏–¥–µ–æ</td><td>Video-Text</td></tr>
      <tr><td><strong>AudioSet</strong></td><td>2M –≤–∏–¥–µ–æ</td><td>Audio-Video-Text</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 14. Downstream –∑–∞–¥–∞—á–∏</h2>
    <ul>
      <li><strong>VQA</strong>: Visual Question Answering</li>
      <li><strong>Image Captioning</strong>: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏–π</li>
      <li><strong>Visual Reasoning</strong>: –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏</li>
      <li><strong>Multimodal Retrieval</strong>: –∫—Ä–æ—Å—Å-–º–æ–¥–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫</li>
      <li><strong>Text-to-Image Generation</strong>: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å conditioning</li>
      <li><strong>Video Understanding</strong>: –∞–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ + —Å—É–±—Ç–∏—Ç—Ä—ã</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 15. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è</h2>
    <ul>
      <li><strong>–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç—ã</strong>: –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π + –¥–∏–∞–ª–æ–≥</li>
      <li><strong>–ü–æ–∏—Å–∫</strong>: –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ (—Ç–µ–∫—Å—Ç, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –≤–∏–¥–µ–æ)</li>
      <li><strong>–ö–æ–Ω—Ç–µ–Ω—Ç-–º–æ–¥–µ—Ä–∞—Ü–∏—è</strong>: –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞</li>
      <li><strong>–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ</strong>: –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ —É—á–µ–±–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã</li>
      <li><strong>–ú–µ–¥–∏—Ü–∏–Ω–∞</strong>: –∞–Ω–∞–ª–∏–∑ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π + —Ç–µ–∫—Å—Ç</li>
      <li><strong>E-commerce</strong>: —É–º–Ω—ã–π –ø–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´–≠—Ç–æ –∫–∞–∫ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–æ–∑–≥, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–Ω–∏–º–∞–µ—Ç –∏ —Ç–µ–∫—Å—Ç, –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∏ –∑–≤—É–∫ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ. 
      –ú–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏, –Ω–∞–π—Ç–∏ –≤–∏–¥–µ–æ –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é, –∏–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø–∏—Å–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. 
      –ú–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è —Å–≤—è–∑—ã–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –∫–∞–∫ —ç—Ç–æ –¥–µ–ª–∞–µ—Ç —á–µ–ª–æ–≤–µ–∫¬ª.
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 16. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É (single/dual-stream)</li>
      <li>[ ] –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å aligned multi-modal –¥–∞–Ω–Ω—ã–µ</li>
      <li>[ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å tokenization –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π</li>
      <li>[ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å cross-modal attention</li>
      <li>[ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å pre-training –∑–∞–¥–∞—á–∏</li>
      <li>[ ] –ü—Ä–∏–º–µ–Ω–∏—Ç—å efficient training (LoRA, gradient checkpointing)</li>
      <li>[ ] Fine-tune –Ω–∞ downstream –∑–∞–¥–∞—á–µ</li>
      <li>[ ] –û—Ü–µ–Ω–∏—Ç—å –Ω–∞ benchmark (VQA, captioning)</li>
      <li>[ ] –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å inference (–∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è)</li>
    </ul>
  </div>

</div>

</body>
</html>
