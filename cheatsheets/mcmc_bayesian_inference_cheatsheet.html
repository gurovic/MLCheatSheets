<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>MCMC –∏ –ë–∞–π–µ—Å–æ–≤—Å–∫–∏–π –≤—ã–≤–æ–¥ Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

    .container {
      column-count: 3;
      column-gap: 20px;
      max-width: 100%;
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üéØ MCMC –∏ –ë–∞–π–µ—Å–æ–≤—Å–∫–∏–π –≤—ã–≤–æ–¥</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –ë–∞–π–µ—Å–æ–≤—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥</h2>
    <p><strong>–ë–∞–π–µ—Å–æ–≤—Å–∫–∏–π –≤—ã–≤–æ–¥</strong> ‚Äî –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ beliefs –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö</p>
    <ul>
      <li><strong>Prior</strong>: P(Œ∏) ‚Äî –∞–ø—Ä–∏–æ—Ä–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö</li>
      <li><strong>Likelihood</strong>: P(D|Œ∏) ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ Œ∏</li>
      <li><strong>Posterior</strong>: P(Œ∏|D) ‚Äî –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ beliefs</li>
      <li><strong>Evidence</strong>: P(D) ‚Äî –Ω–æ—Ä–º–∞–ª–∏–∑—É—é—â–∞—è –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 2. –¢–µ–æ—Ä–µ–º–∞ –ë–∞–π–µ—Å–∞</h2>
    <pre><code>P(Œ∏|D) = P(D|Œ∏) √ó P(Œ∏) / P(D)

posterior = likelihood √ó prior / evidence

P(D) = ‚à´ P(D|Œ∏) P(Œ∏) dŒ∏</code></pre>
    <blockquote>
      Evidence —á–∞—Å—Ç–æ –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω –∏ —Å–ª–æ–∂–µ–Ω –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 3. –ó–∞—á–µ–º –Ω—É–∂–µ–Ω MCMC</h2>
    <p>–ü—Ä–æ–±–ª–µ–º–∞: –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞–ª–∞ P(D) —á–∞—Å—Ç–æ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏</p>
    <ul>
      <li><strong>–¶–µ–ª—å</strong>: –æ—Ü–µ–Ω–∏—Ç—å posterior P(Œ∏|D)</li>
      <li><strong>–†–µ—à–µ–Ω–∏–µ</strong>: —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑ posterior</li>
      <li><strong>MCMC</strong>: —Å–æ–∑–¥–∞—Ç—å —Ü–µ–ø—å –ú–∞—Ä–∫–æ–≤–∞, —Å—Ö–æ–¥—è—â—É—é—Å—è –∫ posterior</li>
      <li><strong>–†–µ–∑—É–ª—å—Ç–∞—Ç</strong>: samples ~ P(Œ∏|D)</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 4. –ú–∞—Ä–∫–æ–≤—Å–∫–∞—è —Ü–µ–ø—å</h2>
    <p>–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–π —Å –º–∞—Ä–∫–æ–≤—Å–∫–∏–º —Å–≤–æ–π—Å—Ç–≤–æ–º</p>
    <ul>
      <li><strong>–°–≤–æ–π—Å—Ç–≤–æ</strong>: P(Œ∏_t+1 | Œ∏_1...Œ∏_t) = P(Œ∏_t+1 | Œ∏_t)</li>
      <li><strong>–°—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ</strong>: œÄ(Œ∏)</li>
      <li><strong>–≠—Ä–≥–æ–¥–∏—á–Ω–æ—Å—Ç—å</strong>: –ª—é–±–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–æ—Å—Ç–∏–∂–∏–º–æ</li>
      <li><strong>–î–µ—Ç–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å</strong>: œÄ(Œ∏)T(Œ∏'|Œ∏) = œÄ(Œ∏')T(Œ∏|Œ∏')</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 5. Metropolis-Hastings –∞–ª–≥–æ—Ä–∏—Ç–º</h2>
    <p>–ë–∞–∑–æ–≤—ã–π MCMC –∞–ª–≥–æ—Ä–∏—Ç–º</p>
    <pre><code>1. –ù–∞—á–∞—Ç—å —Å Œ∏_0
2. –î–ª—è t = 1, 2, ..., N:
   a) –ü—Ä–µ–¥–ª–æ–∂–∏—Ç—å Œ∏* ~ q(Œ∏*|Œ∏_t)
   b) –í—ã—á–∏—Å–ª–∏—Ç—å acceptance ratio:
      Œ± = min(1, P(Œ∏*)q(Œ∏_t|Œ∏*) / (P(Œ∏_t)q(Œ∏*|Œ∏_t)))
   c) –° –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é Œ±:
      Œ∏_t+1 = Œ∏*
      –ò–Ω–∞—á–µ:
      Œ∏_t+1 = Œ∏_t</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è Metropolis-Hastings</h2>
    <pre><code>import numpy as np

def metropolis_hastings(target_pdf, proposal_std, 
                        n_samples, initial_state):
    """
    target_pdf: —Ü–µ–ª–µ–≤–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ P(Œ∏)
    proposal_std: std –¥–ª—è proposal distribution
    """
    samples = [initial_state]
    current = initial_state
    accepted = 0
    
    for i in range(n_samples - 1):
        # Proposal (Gaussian random walk)
        proposed = current + np.random.normal(0, proposal_std)
        
        # Acceptance ratio
        alpha = min(1, target_pdf(proposed) / target_pdf(current))
        
        # Accept or reject
        if np.random.rand() < alpha:
            current = proposed
            accepted += 1
        
        samples.append(current)
    
    print(f"Acceptance rate: {accepted / n_samples:.2%}")
    return np.array(samples)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. Gibbs Sampling</h2>
    <p>–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Å–ª—É—á–∞–π MH –¥–ª—è –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π</p>
    <ul>
      <li><strong>–ò–¥–µ—è</strong>: —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞—Ç—å –ø–æ –æ–¥–Ω–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π</li>
      <li><strong>–£—Å–ª–æ–≤–∏–µ</strong>: P(Œ∏_i | Œ∏_{-i}) –¥–æ—Å—Ç—É–ø–Ω–æ</li>
      <li><strong>Acceptance rate</strong>: –≤—Å–µ–≥–¥–∞ 100%</li>
      <li><strong>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</strong>: LDA, Bayesian networks</li>
    </ul>
    <pre><code>for iteration in range(n_samples):
    for i in range(n_vars):
        # –°–µ–º–ø–ª–∏—Ä–æ–≤–∞—Ç—å i-—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
        # –ø—Ä–∏ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö
        Œ∏[i] = sample_from(P(Œ∏_i | Œ∏_{-i}))</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. Hamiltonian Monte Carlo (HMC)</h2>
    <p><strong>HMC</strong> –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è</p>
    <ul>
      <li><strong>–ò–¥–µ—è</strong>: –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∫ —Ñ–∏–∑–∏—á–µ—Å–∫—É—é —Å–∏—Å—Ç–µ–º—É</li>
      <li><strong>–ò–º–ø—É–ª—å—Å</strong>: –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è p</li>
      <li><strong>Hamiltonian</strong>: H(Œ∏,p) = -log P(Œ∏) + p¬≤/2m</li>
      <li><strong>Leapfrog integrator</strong>: —á–∏—Å–ª–µ–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ</li>
      <li><strong>–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ</strong>: –º–µ–Ω—å—à–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É samples</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 9. No U-Turn Sampler (NUTS)</h2>
    <p>–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ HMC, –∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ –≤ Stan –∏ PyMC3</p>
    <ul>
      <li><strong>–ü—Ä–æ–±–ª–µ–º–∞ HMC</strong>: –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª–∏–Ω—ã —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏</li>
      <li><strong>NUTS</strong>: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—é</li>
      <li><strong>–ö—Ä–∏—Ç–µ—Ä–∏–π</strong>: stop –∫–æ–≥–¥–∞ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è "—Ä–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–µ—Ç—Å—è"</li>
      <li><strong>–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å</strong>: state-of-the-art –¥–ª—è MCMC</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 10. –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏</h2>
    <table>
      <tr><th>–ú–µ—Ç–æ–¥</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th><th>–ö—Ä–∏—Ç–µ—Ä–∏–π</th></tr>
      <tr><td><strong>Trace plots</strong></td><td>–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ü–µ–ø–∏</td><td>–°—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å</td></tr>
      <tr><td><strong>R-hat (Gelman-Rubin)</strong></td><td>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ü–µ–ø–µ–π</td><td>R < 1.1</td></tr>
      <tr><td><strong>Effective sample size</strong></td><td>–ù–µ–∑–∞–≤–∏—Å–∏–º—ã–µ samples</td><td>ESS > 400</td></tr>
      <tr><td><strong>Autocorrelation</strong></td><td>–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ª–∞–≥–æ–≤</td><td>–ë—ã—Å—Ç—Ä–æ–µ –∑–∞—Ç—É—Ö–∞–Ω–∏–µ</td></tr>
      <tr><td><strong>Geweke test</strong></td><td>–ù–∞—á–∞–ª–æ vs –∫–æ–Ω–µ—Ü</td><td>p > 0.05</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 11. Burn-in –∏ thinning</h2>
    <ul>
      <li><strong>Burn-in</strong>: –æ—Ç–±—Ä–æ—Å–∏—Ç—å –ø–µ—Ä–≤—ã–µ N samples (–¥–æ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏)</li>
      <li><strong>Thinning</strong>: –±—Ä–∞—Ç—å –∫–∞–∂–¥—ã–π k-—ã–π sample (—É–º–µ–Ω—å—à–∏—Ç—å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é)</li>
      <li><strong>–û–±—ã—á–Ω–æ</strong>: burn-in = 20-50% samples</li>
      <li><strong>Thinning</strong>: –∑–∞–≤–∏—Å–∏—Ç –æ—Ç autocorrelation</li>
    </ul>
    <pre><code># Burn-in
samples = samples[burn_in:]

# Thinning
samples = samples[::thin]</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 12. PyMC –¥–ª—è Bayesian inference</h2>
    <pre><code>import pymc as pm
import numpy as np

# –î–∞–Ω–Ω—ã–µ
y_obs = np.array([28, 8, -3, 7, -1, 1, 18, 12])

with pm.Model() as model:
    # Priors
    Œº = pm.Normal('Œº', mu=0, sigma=10)
    œÉ = pm.HalfNormal('œÉ', sigma=10)
    
    # Likelihood
    y = pm.Normal('y', mu=Œº, sigma=œÉ, observed=y_obs)
    
    # Sampling (NUTS)
    trace = pm.sample(2000, tune=1000, chains=4)

# –ê–Ω–∞–ª–∏–∑
pm.summary(trace)
pm.plot_trace(trace)
pm.plot_posterior(trace)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 13. Stan –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π</h2>
    <pre><code># Stan model file (model.stan)
data {
  int<lower=0> N;
  vector[N] y;
}
parameters {
  real mu;
  real<lower=0> sigma;
}
model {
  mu ~ normal(0, 10);
  sigma ~ cauchy(0, 5);
  y ~ normal(mu, sigma);
}

# Python
import pystan
model = pystan.StanModel(file='model.stan')
fit = model.sampling(data={'N': len(y), 'y': y}, 
                     iter=2000, chains=4)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 14. Variational Inference –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞</h2>
    <p><strong>VI</strong> ‚Äî –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–º–µ—Å—Ç–æ —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è</p>
    <ul>
      <li><strong>–ò–¥–µ—è</strong>: –∞–ø–ø—Ä–æ–∫—Å–∏–º–∏—Ä–æ–≤–∞—Ç—å P(Œ∏|D) –ø—Ä–æ—Å—Ç—ã–º q(Œ∏)</li>
      <li><strong>–¶–µ–ª—å</strong>: –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å KL(q||p)</li>
      <li><strong>ELBO</strong>: Evidence Lower Bound –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏</li>
      <li><strong>–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ</strong>: –±—ã—Å—Ç—Ä–µ–µ MCMC</li>
      <li><strong>–ù–µ–¥–æ—Å—Ç–∞—Ç–æ–∫</strong>: –º–æ–∂–µ—Ç –Ω–µ–¥–æ–æ—Ü–µ–Ω–∏—Ç—å variance</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 15. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è –ë–∞–π–µ—Å–æ–≤—Å–∫–æ–≥–æ –≤—ã–≤–æ–¥–∞</h2>
    <ul>
      <li><strong>A/B testing</strong>: –æ—Ü–µ–Ω–∫–∞ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏ —Å uncertainty</li>
      <li><strong>Time series</strong>: Bayesian structural models</li>
      <li><strong>Bayesian optimization</strong>: –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã ML</li>
      <li><strong>Causal inference</strong>: interventions</li>
      <li><strong>Hierarchical models</strong>: multi-level data</li>
      <li><strong>Missing data imputation</strong></li>
      <li><strong>Model selection</strong>: Bayes factors</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 16. –ë–∞–π–µ—Å–æ–≤—Å–∫–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏</h2>
    <p>–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–º–µ—Å—Ç–æ —Ç–æ—á–µ—á–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫ –≤–µ—Å–æ–≤</p>
    <pre><code># PyMC3 Bayesian NN
with pm.Model() as nn_model:
    # –í–µ—Å–∞ ‚Äî —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
    w1 = pm.Normal('w1', 0, 1, shape=(n_in, n_hidden))
    w2 = pm.Normal('w2', 0, 1, shape=(n_hidden, n_out))
    
    # Forward pass
    hidden = pm.math.tanh(pm.math.dot(X, w1))
    out = pm.math.dot(hidden, w2)
    
    # Likelihood
    y = pm.Normal('y', mu=out, sigma=1, observed=Y)
    
    trace = pm.sample(1000)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 17. Bayesian optimization</h2>
    <p>–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–æ—Ä–æ–≥–∏—Ö black-box —Ñ—É–Ω–∫—Ü–∏–π</p>
    <ol>
      <li><strong>Surrogate model</strong>: Gaussian Process</li>
      <li><strong>Acquisition function</strong>: EI, UCB, PI</li>
      <li><strong>Optimize acquisition</strong>: –Ω–∞–π—Ç–∏ —Å–ª–µ–¥—É—é—â—É—é —Ç–æ—á–∫—É</li>
      <li><strong>Evaluate</strong>: –ø–æ–ª—É—á–∏—Ç—å f(x)</li>
      <li><strong>Update GP</strong>: –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—É—é —Ç–æ—á–∫—É</li>
    </ol>
    <pre><code>from bayes_opt import BayesianOptimization

def black_box_function(x, y):
    return -x ** 2 - (y - 1) ** 2 + 1

optimizer = BayesianOptimization(
    f=black_box_function,
    pbounds={'x': (-2, 2), 'y': (-3, 3)},
    random_state=1
)

optimizer.maximize(init_points=2, n_iter=3)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 18. –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞</h3>
        <ul>
          <li>Uncertainty quantification</li>
          <li>–ò–Ω–∫–æ—Ä–ø–æ—Ä–∞—Ü–∏—è prior knowledge</li>
          <li>–ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è</li>
          <li>–†–∞–±–æ—Ç–∞ —Å –º–∞–ª—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏</li>
        </ul>
      </div>
      <div class="bad">
        <h3>–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏</h3>
        <ul>
          <li>–í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ –¥–æ—Ä–æ–≥–æ</li>
          <li>–¢—Ä–µ–±—É–µ—Ç –≤—ã–±–æ—Ä–∞ priors</li>
          <li>–°–ª–æ–∂–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞</li>
          <li>–ù–µ –≤—Å–µ–≥–¥–∞ —Å—Ö–æ–¥–∏—Ç—Å—è</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 19. Best Practices</h2>
    <ol>
      <li><strong>–ù–∞—á–∞—Ç—å —Å –ø—Ä–æ—Å—Ç–æ–≥–æ prior</strong>: —Å–ª–∞–±–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π</li>
      <li><strong>–ù–µ—Å–∫–æ–ª—å–∫–æ —Ü–µ–ø–µ–π</strong>: –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏</li>
      <li><strong>–î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ samples</strong>: ESS > 1000</li>
      <li><strong>–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞</strong>: R-hat, trace plots</li>
      <li><strong>Reparametrization</strong>: –¥–ª—è –ª—É—á—à–µ–π —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏</li>
      <li><strong>–ê–¥–∞–ø—Ç–∞—Ü–∏—è</strong>: tune period –¥–ª—è NUTS</li>
    </ol>
  </div>

  <div class="block">
    <h2>üî∑ 20. –ß–µ–∫-–ª–∏—Å—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è</h2>
    <ol>
      <li>‚úì –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å likelihood –∏ prior</li>
      <li>‚úì –í—ã–±—Ä–∞—Ç—å MCMC –∞–ª–≥–æ—Ä–∏—Ç–º (NUTS, MH, Gibbs)</li>
      <li>‚úì –í—ã–±—Ä–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É (PyMC, Stan, NumPyro)</li>
      <li>‚úì –ù–∞—Å—Ç—Ä–æ–∏—Ç—å sampling (chains, samples, warmup)</li>
      <li>‚úì –ó–∞–ø—É—Å—Ç–∏—Ç—å –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å warnings</li>
      <li>‚úì –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏ (R-hat, ESS)</li>
      <li>‚úì –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è trace –∏ posterior</li>
      <li>‚úì –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è</li>
    </ol>
  </div>

</div>

</body>
</html>
