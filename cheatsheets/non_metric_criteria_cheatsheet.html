<!DOCTYPE html>
<html lang="ru">
<head><meta charset="UTF-8"><title>–ù–µ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
<style>@media screen{body{font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Helvetica,Arial,sans-serif;color:#333;background:#fafcff;padding:10px}}@media print{body{background:white;padding:0}@page{size:A4 landscape;margin:10mm}}.container{column-count:3;column-gap:20px;max-width:100%}.block{break-inside:avoid;margin-bottom:1.2em;padding:12px;background:white;border-radius:6px;box-shadow:0 1px 3px rgba(0,0,0,0.05)}h1{font-size:1.6em;font-weight:700;color:#1a5fb4;text-align:center;margin:0 0 8px;column-span:all}.subtitle{text-align:center;color:#666;font-size:0.9em;margin-bottom:12px;column-span:all}h2{font-size:1.15em;font-weight:700;color:#1a5fb4;margin:0 0 8px;padding-bottom:4px;border-bottom:1px solid #e0e7ff}p,ul,ol{font-size:0.92em;margin:0.6em 0}ul,ol{padding-left:18px}li{margin-bottom:4px}code{font-family:'Consolas','Courier New',monospace;background-color:#f0f4ff;padding:1px 4px;border-radius:3px;font-size:0.88em}pre{background-color:#f0f4ff;padding:8px;border-radius:4px;overflow-x:auto;font-size:0.84em;margin:6px 0}pre code{padding:0;background:none;white-space:pre-wrap}table{width:100%;border-collapse:collapse;font-size:0.82em;margin:6px 0}th{background-color:#e6f0ff;text-align:left;padding:4px 6px;font-weight:600}td{padding:4px 6px;border-bottom:1px solid #f0f4ff}tr:nth-child(even){background-color:#f8fbff}blockquote{font-style:italic;margin:8px 0;padding:6px 10px;background:#f8fbff;border-left:2px solid #1a5fb4;font-size:0.88em}</style></head>
<body><div class="container"><h1>üìè –ù–µ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏</h1>
<div class="subtitle">üìÖ 4 —è–Ω–≤–∞—Ä—è 2026</div>

<div class="block"><h2>üî∑ 1. –ó–∞—á–µ–º –Ω—É–∂–Ω—ã –Ω–µ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏</h2>
<ul><li><strong>–ú–µ—Ç—Ä–∏–∫–∏</strong> (MSE, accuracy) ‚Äî –Ω–µ –≤—Å–µ</li>
<li><strong>–ü—Ä–∞–∫—Ç–∏–∫–∞</strong>: —Å–∫–æ—Ä–æ—Å—Ç—å, –ø–∞–º—è—Ç—å, –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å</li>
<li><strong>–ë–∏–∑–Ω–µ—Å</strong>: —Å—Ç–æ–∏–º–æ—Å—Ç—å –æ—à–∏–±–æ–∫, –¥–æ–≤–µ—Ä–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π</li>
<li><strong>–†–µ–≥—É–ª—è—Ü–∏—è</strong>: GDPR —Ç—Ä–µ–±—É–µ—Ç –æ–±—ä—è—Å–Ω–∏–º–æ—Å—Ç–∏</li></ul></div>

<div class="block"><h2>üî∑ 2. –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å</h2>
<p><strong>–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ</strong>: –Ω–∞—Å–∫–æ–ª—å–∫–æ –ø–æ–Ω—è—Ç–Ω—ã —Ä–µ—à–µ–Ω–∏—è –º–æ–¥–µ–ª–∏</p>
<table><tr><th>–ú–æ–¥–µ–ª—å</th><th>–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å</th><th>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π</th></tr>
<tr><td>Linear Regression</td><td>‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ</td><td>–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã = –≤–ª–∏—è–Ω–∏–µ</td></tr>
<tr><td>Decision Tree (–º–∞–ª–æ–µ)</td><td>‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ</td><td>–ü—Ä–∞–≤–∏–ª–∞ –ø–æ–Ω—è—Ç–Ω—ã</td></tr>
<tr><td>Random Forest</td><td>‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ</td><td>–ú–Ω–æ–≥–æ –¥–µ—Ä–µ–≤—å–µ–≤</td></tr>
<tr><td>Gradient Boosting</td><td>‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ</td><td>–°–ª–æ–∂–Ω—ã–π –∞–Ω—Å–∞–º–±–ª—å</td></tr>
<tr><td>Neural Networks</td><td>‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ</td><td>"–ß–µ—Ä–Ω—ã–π —è—â–∏–∫"</td></tr></table></div>

<div class="block"><h2>üî∑ 3. –ú–µ—Ç–æ–¥—ã –ø–æ–≤—ã—à–µ–Ω–∏—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏</h2>
<pre><code># SHAP values
import shap
explainer = shap.Explainer(model)
shap_values = explainer(X_test)
shap.plots.waterfall(shap_values[0])

# Feature importance
import matplotlib.pyplot as plt
importances = model.feature_importances_
indices = np.argsort(importances)[::-1]
plt.barh(range(10), importances[indices[:10]])
plt.yticks(range(10), [features[i] for i in indices[:10]])
plt.show()</code></pre></div>

<div class="block"><h2>üî∑ 4. –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è</h2>
<table><tr><th>–ú–æ–¥–µ–ª—å</th><th>–í—Ä–µ–º—è (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ)</th><th>–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö</th></tr>
<tr><td>Linear Regression</td><td>–û—á–µ–Ω—å –±—ã—Å—Ç—Ä–æ (1x)</td><td>–î–æ –º–∏–ª–ª–∏–æ–Ω–æ–≤</td></tr>
<tr><td>Logistic Regression</td><td>–ë—ã—Å—Ç—Ä–æ (2x)</td><td>–î–æ –º–∏–ª–ª–∏–æ–Ω–æ–≤</td></tr>
<tr><td>Random Forest</td><td>–°—Ä–µ–¥–Ω–µ (50x)</td><td>–î–æ 100K</td></tr>
<tr><td>XGBoost</td><td>–°—Ä–µ–¥–Ω–µ (40x)</td><td>–î–æ 1M</td></tr>
<tr><td>Deep Neural Net</td><td>–ú–µ–¥–ª–µ–Ω–Ω–æ (500x)</td><td>–î–æ –º–∏–ª–ª–∏–æ–Ω–æ–≤</td></tr>
<tr><td>SVM (kernel)</td><td>–û—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ (1000x)</td><td>–î–æ 10K</td></tr></table></div>

<div class="block"><h2>üî∑ 5. –°–∫–æ—Ä–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è</h2>
<pre><code>import time

# –ò–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
start = time.time()
predictions = model.predict(X_test)
end = time.time()
latency_ms = (end - start) * 1000 / len(X_test)
print(f"Latency: {latency_ms:.2f} ms per sample")

# Throughput
throughput = len(X_test) / (end - start)
print(f"Throughput: {throughput:.0f} samples/sec")</code></pre>
<p><strong>–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è</strong>:</p>
<ul><li>Real-time: &lt;100ms</li>
<li>Interactive: &lt;1s</li>
<li>Batch: –º–∏–Ω—É—Ç—ã/—á–∞—Å—ã OK</li></ul></div>

<div class="block"><h2>üî∑ 6. –ü–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏</h2>
<pre><code>import sys

# –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ –≤ –ø–∞–º—è—Ç–∏
model_size_mb = sys.getsizeof(model) / (1024**2)
print(f"Model size: {model_size_mb:.2f} MB")

# –î–ª—è –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π
import joblib
joblib.dump(model, 'model.pkl')
file_size = os.path.getsize('model.pkl') / (1024**2)
print(f"File size: {file_size:.2f} MB")</code></pre>
<table><tr><th>–ú–æ–¥–µ–ª—å</th><th>–†–∞–∑–º–µ—Ä (—Ç–∏–ø–∏—á–Ω—ã–π)</th></tr>
<tr><td>Linear model</td><td>&lt;1 MB</td></tr>
<tr><td>Random Forest (100 trees)</td><td>10-100 MB</td></tr>
<tr><td>XGBoost</td><td>5-50 MB</td></tr>
<tr><td>Neural Network</td><td>10-1000 MB</td></tr></table></div>

<div class="block"><h2>üî∑ 7. –ü—Ä–æ—Å—Ç–æ—Ç–∞ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è</h2>
<p><strong>–ö—Ä–∏—Ç–µ—Ä–∏–∏</strong>:</p>
<ul><li>–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∏–±–ª–∏–æ—Ç–µ–∫)</li>
<li>–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å (–≤–µ—Ä—Å–∏–∏ Python, OS)</li>
<li>–†–∞–∑–º–µ—Ä docker –æ–±—Ä–∞–∑–∞</li>
<li>–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —ç–∫—Å–ø–æ—Ä—Ç–∞ (ONNX, PMML)</li></ul>
<pre><code># –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX
from skl2onnx import convert_sklearn
from skl2onnx.common.data_types import FloatTensorType

initial_type = [('float_input', FloatTensorType([None, n_features]))]
onx = convert_sklearn(model, initial_types=initial_type)
with open("model.onnx", "wb") as f:
    f.write(onx.SerializeToString())</code></pre></div>

<div class="block"><h2>üî∑ 8. –£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å</h2>
<p><strong>–í–∏–¥—ã —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏</strong>:</p>
<ul><li><strong>–ö —à—É–º—É</strong>: –Ω–µ–±–æ–ª—å—à–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤—Ö–æ–¥–∞</li>
<li><strong>–ö –≤—ã–±—Ä–æ—Å–∞–º</strong>: –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è</li>
<li><strong>–ö –∏–∑–º–µ–Ω–µ–Ω–∏—è–º –¥–∞–Ω–Ω—ã—Ö</strong>: concept drift</li></ul>
<pre><code># –¢–µ—Å—Ç —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –∫ —à—É–º—É
noise_levels = [0.01, 0.05, 0.1, 0.2]
for noise in noise_levels:
    X_noisy = X_test + np.random.normal(0, noise, X_test.shape)
    accuracy_noisy = model.score(X_noisy, y_test)
    print(f"Noise {noise}: accuracy {accuracy_noisy:.3f}")</code></pre></div>

<div class="block"><h2>üî∑ 9. –°—Ç–æ–∏–º–æ—Å—Ç—å –æ—à–∏–±–æ–∫</h2>
<p><strong>–ù–µ –≤—Å–µ –æ—à–∏–±–∫–∏ —Ä–∞–≤–Ω—ã</strong>:</p>
<table><tr><th>–û–±–ª–∞—Å—Ç—å</th><th>False Positive</th><th>False Negative</th></tr>
<tr><td>–°–ø–∞–º-—Ñ–∏–ª—å—Ç—Ä</td><td>–ü–æ—Ç–µ—Ä—è –ø–∏—Å—å–º–∞</td><td>–°–ø–∞–º –≤ inbox</td></tr>
<tr><td>–ú–µ–¥–∏—Ü–∏–Ω–∞</td><td>–õ–æ–∂–Ω–∞—è —Ç—Ä–µ–≤–æ–≥–∞</td><td>–ü—Ä–æ–ø—É—Å–∫ –±–æ–ª–µ–∑–Ω–∏</td></tr>
<tr><td>–ö—Ä–µ–¥–∏—Ç</td><td>–û—Ç–∫–∞–∑ —Ö–æ—Ä–æ—à–µ–º—É</td><td>–ö—Ä–µ–¥–∏—Ç –ø–ª–æ—Ö–æ–º—É</td></tr>
<tr><td>Fraud</td><td>–ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞</td><td>–ü—Ä–æ–ø—É—Å–∫ –º–æ—à–µ–Ω–Ω–∏–∫–∞</td></tr></table>
<pre><code># Custom scoring —Å –≤–µ—Å–∞–º–∏
from sklearn.metrics import make_scorer

def custom_score(y_true, y_pred):
    fp_cost = 1  # False Positive
    fn_cost = 10  # False Negative (–¥–æ—Ä–æ–∂–µ!)
    fp = ((y_pred == 1) & (y_true == 0)).sum()
    fn = ((y_pred == 0) & (y_true == 1)).sum()
    return -(fp * fp_cost + fn * fn_cost)

scorer = make_scorer(custom_score)</code></pre></div>

<div class="block"><h2>üî∑ 10. Fairness (—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å)</h2>
<p><strong>–ú–µ—Ç—Ä–∏–∫–∏ fairness</strong>:</p>
<ul><li>Demographic parity</li>
<li>Equal opportunity</li>
<li>Equalized odds</li></ul>
<pre><code>from fairlearn.metrics import demographic_parity_difference

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç–∏ –ø–æ –ø–æ–ª—É
dp = demographic_parity_difference(
    y_true, y_pred, sensitive_features=gender
)
print(f"Demographic parity: {dp:.3f}")
# –¶–µ–ª—å: –±–ª–∏–∑–∫–æ –∫ 0</code></pre></div>

<div class="block"><h2>üî∑ 11. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ</h2>
<pre><code>import time

class MonitoredModel:
    def __init__(self, model):
        self.model = model
        self.predictions_count = 0
        self.total_latency = 0
        
    def predict(self, X):
        start = time.time()
        pred = self.model.predict(X)
        latency = time.time() - start
        
        self.predictions_count += len(X)
        self.total_latency += latency
        
        # Log –º–µ—Ç—Ä–∏–∫–∏
        avg_latency = self.total_latency / self.predictions_count
        if avg_latency > 0.1:  # Threshold
            print(f"WARNING: High latency {avg_latency:.3f}s")
        
        return pred</code></pre></div>

<div class="block"><h2>üî∑ 12. Trade-offs</h2>
<table><tr><th>–ö—Ä–∏—Ç–µ—Ä–∏–π 1</th><th>vs</th><th>–ö—Ä–∏—Ç–µ—Ä–∏–π 2</th></tr>
<tr><td>Accuracy</td><td>‚ÜîÔ∏è</td><td>Interpretability</td></tr>
<tr><td>–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è</td><td>‚ÜîÔ∏è</td><td>Accuracy</td></tr>
<tr><td>–°–∫–æ—Ä–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è</td><td>‚ÜîÔ∏è</td><td>Accuracy</td></tr>
<tr><td>–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏</td><td>‚ÜîÔ∏è</td><td>Accuracy</td></tr>
<tr><td>–ü—Ä–æ—Å—Ç–æ—Ç–∞</td><td>‚ÜîÔ∏è</td><td>–ì–∏–±–∫–æ—Å—Ç—å</td></tr></table></div>

<div class="block"><h2>üî∑ 13. –ú–∞—Ç—Ä–∏—Ü–∞ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏</h2>
<table><tr><th>–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç</th><th>–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –º–æ–¥–µ–ª—å</th></tr>
<tr><td>–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å</td><td>Linear/Logistic Regression, Decision Tree</td></tr>
<tr><td>–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è</td><td>Linear models, Naive Bayes</td></tr>
<tr><td>–°–∫–æ—Ä–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è</td><td>Linear models, small trees</td></tr>
<tr><td>–¢–æ—á–Ω–æ—Å—Ç—å (—Ç–∞–±–ª–∏—á–Ω—ã–µ)</td><td>XGBoost, LightGBM</td></tr>
<tr><td>–¢–æ—á–Ω–æ—Å—Ç—å (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)</td><td>CNN, Vision Transformers</td></tr>
<tr><td>–ú–∞–ª—ã–µ –¥–∞–Ω–Ω—ã–µ</td><td>Linear models, k-NN</td></tr></table></div>

<div class="block"><h2>üî∑ 14. –ß–µ–∫-–ª–∏—Å—Ç –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏</h2>
<ul><li>[ ] –¢–æ—á–Ω–æ—Å—Ç—å: MSE, accuracy, F1</li>
<li>[ ] –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è: —Å–µ–∫—É–Ω–¥—ã/–º–∏–Ω—É—Ç—ã?</li>
<li>[ ] –°–∫–æ—Ä–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: –º—Å –Ω–∞ –æ–±—ä–µ–∫—Ç</li>
<li>[ ] –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏: –ú–ë, –≤–ª–µ–∑–µ—Ç –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ?</li>
<li>[ ] –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å: –Ω—É–∂–Ω–∞ –ª–∏?</li>
<li>[ ] –£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å: –∫ —à—É–º—É, –≤—ã–±—Ä–æ—Å–∞–º</li>
<li>[ ] Fairness: –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞ –ª–∏?</li>
<li>[ ] –°—Ç–æ–∏–º–æ—Å—Ç—å –æ—à–∏–±–æ–∫: —É—á—Ç–µ–Ω–∞ –ª–∏?</li>
<li>[ ] –ü—Ä–æ—Å—Ç–æ—Ç–∞ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è: –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏?</li></ul></div>

<div class="block"><h2>üî∑ 15. –ó–∞–∫–ª—é—á–µ–Ω–∏–µ</h2>
<blockquote>¬´–ù–µ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ —á–∞—Å—Ç–æ –≤–∞–∂–Ω–µ–µ –º–µ—Ç—Ä–∏–∫. –ú–æ–¥–µ–ª—å —Å accuracy 95% –Ω–æ –≤—Ä–µ–º–µ–Ω–µ–º –æ—Ç–≤–µ—Ç–∞ 10 —Å–µ–∫—É–Ω–¥ –±–µ—Å–ø–æ–ª–µ–∑–Ω–∞ 
–¥–ª—è real-time –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è. –ú–æ–¥–µ–ª—å —Å F1=0.98 –Ω–æ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ–±—ä—è—Å–Ω–∏—Ç—å —Ä–µ—à–µ–Ω–∏—è –Ω–µ –ø—Ä–æ–π–¥–µ—Ç –∞—É–¥–∏—Ç. 
–í—ã–±–∏—Ä–∞–π—Ç–µ –º–æ–¥–µ–ª—å, —É—á–∏—Ç—ã–≤–∞—è –≤–µ—Å—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–¥–∞—á–∏, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏¬ª.</blockquote></div>

</div></body></html>