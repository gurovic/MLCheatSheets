<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>Gradient Checkpointing Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen { body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif; color: #333; background: #fafcff; padding: 10px; } }
    @media print { body { background: white; padding: 0; } @page { size: A4 landscape; margin: 10mm; } }
    .container { column-count: 3; column-gap: 20px; max-width: 100%; }
    .block { break-inside: avoid; margin-bottom: 1.2em; padding: 12px; background: white; border-radius: 6px; box-shadow: 0 1px 3px rgba(0,0,0,0.05); }
    h1 { font-size: 1.6em; font-weight: 700; color: #1a5fb4; text-align: center; margin: 0 0 8px; column-span: all; }
    .subtitle { text-align: center; color: #666; font-size: 0.9em; margin-bottom: 12px; column-span: all; }
    h2 { font-size: 1.15em; font-weight: 700; color: #1a5fb4; margin: 0 0 8px; padding-bottom: 4px; border-bottom: 1px solid #e0e7ff; }
    p, ul, ol { font-size: 0.92em; margin: 0.6em 0; }
    ul, ol { padding-left: 18px; }
    li { margin-bottom: 4px; }
    code { font-family: 'Consolas', 'Courier New', monospace; background-color: #f0f4ff; padding: 1px 4px; border-radius: 3px; font-size: 0.88em; }
    pre { background-color: #f0f4ff; padding: 8px; border-radius: 4px; overflow-x: auto; font-size: 0.84em; margin: 6px 0; }
    pre code { padding: 0; background: none; white-space: pre-wrap; }
    table { width: 100%; border-collapse: collapse; font-size: 0.82em; margin: 6px 0; }
    th { background-color: #e6f0ff; text-align: left; padding: 4px 6px; font-weight: 600; }
    td { padding: 4px 6px; border-bottom: 1px solid #f0f4ff; }
    tr:nth-child(even) { background-color: #f8fbff; }
    .good-vs-bad { display: flex; flex-direction: column; gap: 8px; }
    .good-vs-bad div { flex: 1; padding: 6px 8px; border-radius: 4px; }
    .good { background-color: #f0f9f4; border-left: 3px solid #2e8b57; }
    .bad { background-color: #fdf0f2; border-left: 3px solid #d32f2f; }
    .good h3, .bad h3 { margin: 0 0 4px; font-size: 1em; font-weight: 700; }
    .good ul, .bad ul { padding-left: 20px; margin: 0; }
    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }
    blockquote { font-style: italic; margin: 8px 0; padding: 6px 10px; background: #f8fbff; border-left: 2px solid #1a5fb4; font-size: 0.88em; }
    @media print { .container { column-gap: 12px; } .block { box-shadow: none; } code, pre, table { font-size: 0.78em; } h1 { font-size: 1.4em; } h2 { font-size: 1em; } }
  </style>
</head>
<body>
<div class="container">
  <h1>üíæ Gradient Checkpointing Cheatsheet</h1>
  <div class="subtitle">Memory-efficient training ‚Ä¢ –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ñ–æ–∫—É—Å<br>üìÖ 4 —è–Ω–≤–∞—Ä—è 2026</div>
  <div class="block">
    <h2>üî∑ 1. –°—É—Ç—å Gradient Checkpointing</h2>
    <ul>
      <li><strong>–ü—Ä–æ–±–ª–µ–º–∞</strong>: –æ–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ —Ö—Ä–∞–Ω–∏—Ç –≤—Å–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –≤ –ø–∞–º—è—Ç–∏</li>
      <li><strong>–†–µ—à–µ–Ω–∏–µ</strong>: —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ç–æ–ª—å–∫–æ —á–∞—Å—Ç—å –∞–∫—Ç–∏–≤–∞—Ü–∏–π, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞—Ç—å</li>
      <li><strong>Trade-off</strong>: –º–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏ vs –±–æ–ª—å—à–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π</li>
      <li><strong>–í—ã–≥–æ–¥–∞</strong>: –º–æ–∂–Ω–æ –æ–±—É—á–∞—Ç—å –±–æ–ª—å—à–∏–µ –º–æ–¥–µ–ª–∏ –∏–ª–∏ —É–≤–µ–ª–∏—á–∏—Ç—å batch size</li>
      <li><strong>Overhead</strong>: ~20-30% –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏, –Ω–æ –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –±–∞—Ç—á –≤ 2-4x</li>
    </ul>
  </div>
  <div class="block">
    <h2>üî∑ 2. –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç</h2>
    <p><strong>–û–±—ã—á–Ω—ã–π backward:</strong></p>
    <ol>
      <li>Forward: –≤—ã—á–∏—Å–ª–∏—Ç—å –≤—Å–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏, —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Ö</li>
      <li>Backward: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –¥–ª—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤</li>
      <li>–ü–∞–º—è—Ç—å: O(n) –¥–ª—è n —Å–ª–æ–µ–≤</li>
    </ol>
    <p><strong>–° checkpointing:</strong></p>
    <ol>
      <li>Forward: —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ —Ç–æ–ª—å–∫–æ –≤ checkpoints</li>
      <li>Backward: –ø–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –º–µ–∂–¥—É checkpoints</li>
      <li>–ü–∞–º—è—Ç—å: O(‚àön) –ø—Ä–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–º —Ä–∞–∑–º–µ—â–µ–Ω–∏–∏</li>
    </ol>
  </div>
  <div class="block">
    <h2>üî∑ 3. PyTorch –±–∞–∑–æ–≤—ã–π –∫–æ–¥</h2>
    <pre><code>import torch.utils.checkpoint as checkpoint

class MyModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.layer1 = nn.Linear(100, 100)
        self.layer2 = nn.Linear(100, 100)
        self.layer3 = nn.Linear(100, 10)
    
    def forward(self, x):
        # –û–±—ã—á–Ω—ã–π forward
        # x = self.layer1(x)
        
        # –° checkpointing
        x = checkpoint.checkpoint(self.layer1, x)
        x = checkpoint.checkpoint(self.layer2, x)
        x = self.layer3(x)  # –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –±–µ–∑ checkpoint
        return x</code></pre>
  </div>
  <div class="block">
    <h2>üî∑ 4. –î–ª—è Sequential –º–æ–¥–µ–ª–µ–π</h2>
    <pre><code>from torch.utils.checkpoint import checkpoint_sequential

model = nn.Sequential(
    nn.Linear(100, 100),
    nn.ReLU(),
    nn.Linear(100, 100),
    nn.ReLU(),
    nn.Linear(100, 100),
    nn.ReLU(),
    nn.Linear(100, 10)
)

# –†–∞–∑–±–∏—Ç—å –Ω–∞ 2 —Å–µ–≥–º–µ–Ω—Ç–∞ —Å checkpoints
segments = 2

def forward_with_checkpointing(input):
    return checkpoint_sequential(model, segments, input)</code></pre>
  </div>
  <div class="block">
    <h2>üî∑ 5. Transformers –∏ Hugging Face</h2>
    <pre><code>from transformers import GPT2Model, GPT2Config

config = GPT2Config.from_pretrained('gpt2')
config.gradient_checkpointing = True  # –í–∫–ª—é—á–∏—Ç—å

model = GPT2Model(config)

# –ò–ª–∏ –¥–ª—è —É–∂–µ —Å–æ–∑–¥–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
model.gradient_checkpointing_enable()

# –û—Ç–∫–ª—é—á–∏—Ç—å
model.gradient_checkpointing_disable()</code></pre>
  </div>
  <div class="block">
    <h2>üî∑ 6. –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è checkpoints</h2>
    <table>
      <tr><th>–°—Ç—Ä–∞—Ç–µ–≥–∏—è</th><th>–ü–∞–º—è—Ç—å</th><th>–í—Ä–µ–º—è</th></tr>
      <tr><td><strong>–ù–µ—Ç checkpoints</strong></td><td>O(n)</td><td>1x</td></tr>
      <tr><td><strong>–ö–∞–∂–¥—ã–π —Å–ª–æ–π</strong></td><td>O(1)</td><td>2x</td></tr>
      <tr><td><strong>–ö–∞–∂–¥—ã–µ k —Å–ª–æ–µ–≤</strong></td><td>O(n/k)</td><td>1 + k</td></tr>
      <tr><td><strong>–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è (‚àön)</strong></td><td>O(‚àön)</td><td>~1.3x</td></tr>
    </table>
    <p><strong>–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è</strong>: —Å—Ç–∞–≤–∏—Ç—å checkpoint –∫–∞–∂–¥—ã–µ ‚àön —Å–ª–æ–µ–≤</p>
  </div>
  <div class="block">
    <h2>üî∑ 7. –î–ª—è LSTM/RNN</h2>
    <pre><code>class CheckpointedLSTM(nn.Module):
    def __init__(self, *args, **kwargs):
        super().__init__()
        self.lstm = nn.LSTM(*args, **kwargs)
    
    def forward(self, x):
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–æ–ª—å–∫–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —à–∞–≥–∏
        segments = []
        seq_len = x.size(0)
        checkpoint_every = seq_len // 4
        
        h, c = None, None
        for i in range(0, seq_len, checkpoint_every):
            segment = x[i:i+checkpoint_every]
            if h is None:
                out, (h, c) = checkpoint.checkpoint(
                    self.lstm, segment
                )
            else:
                out, (h, c) = checkpoint.checkpoint(
                    self.lstm, segment, h, c
                )
            segments.append(out)
        
        return torch.cat(segments, dim=0), (h, c)</code></pre>
  </div>
  <div class="block">
    <h2>üî∑ 8. DeepSpeed Integration</h2>
    <pre><code>from deepspeed.runtime.activation_checkpointing import checkpointing

# –í –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ DeepSpeed
ds_config = {
    "activation_checkpointing": {
        "partition_activations": True,
        "cpu_checkpointing": True,
        "contiguous_memory_optimization": True,
        "number_checkpoints": 4,
        "synchronize_checkpoint_boundary": True,
        "profile": False
    }
}

# CPU offloading –¥–ª—è –µ—â–µ –±–æ–ª—å—à–µ–π —ç–∫–æ–Ω–æ–º–∏–∏
model, optimizer, _, _ = deepspeed.initialize(
    model=model,
    config=ds_config
)</code></pre>
  </div>
  <div class="block">
    <h2>üî∑ 9. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã</h2>
    <ul>
      <li><strong>–ì–¥–µ –ø—Ä–∏–º–µ–Ω—è—Ç—å</strong>: –Ω–∞ —Å–∞–º—ã—Ö "—Ç—è–∂–µ–ª—ã—Ö" —Å–ª–æ—è—Ö (attention, –±–æ–ª—å—à–∏–µ –º–∞—Ç—Ä–∏—Ü—ã)</li>
      <li><strong>–ù–µ –ø—Ä–∏–º–µ–Ω—è—Ç—å</strong>: –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–ª–æ—è—Ö (–æ–±—ã—á–Ω–æ –Ω–µ–±–æ–ª—å—à–∏–µ)</li>
      <li><strong>Batch size</strong>: –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –≤ 2-4x</li>
      <li><strong>–ù–∞–∫–ª–∞–¥–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã</strong>: 20-30% –≤—Ä–µ–º–µ–Ω–∏, –Ω–æ –æ–±—â–µ–µ –≤—Ä–µ–º—è –º–æ–∂–µ—Ç —Å–Ω–∏–∑–∏—Ç—å—Å—è</li>
      <li><strong>Dropout</strong>: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å deterministic dropout —Å checkpointing</li>
      <li><strong>BatchNorm</strong>: –º–æ–∂–µ—Ç –≤–µ—Å—Ç–∏ —Å–µ–±—è –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ LayerNorm</li>
    </ul>
  </div>
  <div class="block">
    <h2>üî∑ 10. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏</h2>
    <pre><code>import torch

def print_memory_stats():
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1e9
        reserved = torch.cuda.memory_reserved() / 1e9
        print(f"Allocated: {allocated:.2f} GB")
        print(f"Reserved: {reserved:.2f} GB")

# –î–æ checkpointing
print_memory_stats()

# –ü–æ—Å–ª–µ –≤–∫–ª—é—á–µ–Ω–∏—è checkpointing  
model.gradient_checkpointing_enable()
print_memory_stats()

# –†–∞–∑–Ω–∏—Ü–∞ –ø–æ–∫–∞–∂–µ—Ç —ç–∫–æ–Ω–æ–º–∏—é</code></pre>
  </div>
  <div class="block">
    <h2>üî∑ 11. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –¥—Ä—É–≥–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏</h2>
    <table>
      <tr><th>–ú–µ—Ç–æ–¥</th><th>–≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏</th><th>–°–∫–æ—Ä–æ—Å—Ç—å</th></tr>
      <tr><td><strong>Gradient Checkpointing</strong></td><td>2-4x</td><td>0.7-0.8x</td></tr>
      <tr><td><strong>Mixed Precision</strong></td><td>2x</td><td>1.5-2x</td></tr>
      <tr><td><strong>Gradient Accumulation</strong></td><td>–ù–µ—Ç</td><td>~1x</td></tr>
      <tr><td><strong>Model Parallelism</strong></td><td>Nx (N GPUs)</td><td>0.8x</td></tr>
      <tr><td><strong>ZeRO (DeepSpeed)</strong></td><td>4-8x</td><td>0.9x</td></tr>
    </table>
  </div>
  <div class="block">
    <h2>üî∑ 12. –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –•–æ—Ä–æ—à–æ –¥–ª—è</h3>
        <ul>
          <li>–û–±—É—á–µ–Ω–∏–µ –æ—á–µ–Ω—å –≥–ª—É–±–æ–∫–∏—Ö —Å–µ—Ç–µ–π</li>
          <li>–ë–æ–ª—å—à–∏–µ batch sizes</li>
          <li>–û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è GPU –ø–∞–º—è—Ç—å</li>
          <li>Transformers —Å –¥–ª–∏–Ω–Ω—ã–º–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏</li>
          <li>–í—ã—Å–æ–∫–æ—Ä–∞–∑—Ä–µ—à–∞—é—â–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ùå –ù–µ –ø–æ–¥—Ö–æ–¥–∏—Ç</h3>
        <ul>
          <li>–û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ –º–æ–¥–µ–ª–∏</li>
          <li>Inference (—Ç–æ–ª—å–∫–æ training)</li>
          <li>–ö–æ–≥–¥–∞ —Å–∫–æ—Ä–æ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–Ω–∞</li>
          <li>–ú–æ–¥–µ–ª–∏ —Å –º—É—Ç–∏—Ä—É—é—â–∏–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º</li>
        </ul>
      </div>
    </div>
  </div>
  <div class="block">
    <h2>ÔøΩÔøΩ 13. –ö–æ–º–±–∏–Ω–∞—Ü–∏—è —Å –¥—Ä—É–≥–∏–º–∏ —Ç–µ—Ö–Ω–∏–∫–∞–º–∏</h2>
    <pre><code># Gradient checkpointing + Mixed precision + Gradient accumulation

from torch.cuda.amp import autocast, GradScaler
import torch.utils.checkpoint as checkpoint

model.gradient_checkpointing_enable()
scaler = GradScaler()
accumulation_steps = 4

for i, batch in enumerate(dataloader):
    with autocast():
        output = model(batch)
        loss = criterion(output, target) / accumulation_steps
    
    scaler.scale(loss).backward()
    
    if (i + 1) % accumulation_steps == 0:
        scaler.step(optimizer)
        scaler.update()
        optimizer.zero_grad()</code></pre>
  </div>
  <div class="block">
    <h2>üî∑ 14. –û—Ç–ª–∞–¥–∫–∞ –ø—Ä–æ–±–ª–µ–º</h2>
    <table>
      <tr><th>–ü—Ä–æ–±–ª–µ–º–∞</th><th>–†–µ—à–µ–Ω–∏–µ</th></tr>
      <tr><td>–ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è</td><td>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å deterministic operations</td></tr>
      <tr><td>–°–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω–æ</td><td>–£–º–µ–Ω—å—à–∏—Ç—å —á–∏—Å–ª–æ checkpoints</td></tr>
      <tr><td>–í—Å–µ –µ—â–µ OOM</td><td>–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å —Å gradient accumulation</td></tr>
      <tr><td>–ù–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –º–æ–¥–µ–ª—å—é</td><td>–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –Ω–µ—Ç in-place –æ–ø–µ—Ä–∞—Ü–∏–π</td></tr>
    </table>
  </div>
  <div class="block">
    <h2>üî∑ 15. –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è</h2>
    <pre><code># –î–ª—è GPT-like –º–æ–¥–µ–ª–µ–π
config = {
    'gradient_checkpointing': True,
    'checkpoint_num_layers': 2,  # –∫–∞–∂–¥—ã–µ 2 —Å–ª–æ—è
    'fp16': True,  # –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å —Å mixed precision
    'batch_size': 32,  # —É–≤–µ–ª–∏—á–µ–Ω–æ –±–ª–∞–≥–æ–¥–∞—Ä—è checkpointing
    'gradient_accumulation_steps': 4
}

# –î–ª—è Vision Transformers
vit_config = {
    'gradient_checkpointing': True,
    'checkpoint_activations': True,
    'checkpoint_attention': True,  # –æ—Å–æ–±–µ–Ω–Ω–æ –≤–∞–∂–Ω–æ
    'batch_size': 256  # —É–≤–µ–ª–∏—á–µ–Ω–æ
}</code></pre>
  </div>
  <div class="block">
    <h2>üî∑ 16. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –ò–∑–º–µ—Ä–∏—Ç—å baseline –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏</li>
      <li>[ ] –í–∫–ª—é—á–∏—Ç—å gradient checkpointing</li>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é (–∫–∞–∂–¥—ã–π N-—ã–π —Å–ª–æ–π)</li>
      <li>[ ] –£–≤–µ–ª–∏—á–∏—Ç—å batch size</li>
      <li>[ ] –ò–∑–º–µ—Ä–∏—Ç—å –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è (–¥–æ/–ø–æ—Å–ª–µ)</li>
      <li>[ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –æ–±—É—á–µ–Ω–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ</li>
      <li>[ ] –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å —Å mixed precision</li>
      <li>[ ] –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞—Ç—å memory –∏ time</li>
    </ul>
    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´Gradient Checkpointing ‚Äî —ç—Ç–æ –∫–∞–∫ —ç–∫–æ–Ω–æ–º–∏—Ç—å –º–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ: –Ω–µ —Ö—Ä–∞–Ω–∏–º –≤—Å–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ñ–∞–π–ª—ã, –∞ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –∏—Ö –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏. –ù–µ–º–Ω–æ–≥–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ, –∑–∞—Ç–æ –º–æ–∂–µ–º —Ä–∞–±–æ—Ç–∞—Ç—å —Å –≥–æ—Ä–∞–∑–¥–æ –±–æ–ª—å—à–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏ –Ω–∞ —Ç–æ–π –∂–µ hardware¬ª.
    </blockquote>
  </div>
</div>
</body>
</html>
