<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>Scikit-learn –ø–æ–ª–Ω—ã–π –æ–±–∑–æ—Ä Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

        .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üîß Scikit-learn: –ü–æ–ª–Ω—ã–π –æ–±–∑–æ—Ä</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –ß—Ç–æ —Ç–∞–∫–æ–µ Scikit-learn?</h2>
    <ul>
      <li><strong>–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞</strong>: —Å–∞–º–∞—è –ø–æ–ø—É–ª—è—Ä–Ω–∞—è –¥–ª—è ML –≤ Python</li>
      <li><strong>–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å</strong>: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, —Ä–µ–≥—Ä–µ—Å—Å–∏—è, –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è, —Å–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏</li>
      <li><strong>–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å</strong>: –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–π API –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π</li>
      <li><strong>–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è</strong>: NumPy, SciPy, Matplotlib</li>
      <li><strong>–£—Å—Ç–∞–Ω–æ–≤–∫–∞</strong>: <code>pip install scikit-learn</code></li>
    </ul>

  <div class="block">
    <h2>üî∑ 2. –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π API</h2>
    <p>–í—Å–µ –º–æ–¥–µ–ª–∏ —Å–ª–µ–¥—É—é—Ç –æ–¥–Ω–æ–º—É –ø–∞—Ç—Ç–µ—Ä–Ω—É:</p>
    <pre><code>from sklearn.xxx import ModelName

# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
model = ModelName(param1=value1, param2=value2)

# –û–±—É—á–µ–Ω–∏–µ
model.fit(X_train, y_train)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
y_pred = model.predict(X_test)

# –û—Ü–µ–Ω–∫–∞ (–¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏/—Ä–µ–≥—Ä–µ—Å—Å–∏–∏)
score = model.score(X_test, y_test)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 3. –û—Å–Ω–æ–≤–Ω—ã–µ –º–æ–¥—É–ª–∏</h2>
    <table>
      <tr><th>–ú–æ–¥—É–ª—å</th><th>–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ</th></tr>
      <tr><td><code>sklearn.linear_model</code></td><td>–õ–∏–Ω–µ–π–Ω—ã–µ –º–æ–¥–µ–ª–∏</td></tr>
      <tr><td><code>sklearn.tree</code></td><td>–î–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π</td></tr>
      <tr><td><code>sklearn.ensemble</code></td><td>–ê–Ω—Å–∞–º–±–ª–∏</td></tr>
      <tr><td><code>sklearn.svm</code></td><td>SVM</td></tr>
      <tr><td><code>sklearn.neighbors</code></td><td>–ú–µ—Ç–æ–¥—ã —Å–æ—Å–µ–¥–µ–π</td></tr>
      <tr><td><code>sklearn.naive_bayes</code></td><td>–ù–∞–∏–≤–Ω—ã–π –ë–∞–π–µ—Å</td></tr>
      <tr><td><code>sklearn.cluster</code></td><td>–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è</td></tr>
      <tr><td><code>sklearn.decomposition</code></td><td>–°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏</td></tr>
      <tr><td><code>sklearn.preprocessing</code></td><td>–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞</td></tr>
      <tr><td><code>sklearn.model_selection</code></td><td>–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –æ—Ç–±–æ—Ä</td></tr>
      <tr><td><code>sklearn.metrics</code></td><td>–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞</td></tr>
      <tr><td><code>sklearn.pipeline</code></td><td>–ü–∞–π–ø–ª–∞–π–Ω—ã</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 4. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è</h2>
    <pre><code>from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier

# –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è
lr = LogisticRegression(max_iter=1000)
lr.fit(X_train, y_train)

# –°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
proba = rf.predict_proba(X_test)

# –ú–µ—Ç—Ä–∏–∫–∏
from sklearn.metrics import accuracy_score, f1_score
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
print(f"F1: {f1_score(y_test, y_pred, average='macro')}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. –†–µ–≥—Ä–µ—Å—Å–∏—è</h2>
    <pre><code>from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.tree import DecisionTreeRegressor

# –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è
lr = LinearRegression()
lr.fit(X_train, y_train)

# Ridge —Ä–µ–≥—Ä–µ—Å—Å–∏—è —Å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π
ridge = Ridge(alpha=1.0)
ridge.fit(X_train, y_train)

# –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥
gb = GradientBoostingRegressor(n_estimators=100, random_state=42)
gb.fit(X_train, y_train)

# –ú–µ—Ç—Ä–∏–∫–∏
from sklearn.metrics import mean_squared_error, r2_score
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"MSE: {mse:.3f}, R¬≤: {r2:.3f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö</h2>
    <pre><code>from sklearn.preprocessing import (
    StandardScaler, MinMaxScaler, RobustScaler,
    LabelEncoder, OneHotEncoder, OrdinalEncoder
)

# –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# One-Hot encoding
from sklearn.preprocessing import OneHotEncoder
ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')
X_encoded = ohe.fit_transform(X_cat)

# –ò–º–ø—É—Ç–∞—Ü–∏—è –ø—Ä–æ–ø—É—Å–∫–æ–≤
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö</h2>
    <pre><code>from sklearn.model_selection import train_test_split

# –ü—Ä–æ—Å—Ç–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2,    # 20% –Ω–∞ —Ç–µ—Å—Ç
    random_state=42,  # –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    stratify=y        # —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ –∫–ª–∞—Å—Å–æ–≤
)

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ 3 –Ω–∞–±–æ—Ä–∞
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=42
)
# –ò—Ç–æ–≥: 60% train, 20% val, 20% test</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è</h2>
    <pre><code>from sklearn.model_selection import (
    cross_val_score, cross_validate, KFold, StratifiedKFold
)

# –ü—Ä–æ—Å—Ç–∞—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
scores = cross_val_score(
    model, X, y, 
    cv=5,           # 5 —Ñ–æ–ª–¥–æ–≤
    scoring='accuracy'
)
print(f"Scores: {scores}")
print(f"Mean: {scores.mean():.3f} (+/- {scores.std():.3f})")

# –î–µ—Ç–∞–ª—å–Ω–∞—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
cv_results = cross_validate(
    model, X, y,
    cv=5,
    scoring=['accuracy', 'precision', 'recall'],
    return_train_score=True
)

# –ö–∞—Å—Ç–æ–º–Ω–∞—è —Ä–∞–∑–±–∏–≤–∫–∞
kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
for train_idx, val_idx in kf.split(X, y):
    X_train, X_val = X[train_idx], X[val_idx]
    y_train, y_val = y[train_idx], y[val_idx]
    # –æ–±—É—á–µ–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. –ü–æ–∏—Å–∫ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</h2>
    <pre><code>from sklearn.model_selection import GridSearchCV, RandomizedSearchCV

# Grid Search - –ø–µ—Ä–µ–±–æ—Ä –≤—Å–µ—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7, None],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(
    RandomForestClassifier(random_state=42),
    param_grid,
    cv=5,
    scoring='f1_weighted',
    n_jobs=-1,  # –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å–µ —è–¥—Ä–∞
    verbose=1
)

grid_search.fit(X_train, y_train)
print(f"Best params: {grid_search.best_params_}")
print(f"Best score: {grid_search.best_score_:.3f}")

# –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å
best_model = grid_search.best_estimator_

# Random Search - —Å–ª—É—á–∞–π–Ω—ã–π –ø–æ–∏—Å–∫ (–±—ã—Å—Ç—Ä–µ–µ)
from scipy.stats import randint
param_dist = {
    'n_estimators': randint(50, 200),
    'max_depth': [3, 5, 7, None]
}

random_search = RandomizedSearchCV(
    RandomForestClassifier(random_state=42),
    param_dist,
    n_iter=20,  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π
    cv=5,
    random_state=42
)
random_search.fit(X_train, y_train)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. Pipeline (–ü–∞–π–ø–ª–∞–π–Ω—ã)</h2>
    <pre><code>from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier

# –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('pca', PCA(n_components=10)),
    ('classifier', RandomForestClassifier(random_state=42))
])

# –û–±—É—á–µ–Ω–∏–µ –≤—Å–µ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞
pipeline.fit(X_train, y_train)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
y_pred = pipeline.predict(X_test)

# –î–æ—Å—Ç—É–ø –∫ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º
scaler = pipeline.named_steps['scaler']
pca = pipeline.named_steps['pca']

# –ü–∞–π–ø–ª–∞–π–Ω —Å GridSearch
param_grid = {
    'pca__n_components': [5, 10, 15],
    'classifier__n_estimators': [50, 100],
    'classifier__max_depth': [3, 5, None]
}

grid = GridSearchCV(pipeline, param_grid, cv=5)
grid.fit(X_train, y_train)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è</h2>
    <pre><code>from sklearn.cluster import (
    KMeans, DBSCAN, AgglomerativeClustering,
    MeanShift, SpectralClustering
)
from sklearn.mixture import GaussianMixture

# K-means
kmeans = KMeans(n_clusters=3, random_state=42)
labels = kmeans.fit_predict(X)

# DBSCAN (–Ω–µ –Ω—É–∂–Ω–æ —É–∫–∞–∑—ã–≤–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤)
dbscan = DBSCAN(eps=0.5, min_samples=5)
labels = dbscan.fit_predict(X)

# Gaussian Mixture Model
gmm = GaussianMixture(n_components=3, random_state=42)
labels = gmm.fit_predict(X)
proba = gmm.predict_proba(X)  # –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏

# –ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
from sklearn.metrics import silhouette_score, davies_bouldin_score
sil_score = silhouette_score(X, labels)
db_score = davies_bouldin_score(X, labels)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 12. –°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏</h2>
    <pre><code>from sklearn.decomposition import PCA, TruncatedSVD, NMF
from sklearn.manifold import TSNE
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

# PCA - –≥–ª–∞–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)
print(f"Explained variance: {pca.explained_variance_ratio_}")

# t-SNE - –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
tsne = TSNE(n_components=2, random_state=42)
X_tsne = tsne.fit_transform(X)

# LDA - —Å —É—á–µ—Ç–æ–º –º–µ—Ç–æ–∫
lda = LinearDiscriminantAnalysis(n_components=2)
X_lda = lda.fit_transform(X, y)

# –í—ã–±–æ—Ä —á–∏—Å–ª–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –≤ PCA
pca_full = PCA()
pca_full.fit(X)
cumsum = np.cumsum(pca_full.explained_variance_ratio_)
n_components = np.argmax(cumsum >= 0.95) + 1  # 95% –¥–∏—Å–ø–µ—Ä—Å–∏–∏</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 13. –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</h2>
    <pre><code>from sklearn.feature_selection import (
    SelectKBest, f_classif, mutual_info_classif,
    RFE, SelectFromModel, VarianceThreshold
)

# SelectKBest - K –ª—É—á—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
selector = SelectKBest(f_classif, k=10)
X_selected = selector.fit_transform(X, y)
selected_features = selector.get_support(indices=True)

# RFE - —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
from sklearn.ensemble import RandomForestClassifier
rfe = RFE(
    estimator=RandomForestClassifier(random_state=42),
    n_features_to_select=10
)
X_selected = rfe.fit_transform(X, y)

# SelectFromModel - –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
selector = SelectFromModel(
    RandomForestClassifier(random_state=42),
    threshold='median'
)
selector.fit(X, y)
X_selected = selector.transform(X)

# –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –Ω–∏–∑–∫–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π
vt = VarianceThreshold(threshold=0.1)
X_filtered = vt.fit_transform(X)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 14. –ê–Ω—Å–∞–º–±–ª–∏</h2>
    <pre><code>from sklearn.ensemble import (
    RandomForestClassifier, GradientBoostingClassifier,
    AdaBoostClassifier, VotingClassifier, StackingClassifier,
    BaggingClassifier
)

# Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42)

# Gradient Boosting
gb = GradientBoostingClassifier(n_estimators=100, random_state=42)

# Voting Classifier - –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ
voting = VotingClassifier(
    estimators=[
        ('lr', LogisticRegression()),
        ('rf', RandomForestClassifier()),
        ('svc', SVC(probability=True))
    ],
    voting='soft'  # 'hard' –∏–ª–∏ 'soft' (–ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º)
)
voting.fit(X_train, y_train)

# Stacking - –º–µ—Ç–∞-–º–æ–¥–µ–ª—å
stacking = StackingClassifier(
    estimators=[
        ('rf', RandomForestClassifier()),
        ('gb', GradientBoostingClassifier())
    ],
    final_estimator=LogisticRegression()
)
stacking.fit(X_train, y_train)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 15. –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö</h2>
    <pre><code>from sklearn.utils.class_weight import compute_class_weight
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler

# –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤
class_weights = compute_class_weight(
    'balanced',
    classes=np.unique(y_train),
    y=y_train
)
weights_dict = dict(zip(np.unique(y_train), class_weights))

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤–µ—Å–æ–≤ –≤ –º–æ–¥–µ–ª–∏
model = RandomForestClassifier(class_weight='balanced')
# –∏–ª–∏
model = RandomForestClassifier(class_weight=weights_dict)

# SMOTE (—Ç—Ä–µ–±—É–µ—Ç imblearn)
# pip install imbalanced-learn
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 16. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π</h2>
    <pre><code>import pickle
import joblib

# –°–ø–æ—Å–æ–± 1: pickle
with open('model.pkl', 'wb') as f:
    pickle.dump(model, f)

with open('model.pkl', 'rb') as f:
    loaded_model = pickle.load(f)

# –°–ø–æ—Å–æ–± 2: joblib (–ª—É—á—à–µ –¥–ª—è –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π)
joblib.dump(model, 'model.joblib')
loaded_model = joblib.load('model.joblib')

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞
joblib.dump(pipeline, 'pipeline.joblib')
loaded_pipeline = joblib.load('pipeline.joblib')

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
predictions = loaded_model.predict(X_test)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 17. –ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏</h2>
    <pre><code>from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, roc_auc_score, confusion_matrix,
    classification_report, roc_curve
)

# –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

# –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
cm = confusion_matrix(y_test, y_pred)

# –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç
report = classification_report(y_test, y_pred)
print(report)

# ROC AUC
y_proba = model.predict_proba(X_test)[:, 1]
auc = roc_auc_score(y_test, y_proba)

# ROC –∫—Ä–∏–≤–∞—è
fpr, tpr, thresholds = roc_curve(y_test, y_proba)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 18. –ú–µ—Ç—Ä–∏–∫–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏</h2>
    <pre><code>from sklearn.metrics import (
    mean_squared_error, mean_absolute_error,
    r2_score, mean_absolute_percentage_error
)
import numpy as np

# MSE –∏ RMSE
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

# MAE
mae = mean_absolute_error(y_test, y_pred)

# R¬≤ (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏)
r2 = r2_score(y_test, y_pred)

# MAPE
mape = mean_absolute_percentage_error(y_test, y_pred)

print(f"RMSE: {rmse:.3f}")
print(f"MAE: {mae:.3f}")
print(f"R¬≤: {r2:.3f}")
print(f"MAPE: {mape:.3f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 19. –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –º–æ–¥–µ–ª–µ–π</h2>
    <pre><code>from sklearn.calibration import CalibratedClassifierCV
from sklearn.calibration import calibration_curve

# –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏
calibrated = CalibratedClassifierCV(
    base_estimator=model,
    method='sigmoid',  # 'sigmoid' –∏–ª–∏ 'isotonic'
    cv=5
)
calibrated.fit(X_train, y_train)

# –û—Ü–µ–Ω–∫–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
y_proba = calibrated.predict_proba(X_test)[:, 1]
fraction_of_positives, mean_predicted_value = calibration_curve(
    y_test, y_proba, n_bins=10
)

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
import matplotlib.pyplot as plt
plt.plot(mean_predicted_value, fraction_of_positives, 's-')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('Mean predicted probability')
plt.ylabel('Fraction of positives')
plt.title('Calibration curve')
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 20. –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</h2>
    <pre><code># –î–ª—è –¥–µ—Ä–µ–≤—å–µ–≤ –∏ –∞–Ω—Å–∞–º–±–ª–µ–π
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
importances = model.feature_importances_
indices = np.argsort(importances)[::-1]

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))
plt.bar(range(X.shape[1]), importances[indices])
plt.xlabel('Feature')
plt.ylabel('Importance')
plt.title('Feature Importances')
plt.show()

# –î–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã
lr = LogisticRegression()
lr.fit(X_train, y_train)
coefficients = lr.coef_[0]

# –ü–µ—Ä–º—É—Ç–∞—Ü–∏–æ–Ω–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è)
from sklearn.inspection import permutation_importance
result = permutation_importance(
    model, X_test, y_test, 
    n_repeats=10, random_state=42
)
print(f"Importances: {result.importances_mean}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 21. –†–∞–±–æ—Ç–∞ —Å —Ç–µ–∫—Å—Ç–æ–º</h2>
    <pre><code>from sklearn.feature_extraction.text import (
    CountVectorizer, TfidfVectorizer, HashingVectorizer
)

# Bag of Words
vectorizer = CountVectorizer(
    max_features=1000,
    ngram_range=(1, 2),  # —É–Ω–∏–≥—Ä–∞–º–º—ã –∏ –±–∏–≥—Ä–∞–º–º—ã
    stop_words='english'
)
X = vectorizer.fit_transform(texts)

# TF-IDF
tfidf = TfidfVectorizer(
    max_features=1000,
    ngram_range=(1, 2),
    min_df=2,  # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    max_df=0.8  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–æ–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
)
X_tfidf = tfidf.fit_transform(texts)

# –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
from sklearn.pipeline import Pipeline
from sklearn.naive_bayes import MultinomialNB

text_clf = Pipeline([
    ('tfidf', TfidfVectorizer()),
    ('clf', MultinomialNB())
])
text_clf.fit(texts_train, y_train)
y_pred = text_clf.predict(texts_test)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 22. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã</h2>
    <pre><code># –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
from sklearn.datasets import (
    make_classification, make_regression,
    make_blobs, make_moons
)

X, y = make_classification(
    n_samples=1000,
    n_features=20,
    n_informative=15,
    n_redundant=5,
    random_state=42
)

# –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
from sklearn.datasets import (
    load_iris, load_wine, load_breast_cancer,
    load_boston, load_diabetes
)

iris = load_iris()
X, y = iris.data, iris.target

# –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –∫—Ä–∏–≤—ã–µ
from sklearn.model_selection import validation_curve

train_scores, val_scores = validation_curve(
    model, X, y,
    param_name="max_depth",
    param_range=range(1, 11),
    cv=5
)

# –ö—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è
from sklearn.model_selection import learning_curve

train_sizes, train_scores, val_scores = learning_curve(
    model, X, y,
    train_sizes=np.linspace(0.1, 1.0, 10),
    cv=5
)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 23. –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏</h2>
    <ul>
      <li><strong>–í—Å–µ–≥–¥–∞ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–π—Ç–µ –¥–∞–Ω–Ω—ã–µ</strong> –¥–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, SVM, k-NN</li>
      <li><strong>–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–∞–π–ø–ª–∞–π–Ω—ã</strong> –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö</li>
      <li><strong>–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ random_state</strong> –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏</li>
      <li><strong>–ü—Ä–∏–º–µ–Ω—è–π—Ç–µ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é</strong> –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–π –æ—Ü–µ–Ω–∫–∏</li>
      <li><strong>–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ GridSearchCV</strong> –¥–ª—è –ø–æ–∏—Å–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</li>
      <li><strong>–ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ –Ω–∞ overfitting</strong> - —Å—Ä–∞–≤–Ω–∏–≤–∞–π—Ç–µ train –∏ test scores</li>
      <li><strong>–°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ –º–æ–¥–µ–ª–∏</strong> —Å –ø–æ–º–æ—â—å—é joblib</li>
      <li><strong>–î–æ–∫—É–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã</strong> –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 24. –ß–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏</h2>
    <div class="good-vs-bad">
      <div class="bad">
        <h3>‚ùå –ü–ª–æ—Ö–æ</h3>
        <ul>
          <li>–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö</li>
          <li>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ test set –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</li>
          <li>–ó–∞–±—ã–≤–∞—Ç—å –ø—Ä–æ stratify –ø—Ä–∏ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–∞—Ö</li>
          <li>–ù–µ –ø—Ä–æ–≤–µ—Ä—è—Ç—å –Ω–∞ overfitting</li>
          <li>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å accuracy –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö</li>
          <li>–ù–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è</li>
        </ul>
      </div>
      <div class="good">
        <h3>‚úÖ –•–æ—Ä–æ—à–æ</h3>
        <ul>
          <li>–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ</li>
          <li>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏</li>
          <li>–°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö</li>
          <li>–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –º–µ—Ç—Ä–∏–∫ –Ω–∞ train –∏ validation</li>
          <li>–í—ã–±–æ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –¥–ª—è –∑–∞–¥–∞—á–∏</li>
          <li>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ SimpleImputer –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–æ–≤</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 25. –ß–µ–∫-–ª–∏—Å—Ç –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞</h2>
    <ul>
      <li>[ ] –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∏–∑—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö</li>
      <li>[ ] –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤</li>
      <li>[ ] –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</li>
      <li>[ ] –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test —Å stratify</li>
      <li>[ ] –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</li>
      <li>[ ] –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ (baseline)</li>
      <li>[ ] –í—ã–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏</li>
      <li>[ ] –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è</li>
      <li>[ ] –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</li>
      <li>[ ] –ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</li>
      <li>[ ] –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ overfitting</li>
      <li>[ ] –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞</li>
      <li>[ ] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´Scikit-learn ‚Äî —ç—Ç–æ –∫–∞–∫ —à–≤–µ–π—Ü–∞—Ä—Å–∫–∏–π –Ω–æ–∂ –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –û–Ω –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –µ–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ª—é–±—ã—Ö –∑–∞–¥–∞—á: –æ—Ç –ø—Ä–æ—Å—Ç–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–æ —Å–ª–æ–∂–Ω—ã—Ö –∞–Ω—Å–∞–º–±–ª–µ–π, —Å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π¬ª.
    </blockquote>
  </div>

</div>

</div>
</body>
</html>
