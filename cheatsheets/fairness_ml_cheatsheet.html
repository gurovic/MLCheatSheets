<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>Fairness –≤ ML Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {body{font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Helvetica,Arial,sans-serif;color:#333;background:#fafcff;padding:10px}}
    @media print{body{background:white;padding:0}@page{size:A4 landscape;margin:10mm}}
    .container{column-count:3;column-gap:20px;max-width:100%}
    .block{break-inside:avoid;margin-bottom:1.2em;padding:12px;background:white;border-radius:6px;box-shadow:0 1px 3px rgba(0,0,0,0.05)}
    h1{font-size:1.6em;font-weight:700;color:#1a5fb4;text-align:center;margin:0 0 8px;column-span:all}
    .subtitle{text-align:center;color:#666;font-size:0.9em;margin-bottom:12px;column-span:all}
    h2{font-size:1.15em;font-weight:700;color:#1a5fb4;margin:0 0 8px;padding-bottom:4px;border-bottom:1px solid #e0e7ff}
    p,ul,ol{font-size:0.92em;margin:0.6em 0}ul,ol{padding-left:18px}li{margin-bottom:4px}
    code{font-family:'Consolas','Courier New',monospace;background-color:#f0f4ff;padding:1px 4px;border-radius:3px;font-size:0.88em}
    pre{background-color:#f0f4ff;padding:8px;border-radius:4px;overflow-x:auto;font-size:0.84em;margin:6px 0}
    pre code{padding:0;background:none;white-space:pre-wrap}
    table{width:100%;border-collapse:collapse;font-size:0.82em;margin:6px 0}
    th{background-color:#e6f0ff;text-align:left;padding:4px 6px;font-weight:600}
    td{padding:4px 6px;border-bottom:1px solid #f0f4ff}tr:nth-child(even){background-color:#f8fbff}
    .good-vs-bad{display:flex;flex-direction:column;gap:8px}.good-vs-bad div{flex:1;padding:6px 8px;border-radius:4px}
    .good{background-color:#f0f9f4;border-left:3px solid #2e8b57}.bad{background-color:#fdf0f2;border-left:3px solid #d32f2f}
    .good h3,.bad h3{margin:0 0 4px;font-size:1em;font-weight:700}.good ul,.bad ul{padding-left:20px;margin:0}
    .good li::before{content:"‚úÖ ";font-weight:bold}.bad li::before{content:"‚ùå ";font-weight:bold}
    blockquote{font-style:italic;margin:8px 0;padding:6px 10px;background:#f8fbff;border-left:2px solid #1a5fb4;font-size:0.88em}
  </style>
</head>
<body>
<div class="container">
  <h1>‚öñÔ∏è Fairness –≤ ML (–°–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å) Cheatsheet</h1>
  <div class="subtitle">–≠—Ç–∏–∫–∞ –∏ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å –≤ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏<br>üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –ß—Ç–æ —Ç–∞–∫–æ–µ Fairness –≤ ML</h2>
    <p><strong>Fairness (—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å)</strong> ‚Äî –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏–∏ –∏ –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–∏ –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö ML-–º–æ–¥–µ–ª–µ–π –ø–æ –∑–∞—â–∏—â—ë–Ω–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º.</p>
    <ul>
      <li><strong>–ü—Ä–æ–±–ª–µ–º–∞</strong>: –º–æ–¥–µ–ª–∏ –º–æ–≥—É—Ç —É—Å–∏–ª–∏–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–µ–¥—Ä–∞—Å—Å—É–¥–∫–∏</li>
      <li><strong>–ó–∞—â–∏—â—ë–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏</strong>: —Ä–∞—Å–∞, –ø–æ–ª, –≤–æ–∑—Ä–∞—Å—Ç, —Ä–µ–ª–∏–≥–∏—è, –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å</li>
      <li><strong>–ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è</strong>: —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Ä–∏—Å–∫–∏, —Ä–µ–ø—É—Ç–∞—Ü–∏–æ–Ω–Ω—ã–π —É—â–µ—Ä–±</li>
      <li><strong>–†–µ—à–µ–Ω–∏–µ</strong>: –∏–∑–º–µ—Ä–µ–Ω–∏–µ –∏ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ bias</li>
    </ul>
    <blockquote>–ú–æ–¥–µ–ª–∏ –æ–±—É—á–∞—é—Ç—Å—è –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –æ—Ç—Ä–∞–∂–∞—Ç—å —Å–∏—Å—Ç–µ–º–Ω—É—é –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏—é. –ë–µ–∑ –∫–æ–Ω—Ç—Ä–æ–ª—è ML –º–æ–∂–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å –Ω–µ—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å.</blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 2. –¢–∏–ø—ã Bias (–ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–∏)</h2>
    <table>
      <tr><th>–¢–∏–ø</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th><th>–ü—Ä–∏–º–µ—Ä</th></tr>
      <tr><td><strong>Historical Bias</strong></td><td>–ü—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö</td><td>–ú–µ–Ω—å—à–µ –∂–µ–Ω—â–∏–Ω –≤ IT</td></tr>
      <tr><td><strong>Representation Bias</strong></td><td>–ù–µ—Ä–∞–≤–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≥—Ä—É–ø–ø</td><td>–ú–∞–ª–æ —Ç—ë–º–Ω–æ–∫–æ–∂–∏—Ö –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ –ª–∏—Ü</td></tr>
      <tr><td><strong>Measurement Bias</strong></td><td>–ù–µ—Ç–æ—á–Ω—ã–µ –∏–∑–º–µ—Ä–µ–Ω–∏—è</td><td>–û—Ü–µ–Ω–∫–∞ creditworthiness</td></tr>
      <tr><td><strong>Aggregation Bias</strong></td><td>–û–¥–Ω–∞ –º–æ–¥–µ–ª—å –¥–ª—è –≤—Å–µ—Ö</td><td>–ú–µ–¥–∏—Ü–∏–Ω–∞ –¥–ª—è –º—É–∂—á–∏–Ω</td></tr>
      <tr><td><strong>Evaluation Bias</strong></td><td>–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏</td><td>Accuracy –Ω–∞ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö</td></tr>
      <tr><td><strong>Deployment Bias</strong></td><td>–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</td><td>–ú–æ–¥–µ–ª—å –≤ –¥—Ä—É–≥–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 3. –ú–µ—Ç—Ä–∏–∫–∏ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç–∏</h2>
    <p><strong>1. Demographic Parity (–î–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –ø–∞—Ä–∏—Ç–µ—Ç)</strong></p>
    <pre><code># –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ–¥–∏–Ω–∞–∫–æ–≤–∞
P(≈∑=1 | A=0) = P(≈∑=1 | A=1)

# –≥–¥–µ A - –∑–∞—â–∏—â—ë–Ω–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ–ª)</code></pre>
    <p><strong>2. Equal Opportunity</strong></p>
    <pre><code># –†–∞–≤–Ω–∞—è TPR (True Positive Rate) –¥–ª—è –≤—Å–µ—Ö –≥—Ä—É–ø–ø
P(≈∑=1 | y=1, A=0) = P(≈∑=1 | y=1, A=1)</code></pre>
    <p><strong>3. Equalized Odds</strong></p>
    <pre><code># –†–∞–≤–Ω—ã–µ TPR –∏ FPR –¥–ª—è –≤—Å–µ—Ö –≥—Ä—É–ø–ø
P(≈∑=1 | y=k, A=0) = P(≈∑=1 | y=k, A=1) –¥–ª—è k‚àà{0,1}</code></pre>
    <p><strong>4. Predictive Parity</strong></p>
    <pre><code># –†–∞–≤–Ω–∞—è PPV (Positive Predictive Value)
P(y=1 | ≈∑=1, A=0) = P(y=1 | ≈∑=1, A=1)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. –ò–∑–º–µ—Ä–µ–Ω–∏–µ Bias</h2>
    <pre><code>from sklearn.metrics import confusion_matrix
import numpy as np

def measure_fairness(y_true, y_pred, protected_attr):
    groups = np.unique(protected_attr)
    
    for group in groups:
        mask = (protected_attr == group)
        y_true_group = y_true[mask]
        y_pred_group = y_pred[mask]
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        tn, fp, fn, tp = confusion_matrix(y_true_group, y_pred_group).ravel()
        
        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0  # True Positive Rate
        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  # False Positive Rate
        ppv = tp / (tp + fp) if (tp + fp) > 0 else 0  # Precision
        
        print(f"Group {group}:")
        print(f"  TPR (Recall): {tpr:.3f}")
        print(f"  FPR: {fpr:.3f}")
        print(f"  PPV (Precision): {ppv:.3f}")
        print(f"  Selection Rate: {y_pred_group.mean():.3f}")

# Demographic Parity Difference
def demographic_parity_difference(y_pred, protected_attr):
    groups = np.unique(protected_attr)
    rates = []
    for group in groups:
        mask = (protected_attr == group)
        rate = y_pred[mask].mean()
        rates.append(rate)
    return abs(rates[0] - rates[1])

# Disparate Impact Ratio
def disparate_impact_ratio(y_pred, protected_attr, privileged=1):
    privileged_rate = y_pred[protected_attr == privileged].mean()
    unprivileged_rate = y_pred[protected_attr != privileged].mean()
    return unprivileged_rate / privileged_rate if privileged_rate > 0 else 0

# –ü—Ä–∞–≤–∏–ª–æ 80%: ratio > 0.8 —Å—á–∏—Ç–∞–µ—Ç—Å—è —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤—ã–º</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è Fairness</h2>
    <p><strong>Fairlearn (Microsoft)</strong></p>
    <pre><code>pip install fairlearn

from fairlearn.metrics import MetricFrame, selection_rate
from sklearn.metrics import accuracy_score

# –û—Ü–µ–Ω–∫–∞ –º–µ—Ç—Ä–∏–∫ –ø–æ –≥—Ä—É–ø–ø–∞–º
metric_frame = MetricFrame(
    metrics={
        'accuracy': accuracy_score,
        'selection_rate': selection_rate
    },
    y_true=y_test,
    y_pred=y_pred,
    sensitive_features=protected_attr
)

print(metric_frame.by_group)
print(f"Difference: {metric_frame.difference()}")
print(f"Ratio: {metric_frame.ratio()}")</code></pre>

    <p><strong>AIF360 (IBM)</strong></p>
    <pre><code>pip install aif360

from aif360.datasets import BinaryLabelDataset
from aif360.metrics import BinaryLabelDatasetMetric

dataset = BinaryLabelDataset(
    df=df,
    label_names=['target'],
    protected_attribute_names=['protected_attr']
)

metric = BinaryLabelDatasetMetric(
    dataset,
    unprivileged_groups=[{'protected_attr': 0}],
    privileged_groups=[{'protected_attr': 1}]
)

print(f"Disparate Impact: {metric.disparate_impact()}")
print(f"Mean Difference: {metric.mean_difference()}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. Preprocessing: –£–¥–∞–ª–µ–Ω–∏–µ Bias –∏–∑ –¥–∞–Ω–Ω—ã—Ö</h2>
    <p><strong>Reweighting</strong></p>
    <pre><code>from aif360.algorithms.preprocessing import Reweighing

# –ü—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏–µ –≤–µ—Å–æ–≤ –¥–ª—è –±–∞–ª–∞–Ω—Å–∞ –≥—Ä—É–ø–ø
RW = Reweighing(
    unprivileged_groups=[{'protected_attr': 0}],
    privileged_groups=[{'protected_attr': 1}]
)
dataset_transf = RW.fit_transform(dataset)

# –û–±—É—á–µ–Ω–∏–µ —Å –≤–µ—Å–∞–º–∏
model.fit(X_train, y_train, sample_weight=dataset_transf.instance_weights)</code></pre>

    <p><strong>Learning Fair Representations (LFR)</strong></p>
    <pre><code>from aif360.algorithms.preprocessing import LearningFairRepresentations

# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è bias
LFR = LearningFairRepresentations(
    unprivileged_groups=[{'protected_attr': 0}],
    privileged_groups=[{'protected_attr': 1}]
)
dataset_transf = LFR.fit_transform(dataset)

# –ù–æ–≤—ã–µ "—á–µ—Å—Ç–Ω—ã–µ" –ø—Ä–∏–∑–Ω–∞–∫–∏
X_fair = dataset_transf.features</code></pre>

    <p><strong>Disparate Impact Remover</strong></p>
    <pre><code>from aif360.algorithms.preprocessing import DisparateImpactRemover

# –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
DIR = DisparateImpactRemover(repair_level=1.0)
dataset_transf = DIR.fit_transform(dataset)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. In-processing: –°–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ</h2>
    <p><strong>Adversarial Debiasing</strong></p>
    <pre><code>from aif360.algorithms.inprocessing import AdversarialDebiasing

# –ù–µ–π—Ä–æ—Å–µ—Ç—å —Å adversarial –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–π
sess = tf.Session()
debiaser = AdversarialDebiasing(
    privileged_groups=[{'protected_attr': 1}],
    unprivileged_groups=[{'protected_attr': 0}],
    scope_name='debiaser',
    debias=True,
    sess=sess
)
debiaser.fit(dataset_train)
dataset_pred = debiaser.predict(dataset_test)</code></pre>

    <p><strong>Prejudice Remover</strong></p>
    <pre><code>from aif360.algorithms.inprocessing import PrejudiceRemover

# –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è fairness
PR = PrejudiceRemover(
    eta=1.0,  # –°–∏–ª–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
    sensitive_attr='protected_attr'
)
PR.fit(dataset_train)
dataset_pred = PR.predict(dataset_test)</code></pre>

    <p><strong>Fairlearn - Reduction</strong></p>
    <pre><code>from fairlearn.reductions import ExponentiatedGradient, DemographicParity
from sklearn.linear_model import LogisticRegression

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏ –Ω–∞ fairness
constraint = DemographicParity()
mitigator = ExponentiatedGradient(
    LogisticRegression(),
    constraint
)

mitigator.fit(X_train, y_train, sensitive_features=protected_attr_train)
y_pred = mitigator.predict(X_test)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. Post-processing: –ö–æ—Ä—Ä–µ–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π</h2>
    <p><strong>Threshold Optimizer</strong></p>
    <pre><code>from fairlearn.postprocessing import ThresholdOptimizer

# –†–∞–∑–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –≥—Ä—É–ø–ø
postprocessor = ThresholdOptimizer(
    estimator=model,
    constraints="demographic_parity",
    objective="balanced_accuracy_score"
)

postprocessor.fit(X_train, y_train, sensitive_features=protected_attr_train)
y_pred_fair = postprocessor.predict(X_test, sensitive_features=protected_attr_test)</code></pre>

    <p><strong>Calibrated Equalized Odds</strong></p>
    <pre><code>from aif360.algorithms.postprocessing import CalibratedEqOddsPostprocessing

# –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –¥–ª—è equalized odds
CPP = CalibratedEqOddsPostprocessing(
    unprivileged_groups=[{'protected_attr': 0}],
    privileged_groups=[{'protected_attr': 1}],
    cost_constraint='fpr',  # –∏–ª–∏ 'fnr', 'weighted'
    seed=42
)
CPP.fit(dataset_true, dataset_pred)
dataset_pred_fair = CPP.predict(dataset_pred)</code></pre>

    <p><strong>Reject Option Classification</strong></p>
    <pre><code>from aif360.algorithms.postprocessing import RejectOptionClassification

# –ò–∑–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –≤ "—Å–æ–º–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö" —Å–ª—É—á–∞—è—Ö
ROC = RejectOptionClassification(
    unprivileged_groups=[{'protected_attr': 0}],
    privileged_groups=[{'protected_attr': 1}],
    low_class_thresh=0.01,
    high_class_thresh=0.99,
    num_class_thresh=100,
    num_ROC_margin=50,
    metric_name="Statistical parity difference"
)
ROC.fit(dataset_true, dataset_pred)
dataset_pred_fair = ROC.predict(dataset_pred)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π workflow</h2>
    <pre><code># 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
import pandas as pd
df = pd.read_csv('data.csv')

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∑–∞—â–∏—â—ë–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
print(df['gender'].value_counts())
print(df['race'].value_counts())

# 2. –û—Ü–µ–Ω–∫–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ bias
from fairlearn.metrics import demographic_parity_difference, equalized_odds_difference

# –û–±—É—á–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
model = LogisticRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# –ú–µ—Ç—Ä–∏–∫–∏ fairness
dp_diff = demographic_parity_difference(
    y_test, y_pred, sensitive_features=protected_attr_test
)
eo_diff = equalized_odds_difference(
    y_test, y_pred, sensitive_features=protected_attr_test
)

print(f"Demographic Parity Difference: {dp_diff:.3f}")  # –ñ–µ–ª–∞—Ç–µ–ª—å–Ω–æ < 0.1
print(f"Equalized Odds Difference: {eo_diff:.3f}")      # –ñ–µ–ª–∞—Ç–µ–ª—å–Ω–æ < 0.1

# 3. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ mitigation
from fairlearn.reductions import ExponentiatedGradient, EqualizedOdds

mitigator = ExponentiatedGradient(
    LogisticRegression(),
    constraints=EqualizedOdds()
)
mitigator.fit(X_train, y_train, sensitive_features=protected_attr_train)

# 4. –û—Ü–µ–Ω–∫–∞ –ø–æ—Å–ª–µ mitigation
y_pred_fair = mitigator.predict(X_test)

dp_diff_after = demographic_parity_difference(
    y_test, y_pred_fair, sensitive_features=protected_attr_test
)
eo_diff_after = equalized_odds_difference(
    y_test, y_pred_fair, sensitive_features=protected_attr_test
)

print(f"After mitigation:")
print(f"Demographic Parity Difference: {dp_diff_after:.3f}")
print(f"Equalized Odds Difference: {eo_diff_after:.3f}")

# 5. –ê–Ω–∞–ª–∏–∑ trade-off accuracy vs fairness
from sklearn.metrics import accuracy_score
print(f"Accuracy before: {accuracy_score(y_test, y_pred):.3f}")
print(f"Accuracy after: {accuracy_score(y_test, y_pred_fair):.3f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. Fairness-Accuracy Trade-off</h2>
    <ul>
      <li>–£–ª—É—á—à–µ–Ω–∏–µ fairness —á–∞—Å—Ç–æ —Å–Ω–∏–∂–∞–µ—Ç accuracy</li>
      <li>–ù—É–∂–µ–Ω –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –º–µ—Ç—Ä–∏–∫–∞–º–∏</li>
      <li>Trade-off curve: Pareto frontier</li>
      <li>–ë–∏–∑–Ω–µ—Å —Ä–µ—à–∞–µ—Ç –ø—Ä–∏–µ–º–ª–µ–º—ã–π –∫–æ–º–ø—Ä–æ–º–∏—Å—Å</li>
    </ul>
    <pre><code># –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è trade-off
from fairlearn.metrics import MetricFrame
import matplotlib.pyplot as plt

# –†–∞–∑–ª–∏—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è constraint relaxation
fairness_vals = []
accuracy_vals = []

for epsilon in [0.01, 0.05, 0.1, 0.15, 0.2]:
    constraint = EqualizedOdds(difference_bound=epsilon)
    mitigator = ExponentiatedGradient(model, constraint)
    mitigator.fit(X_train, y_train, sensitive_features=protected_attr_train)
    
    y_pred = mitigator.predict(X_test)
    
    acc = accuracy_score(y_test, y_pred)
    eo_diff = equalized_odds_difference(y_test, y_pred, sensitive_features=protected_attr_test)
    
    accuracy_vals.append(acc)
    fairness_vals.append(eo_diff)

plt.plot(fairness_vals, accuracy_vals, 'o-')
plt.xlabel('Equalized Odds Difference')
plt.ylabel('Accuracy')
plt.title('Fairness-Accuracy Trade-off')
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. Intersectionality</h2>
    <p>–ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–∞—â–∏—â—ë–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ–∑–¥–∞—ë—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –≥—Ä—É–ø–ø—ã —Å –æ—Å–æ–±—ã–º–∏ bias.</p>
    <pre><code># –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ–ª √ó —Ä–∞—Å–∞)
df['intersection'] = df['gender'].astype(str) + '_' + df['race'].astype(str)

# –û—Ü–µ–Ω–∫–∞ –ø–æ –≤—Å–µ–º –≥—Ä—É–ø–ø–∞–º
metric_frame = MetricFrame(
    metrics=accuracy_score,
    y_true=y_test,
    y_pred=y_pred,
    sensitive_features=df.loc[test_indices, 'intersection']
)

print(metric_frame.by_group)

# –í—ã—è–≤–ª–µ–Ω–∏–µ –Ω–∞–∏–±–æ–ª–µ–µ —É—è–∑–≤–∏–º—ã—Ö –≥—Ä—É–ø–ø
worst_group = metric_frame.by_group.idxmin()
best_group = metric_frame.by_group.idxmax()

print(f"Worst performing group: {worst_group}")
print(f"Best performing group: {best_group}")
print(f"Gap: {metric_frame.by_group[best_group] - metric_frame.by_group[worst_group]:.3f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 12. Auditing –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥</h2>
    <pre><code># –†–µ–≥—É–ª—è—Ä–Ω—ã–π –∞—É–¥–∏—Ç –º–æ–¥–µ–ª–∏ –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ
class FairnessMonitor:
    def __init__(self, sensitive_features):
        self.sensitive_features = sensitive_features
        self.history = []
    
    def log_predictions(self, y_true, y_pred, timestamp):
        metrics = {}
        
        for sf in self.sensitive_features:
            dp_diff = demographic_parity_difference(y_true, y_pred, sensitive_features=sf)
            eo_diff = equalized_odds_difference(y_true, y_pred, sensitive_features=sf)
            
            metrics[f'{sf}_dp_diff'] = dp_diff
            metrics[f'{sf}_eo_diff'] = eo_diff
        
        self.history.append({
            'timestamp': timestamp,
            **metrics
        })
    
    def check_drift(self, threshold=0.1):
        if len(self.history) < 2:
            return False
        
        latest = self.history[-1]
        baseline = self.history[0]
        
        for key in latest:
            if key == 'timestamp':
                continue
            if abs(latest[key] - baseline[key]) > threshold:
                print(f"ALERT: {key} changed by {abs(latest[key] - baseline[key]):.3f}")
                return True
        
        return False

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
monitor = FairnessMonitor(sensitive_features=['gender', 'race'])
monitor.log_predictions(y_true, y_pred, datetime.now())

if monitor.check_drift():
    # –ü–µ—Ä–µ–æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –∏–ª–∏ –ø—Ä–∏–º–µ–Ω–∏—Ç—å mitigation
    pass</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 13. –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã</h2>
    <ul>
      <li><strong>GDPR (EU)</strong>: –ø—Ä–∞–≤–æ –Ω–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ—à–µ–Ω–∏–π</li>
      <li><strong>Equal Credit Opportunity Act (US)</strong>: –∑–∞–ø—Ä–µ—Ç –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏–∏ –≤ –∫—Ä–µ–¥–∏—Ç–æ–≤–∞–Ω–∏–∏</li>
      <li><strong>Fair Housing Act (US)</strong>: —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å –≤ –∂–∏–ª–∏—â–Ω–æ–π —Å—Ñ–µ—Ä–µ</li>
      <li><strong>Employment Law</strong>: –∑–∞–ø—Ä–µ—Ç –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏–∏ –ø—Ä–∏ –Ω–∞–π–º–µ</li>
      <li><strong>Disparate Impact</strong>: —é—Ä–∏–¥–∏—á–µ—Å–∫–∞—è –∫–æ–Ω—Ü–µ–ø—Ü–∏—è –Ω–µ–ø—Ä—è–º–æ–π –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏–∏</li>
    </ul>
    <blockquote>–î–∞–∂–µ –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∑–∞—â–∏—â—ë–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–∞–ø—Ä—è–º—É—é, –æ–Ω–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–∑–∞–∫–æ–Ω–Ω–æ–π, –µ—Å–ª–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç disparate impact –Ω–∞ –∑–∞—â–∏—â—ë–Ω–Ω—ã–µ –≥—Ä—É–ø–ø—ã.</blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 14. Best Practices</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏</h3>
        <ul>
          <li>–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ bias –î–û –æ–±—É—á–µ–Ω–∏—è</li>
          <li>–ò–∑–º–µ—Ä—è—Ç—å fairness –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ —Ç–µ—Å—Ç–µ</li>
          <li>–î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å trade-offs</li>
          <li>–ü—Ä–∏–≤–ª–µ–∫–∞—Ç—å domain experts –∏ —ç—Ç–∏–∫–æ–≤</li>
          <li>–†–µ–≥—É–ª—è—Ä–Ω—ã–π –∞—É–¥–∏—Ç –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ</li>
          <li>–¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ intersectionality</li>
          <li>Transparency: –æ–±—ä—è—Å–Ω—è—Ç—å —Ä–µ—à–µ–Ω–∏—è</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ùå –û—à–∏–±–∫–∏</h3>
        <ul>
          <li>–ü—Ä–æ—Å—Ç–æ —É–¥–∞–ª–∏—Ç—å –∑–∞—â–∏—â—ë–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏</li>
          <li>–ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å fairness –º–µ—Ç—Ä–∏–∫–∏</li>
          <li>–û–¥–Ω–∞ –º–æ–¥–µ–ª—å –¥–ª—è –≤—Å–µ—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤</li>
          <li>–ù–µ —É—á–∏—Ç—ã–≤–∞—Ç—å feedback loops</li>
          <li>–ü–µ—Ä–µ–æ—Ü–µ–Ω–∏–≤–∞—Ç—å "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç—å" –¥–∞–Ω–Ω—ã—Ö</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 15. –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–±–ª–µ–º Fairness</h2>
    <ul>
      <li><strong>COMPAS</strong>: —Å–∏—Å—Ç–µ–º–∞ –æ—Ü–µ–Ω–∫–∏ —Ä–µ—Ü–∏–¥–∏–≤–∏–∑–º–∞ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∏—Ä–æ–≤–∞–ª–∞ –∞—Ñ—Ä–æ–∞–º–µ—Ä–∏–∫–∞–Ω—Ü–µ–≤</li>
      <li><strong>Amazon Hiring AI</strong>: –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏—è –∂–µ–Ω—â–∏–Ω –∏–∑-–∑–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö</li>
      <li><strong>Face Recognition</strong>: –Ω–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –¥–ª—è —Ç—ë–º–Ω–æ–∫–æ–∂–∏—Ö –∂–µ–Ω—â–∏–Ω</li>
      <li><strong>Credit Scoring</strong>: —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∑–∞–Ω–∏–∂–µ–Ω–∏–µ –¥–ª—è –º–µ–Ω—å—à–∏–Ω—Å—Ç–≤</li>
      <li><strong>Healthcare</strong>: –Ω–µ–¥–æ–æ—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–∞ –¥–ª—è —á—ë—Ä–Ω—ã—Ö –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 16. –ß–µ–∫-–ª–∏—Å—Ç Fairness</h2>
    <ul>
      <li>[ ] –ò–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∑–∞—â–∏—â—ë–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏</li>
      <li>[ ] –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å representation bias –≤ –¥–∞–Ω–Ω—ã—Ö</li>
      <li>[ ] –ò–∑–º–µ—Ä–∏—Ç—å baseline fairness –º–µ—Ç—Ä–∏–∫–∏</li>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å –ø–æ–¥—Ö–æ–¥—è—â–µ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ fairness</li>
      <li>[ ] –ü—Ä–∏–º–µ–Ω–∏—Ç—å pre/in/post-processing mitigation</li>
      <li>[ ] –û—Ü–µ–Ω–∏—Ç—å fairness-accuracy trade-off</li>
      <li>[ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å intersectionality</li>
      <li>[ ] –í–Ω–µ–¥—Ä–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ production</li>
      <li>[ ] –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏</li>
      <li>[ ] –ü–æ–ª—É—á–∏—Ç—å —é—Ä–∏–¥–∏—á–µ—Å–∫—É—é –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é</li>
      <li>[ ] –°–æ–∑–¥–∞—Ç—å –ø—Ä–æ—Ü–µ–¥—É—Ä—É appeal –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´Fairness –≤ ML ‚Äî —ç—Ç–æ –ø—Ä–æ —Ç–æ, —á—Ç–æ–±—ã AI-—Å–∏—Å—Ç–µ–º—ã –Ω–µ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∏—Ä–æ–≤–∞–ª–∏ –ª—é–¥–µ–π –ø–æ –ø–æ–ª—É, —Ä–∞—Å–µ, –≤–æ–∑—Ä–∞—Å—Ç—É –∏ –¥—Ä—É–≥–∏–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º. –ù–∞–ø—Ä–∏–º–µ—Ä, —Å–∏—Å—Ç–µ–º–∞ –æ–¥–æ–±—Ä–µ–Ω–∏—è –∫—Ä–µ–¥–∏—Ç–æ–≤ –Ω–µ –¥–æ–ª–∂–Ω–∞ –æ—Ç–∫–∞–∑—ã–≤–∞—Ç—å –∂–µ–Ω—â–∏–Ω–∞–º —á–∞—â–µ, —á–µ–º –º—É–∂—á–∏–Ω–∞–º —Å —Ç–∞–∫–æ–π –∂–µ –∫—Ä–µ–¥–∏—Ç–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–µ–π. –ú—ã –∏–∑–º–µ—Ä—è–µ–º –∏ —É—Å—Ç—Ä–∞–Ω—è–µ–º —Ç–∞–∫—É—é –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏¬ª.
    </blockquote>
  </div>

</div>
</body>
</html>
