<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      
        min-width: 900px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

        .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üíæ –°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –ó–∞—á–µ–º —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è?</h2>
    <p><strong>–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è</strong> ‚Äî —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∏—Å–∫ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.</p>
    <ul>
      <li><strong>Deployment</strong>: —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –≤ production</li>
      <li><strong>Checkpoint</strong>: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è</li>
      <li><strong>Sharing</strong>: –ø–µ—Ä–µ–¥–∞—á–∞ –º–æ–¥–µ–ª–∏ –¥—Ä—É–≥–∏–º</li>
      <li><strong>Versioning</strong>: —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–µ—Ä—Å–∏—è–º–∏</li>
      <li><strong>Inference</strong>: –±—ã—Å—Ç—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π</li>
    </ul>
    <blockquote>üí° "–ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è ‚Äî –∫–ª—é—á –∫ —É—Å–ø–µ—à–Ω–æ–º—É deployment"</blockquote>

    </div>

</div>
<div class="block">
    <h2>üî∑ 2. –ß—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å?</h2>
    <table>
      <tr><th>–ö–æ–º–ø–æ–Ω–µ–Ω—Ç</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th></tr>
      <tr>
        <td><strong>–í–µ—Å–∞ –º–æ–¥–µ–ª–∏</strong></td>
        <td>–û–±—É—á–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–µ—Ç–∏</td>
      </tr>
      <tr>
        <td><strong>–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞</strong></td>
        <td>–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–µ—Ç–∏</td>
      </tr>
      <tr>
        <td><strong>Optimizer state</strong></td>
        <td>–°–æ—Å—Ç–æ—è–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞</td>
      </tr>
      <tr>
        <td><strong>Training config</strong></td>
        <td>–ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã</td>
      </tr>
      <tr>
        <td><strong>Preprocessing</strong></td>
        <td>–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è, —Å–∫–µ–π–ª–µ—Ä—ã</td>
      </tr>
      <tr>
        <td><strong>Metadata</strong></td>
        <td>–í–µ—Ä—Å–∏—è, –º–µ—Ç—Ä–∏–∫–∏, –¥–∞—Ç–∞</td>
      </tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 3. PyTorch —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è</h2>
    <p><strong>–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–µ—Å–æ–≤</strong>:</p>
    <pre><code>import torch

# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–æ–ª—å–∫–æ –≤–µ—Å–∞
torch.save(model.state_dict(), 'model_weights.pth')

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤–µ—Å–∞
model = MyModel()  # —Å–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å
model.load_state_dict(torch.load('model_weights.pth'))
model.eval()

# –î–ª—è inference
with torch.no_grad():
    output = model(input_tensor)</code></pre>

    <p><strong>–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ–π –º–æ–¥–µ–ª–∏</strong>:</p>
    <pre><code># –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å —Ü–µ–ª–∏–∫–æ–º (–Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
torch.save(model, 'model_full.pth')

# –ó–∞–≥—Ä—É–∑–∏—Ç—å
model = torch.load('model_full.pth')
model.eval()</code></pre>

    <p><strong>Checkpoint (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)</strong>:</p>
    <pre><code># –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å–µ –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è
checkpoint = {
    'epoch': epoch,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'loss': loss,
    'accuracy': accuracy
}
torch.save(checkpoint, 'checkpoint.pth')

# –ó–∞–≥—Ä—É–∑–∏—Ç—å checkpoint
checkpoint = torch.load('checkpoint.pth')
model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']
loss = checkpoint['loss']</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. TensorFlow/Keras —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è</h2>
    <p><strong>Keras API (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)</strong>:</p>
    <pre><code>import tensorflow as tf

# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ + –≤–µ—Å–∞)
model.save('my_model.keras')  # –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç
# –∏–ª–∏
model.save('my_model.h5')  # —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
model = tf.keras.models.load_model('my_model.keras')

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
predictions = model.predict(test_data)</code></pre>

    <p><strong>SavedModel format (production)</strong>:</p>
    <pre><code># –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ SavedModel —Ñ–æ—Ä–º–∞—Ç–µ
model.save('saved_model_dir')

# –°—Ç—Ä—É–∫—Ç—É—Ä–∞:
# saved_model_dir/
#   - saved_model.pb
#   - variables/
#   - assets/

# –ó–∞–≥—Ä—É–∑–∏—Ç—å
model = tf.keras.models.load_model('saved_model_dir')</code></pre>

    <p><strong>–¢–æ–ª—å–∫–æ –≤–µ—Å–∞</strong>:</p>
    <pre><code># –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–µ—Å–∞
model.save_weights('model_weights.h5')

# –ó–∞–≥—Ä—É–∑–∏—Ç—å (–Ω—É–∂–Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)
model = create_model()  # —Å–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å
model.load_weights('model_weights.h5')</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. ONNX —Ñ–æ—Ä–º–∞—Ç</h2>
    <p><strong>Open Neural Network Exchange</strong> ‚Äî —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç.</p>
    
    <p><strong>PyTorch ‚Üí ONNX</strong>:</p>
    <pre><code>import torch.onnx

# Dummy input –¥–ª—è trace
dummy_input = torch.randn(1, 3, 224, 224)

# –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX
torch.onnx.export(
    model,
    dummy_input,
    "model.onnx",
    export_params=True,
    opset_version=11,
    do_constant_folding=True,
    input_names=['input'],
    output_names=['output'],
    dynamic_axes={
        'input': {0: 'batch_size'},
        'output': {0: 'batch_size'}
    }
)

# –ó–∞–≥—Ä—É–∑–∫–∞ —Å ONNX Runtime
import onnxruntime as ort

session = ort.InferenceSession("model.onnx")
outputs = session.run(
    None,
    {"input": input_data.numpy()}
)</code></pre>

    <p><strong>TensorFlow ‚Üí ONNX</strong>:</p>
    <pre><code>import tf2onnx

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
spec = (tf.TensorSpec((None, 224, 224, 3), tf.float32),)
model_proto, _ = tf2onnx.convert.from_keras(
    model,
    input_signature=spec,
    opset=13
)

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
with open("model.onnx", "wb") as f:
    f.write(model_proto.SerializeToString())</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. TorchScript</h2>
    <p>–ù–µ–∑–∞–≤–∏—Å–∏–º–∞—è –æ—Ç Python –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ PyTorch –º–æ–¥–µ–ª–∏.</p>
    
    <p><strong>Tracing</strong>:</p>
    <pre><code>import torch.jit

# Trace –º–æ–¥–µ–ª—å
example = torch.rand(1, 3, 224, 224)
traced_script_module = torch.jit.trace(model, example)

# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
traced_script_module.save("model_traced.pt")

# –ó–∞–≥—Ä—É–∑–∏—Ç—å (–±–µ–∑ Python –∫–æ–¥–∞)
loaded_model = torch.jit.load("model_traced.pt")

# Inference
output = loaded_model(input_tensor)</code></pre>

    <p><strong>Scripting (–¥–ª—è control flow)</strong>:</p>
    <pre><code># –î–ª—è –º–æ–¥–µ–ª–µ–π —Å if/for statements
scripted_module = torch.jit.script(model)
scripted_module.save("model_scripted.pt")

# –ò–ª–∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
class MyModel(torch.nn.Module):
    @torch.jit.export
    def forward(self, x):
        if x.sum() > 0:
            return x * 2
        return x

# Script
model = torch.jit.script(MyModel())
model.save("model.pt")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. Pickle (–Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è production)</h2>
    <p>–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è Python —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è.</p>
    
    <pre><code>import pickle

# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
with open('model.pkl', 'wb') as f:
    pickle.dump(model, f)

# –ó–∞–≥—Ä—É–∑–∏—Ç—å
with open('model.pkl', 'rb') as f:
    model = pickle.load(f)

# –ü—Ä–æ–±–ª–µ–º—ã:
# - –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç –≤–µ—Ä—Å–∏–∏ Python
# - –¢—Ä–µ–±—É–µ—Ç –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞ –∫–ª–∞—Å—Å–∞
# - –ú–µ–¥–ª–µ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
# - –£—è–∑–≤–∏–º–æ—Å—Ç–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏

# –õ—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å joblib –¥–ª—è scikit-learn
from joblib import dump, load

# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
dump(sklearn_model, 'model.joblib')

# –ó–∞–≥—Ä—É–∑–∏—Ç—å
model = load('model.joblib')</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ preprocessing</h2>
    <p>–í–∞–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –≤–º–µ—Å—Ç–µ —Å –º–æ–¥–µ–ª—å—é!</p>
    
    <pre><code>import pickle
import numpy as np
from sklearn.preprocessing import StandardScaler

# –û–±—É—á–µ–Ω–∏–µ
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_train)

# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å scaler
with open('scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)

# –ü–æ–ª–Ω—ã–π pipeline
class ModelWithPreprocessing:
    def __init__(self, model, scaler):
        self.model = model
        self.scaler = scaler
    
    def predict(self, X):
        X_scaled = self.scaler.transform(X)
        return self.model.predict(X_scaled)

# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å–µ –≤–º–µ—Å—Ç–µ
pipeline = ModelWithPreprocessing(model, scaler)
torch.save({
    'model': model.state_dict(),
    'scaler': scaler
}, 'full_pipeline.pth')</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. Quantization –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏</h2>
    <p>–£–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é.</p>
    
    <p><strong>PyTorch dynamic quantization</strong>:</p>
    <pre><code>import torch.quantization

# –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è
model_fp32 = MyModel()
model_int8 = torch.quantization.quantize_dynamic(
    model_fp32,
    {torch.nn.Linear},  # —Å–ª–æ–∏ –¥–ª—è –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏
    dtype=torch.qint8
)

# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
torch.save(model_int8.state_dict(), 'model_int8.pth')

# –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è –≤ 4 —Ä–∞–∑–∞!</code></pre>

    <p><strong>TensorFlow Lite</strong>:</p>
    <pre><code># –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ TFLite —Å –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–µ–π
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]

# –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è
tflite_model = converter.convert()

# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
with open('model.tflite', 'wb') as f:
    f.write(tflite_model)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. Version control –¥–ª—è –º–æ–¥–µ–ª–µ–π</h2>
    <p>–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–µ—Ä—Å–∏—è–º–∏ –º–æ–¥–µ–ª–µ–π.</p>
    
    <pre><code># –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
import json
from datetime import datetime

metadata = {
    'model_name': 'ResNet50',
    'version': '1.2.0',
    'created_at': datetime.now().isoformat(),
    'framework': 'pytorch',
    'accuracy': 0.95,
    'dataset': 'ImageNet',
    'hyperparameters': {
        'learning_rate': 0.001,
        'batch_size': 32,
        'epochs': 100
    }
}

# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
torch.save({
    'model_state_dict': model.state_dict(),
    'metadata': metadata
}, 'model_v1.2.0.pth')

# DVC –¥–ª—è –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
# dvc add model.pth
# git add model.pth.dvc
# git commit -m "Add model v1.2.0"

# MLflow –¥–ª—è tracking
import mlflow

with mlflow.start_run():
    mlflow.log_param("learning_rate", 0.001)
    mlflow.log_metric("accuracy", 0.95)
    mlflow.pytorch.log_model(model, "model")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. Cross-platform —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è</h2>
    <p>–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º.</p>
    
    <pre><code># CoreML –¥–ª—è iOS (–∏–∑ PyTorch)
import coremltools as ct

# Trace –º–æ–¥–µ–ª—å
traced_model = torch.jit.trace(model, example_input)

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ CoreML
coreml_model = ct.convert(
    traced_model,
    inputs=[ct.TensorType(shape=(1, 3, 224, 224))]
)

# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
coreml_model.save('model.mlmodel')

# TensorFlow Lite –¥–ª—è Android
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with open('model.tflite', 'wb') as f:
    f.write(tflite_model)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 12. Best practices</h2>
    <ul>
      <li>‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ framework-specific —Ñ–æ—Ä–º–∞—Ç—ã</li>
      <li>‚úÖ –°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏ –≤–µ—Å–∞ –æ—Ç–¥–µ–ª—å–Ω–æ</li>
      <li>‚úÖ –î–æ–±–∞–≤–ª—è–π—Ç–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–≤–µ—Ä—Å–∏—è, –¥–∞—Ç–∞, –º–µ—Ç—Ä–∏–∫–∏)</li>
      <li>‚úÖ –°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ preprocessing –≤–º–µ—Å—Ç–µ —Å –º–æ–¥–µ–ª—å—é</li>
      <li>‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ checksums –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏</li>
      <li>‚úÖ –í–µ—Ä—Å–∏–æ–Ω–∏—Ä—É–π—Ç–µ –º–æ–¥–µ–ª–∏ (git, DVC, MLflow)</li>
      <li>‚úÖ –¢–µ—Å—Ç–∏—Ä—É–π—Ç–µ –∑–∞–≥—Ä—É–∑–∫—É –ø–æ—Å–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è</li>
      <li>‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ ONNX –¥–ª—è inter-framework</li>
      <li>‚úÖ –ö–≤–∞–Ω—Ç–∏–∑—É–π—Ç–µ –¥–ª—è production</li>
      <li>‚ùå –ò–∑–±–µ–≥–∞–π—Ç–µ pickle –¥–ª—è production</li>
    </ul>

    <pre><code># –ü—Ä–∏–º–µ—Ä –ø–æ–ª–Ω–æ–≥–æ pipeline —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
def save_model_complete(model, scaler, metadata, path):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å —Å–æ –≤—Å–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–º"""
    
    # –°–æ–∑–¥–∞—Ç—å checkpoint
    checkpoint = {
        'model_state_dict': model.state_dict(),
        'scaler': scaler,
        'metadata': metadata,
        'pytorch_version': torch.__version__
    }
    
    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
    torch.save(checkpoint, path)
    
    # –í—ã—á–∏—Å–ª–∏—Ç—å checksum
    import hashlib
    with open(path, 'rb') as f:
        file_hash = hashlib.sha256(f.read()).hexdigest()
    
    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å checksum
    with open(f"{path}.sha256", 'w') as f:
        f.write(file_hash)
    
    print(f"Model saved: {path}")
    print(f"Checksum: {file_hash}")</code></pre>
  </div>



</body>
</html>
