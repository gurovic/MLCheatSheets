<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>Neural Architecture Search Cheatsheet</title>
  <style>
    @media screen { body { font-family: -apple-system, sans-serif; color: #333; background: #fafcff; padding: 10px; } }
    .container { column-count: 3; column-gap: 20px; }
    .block { break-inside: avoid; margin-bottom: 1.2em; padding: 12px; background: white; border-radius: 6px; box-shadow: 0 1px 3px rgba(0,0,0,0.05); }
    h1 { font-size: 1.6em; font-weight: 700; color: #1a5fb4; text-align: center; margin: 0 0 8px; column-span: all; }
    .subtitle { text-align: center; color: #666; font-size: 0.9em; margin-bottom: 12px; column-span: all; }
    h2 { font-size: 1.15em; font-weight: 700; color: #1a5fb4; margin: 0 0 8px; padding-bottom: 4px; border-bottom: 1px solid #e0e7ff; }
    p, ul, ol { font-size: 0.92em; margin: 0.6em 0; }
    ul, ol { padding-left: 18px; }
    code { font-family: 'Consolas', monospace; background-color: #f0f4ff; padding: 1px 4px; border-radius: 3px; font-size: 0.88em; }
    pre { background-color: #f0f4ff; padding: 8px; border-radius: 4px; overflow-x: auto; font-size: 0.84em; margin: 6px 0; }
    table { width: 100%; border-collapse: collapse; font-size: 0.82em; margin: 6px 0; }
    th { background-color: #e6f0ff; text-align: left; padding: 4px 6px; font-weight: 600; }
    td { padding: 4px 6px; border-bottom: 1px solid #f0f4ff; }
    blockquote { font-style: italic; margin: 8px 0; padding: 6px 10px; background: #f8fbff; border-left: 2px solid #1a5fb4; font-size: 0.88em; }
  </style>
</head>
<body>
<div class="container">
  <h1>üîç Neural Architecture Search Cheatsheet</h1>
  <div class="subtitle">–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä<br>üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –ß—Ç–æ —Ç–∞–∫–æ–µ NAS?</h2>
    <p><strong>NAS</strong> ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.</p>
    <p><strong>–ú–æ—Ç–∏–≤–∞—Ü–∏—è:</strong></p>
    <ul>
      <li>–†—É—á–Ω–æ–π design –¥–æ–ª–≥–∏–π</li>
      <li>–û–≥—Ä–æ–º–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤</li>
      <li>NAS –Ω–∞—Ö–æ–¥–∏—Ç –ª—É—á—à–µ —á–µ–ª–æ–≤–µ–∫–∞</li>
    </ul>
    <p><strong>–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:</strong></p>
    <ol>
      <li>Search Space: –≤–æ–∑–º–æ–∂–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã</li>
      <li>Search Strategy: –∫–∞–∫ –∏—Å–∫–∞—Ç—å</li>
      <li>Performance Estimation: –∫–∞–∫ –æ—Ü–µ–Ω–∏–≤–∞—Ç—å</li>
    </ol>
  </div>

  <div class="block">
    <h2>üî∑ 2. Search Space</h2>
    <pre><code># Cell-based search space
operations = [
    'none',
    'skip_connect',
    'conv_3x3',
    'conv_5x5',
    'max_pool_3x3',
    'avg_pool_3x3',
    'sep_conv_3x3',
    'dil_conv_3x3'
]

# Cell = –≥—Ä–∞—Ñ
# Node = operation
# Edge = connection</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 3. DARTS</h2>
    <p><strong>Differentiable Architecture Search</strong></p>
    <pre><code>class MixedOp(nn.Module):
    def __init__(self, C):
        super().__init__()
        self.ops = nn.ModuleList([
            OPS[op](C) for op in OPERATIONS
        ])
    
    def forward(self, x, weights):
        # Weighted sum
        return sum(w * op(x) 
                  for w, op in zip(weights, self.ops))

# Architecture parameters
arch_params = nn.Parameter(
    torch.randn(num_edges, num_ops)
)

# Bi-level optimization
# 1. Train arch_params on validation
# 2. Train model weights on training</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. EfficientNet</h2>
    <p><strong>Compound Scaling</strong></p>
    <pre><code># –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ depth, width, resolution
def compound_scaling(phi):
    alpha = 1.2  # depth
    beta = 1.1   # width
    gamma = 1.15 # resolution
    
    return {
        'depth': alpha ** phi,
        'width': beta ** phi,
        'resolution': gamma ** phi
    }

# B0: phi=0
# B7: phi=2

from efficientnet_pytorch import EfficientNet
model = EfficientNet.from_pretrained('efficientnet-b0')</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. Once-for-All</h2>
    <p><strong>Progressive Shrinking</strong></p>
    <pre><code># –û–±—É—á–∏—Ç—å –æ–¥–Ω—É —Å–µ—Ç—å –¥–ª—è –≤—Å–µ—Ö —Ä–∞–∑–º–µ—Ä–æ–≤

# 1. Train largest
model = build_largest()
train(model)

# 2. Shrink depth
for d in [4, 3, 2]:
    model.set_active_depth(d)
    finetune(model)

# 3. Shrink width
for w in [1.0, 0.75, 0.5]:
    model.set_active_width(w)
    finetune(model)

# 4. Select subnet
model.set_active_subnet(d=3, w=0.75)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. AutoML —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏</h2>
    <pre><code># Auto-PyTorch
from autoPyTorch import AutoNetClassification

auto = AutoNetClassification()
auto.fit(X_train, y_train, validation_split=0.2)

# NNI
import nni

search_space = {
    'lr': {'_type': 'loguniform', '_value': [0.0001, 0.1]},
    'layers': {'_type': 'choice', '_value': [2, 3, 4]}
}

params = nni.get_next_parameter()
model = build_model(**params)
nni.report_final_result(accuracy)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. Search Strategies</h2>
    <table>
      <tr><th>–ú–µ—Ç–æ–¥</th><th>GPU-days</th></tr>
      <tr><td>Random</td><td>100+</td></tr>
      <tr><td>Evolution</td><td>3150</td></tr>
      <tr><td>RL (NASNet)</td><td>1800</td></tr>
      <tr><td>Gradient (DARTS)</td><td>4</td></tr>
      <tr><td>Weight Sharing</td><td>0.5</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 8. Performance Estimation</h2>
    <ul>
      <li><strong>Train from scratch</strong>: —Ç–æ—á–Ω–æ, –º–µ–¥–ª–µ–Ω–Ω–æ</li>
      <li><strong>Proxy –∑–∞–¥–∞—á–∏</strong>: –º–µ–Ω—å—à–µ —ç–ø–æ—Ö/–¥–∞–Ω–Ω—ã—Ö</li>
      <li><strong>Weight sharing</strong>: —É—Å–∫–æ—Ä–µ–Ω–∏–µ 1000x</li>
      <li><strong>Early stopping</strong>: –ø–æ loss curve</li>
      <li><strong>Transfer</strong>: ImageNet ‚Üí —Å–≤–æ—è –∑–∞–¥–∞—á–∞</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 9. Multi-Objective NAS</h2>
    <pre><code># –£—á–∏—Ç—ã–≤–∞—Ç—å accuracy + latency + size
objectives = {
    'accuracy': maximize,
    'latency': minimize,
    'model_size': minimize
}

# Pareto frontier
# –ù–∞—Ö–æ–¥–∏–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–∞ –≥—Ä–∞–Ω–∏—Ü–µ

# Hardware-aware NAS
# –ò–∑–º–µ—Ä—è–µ–º latency –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. Best Practices</h2>
    <ul>
      <li>–ù–∞—á–Ω–∏—Ç–µ —Å small search space</li>
      <li>–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ proxy tasks</li>
      <li>Weight sharing –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è</li>
      <li>–£—á–∏—Ç—ã–≤–∞–π—Ç–µ hardware constraints</li>
      <li>–í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö</li>
      <li>Transfer –æ—Ç ImageNet</li>
    </ul>
    <blockquote>
¬´NAS –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä. –í–º–µ—Å—Ç–æ –Ω–µ–¥–µ–ª—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –≤—Ä—É—á–Ω—É—é, –∞–ª–≥–æ—Ä–∏—Ç–º –∑–∞ –¥–Ω–∏ –Ω–∞—Ö–æ–¥–∏—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É¬ª.
    </blockquote>
  </div>

</div>
</body>
</html>
