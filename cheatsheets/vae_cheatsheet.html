<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>VAE (Variational Autoencoders) Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

    .container {
      column-count: 3;
      column-gap: 20px;
      max-width: 100%;
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üéØ VAE (Variational Autoencoders) Cheatsheet</h1>
  <div class="subtitle">–î–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö ‚Ä¢ –í–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω—ã–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä—ã ‚Ä¢ –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ñ–æ–∫—É—Å<br>üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –°—É—Ç—å VAE</h2>
    <ul>
      <li><strong>–ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å</strong>: —Å–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ</li>
      <li><strong>–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥</strong>: –º–æ–¥–µ–ª–∏—Ä—É–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö</li>
      <li><strong>Encoder</strong>: —Å–∂–∏–º–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ latent space (Œº, œÉ)</li>
      <li><strong>Decoder</strong>: –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∏–∑ latent space</li>
      <li><strong>Reparameterization trick</strong>: z = Œº + œÉ ¬∑ Œµ</li>
      <li><strong>–û—Ç–ª–∏—á–∏–µ –æ—Ç AE</strong>: —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–æ–µ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 2. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞</h2>
    <p><strong>Encoder</strong>: x ‚Üí Œº, log(œÉ¬≤)</p>
    <p><strong>Sampling</strong>: z = Œº + œÉ ¬∑ Œµ, –≥–¥–µ Œµ ~ N(0,1)</p>
    <p><strong>Decoder</strong>: z ‚Üí xÃÇ</p>
    <p><strong>Loss</strong> = Reconstruction Loss + KL Divergence</p>
    <ul>
      <li><strong>Reconstruction</strong>: –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–ª–∏</li>
      <li><strong>KL Divergence</strong>: —à—Ç—Ä–∞—Ñ –∑–∞ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç N(0,1)</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 3. –ë–∞–∑–æ–≤—ã–π –∫–æ–¥ (PyTorch)</h2>
    <pre><code>import torch
import torch.nn as nn
import torch.nn.functional as F

class VAE(nn.Module):
    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):
        super().__init__()
        
        # Encoder
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc_mu = nn.Linear(hidden_dim, latent_dim)
        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)
        
        # Decoder
        self.fc3 = nn.Linear(latent_dim, hidden_dim)
        self.fc4 = nn.Linear(hidden_dim, input_dim)
    
    def encode(self, x):
        h = F.relu(self.fc1(x))
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar
    
    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        z = mu + eps * std
        return z
    
    def decode(self, z):
        h = F.relu(self.fc3(z))
        x_recon = torch.sigmoid(self.fc4(h))
        return x_recon
    
    def forward(self, x):
        mu, logvar = self.encode(x.view(-1, 784))
        z = self.reparameterize(mu, logvar)
        x_recon = self.decode(z)
        return x_recon, mu, logvar</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. Loss Function</h2>
    <pre><code>def vae_loss(recon_x, x, mu, logvar):
    # Reconstruction loss (BCE –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)
    BCE = F.binary_cross_entropy(
        recon_x, 
        x.view(-1, 784), 
        reduction='sum'
    )
    
    # KL Divergence
    # KL(q(z|x) || p(z)) –≥–¥–µ p(z) = N(0,1)
    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    
    return BCE + KLD

# Training loop
for epoch in range(num_epochs):
    for batch_idx, (data, _) in enumerate(train_loader):
        optimizer.zero_grad()
        
        recon_batch, mu, logvar = model(data)
        loss = vae_loss(recon_batch, data, mu, logvar)
        
        loss.backward()
        optimizer.step()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö</h2>
    <pre><code># –°—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑ N(0,1)
with torch.no_grad():
    z = torch.randn(64, latent_dim)
    samples = model.decode(z)
    
# –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –º–µ–∂–¥—É –¥–≤—É–º—è —Ç–æ—á–∫–∞–º–∏
z1 = torch.randn(1, latent_dim)
z2 = torch.randn(1, latent_dim)

# –õ–∏–Ω–µ–π–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è
alphas = torch.linspace(0, 1, 10)
interpolated = []
for alpha in alphas:
    z_interp = alpha * z1 + (1 - alpha) * z2
    x_interp = model.decode(z_interp)
    interpolated.append(x_interp)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. –°–≤–µ—Ä—Ç–æ—á–Ω—ã–π VAE –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π</h2>
    <pre><code>class ConvVAE(nn.Module):
    def __init__(self, latent_dim=128):
        super().__init__()
        
        # Encoder
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 32, 4, 2, 1),  # 16x16
            nn.ReLU(),
            nn.Conv2d(32, 64, 4, 2, 1), # 8x8
            nn.ReLU(),
            nn.Conv2d(64, 128, 4, 2, 1), # 4x4
            nn.ReLU(),
        )
        
        self.fc_mu = nn.Linear(128 * 4 * 4, latent_dim)
        self.fc_logvar = nn.Linear(128 * 4 * 4, latent_dim)
        
        # Decoder
        self.fc_decode = nn.Linear(latent_dim, 128 * 4 * 4)
        
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(128, 64, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(32, 3, 4, 2, 1),
            nn.Sigmoid()
        )</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. Œ≤-VAE</h2>
    <p><strong>–î–æ–±–∞–≤–ª—è–µ—Ç –≤–µ—Å Œ≤ –∫ KL Divergence</strong></p>
    <pre><code>def beta_vae_loss(recon_x, x, mu, logvar, beta=4.0):
    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')
    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    
    return BCE + beta * KLD

# Œ≤ > 1: –±–æ–ª—å—à–µ disentanglement (—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
# Œ≤ < 1: –ª—É—á—à–µ reconstruction
# Œ≤ = 1: –æ–±—ã—á–Ω—ã–π VAE</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ VAE</h2>
    <ul>
      <li><strong>–°—Ç–∞–±–∏–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ</strong>: –≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç GAN</li>
      <li><strong>–ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è</strong>: –≥–ª–∞–¥–∫–æ–µ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ</li>
      <li><strong>–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ</strong>: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥</li>
      <li><strong>–ö–æ–Ω—Ç—Ä–æ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏</strong>: –º–æ–∂–Ω–æ –≤–∞—Ä—å–∏—Ä–æ–≤–∞—Ç—å z</li>
      <li><strong>Anomaly detection</strong>: –≤—ã—Å–æ–∫–∏–π reconstruction loss = –∞–Ω–æ–º–∞–ª–∏—è</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 9. VAE vs GAN</h2>
    <table>
      <tr><th>–ö—Ä–∏—Ç–µ—Ä–∏–π</th><th>VAE</th><th>GAN</th></tr>
      <tr><td><strong>–û–±—É—á–µ–Ω–∏–µ</strong></td><td>–°—Ç–∞–±–∏–ª—å–Ω–æ–µ</td><td>–ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ–µ</td></tr>
      <tr><td><strong>–ö–∞—á–µ—Å—Ç–≤–æ</strong></td><td>–°—Ä–µ–¥–Ω–µ (—Ä–∞–∑–º—ã—Ç–æ)</td><td>–í—ã—Å–æ–∫–æ–µ</td></tr>
      <tr><td><strong>–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ</strong></td><td>–•–æ—Ä–æ—à–µ–µ</td><td>Mode collapse</td></tr>
      <tr><td><strong>–õ–∞—Ç–µ–Ω—Ç–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ</strong></td><td>–£–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–æ–µ</td><td>–ù–µ—É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–æ–µ</td></tr>
      <tr><td><strong>–ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è</strong></td><td>–ì–ª–∞–¥–∫–∞—è</td><td>–°–ª–æ–∂–Ω–æ</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 10. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è VAE</h2>
    <ul>
      <li><strong>–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π</strong></li>
      <li><strong>Anomaly detection</strong>: —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π –ø–ª–æ—Ö–∞—è</li>
      <li><strong>Data augmentation</strong>: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∞—Ä–∏–∞—Ü–∏–π</li>
      <li><strong>Denoising</strong>: —É–¥–∞–ª–µ–Ω–∏–µ —à—É–º–∞</li>
      <li><strong>Feature extraction</strong>: latent space –∫–∞–∫ –ø—Ä–∏–∑–Ω–∞–∫–∏</li>
      <li><strong>Semi-supervised learning</strong></li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 11. Conditional VAE</h2>
    <pre><code>class ConditionalVAE(nn.Module):
    def __init__(self, input_dim=784, latent_dim=20, n_classes=10):
        super().__init__()
        self.label_emb = nn.Embedding(n_classes, n_classes)
        
        # Encoder –ø–æ–ª—É—á–∞–µ—Ç x + label
        self.fc1 = nn.Linear(input_dim + n_classes, 400)
        # ... mu, logvar
        
        # Decoder –ø–æ–ª—É—á–∞–µ—Ç z + label
        self.fc3 = nn.Linear(latent_dim + n_classes, 400)
        
    def forward(self, x, labels):
        label_emb = self.label_emb(labels)
        
        # Encode —Å label
        x_with_label = torch.cat([x, label_emb], dim=1)
        mu, logvar = self.encode(x_with_label)
        
        z = self.reparameterize(mu, logvar)
        
        # Decode —Å label
        z_with_label = torch.cat([z, label_emb], dim=1)
        recon_x = self.decode(z_with_label)
        
        return recon_x, mu, logvar</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 12. –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏</h2>
    <ul>
      <li><strong>Latent dim</strong>: 20-200 (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏)</li>
      <li><strong>Œ≤</strong>: –Ω–∞—á–∞—Ç—å —Å 1.0, —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å</li>
      <li><strong>Learning rate</strong>: 1e-3 –¥–æ 1e-4</li>
      <li><strong>Warm-up</strong>: –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å –≤–µ—Å KL</li>
      <li><strong>BatchNorm</strong>: –ø–æ–º–æ–≥–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏</li>
      <li><strong>–í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å</strong>: latent space –∏ reconstruction</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 13. KL Annealing</h2>
    <pre><code># –ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å KL
kl_weight = min(1.0, epoch / kl_anneal_epochs)

loss = reconstruction_loss + kl_weight * kl_divergence

# –ü–æ–º–æ–≥–∞–µ—Ç –∏–∑–±–µ–∂–∞—Ç—å "posterior collapse"
# (–∫–æ–≥–¥–∞ encoder –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç input)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 14. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å reparameterization trick</li>
      <li>[ ] –ü—Ä–∞–≤–∏–ª—å–Ω–æ –≤—ã—á–∏—Å–ª–∏—Ç—å KL Divergence</li>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å –ø–æ–¥—Ö–æ–¥—è—â–∏–π latent_dim</li>
      <li>[ ] –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å reconstruction loss –∏ KL –æ—Ç–¥–µ–ª—å–Ω–æ</li>
      <li>[ ] –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å reconstruction</li>
      <li>[ ] –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å latent space (t-SNE/PCA)</li>
      <li>[ ] –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å Œ≤-VAE –¥–ª—è –ª—É—á—à–µ–≥–æ disentanglement</li>
      <li>[ ] –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å KL annealing</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´VAE ‚Äî —ç—Ç–æ –∫–∞–∫ "—É–º–Ω—ã–π –∞—Ä—Ö–∏–≤–∞—Ç–æ—Ä" –¥–ª—è –¥–∞–Ω–Ω—ã—Ö. –û–Ω —Å–∂–∏–º–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∫–æ–º–ø–∞–∫—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ, –Ω–æ –¥–µ–ª–∞–µ—Ç —ç—Ç–æ –æ—Å–æ–±—ã–º –æ–±—Ä–∞–∑–æ–º: –≤—Å–µ –ø–æ—Ö–æ–∂–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ–∫–∞–∑—ã–≤–∞—é—Ç—Å—è —Ä—è–¥–æ–º –≤ —ç—Ç–æ–º —Å–∂–∞—Ç–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ. –ë–ª–∞–≥–æ–¥–∞—Ä—è —ç—Ç–æ–º—É –º—ã –º–æ–∂–µ–º –ø–ª–∞–≤–Ω–æ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç—å –æ—Ç –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫ –¥—Ä—É–≥–æ–º—É, –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã, –∏–ª–∏ –Ω–∞—Ö–æ–¥–∏—Ç—å –∞–Ω–æ–º–∞–ª–∏–∏¬ª.
    </blockquote>
  </div>

</div>

</body>
</html>
