<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Sequence-aware —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      
        min-width: 900px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

        .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.88em;
      margin: 6px 0;
    }

    th, td {
      padding: 6px 8px;
      text-align: left;
      border: 1px solid #e0e7ff;
    }

    th {
      background-color: #1a5fb4;
      color: white;
      font-weight: 700;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üìö Sequence-aware —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –°—É—Ç—å sequence-aware —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π</h2>
    <p><strong>–£—á–µ—Ç –ø–æ—Ä—è–¥–∫–∞ –¥–µ–π—Å—Ç–≤–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤–æ –≤—Ä–µ–º–µ–Ω–∏</strong></p>
    <ul>
            <li><strong>–£—á–µ—Ç –ø–æ—Ä—è–¥–∫–∞</strong>:  –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–µ–π—Å—Ç–≤–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤–∞–∂–Ω–∞</li>
      <li><strong>Session-based</strong>:  —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –≤ —Ä–∞–º–∫–∞—Ö —Å–µ—Å—Å–∏–∏</li>
      <li><strong>Temporal dynamics</strong>:  –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –º–µ–Ω—è—é—Ç—Å—è –≤–æ –≤—Ä–µ–º–µ–Ω–∏</li>
      <li><strong>Next-item prediction</strong>:  —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±–µ—Ä–µ—Ç —Å–ª–µ–¥—É—é—â–∏–º</li>
      <li><strong>Context</strong>:  –Ω–µ–¥–∞–≤–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç</li>
      <li><strong>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</strong>:  e-commerce, –º—É–∑—ã–∫–∞, –≤–∏–¥–µ–æ, –Ω–æ–≤–æ—Å—Ç–∏</li>

    </ul>
    <blockquote>
      üí° –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫–ª–∏–∫–æ–≤ —Å–æ–¥–µ—Ä–∂–∏—Ç –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, —á–µ–º –ø—Ä–æ—Å—Ç–æ –Ω–∞–±–æ—Ä –∫–ª–∏–∫–æ–≤
    </blockquote>

    </div>
<div class="block">
    <h2>üî∑ 2. –û—Ç–ª–∏—á–∏–µ –æ—Ç –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö CF</h2>
    <p><strong>–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∞–∂–Ω–∞: [A,B,C] ‚â† [C,B,A]</strong></p>
    <ul>
            <li><strong>Classical CF</strong>:  –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç –ø–æ—Ä—è–¥–æ–∫ –∏ –≤—Ä–µ–º—è</li>
      <li><strong>Sequential</strong>:  —è–≤–Ω–æ –º–æ–¥–µ–ª–∏—Ä—É–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å</li>
      <li><strong>Short-term vs long-term</strong>:  —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–∞—Å—à—Ç–∞–±—ã</li>
      <li><strong>Session context</strong>:  —É—á–µ—Ç —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏</li>
      <li><strong>Dynamic preferences</strong>:  –∞–¥–∞–ø—Ç–∞—Ü–∏—è –∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º</li>
      <li><strong>Recency</strong>:  –Ω–µ–¥–∞–≤–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –≤–∞–∂–Ω–µ–µ</li>

    </ul>
    <blockquote>
      üí° Classical CF –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç —Å—Ç–∞—Ç–∏—á–Ω—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è, sequential ‚Äî –¥–∏–Ω–∞–º–∏—á–Ω—ã–µ
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 3. Markov Chains</h2>
    <p><strong>–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–ª–µ–¥—É—é—â–µ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö</strong></p>
    <ul>
            <li><strong>First-order</strong>:  P(item_t | item_{t-1})</li>
      <li><strong>Higher-order</strong>:  —É—á–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö item</li>
      <li><strong>Transition matrix</strong>:  –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤</li>
      <li><strong>–ü—Ä–æ—Å—Ç–æ—Ç–∞</strong>:  –ª–µ–≥–∫–æ –ø–æ–Ω—è—Ç—å –∏ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å</li>
      <li><strong>–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ</strong>:  –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç long-term dependencies</li>
      <li><strong>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</strong>:  –ø—Ä–æ—Å—Ç–æ–π baseline –¥–ª—è sequential RS</li>

    </ul>
    <blockquote>
      üí° Markov Chains ‚Äî –ø—Ä–æ—Å—Ç–æ–π, –Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
    </blockquote>
    <pre><code>import numpy as np
from collections import defaultdict

# Markov Chain for next-item prediction
class MarkovChainRS:
    def __init__(self, order=1):
        self.order = order
        self.transitions = defaultdict(lambda: defaultdict(int))
    
    def fit(self, sequences):
        for seq in sequences:
            for i in range(len(seq) - self.order):
                state = tuple(seq[i:i+self.order])
                next_item = seq[i+self.order]
                self.transitions[state][next_item] += 1
    
    def predict(self, history, k=10):
        state = tuple(history[-self.order:])
        if state not in self.transitions:
            return []
        
        # Normalize to probabilities
        candidates = self.transitions[state]
        total = sum(candidates.values())
        probs = {item: count/total for item, count in candidates.items()}
        
        # Top-k
        return sorted(probs.items(), key=lambda x: x[1], reverse=True)[:k]

# Train on session data
sessions = [[1, 2, 3, 5], [1, 3, 4], [2, 3, 5, 7]]
mc = MarkovChainRS(order=1)
mc.fit(sessions)

# Predict
recommendations = mc.predict(history=[1, 2], k=5)
print(recommendations)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. Session-based —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏</h2>
    <p><strong>–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–π —Å–µ—Å—Å–∏–∏</strong></p>
    <ul>
            <li><strong>–°–µ—Å—Å–∏—è</strong>:  –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–µ–π—Å—Ç–≤–∏–π –≤ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏</li>
      <li><strong>–ê–Ω–æ–Ω–∏–º–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏</strong>:  –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –∏—Å—Ç–æ—Ä–∏—è</li>
      <li><strong>Real-time</strong>:  —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ —Å–µ—Å—Å–∏–∏</li>
      <li><strong>Cold start friendly</strong>:  —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ user profile</li>
      <li><strong>Item-to-item</strong>:  –ø–µ—Ä–µ—Ö–æ–¥—ã –º–µ–∂–¥—É items</li>
      <li><strong>Applications</strong>:  e-commerce browsing, video streaming</li>

    </ul>
    <blockquote>
      üí° Session-based RS —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É —Ö–æ–ª–æ–¥–Ω–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞ –¥–ª—è –Ω–æ–≤—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 5. RNN –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π</h2>
    <p><strong>GRU, LSTM –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –ø–æ–∫—É–ø–æ–∫/–ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤</strong></p>
    <ul>
            <li><strong>LSTM/GRU</strong>:  –∑–∞—Ö–≤–∞—Ç long-term dependencies</li>
      <li><strong>Hidden state</strong>:  representation —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è</li>
      <li><strong>Input</strong>:  embeddings –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö items</li>
      <li><strong>Output</strong>:  –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ next items</li>
      <li><strong>–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ</strong>:  –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤</li>
      <li><strong>–ù–µ–¥–æ—Å—Ç–∞—Ç–æ–∫</strong>:  –º–µ–¥–ª–µ–Ω–Ω–µ–µ, —á–µ–º Markov Chains</li>

    </ul>
    <blockquote>
      üí° RNN –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –º–æ–¥–µ–ª–∏—Ä—É—é—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è Markov –ø–æ–¥—Ö–æ–¥—ã
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 6. Attention mechanisms</h2>
    <p><strong>Self-attention –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π (SASRec, BERT4Rec)</strong></p>
    <ul>
            <li><strong>Self-attention</strong>:  —Ñ–æ–∫—É—Å –Ω–∞ –≤–∞–∂–Ω—ã—Ö items –≤ –∏—Å—Ç–æ—Ä–∏–∏</li>
      <li><strong>Transformer-based</strong>:  SASRec, BERT4Rec</li>
      <li><strong>Positional encoding</strong>:  —É—á–µ—Ç –ø–æ–∑–∏—Ü–∏–∏ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏</li>
      <li><strong>Multi-head attention</strong>:  —Ä–∞–∑–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã –≤–Ω–∏–º–∞–Ω–∏—è</li>
      <li><strong>Parallel processing</strong>:  –±—ã—Å—Ç—Ä–µ–µ, —á–µ–º RNN</li>
      <li><strong>State-of-the-art</strong>:  –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö</li>

    </ul>
    <blockquote>
      üí° Transformer-based –º–æ–¥–µ–ª–∏ ‚Äî current state-of-the-art –¥–ª—è sequential RS
    </blockquote>
    <pre><code>import tensorflow as tf
from tensorflow.keras.layers import LSTM, Embedding, Dense
from tensorflow.keras.models import Sequential

# LSTM for session-based recommendations
max_len = 20  # max session length
n_items = 10000  # vocabulary size

model = Sequential([
    # Item embeddings
    Embedding(n_items, 128, input_length=max_len, mask_zero=True),
    
    # LSTM layers
    LSTM(256, return_sequences=True, dropout=0.2),
    LSTM(128, dropout=0.2),
    
    # Output: probabilities for all items
    Dense(n_items, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Training data: sequences of item IDs
# X_train: (sessions, max_len-1) - input sequence
# y_train: (sessions,) - next item to predict

model.fit(X_train, y_train, epochs=10, batch_size=128)

# Predict next item given session history
session_history = [103, 256, 789]
X_pred = tf.keras.preprocessing.sequence.pad_sequences(
    [session_history], maxlen=max_len-1
)
next_item_probs = model.predict(X_pred)[0]
top_k = np.argsort(next_item_probs)[-10:][::-1]
print(f"Top 10 recommended items: {top_k}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. Temporal Convolutional Networks</h2>
    <p><strong>CNN –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π</strong></p>
    <ul>
            <li><strong>1D CNN</strong>:  convolutions –Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏</li>
      <li><strong>Dilated convolutions</strong>:  –±–æ–ª—å—à–∏–µ receptive fields</li>
      <li><strong>Parallel computation</strong>:  –±—ã—Å—Ç—Ä–µ–µ, —á–µ–º RNN</li>
      <li><strong>Causality</strong>:  –Ω–µ —Å–º–æ—Ç—Ä–∏—Ç –≤ –±—É–¥—É—â–µ–µ</li>
      <li><strong>–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ</strong>:  —Å–∫–æ—Ä–æ—Å—Ç—å –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å</li>
      <li><strong>NextItNet</strong>:  –ø–æ–ø—É–ª—è—Ä–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞</li>

    </ul>
    <blockquote>
      üí° TCN ‚Äî –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ RNN —Å –ª—É—á—à–µ–π —Å–∫–æ—Ä–æ—Å—Ç—å—é –∏ comparable —Ç–æ—á–Ω–æ—Å—Ç—å—é
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 8. Next-item prediction</h2>
    <p><strong>–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏</strong></p>
    <ul>
            <li><strong>–ó–∞–¥–∞—á–∞</strong>:  –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π item –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏</li>
      <li><strong>Ranking</strong>:  —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ candidates –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏</li>
      <li><strong>Metrics</strong>:  Recall@k, NDCG@k, MRR</li>
      <li><strong>Negative sampling</strong>:  –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è</li>
      <li><strong>Loss functions</strong>:  BCE, BPR, cross-entropy</li>
      <li><strong>Evaluation</strong>:  leave-one-out, last-n-out</li>

    </ul>
    <blockquote>
      üí° Next-item prediction ‚Äî –æ—Å–Ω–æ–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ sequential recommender systems
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 9. Session-based GNN</h2>
    <p><strong>Graph Neural Networks –¥–ª—è —Å–µ—Å—Å–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö</strong></p>
    <ul>
            <li><strong>Graph structure</strong>:  items –∫–∞–∫ nodes, transitions –∫–∞–∫ edges</li>
      <li><strong>GNN</strong>:  Graph Neural Networks –¥–ª—è —Å–µ—Å—Å–∏–π</li>
      <li><strong>SR-GNN</strong>:  Session-based Recommendation with GNN</li>
      <li><strong>Message passing</strong>:  –∞–≥—Ä–µ–≥–∞—Ü–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ—Ç neighbors</li>
      <li><strong>Global and local</strong>:  —É—á–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö –∏ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤</li>
      <li><strong>–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ</strong>:  –∑–∞—Ö–≤–∞—Ç —Å–ª–æ–∂–Ω—ã—Ö item relationships</li>

    </ul>
    <blockquote>
      üí° GNN –º–æ–¥–µ–ª–∏—Ä—É—é—Ç —Å–ª–æ–∂–Ω—ã–µ item transitions –ª—É—á—à–µ, —á–µ–º sequential models
    </blockquote>
    <pre><code># SASRec - Self-Attentive Sequential Recommendation
import tensorflow as tf
from tensorflow.keras.layers import Layer, MultiHeadAttention, LayerNormalization

class SASRecBlock(Layer):
    def __init__(self, d_model, num_heads):
        super().__init__()
        self.mha = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)
        self.ffn = tf.keras.Sequential([
            tf.keras.layers.Dense(d_model * 4, activation='relu'),
            tf.keras.layers.Dense(d_model)
        ])
        self.layernorm1 = LayerNormalization(epsilon=1e-6)
        self.layernorm2 = LayerNormalization(epsilon=1e-6)
        self.dropout = tf.keras.layers.Dropout(0.2)
    
    def call(self, x, training, mask=None):
        # Self-attention
        attn_output = self.mha(x, x, x, attention_mask=mask)
        attn_output = self.dropout(attn_output, training=training)
        out1 = self.layernorm1(x + attn_output)
        
        # Feed-forward
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)

# Build SASRec model
maxlen = 50
num_blocks = 2
d_model = 128
num_heads = 4

inputs = tf.keras.Input(shape=(maxlen,))
x = Embedding(n_items, d_model)(inputs)

# Positional encoding
positions = tf.range(maxlen)
pos_encoding = Embedding(maxlen, d_model)(positions)
x = x + pos_encoding

# Stacked self-attention blocks
for _ in range(num_blocks):
    x = SASRecBlock(d_model, num_heads)(x)

# Prediction layer
outputs = Dense(n_items)(x)

model = tf.keras.Model(inputs=inputs, outputs=outputs)
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')

print("SASRec model ready")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è sequential RS</h2>
    <p><strong>Hit Rate@K, MRR, NDCG —Å —É—á–µ—Ç–æ–º –ø–æ—Ä—è–¥–∫–∞</strong></p>
    <ul>
            <li><strong>Recall@k</strong>:  –¥–æ–ª—è relevant items –≤ top-k</li>
      <li><strong>NDCG@k</strong>:  normalized discounted cumulative gain</li>
      <li><strong>MRR</strong>:  mean reciprocal rank –ø–µ—Ä–≤–æ–≥–æ relevant</li>
      <li><strong>Hit Rate</strong>:  —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω relevant –≤ top-k</li>
      <li><strong>Coverage</strong>:  —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã—Ö items</li>
      <li><strong>Sequence-aware</strong>:  —É—á–µ—Ç –ø–æ–∑–∏—Ü–∏–∏ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏</li>

    </ul>
    <blockquote>
      üí° Ranking metrics (NDCG, MRR) –≤–∞–∂–Ω–µ–µ accuracy –¥–ª—è sequential RS
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 11. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è</h2>
    <p><strong>–ü—Ä–∏–º–µ—Ä —Å RNN –∏ attention</strong></p>
    <ul>
            <li><strong>Data preparation</strong>:  —Å–µ—Å—Å–∏–∏, timestamps, item sequences</li>
      <li><strong>Negative sampling</strong>:  —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ</li>
      <li><strong>Batch processing</strong>:  –¥–ª—è RNN/Transformer</li>
      <li><strong>Model selection</strong>:  Markov ‚Üí RNN ‚Üí Transformer</li>
      <li><strong>Hyperparameter tuning</strong>:  embedding size, layers, attention heads</li>
      <li><strong>Online evaluation</strong>:  A/B testing –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ</li>

    </ul>
    <blockquote>
      üí° –ù–∞—á–Ω–∏—Ç–µ —Å –ø—Ä–æ—Å—Ç—ã—Ö Markov baseline, –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ deep models –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    </blockquote>
  </div>

</div>

  <div class="block">
    <h2>üî∑ 12. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è</h2>
    <p><strong>E-commerce, –º—É–∑—ã–∫–∞, –≤–∏–¥–µ–æ, –Ω–æ–≤–æ—Å—Ç–∏</strong></p>
    <ul>
            <li><strong>E-commerce</strong>:  next product prediction</li>
      <li><strong>Music streaming</strong>:  playlist continuation (Spotify)</li>
      <li><strong>Video platforms</strong>:  next video recommendation (YouTube)</li>
      <li><strong>News</strong>:  article reading sequences</li>
      <li><strong>POI</strong>:  next location recommendation</li>
      <li><strong>Gaming</strong>:  in-game item recommendations</li>

    </ul>
    <blockquote>
      üí° Sequential RS ‚Äî —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è modern content platforms —Å continuous engagement
    </blockquote>
    <pre><code># –ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
data = pd.read_csv('data.csv')
X = data.drop('target', axis=1)
y = data['target']

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# –û—Ü–µ–Ω–∫–∞
from sklearn.metrics import accuracy_score, classification_report

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.3f}")
print(classification_report(y_test, y_pred))</code></pre>
  </div>



</body>
</html>
