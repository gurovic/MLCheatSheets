<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>Model-Agnostic Meta-Learning (MAML) Cheatsheet</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

    .container {
      column-count: 3;
      column-gap: 20px;
      max-width: 100%;
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üéØ Model-Agnostic Meta-Learning (MAML)</h1>
  <div class="subtitle">Meta-Learning ‚Ä¢ "Learning to Learn" ‚Ä¢ Few-Shot Learning<br>üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –ß—Ç–æ —Ç–∞–∫–æ–µ Meta-Learning?</h2>
    <p><strong>–ò–¥–µ—è</strong>: –Ω–∞—É—á–∏—Ç—å –º–æ–¥–µ–ª—å —É—á–∏—Ç—å—Å—è –±—ã—Å—Ç—Ä–æ –Ω–∞ –Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á–∞—Ö</p>
    <p><strong>–¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ–µ ML</strong>:</p>
    <ul>
      <li>–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–π –∑–∞–¥–∞—á–µ</li>
      <li>–¢—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö</li>
      <li>–ü–ª–æ—Ö–æ –æ–±–æ–±—â–∞–µ—Ç—Å—è –Ω–∞ –Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏</li>
    </ul>
    <p><strong>Meta-Learning</strong>:</p>
    <ul>
      <li>–û–±—É—á–µ–Ω–∏–µ –Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –∑–∞–¥–∞—á</li>
      <li>–ë—ã—Å—Ç—Ä–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –∫ –Ω–æ–≤—ã–º –∑–∞–¥–∞—á–∞–º</li>
      <li>Few-shot learning: 1-5 –ø—Ä–∏–º–µ—Ä–æ–≤</li>
    </ul>
    <p><strong>–ö–æ–Ω—Ü–µ–ø—Ü–∏—è</strong>: "Learning to Learn"</p>
    <blockquote>
      ¬´Meta-learning ‚Äî —ç—Ç–æ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω–∞ –º–æ–≥–ª–∞ –±—ã—Å—Ç—Ä–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è –∫ –Ω–æ–≤—ã–º –∑–∞–¥–∞—á–∞–º —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–∞–Ω–Ω—ã—Ö¬ª.
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 2. MAML: –û—Å–Ω–æ–≤–Ω–∞—è –∏–¥–µ—è</h2>
    <p><strong>Chelsea Finn et al., 2017</strong></p>
    <p><strong>–¶–µ–ª—å</strong>: –Ω–∞–π—Ç–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª—è–µ—Ç –±—ã—Å—Ç—Ä–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è –∫ –Ω–æ–≤—ã–º –∑–∞–¥–∞—á–∞–º</p>
    <p><strong>–ö–ª—é—á–µ–≤–∞—è –∏–¥–µ—è</strong>:</p>
    <ul>
      <li>–ò—â–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã Œ∏, –∫–æ—Ç–æ—Ä—ã–µ —Ö–æ—Ä–æ—à–∏ –∫–∞–∫ —Å—Ç–∞—Ä—Ç–æ–≤–∞—è —Ç–æ—á–∫–∞</li>
      <li>–û–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã—Ö —à–∞–≥–æ–≤ ‚Üí –æ—Ç–ª–∏—á–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∑–∞–¥–∞—á–∏</li>
      <li>Model-agnostic: —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±–æ–π –º–æ–¥–µ–ª—å—é (CNN, RNN, etc.)</li>
    </ul>
    <p><strong>–ú–µ—Ç–∞—Ñ–æ—Ä–∞</strong>: –Ω–∞–π—Ç–∏ "—Ü–µ–Ω—Ç—Ä" –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –∑–∞–¥–∞—á, –æ—Ç–∫—É–¥–∞ –ª–µ–≥–∫–æ –¥–æ–±—Ä–∞—Ç—å—Å—è –¥–æ –ª—é–±–æ–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏</p>
  </div>

  <div class="block">
    <h2>üî∑ 3. MAML –∞–ª–≥–æ—Ä–∏—Ç–º</h2>
    <p><strong>Meta-Training</strong>:</p>
    <ol>
      <li><strong>Sample task</strong> T·µ¢ –∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∑–∞–¥–∞—á</li>
      <li><strong>Split data</strong>: support set (–¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏) –∏ query set (–¥–ª—è –æ—Ü–µ–Ω–∫–∏)</li>
      <li><strong>Inner loop</strong>: –∞–¥–∞–ø—Ç–∞—Ü–∏—è –∫ –∑–∞–¥–∞—á–µ
        <ul>
          <li>Œ∏'·µ¢ = Œ∏ - Œ±‚àáŒ∏L_T·µ¢(Œ∏)</li>
          <li>Œ± ‚Äî inner learning rate</li>
        </ul>
      </li>
      <li><strong>Outer loop</strong>: –º–µ—Ç–∞-–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
        <ul>
          <li>Œ∏ = Œ∏ - Œ≤‚àáŒ∏ Œ£·µ¢ L_T·µ¢(Œ∏'·µ¢)</li>
          <li>Œ≤ ‚Äî outer learning rate</li>
        </ul>
      </li>
    </ol>
    <p><strong>Meta-Testing</strong>:</p>
    <ul>
      <li>–ù–æ–≤–∞—è –∑–∞–¥–∞—á–∞: Œ∏* = Œ∏ - Œ±‚àáŒ∏L_new(Œ∏)</li>
      <li>–ù–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ fine-tuning</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 4. –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞</h2>
    <p><strong>–ú–µ—Ç–∞-—Ü–µ–ª—å</strong>:</p>
    <p>min_Œ∏ Œ£_T·µ¢ L_T·µ¢(Œ∏ - Œ±‚àáŒ∏L_T·µ¢(Œ∏))</p>
    <p><strong>–ì—Ä–∞–¥–∏–µ–Ω—Ç –≤—Ç–æ—Ä–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞</strong>:</p>
    <p>‚àáŒ∏ L_T·µ¢(Œ∏'·µ¢) = ‚àáŒ∏'·µ¢ L_T·µ¢(Œ∏'·µ¢) ¬∑ ‚àáŒ∏ Œ∏'·µ¢</p>
    <p>–≥–¥–µ Œ∏'·µ¢ = Œ∏ - Œ±‚àáŒ∏L_T·µ¢(Œ∏)</p>
    <p><strong>Second-order derivatives</strong>: –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ Hessian</p>
    <p><strong>–í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å</strong>:</p>
    <ul>
      <li>–ü–æ–ª–Ω–∞—è MAML: O(n¬≤) –∏–∑-–∑–∞ second-order</li>
      <li>First-order MAML (FOMAML): O(n), –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç Hessian</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 5. –ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞ (PyTorch)</h2>
    <pre><code># –ü—Å–µ–≤–¥–æ–∫–æ–¥ MAML
def maml_train(model, tasks, inner_lr, outer_lr):
    meta_optimizer = torch.optim.Adam(model.parameters(), lr=outer_lr)
    
    for iteration in range(num_iterations):
        meta_loss = 0
        
        for task in sample_tasks(tasks):
            # Support –∏ query sets
            support_x, support_y = task.support_set()
            query_x, query_y = task.query_set()
            
            # Inner loop: –∞–¥–∞–ø—Ç–∞—Ü–∏—è –∫ –∑–∞–¥–∞—á–µ
            fast_weights = model.parameters()
            for _ in range(inner_steps):
                support_loss = loss_fn(model(support_x, fast_weights), support_y)
                fast_weights = fast_weights - inner_lr * grad(support_loss, fast_weights)
            
            # Outer loop: –º–µ—Ç–∞-–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
            query_loss = loss_fn(model(query_x, fast_weights), query_y)
            meta_loss += query_loss
        
        # –ú–µ—Ç–∞-–≥—Ä–∞–¥–∏–µ–Ω—Ç
        meta_optimizer.zero_grad()
        meta_loss.backward()
        meta_optimizer.step()
    
    return model</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. N-way K-shot –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è</h2>
    <p><strong>Few-shot learning setup</strong></p>
    <p><strong>–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è</strong>:</p>
    <ul>
      <li><strong>N-way</strong>: N –∫–ª–∞—Å—Å–æ–≤ –≤ –∑–∞–¥–∞—á–µ</li>
      <li><strong>K-shot</strong>: K –ø—Ä–∏–º–µ—Ä–æ–≤ –Ω–∞ –∫–ª–∞—Å—Å</li>
      <li><strong>Query set</strong>: —Ç–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã</li>
    </ul>
    <p><strong>–ü—Ä–∏–º–µ—Ä—ã</strong>:</p>
    <ul>
      <li><strong>5-way 1-shot</strong>: 5 –∫–ª–∞—Å—Å–æ–≤, 1 –ø—Ä–∏–º–µ—Ä –Ω–∞ –∫–ª–∞—Å—Å</li>
      <li><strong>5-way 5-shot</strong>: 5 –∫–ª–∞—Å—Å–æ–≤, 5 –ø—Ä–∏–º–µ—Ä–æ–≤ –Ω–∞ –∫–ª–∞—Å—Å</li>
    </ul>
    <p><strong>–î–∞—Ç–∞—Å–µ—Ç—ã</strong>:</p>
    <ul>
      <li><strong>Omniglot</strong>: "MNIST –º–µ—Ç–∞-–æ–±—É—á–µ–Ω–∏—è", –∞–ª—Ñ–∞–≤–∏—Ç—ã</li>
      <li><strong>Mini-ImageNet</strong>: subset ImageNet –¥–ª—è few-shot</li>
      <li><strong>Tiered-ImageNet</strong>: –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è –≤–µ—Ä—Å–∏—è</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 7. –í–∞—Ä–∏–∞—Ü–∏–∏ MAML</h2>
    <p><strong>First-Order MAML (FOMAML)</strong>:</p>
    <ul>
      <li>–ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ second-order –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤</li>
      <li>–ë—ã—Å—Ç—Ä–µ–µ, –º–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏</li>
      <li>–ù–µ–±–æ–ª—å—à–∞—è –ø–æ—Ç–µ—Ä—è –∫–∞—á–µ—Å—Ç–≤–∞</li>
    </ul>
    <p><strong>Reptile</strong> (OpenAI, 2018):</p>
    <ul>
      <li>–ï—â–µ –ø—Ä–æ—â–µ: –ø—Ä–æ—Å—Ç–æ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –≤–µ—Å–æ–≤</li>
      <li>Œ∏ = Œ∏ + Œµ(Œ∏'·µ¢ - Œ∏)</li>
      <li>–ë–µ–∑ –º–µ—Ç–∞-–≥—Ä–∞–¥–∏–µ–Ω—Ç–∞</li>
    </ul>
    <p><strong>MAML++</strong>:</p>
    <ul>
      <li>Multi-step loss optimization</li>
      <li>Per-parameter learning rates</li>
      <li>Batch normalization –∞–¥–∞–ø—Ç–∞—Ü–∏—è</li>
    </ul>
    <p><strong>ANIL</strong> (Almost No Inner Loop):</p>
    <ul>
      <li>–ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π</li>
      <li>–ë—ã—Å—Ç—Ä–µ–µ, –ø—Ä–æ—â–µ</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 8. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è MAML</h2>
    <p><strong>Computer Vision</strong>:</p>
    <ul>
      <li>Few-shot image classification</li>
      <li>Object detection —Å –º–∞–ª—ã–º —á–∏—Å–ª–æ–º –ø—Ä–∏–º–µ—Ä–æ–≤</li>
      <li>Image segmentation</li>
    </ul>
    <p><strong>NLP</strong>:</p>
    <ul>
      <li>Few-shot text classification</li>
      <li>Named Entity Recognition (NER)</li>
      <li>Sentiment analysis –¥–ª—è –Ω–æ–≤—ã—Ö –¥–æ–º–µ–Ω–æ–≤</li>
    </ul>
    <p><strong>Reinforcement Learning</strong>:</p>
    <ul>
      <li>–ë—ã—Å—Ç—Ä–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –∫ –Ω–æ–≤—ã–º –∑–∞–¥–∞—á–∞–º</li>
      <li>Robotics: –±—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–æ–≤—ã–º –Ω–∞–≤—ã–∫–∞–º</li>
      <li>Multi-task RL</li>
    </ul>
    <p><strong>Other</strong>:</p>
    <ul>
      <li>Neural Architecture Search</li>
      <li>Hyperparameter optimization</li>
      <li>Drug discovery</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 9. –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏</h2>
    <p><strong>‚úÖ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞</strong>:</p>
    <ul>
      <li><strong>Model-agnostic</strong>: —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π</li>
      <li><strong>Few-shot</strong>: –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–æ–≤–æ–π –∑–∞–¥–∞—á–∏</li>
      <li><strong>–ë—ã—Å—Ç—Ä–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è</strong>: 1-5 –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã—Ö —à–∞–≥–æ–≤</li>
      <li><strong>–ò–Ω—Ç—É–∏—Ç–∏–≤–Ω–æ –ø–æ–Ω—è—Ç–Ω—ã–π</strong>: –ø—Ä–æ—Å—Ç–∞—è –∏–¥–µ—è</li>
      <li><strong>Strong theoretical foundation</strong></li>
    </ul>
    <p><strong>‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏</strong>:</p>
    <ul>
      <li><strong>–í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ –¥–æ—Ä–æ–≥–æ</strong>: second-order –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã</li>
      <li><strong>–ú–Ω–æ–≥–æ –ø–∞–º—è—Ç–∏</strong>: backprop —á–µ—Ä–µ–∑ backprop</li>
      <li><strong>–ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å</strong>: —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫ hyperparameters</li>
      <li><strong>–¢—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ –∑–∞–¥–∞—á</strong>: –¥–ª—è –º–µ—Ç–∞-–æ–±—É—á–µ–Ω–∏—è</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 10. MAML –¥–ª—è Reinforcement Learning</h2>
    <p><strong>–ê–¥–∞–ø—Ç–∞—Ü–∏—è –∫ –Ω–æ–≤—ã–º RL –∑–∞–¥–∞—á–∞–º</strong></p>
    <p><strong>–ü—Ä–æ—Ü–µ—Å—Å</strong>:</p>
    <ul>
      <li><strong>Meta-training</strong>: –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ MDP</li>
      <li><strong>Inner loop</strong>: policy gradient –Ω–∞ support trajectories</li>
      <li><strong>Outer loop</strong>: –º–µ—Ç–∞-–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–∞ query trajectories</li>
    </ul>
    <p><strong>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è</strong>:</p>
    <ul>
      <li>–†–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∞: –±—ã—Å—Ç—Ä–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –∫ –Ω–æ–≤—ã–º —É—Å–ª–æ–≤–∏—è–º</li>
      <li>Locomotion: —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã terrain</li>
      <li>Manipulation: —Ä–∞–∑–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã</li>
    </ul>
    <p><strong>–ü—Ä–∏–º–µ—Ä—ã</strong>:</p>
    <ul>
      <li>MuJoCo –∑–∞–¥–∞—á–∏: HalfCheetah, Ant</li>
      <li>2D navigation</li>
      <li>Robotic manipulation</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 11. –¢–µ–æ—Ä–∏—è MAML</h2>
    <p><strong>–ü–æ—á–µ–º—É MAML —Ä–∞–±–æ—Ç–∞–µ—Ç?</strong></p>
    <p><strong>Geometrical interpretation</strong>:</p>
    <ul>
      <li>MAML –∏—â–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ "—Ü–µ–Ω—Ç—Ä–µ" loss landscape</li>
      <li>–û—Ç–∫—É–¥–∞ –≤—Å–µ –∑–∞–¥–∞—á–∏ –¥–æ—Å—Ç–∏–∂–∏–º—ã –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤</li>
      <li>–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</li>
    </ul>
    <p><strong>Feature reuse</strong>:</p>
    <ul>
      <li>–ù–∏–∂–Ω–∏–µ —Å–ª–æ–∏: –æ–±—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏</li>
      <li>–í–µ—Ä—Ö–Ω–∏–µ —Å–ª–æ–∏: task-specific –∞–¥–∞–ø—Ç–∞—Ü–∏—è</li>
    </ul>
    <p><strong>–°–≤—è–∑—å —Å transfer learning</strong>:</p>
    <ul>
      <li>Transfer learning: —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ ‚Üí fine-tune</li>
      <li>MAML: –º–µ—Ç–∞-–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ ‚Üí –±—ã—Å—Ç—Ä—ã–π fine-tune</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 12. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏</h2>
    <p><strong>Hyperparameters</strong>:</p>
    <ul>
      <li><strong>Inner learning rate (Œ±)</strong>: 0.01-0.1, –∫—Ä–∏—Ç–∏—á–Ω–æ!</li>
      <li><strong>Outer learning rate (Œ≤)</strong>: 0.001-0.01</li>
      <li><strong>Inner steps</strong>: 1-5 –¥–ª—è supervised, 5-20 –¥–ª—è RL</li>
      <li><strong>Tasks per batch</strong>: 4-32</li>
    </ul>
    <p><strong>–°–æ–≤–µ—Ç—ã</strong>:</p>
    <ul>
      <li>–ù–∞—á–Ω–∏—Ç–µ —Å FOMAML (–ø—Ä–æ—â–µ –∏ –±—ã—Å—Ç—Ä–µ–µ)</li>
      <li>–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ batch normalization –∞–∫–∫—É—Ä–∞—Ç–Ω–æ</li>
      <li>Per-layer learning rates –º–æ–≥—É—Ç –ø–æ–º–æ—á—å</li>
      <li>–ë–æ–ª—å—à–µ inner steps ‚Üí –ª—É—á—à–µ, –Ω–æ –¥–æ–ª—å—à–µ</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 13. –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã</h2>
    <p><strong>learn2learn</strong> (PyTorch):</p>
    <pre><code>import learn2learn as l2l

# –°–æ–∑–¥–∞–Ω–∏–µ MAML learner
model = Net()
maml = l2l.algorithms.MAML(model, lr=0.01)

# Training loop
for task in tasks:
    learner = maml.clone()
    # –ê–¥–∞–ø—Ç–∞—Ü–∏—è
    for _ in range(adapt_steps):
        support_loss = loss(learner(support_x), support_y)
        learner.adapt(support_loss)
    # –ú–µ—Ç–∞-–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
    query_loss = loss(learner(query_x), query_y)
    query_loss.backward()
    meta_optimizer.step()</code></pre>
    <p><strong>–î—Ä—É–≥–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏</strong>:</p>
    <ul>
      <li><strong>Torchmeta</strong>: –¥–∞—Ç–∞—Å–µ—Ç—ã –¥–ª—è meta-learning</li>
      <li><strong>Higher</strong>: higher-order –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 14. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –¥—Ä—É–≥–∏–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</h2>
    <table>
      <tr><th>–ü–æ–¥—Ö–æ–¥</th><th>–ò–¥–µ—è</th><th>–ü–ª—é—Å—ã</th><th>–ú–∏–Ω—É—Å—ã</th></tr>
      <tr><td><strong>MAML</strong></td><td>–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏</td><td>Model-agnostic, –±—ã—Å—Ç—Ä–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è</td><td>–í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ –¥–æ—Ä–æ–≥–æ</td></tr>
      <tr><td><strong>Prototypical Networks</strong></td><td>Metric learning</td><td>–ü—Ä–æ—Å—Ç–æ—Ç–∞, —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å</td><td>–¢–æ–ª—å–∫–æ classification</td></tr>
      <tr><td><strong>Matching Networks</strong></td><td>Attention-based</td><td>–ù–µ —Ç—Ä–µ–±—É–µ—Ç gradient</td><td>–û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –≥–∏–±–∫–æ—Å—Ç—å</td></tr>
      <tr><td><strong>Transfer Learning</strong></td><td>Pre-train ‚Üí Fine-tune</td><td>–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ –≤—Ä–µ–º–µ–Ω–µ–º</td><td>–ú–µ–¥–ª–µ–Ω–Ω–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 15. –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è</h2>
    <ul>
      <li><strong>Task-Agnostic Meta-Learning</strong>: –æ–±–æ–±—â–µ–Ω–∏–µ –∑–∞ –ø—Ä–µ–¥–µ–ª—ã –æ–±—É—á–∞—é—â–∏—Ö –∑–∞–¥–∞—á</li>
      <li><strong>Meta-Learning –¥–ª—è –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π</strong>: MAML + Transformers</li>
      <li><strong>Continual Meta-Learning</strong>: –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø–æ—Ç–æ–∫–µ –∑–∞–¥–∞—á</li>
      <li><strong>Multi-Task Meta-Learning</strong>: –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á</li>
      <li><strong>Meta-Learning + NAS</strong>: –ø–æ–∏—Å–∫ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∞–¥–∞–ø—Ç–∞—Ü–∏–∏</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 16. –í—ã–≤–æ–¥—ã</h2>
    <ul>
      <li><strong>MAML = "learning to learn"</strong>: –º–µ—Ç–∞-–æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∞–¥–∞–ø—Ç–∞—Ü–∏–∏</li>
      <li><strong>–ö–ª—é—á–µ–≤–∞—è –∏–¥–µ—è</strong>: –Ω–∞–π—Ç–∏ —Ö–æ—Ä–æ—à—É—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</li>
      <li><strong>Model-agnostic</strong>: —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π</li>
      <li><strong>Few-shot learning</strong>: 1-5 –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ</li>
      <li><strong>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è</strong>: CV, NLP, RL, robotics</li>
      <li><strong>–í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ –¥–æ—Ä–æ–≥–æ</strong>, –Ω–æ –µ—Å—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã (FOMAML)</li>
    </ul>
    <blockquote>
      ¬´MAML –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –º–æ–¥–µ–ª–∏ –º–æ–≥—É—Ç –Ω–∞—É—á–∏—Ç—å—Å—è —É—á–∏—Ç—å—Å—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ, –∫–∞–∫ —ç—Ç–æ –¥–µ–ª–∞—é—Ç –ª—é–¥–∏ ‚Äî –±—ã—Å—Ç—Ä–æ –∞–¥–∞–ø—Ç–∏—Ä—É—è—Å—å –∫ –Ω–æ–≤—ã–º –∑–∞–¥–∞—á–∞–º —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–∏–º–µ—Ä–æ–≤¬ª.
    </blockquote>
  </div>

</div>

</body>
</html>
