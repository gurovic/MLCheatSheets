<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>Metric Learning (Triplet Loss, ArcFace) Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

        .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üìè Metric Learning (Triplet Loss, ArcFace)</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –ß—Ç–æ —Ç–∞–∫–æ–µ Metric Learning</h2>
    <ul>
      <li><strong>–¶–µ–ª—å</strong>: –Ω–∞—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –∏–∑–º–µ—Ä—è—Ç—å –ø–æ—Ö–æ–∂–µ—Å—Ç—å –æ–±—ä–µ–∫—Ç–æ–≤</li>
      <li><strong>–ò–¥–µ—è</strong>: –ø–æ—Ö–æ–∂–∏–µ –±–ª–∏–∑–∫–æ, –Ω–µ–ø–æ—Ö–æ–∂–∏–µ –¥–∞–ª–µ–∫–æ –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</li>
      <li><strong>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</strong>: face recognition, image retrieval, re-identification</li>
      <li><strong>–†–µ–∑—É–ª—å—Ç–∞—Ç</strong>: –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ embeddings –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è</li>
      <li><strong>–ö–ª—é—á–µ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å</strong>: Triplet, Center, ArcFace, CosFace</li>
    </ul>

  <div class="block">
    <h2>ÔøΩÔøΩ 2. Triplet Loss</h2>
    <p><strong>–ö–æ–Ω—Ü–µ–ø—Ü–∏—è</strong>: —Ç—Ä–æ–π–∫–∞ (anchor, positive, negative)</p>
    <ul>
      <li>Anchor (A): –±–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä</li>
      <li>Positive (P): –ø–æ—Ö–æ–∂–∏–π –Ω–∞ anchor</li>
      <li>Negative (N): –Ω–µ–ø–æ—Ö–æ–∂–∏–π –Ω–∞ anchor</li>
      <li>–¶–µ–ª—å: d(A, P) + margin < d(A, N)</li>
    </ul>
    <pre><code>import torch
import torch.nn as nn
import torch.nn.functional as F

class TripletLoss(nn.Module):
    def __init__(self, margin=0.2):
        super().__init__()
        self.margin = margin
    
    def forward(self, anchor, positive, negative):
        # –ï–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
        distance_positive = F.pairwise_distance(anchor, positive, 2)
        distance_negative = F.pairwise_distance(anchor, negative, 2)
        
        # Triplet loss
        losses = F.relu(
            distance_positive - distance_negative + self.margin
        )
        
        return losses.mean()


# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
class EmbeddingNetwork(nn.Module):
    def __init__(self, embedding_dim=128):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 64, 3)
        self.conv2 = nn.Conv2d(64, 128, 3)
        self.fc1 = nn.Linear(128 * 6 * 6, 256)
        self.fc2 = nn.Linear(256, embedding_dim)
    
    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu(F.max_pool2d(self.conv2(x), 2))
        x = x.view(x.size(0), -1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        # L2 normalization
        return F.normalize(x, p=2, dim=1)


# Training
model = EmbeddingNetwork().cuda()
criterion = TripletLoss(margin=0.2)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

for epoch in range(100):
    for anchor_imgs, pos_imgs, neg_imgs in triplet_loader:
        anchor_imgs = anchor_imgs.cuda()
        pos_imgs = pos_imgs.cuda()
        neg_imgs = neg_imgs.cuda()
        
        # Get embeddings
        anchor_embed = model(anchor_imgs)
        positive_embed = model(pos_imgs)
        negative_embed = model(neg_imgs)
        
        # Loss
        loss = criterion(anchor_embed, positive_embed, negative_embed)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    
    print(f'Epoch {epoch}, Loss: {loss.item():.4f}')</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 3. Triplet Mining</h2>
    <p>–°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≤—ã–±–æ—Ä–∞ —Ç—Ä–∏–ø–ª–µ—Ç–æ–≤ –∫—Ä–∏—Ç–∏—á–Ω—ã –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞:</p>
    <pre><code>class TripletDataset(torch.utils.data.Dataset):
    def __init__(self, images, labels):
        self.images = images
        self.labels = labels
        
        # –ò–Ω–¥–µ–∫—Å—ã –ø–æ –∫–ª–∞—Å—Å–∞–º
        self.label_to_indices = {}
        for idx, label in enumerate(labels):
            if label not in self.label_to_indices:
                self.label_to_indices[label] = []
            self.label_to_indices[label].append(idx)
    
    def __getitem__(self, idx):
        anchor_label = self.labels[idx]
        anchor_img = self.images[idx]
        
        # Positive: —Ç–æ—Ç –∂–µ –∫–ª–∞—Å—Å
        positive_idx = idx
        while positive_idx == idx:
            positive_idx = np.random.choice(
                self.label_to_indices[anchor_label]
            )
        positive_img = self.images[positive_idx]
        
        # Negative: –¥—Ä—É–≥–æ–π –∫–ª–∞—Å—Å
        negative_label = anchor_label
        while negative_label == anchor_label:
            negative_label = np.random.choice(
                list(self.label_to_indices.keys())
            )
        negative_idx = np.random.choice(
            self.label_to_indices[negative_label]
        )
        negative_img = self.images[negative_idx]
        
        return anchor_img, positive_img, negative_img


# Hard Negative Mining
class HardTripletLoss(nn.Module):
    def __init__(self, margin=0.2):
        super().__init__()
        self.margin = margin
    
    def forward(self, embeddings, labels):
        # –í—ã—á–∏—Å–ª—è–µ–º –≤—Å–µ –ø–æ–ø–∞—Ä–Ω—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
        pairwise_dist = torch.cdist(embeddings, embeddings, p=2)
        
        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ anchor –Ω–∞—Ö–æ–¥–∏–º hardest positive –∏ negative
        loss = 0
        num_triplets = 0
        
        for i in range(len(labels)):
            # Hardest positive (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ —Å—Ä–µ–¥–∏ positive)
            positive_mask = labels == labels[i]
            positive_mask[i] = False  # –ò—Å–∫–ª—é—á–∞–µ–º —Å–∞–º anchor
            
            if positive_mask.sum() > 0:
                hardest_positive_dist = pairwise_dist[i][positive_mask].max()
                
                # Hardest negative (–º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ —Å—Ä–µ–¥–∏ negative)
                negative_mask = labels != labels[i]
                
                if negative_mask.sum() > 0:
                    hardest_negative_dist = pairwise_dist[i][negative_mask].min()
                    
                    triplet_loss = F.relu(
                        hardest_positive_dist - hardest_negative_dist + self.margin
                    )
                    
                    loss += triplet_loss
                    num_triplets += 1
        
        return loss / max(num_triplets, 1)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. Center Loss</h2>
    <pre><code>class CenterLoss(nn.Module):
    """
    Minimizes intra-class variations
    Ref: Wen et al. "A Discriminative Feature Learning Approach"
    """
    def __init__(self, num_classes, feat_dim, lambda_c=0.003):
        super().__init__()
        self.num_classes = num_classes
        self.feat_dim = feat_dim
        self.lambda_c = lambda_c
        
        # Centers –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
        self.centers = nn.Parameter(
            torch.randn(num_classes, feat_dim)
        )
    
    def forward(self, embeddings, labels):
        batch_size = embeddings.size(0)
        
        # –†–∞—Å—Å—Ç–æ—è–Ω–∏—è –¥–æ —Ü–µ–Ω—Ç—Ä–æ–≤ —Å–≤–æ–∏—Ö –∫–ª–∞—Å—Å–æ–≤
        centers_batch = self.centers[labels]
        loss = ((embeddings - centers_batch) ** 2).sum() / batch_size
        
        return loss * self.lambda_c


# –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
class CombinedLoss(nn.Module):
    def __init__(self, num_classes, feat_dim):
        super().__init__()
        self.softmax_loss = nn.CrossEntropyLoss()
        self.center_loss = CenterLoss(num_classes, feat_dim)
    
    def forward(self, embeddings, logits, labels):
        # Softmax –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        loss_softmax = self.softmax_loss(logits, labels)
        
        # Center loss –¥–ª—è –∫–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç–∏
        loss_center = self.center_loss(embeddings, labels)
        
        return loss_softmax + loss_center


# Model —Å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π
class MetricLearningModel(nn.Module):
    def __init__(self, num_classes, embedding_dim=128):
        super().__init__()
        self.backbone = EmbeddingNetwork(embedding_dim)
        self.classifier = nn.Linear(embedding_dim, num_classes)
    
    def forward(self, x):
        embeddings = self.backbone(x)
        logits = self.classifier(embeddings)
        return embeddings, logits</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. ArcFace Loss</h2>
    <p>State-of-the-art –¥–ª—è face recognition:</p>
    <pre><code>import math

class ArcFaceLoss(nn.Module):
    """
    ArcFace: Additive Angular Margin Loss
    Ref: Deng et al. "ArcFace: Additive Angular Margin Loss"
    """
    def __init__(self, in_features, out_features, 
                 scale=64.0, margin=0.5):
        super().__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.scale = scale  # s
        self.margin = margin  # m
        
        # Weight matrix (normalized)
        self.weight = nn.Parameter(
            torch.FloatTensor(out_features, in_features)
        )
        nn.init.xavier_uniform_(self.weight)
    
    def forward(self, embeddings, labels):
        # Normalize embeddings and weights
        embeddings = F.normalize(embeddings, p=2, dim=1)
        weight = F.normalize(self.weight, p=2, dim=1)
        
        # Cosine similarity
        cosine = F.linear(embeddings, weight)
        
        # Convert to angle
        theta = torch.acos(torch.clamp(cosine, -1.0 + 1e-7, 1.0 - 1e-7))
        
        # Add angular margin
        target_logits = torch.cos(theta + self.margin)
        
        # One-hot encoding
        one_hot = torch.zeros_like(cosine)
        one_hot.scatter_(1, labels.view(-1, 1), 1.0)
        
        # Combine
        output = (one_hot * target_logits) + ((1.0 - one_hot) * cosine)
        output = output * self.scale
        
        return output


# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
class ArcFaceModel(nn.Module):
    def __init__(self, num_classes, embedding_dim=512):
        super().__init__()
        self.backbone = EmbeddingNetwork(embedding_dim)
        self.arcface = ArcFaceLoss(
            in_features=embedding_dim,
            out_features=num_classes,
            scale=64.0,
            margin=0.5
        )
    
    def forward(self, x, labels=None):
        embeddings = self.backbone(x)
        
        if labels is not None:
            logits = self.arcface(embeddings, labels)
            return logits, embeddings
        else:
            return embeddings


# Training
model = ArcFaceModel(num_classes=10000).cuda()
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(
    model.parameters(), 
    lr=0.1,
    momentum=0.9,
    weight_decay=5e-4
)

for epoch in range(100):
    for images, labels in dataloader:
        images = images.cuda()
        labels = labels.cuda()
        
        logits, embeddings = model(images, labels)
        loss = criterion(logits, labels)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    
    print(f'Epoch {epoch}, Loss: {loss.item():.4f}')</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. CosFace Loss</h2>
    <pre><code>class CosFaceLoss(nn.Module):
    """
    CosFace: Large Margin Cosine Loss
    Ref: Wang et al. "CosFace: Large Margin Cosine Loss"
    """
    def __init__(self, in_features, out_features,
                 scale=64.0, margin=0.35):
        super().__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.scale = scale  # s
        self.margin = margin  # m
        
        self.weight = nn.Parameter(
            torch.FloatTensor(out_features, in_features)
        )
        nn.init.xavier_uniform_(self.weight)
    
    def forward(self, embeddings, labels):
        # Normalize
        embeddings = F.normalize(embeddings, p=2, dim=1)
        weight = F.normalize(self.weight, p=2, dim=1)
        
        # Cosine similarity
        cosine = F.linear(embeddings, weight)
        
        # One-hot
        one_hot = torch.zeros_like(cosine)
        one_hot.scatter_(1, labels.view(-1, 1), 1.0)
        
        # Add cosine margin
        output = cosine - one_hot * self.margin
        output = output * self.scale
        
        return output</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. Contrastive Loss</h2>
    <pre><code>class ContrastiveLoss(nn.Module):
    """
    Contrastive Loss –¥–ª—è –ø–∞—Ä
    """
    def __init__(self, margin=2.0):
        super().__init__()
        self.margin = margin
    
    def forward(self, embedding1, embedding2, label):
        # label: 1 = similar, 0 = dissimilar
        euclidean_distance = F.pairwise_distance(
            embedding1, embedding2, keepdim=True
        )
        
        # Positive pairs: minimize distance
        loss_positive = label * torch.pow(euclidean_distance, 2)
        
        # Negative pairs: maximize distance (up to margin)
        loss_negative = (1 - label) * torch.pow(
            torch.clamp(self.margin - euclidean_distance, min=0.0),
            2
        )
        
        loss = torch.mean(loss_positive + loss_negative)
        return loss


# –ü–∞—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
class PairDataset(torch.utils.data.Dataset):
    def __init__(self, images, labels):
        self.images = images
        self.labels = labels
    
    def __getitem__(self, idx):
        # –ü–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img1 = self.images[idx]
        label1 = self.labels[idx]
        
        # –í—Ç–æ—Ä–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (50% same class)
        if np.random.rand() > 0.5:
            # Same class
            same_class_indices = np.where(
                self.labels == label1
            )[0]
            idx2 = np.random.choice(same_class_indices)
            is_same = 1
        else:
            # Different class
            diff_class_indices = np.where(
                self.labels != label1
            )[0]
            idx2 = np.random.choice(diff_class_indices)
            is_same = 0
        
        img2 = self.images[idx2]
        
        return img1, img2, is_same</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤</h2>
    <table>
      <tr><th>–ú–µ—Ç–æ–¥</th><th>–°–ª–æ–∂–Ω–æ—Å—Ç—å</th><th>–ö–∞—á–µ—Å—Ç–≤–æ</th><th>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</th></tr>
      <tr><td><strong>Contrastive</strong></td><td>–ù–∏–∑–∫–∞—è</td><td>–°—Ä–µ–¥–Ω–µ–µ</td><td>–ü–∞—Ä—ã</td></tr>
      <tr><td><strong>Triplet</strong></td><td>–°—Ä–µ–¥–Ω—è—è</td><td>–•–æ—Ä–æ—à–µ–µ</td><td>–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ</td></tr>
      <tr><td><strong>Center Loss</strong></td><td>–°—Ä–µ–¥–Ω—è—è</td><td>–•–æ—Ä–æ—à–µ–µ</td><td>+ Softmax</td></tr>
      <tr><td><strong>ArcFace</strong></td><td>–í—ã—Å–æ–∫–∞—è</td><td>–û—Ç–ª–∏—á–Ω–æ–µ</td><td>Face Recognition</td></tr>
      <tr><td><strong>CosFace</strong></td><td>–í—ã—Å–æ–∫–∞—è</td><td>–û—Ç–ª–∏—á–Ω–æ–µ</td><td>Face Recognition</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 9. Evaluation –∏ Inference</h2>
    <pre><code># Extraction embeddings
model.eval()
embeddings_list = []
labels_list = []

with torch.no_grad():
    for images, labels in test_loader:
        images = images.cuda()
        embeddings = model.backbone(images)
        embeddings_list.append(embeddings.cpu())
        labels_list.append(labels)

embeddings = torch.cat(embeddings_list)
labels = torch.cat(labels_list)

# Similarity matrix
from sklearn.metrics.pairwise import cosine_similarity

similarity = cosine_similarity(embeddings.numpy())

# Verification (1:1 matching)
def verify(embedding1, embedding2, threshold=0.5):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞, –æ–¥–∏–Ω –ª–∏ —ç—Ç–æ —á–µ–ª–æ–≤–µ–∫"""
    similarity = F.cosine_similarity(
        embedding1.unsqueeze(0),
        embedding2.unsqueeze(0)
    )
    return similarity.item() > threshold

# Identification (1:N matching)
def identify(query_embedding, gallery_embeddings, top_k=5):
    """–ü–æ–∏—Å–∫ –≤ –≥–∞–ª–µ—Ä–µ–µ"""
    similarities = F.cosine_similarity(
        query_embedding.unsqueeze(0),
        gallery_embeddings
    )
    top_k_values, top_k_indices = torch.topk(similarities, top_k)
    return top_k_indices, top_k_values

# Metrics
from sklearn.metrics import roc_auc_score, accuracy_score

# Generate pairs for verification
positive_pairs = []
negative_pairs = []

for i in range(len(labels)):
    for j in range(i+1, len(labels)):
        sim = similarity[i, j]
        if labels[i] == labels[j]:
            positive_pairs.append(sim)
        else:
            negative_pairs.append(sim)

# ROC-AUC
true_labels = [1] * len(positive_pairs) + [0] * len(negative_pairs)
scores = positive_pairs + negative_pairs
auc = roc_auc_score(true_labels, scores)
print(f'ROC-AUC: {auc:.4f}')</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã</h2>
    <ul>
      <li><strong>Margin</strong>: 0.2-0.5 –¥–ª—è Triplet, 0.3-0.5 –¥–ª—è ArcFace</li>
      <li><strong>Scale</strong>: 30-64 –¥–ª—è angular margins</li>
      <li><strong>Embedding dim</strong>: 128-512</li>
      <li><strong>Normalization</strong>: –≤—Å–µ–≥–¥–∞ L2-normalize embeddings</li>
      <li><strong>Mining</strong>: hard negative mining –∫—Ä–∏—Ç–∏—á–µ–Ω</li>
      <li><strong>Augmentation</strong>: –≤–∞–∂–Ω–æ –¥–ª—è generalization</li>
      <li><strong>Batch size</strong>: –±–æ–ª—å—à–µ = –ª—É—á—à–µ (–æ—Å–æ–±–µ–Ω–Ω–æ –¥–ª—è triplet)</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 11. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –•–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç</h3>
        <ul>
          <li>Face recognition –∏ verification</li>
          <li>Person re-identification</li>
          <li>Image retrieval</li>
          <li>Product matching</li>
          <li>Signature verification</li>
          <li>Few-shot learning</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ùå –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è</h3>
        <ul>
          <li>–¢—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö</li>
          <li>–°–ª–æ–∂–Ω–æ—Å—Ç—å –≤—ã–±–æ—Ä–∞ —Ç—Ä–∏–ø–ª–µ—Ç–æ–≤</li>
          <li>–î–æ–ª–≥–æ–µ –æ–±—É—á–µ–Ω–∏–µ</li>
          <li>–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 12. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å –ø–æ–¥—Ö–æ–¥—è—â—É—é loss function</li>
      <li>[ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å margin –∏ scale</li>
      <li>[ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π triplet mining</li>
      <li>[ ] L2-normalize embeddings</li>
      <li>[ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π batch size</li>
      <li>[ ] –î–æ–±–∞–≤–∏—Ç—å data augmentation</li>
      <li>[ ] –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ validation</li>
      <li>[ ] –û—Ü–µ–Ω–∏—Ç—å —á–µ—Ä–µ–∑ ROC-AUC –∏ accuracy</li>
      <li>[ ] –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å embeddings (t-SNE)</li>
      <li>[ ] –°—Ä–∞–≤–Ω–∏—Ç—å —Å baseline</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´Metric Learning –æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –ø–æ–Ω–∏–º–∞—Ç—å –ø–æ—Ö–æ–∂–µ—Å—Ç—å –æ–±—ä–µ–∫—Ç–æ–≤ ‚Äî –Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–∏—Å—Ç–µ–º–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ª–∏—Ü —É—á–∏—Ç—Å—è, —á—Ç–æ —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –æ–¥–Ω–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –±–ª–∏–∑–∫–∏ –¥—Ä—É–≥ –∫ –¥—Ä—É–≥—É, –∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ —Ä–∞–∑–Ω—ã—Ö –ª—é–¥–µ–π –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –¥–∞–ª–µ–∫–∏¬ª.
    </blockquote>
  </div>

</div>

</div>
</body>
</html>
