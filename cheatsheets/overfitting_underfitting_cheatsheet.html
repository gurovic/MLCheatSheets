<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –∏ –Ω–µ–¥–æ–æ–±—É—á–µ–Ω–∏–µ Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen{body{font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Helvetica,Arial,sans-serif;color:#333;background:#fafcff;padding:10px}}
    @media print{body{background:white;padding:0}@page{size:A4 landscape;margin:10mm}}
    .container{column-count:3;column-gap:20px;max-width:100%}
    .block{break-inside:avoid;margin-bottom:1.2em;padding:12px;background:white;border-radius:6px;box-shadow:0 1px 3px rgba(0,0,0,0.05)}
    h1{font-size:1.6em;font-weight:700;color:#1a5fb4;text-align:center;margin:0 0 8px;column-span:all}
    .subtitle{text-align:center;color:#666;font-size:0.9em;margin-bottom:12px;column-span:all}
    h2{font-size:1.15em;font-weight:700;color:#1a5fb4;margin:0 0 8px;padding-bottom:4px;border-bottom:1px solid #e0e7ff}
    p,ul,ol{font-size:0.92em;margin:0.6em 0}ul,ol{padding-left:18px}li{margin-bottom:4px}
    code{font-family:'Consolas','Courier New',monospace;background-color:#f0f4ff;padding:1px 4px;border-radius:3px;font-size:0.88em}
    pre{background-color:#f0f4ff;padding:8px;border-radius:4px;overflow-x:auto;font-size:0.84em;margin:6px 0}
    pre code{padding:0;background:none;white-space:pre-wrap}
    table{width:100%;border-collapse:collapse;font-size:0.82em;margin:6px 0}
    th{background-color:#e6f0ff;text-align:left;padding:4px 6px;font-weight:600}
    td{padding:4px 6px;border-bottom:1px solid #f0f4ff}tr:nth-child(even){background-color:#f8fbff}
    .good-vs-bad{display:flex;flex-direction:column;gap:8px}
    .good-vs-bad div{flex:1;padding:6px 8px;border-radius:4px}
    .good{background-color:#f0f9f4;border-left:3px solid #2e8b57}
    .bad{background-color:#fdf0f2;border-left:3px solid #d32f2f}
    .good h3,.bad h3{margin:0 0 4px;font-size:1em;font-weight:700}
    .good ul,.bad ul{padding-left:20px;margin:0}
    .good li::before{content:"‚úÖ ";font-weight:bold}
    .bad li::before{content:"‚ùå ";font-weight:bold}
    blockquote{font-style:italic;margin:8px 0;padding:6px 10px;background:#f8fbff;border-left:2px solid #1a5fb4;font-size:0.88em}
    @media print{.container{column-gap:12px}.block{box-shadow:none}code,pre,table{font-size:0.78em}h1{font-size:1.4em}h2{font-size:1em}}
  </style>
</head>
<body>
<div class="container">
  <h1>‚öñÔ∏è –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –∏ –Ω–µ–¥–æ–æ–±—É—á–µ–Ω–∏–µ Cheatsheet</h1>
  <div class="subtitle">–î–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö ‚Ä¢ –ë–µ–∑ —Å–ª–æ–∂–Ω–æ–π –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ ‚Ä¢ –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ñ–æ–∫—É—Å<br>üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –°—É—Ç—å</h2>
    <ul>
      <li><strong>Overfitting (–ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ)</strong>: –º–æ–¥–µ–ª—å –∑–∞–ø–æ–º–Ω–∏–ª–∞ –¥–∞–Ω–Ω—ã–µ</li>
      <li><strong>Underfitting (–Ω–µ–¥–æ–æ–±—É—á–µ–Ω–∏–µ)</strong>: –º–æ–¥–µ–ª—å —Å–ª–∏—à–∫–æ–º –ø—Ä–æ—Å—Ç–∞—è</li>
      <li><strong>–¶–µ–ª—å</strong>: –Ω–∞–π—Ç–∏ –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –Ω–∏–º–∏</li>
      <li><strong>–ü—Ä–æ–±–ª–µ–º–∞</strong>: —Ö–æ—Ä–æ—à–æ –Ω–∞ train, –ø–ª–æ—Ö–æ –Ω–∞ test</li>
    </ul>
    <blockquote>–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ ‚Äî –∫–∞–∫ —Å—Ç—É–¥–µ–Ω—Ç, –∑–∞–∑—É–±—Ä–∏–≤—à–∏–π —É—á–µ–±–Ω–∏–∫: –æ—Ç–ª–∏—á–Ω–æ –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –∑–Ω–∞–∫–æ–º—ã–µ –≤–æ–ø—Ä–æ—Å—ã, –Ω–æ –Ω–µ –º–æ–∂–µ—Ç –ø—Ä–∏–º–µ–Ω–∏—Ç—å –∑–Ω–∞–Ω–∏—è –∫ –Ω–æ–≤—ã–º –∑–∞–¥–∞—á–∞–º.</blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 2. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ</h2>
    <table>
      <tr><th>–ê—Å–ø–µ–∫—Ç</th><th>Overfitting</th><th>Good Fit</th><th>Underfitting</th></tr>
      <tr><td><strong>Train Error</strong></td><td>–û—á–µ–Ω—å –Ω–∏–∑–∫–∏–π</td><td>–ù–∏–∑–∫–∏–π</td><td>–í—ã—Å–æ–∫–∏–π</td></tr>
      <tr><td><strong>Test Error</strong></td><td>–í—ã—Å–æ–∫–∏–π</td><td>–ù–∏–∑–∫–∏–π</td><td>–í—ã—Å–æ–∫–∏–π</td></tr>
      <tr><td><strong>Complexity</strong></td><td>–°–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∞—è</td><td>–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è</td><td>–°–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∞—è</td></tr>
      <tr><td><strong>Variance</strong></td><td>–í—ã—Å–æ–∫–∞—è</td><td>–°—Ä–µ–¥–Ω—è—è</td><td>–ù–∏–∑–∫–∞—è</td></tr>
      <tr><td><strong>Bias</strong></td><td>–ù–∏–∑–∫–∏–π</td><td>–°—Ä–µ–¥–Ω–∏–π</td><td>–í—ã—Å–æ–∫–∏–π</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 3. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è</h2>
    <pre><code>import numpy as np
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
X = np.linspace(0, 10, 100).reshape(-1, 1)
y = np.sin(X).ravel() + np.random.normal(0, 0.1, 100)

# –ú–æ–¥–µ–ª–∏ —Ä–∞–∑–Ω–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
degrees = [1, 4, 15]  # underfitting, good, overfitting
plt.figure(figsize=(15, 5))

for i, degree in enumerate(degrees, 1):
    plt.subplot(1, 3, i)
    
    # –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è
    model = Pipeline([
        ('poly', PolynomialFeatures(degree=degree)),
        ('linear', LinearRegression())
    ])
    model.fit(X[:70], y[:70])
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    X_plot = np.linspace(0, 10, 300).reshape(-1, 1)
    y_plot = model.predict(X_plot)
    
    plt.scatter(X[:70], y[:70], alpha=0.5, label='Train')
    plt.scatter(X[70:], y[70:], alpha=0.5, label='Test')
    plt.plot(X_plot, y_plot, 'r-', label='Model')
    plt.title(f'Degree {degree}')
    plt.legend()

plt.tight_layout()
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è</h2>
    <div class="good-vs-bad">
      <div class="bad">
        <h3>‚ùå –ü—Ä–∏–∑–Ω–∞–∫–∏ Overfitting</h3>
        <ul>
          <li>Train loss << Val loss</li>
          <li>Train accuracy >> Val accuracy</li>
          <li>–ú–æ–¥–µ–ª—å —Å–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–∞—è</li>
          <li>–ú–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –¥–∞–Ω–Ω—ã—Ö</li>
          <li>–ò–¥–µ–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 5. –ü—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ–¥–æ–æ–±—É—á–µ–Ω–∏—è</h2>
    <div class="good-vs-bad">
      <div class="bad">
        <h3>‚ùå –ü—Ä–∏–∑–Ω–∞–∫–∏ Underfitting</h3>
        <ul>
          <li>Train loss –∏ Val loss –æ–±–∞ –≤—ã—Å–æ–∫–∏–µ</li>
          <li>Train accuracy –∏ Val accuracy –æ–±–∞ –Ω–∏–∑–∫–∏–µ</li>
          <li>–ú–æ–¥–µ–ª—å —Å–ª–∏—à–∫–æ–º –ø—Ä–æ—Å—Ç–∞—è</li>
          <li>–ù–µ –º–æ–∂–µ—Ç –∑–∞—Ö–≤–∞—Ç–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –¥–∞–Ω–Ω—ã—Ö</li>
          <li>–ü–ª–æ—Ö–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–∞–∂–µ –Ω–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 6. –†–µ—à–µ–Ω–∏–µ Overfitting</h2>
    <ul>
      <li><strong>–ë–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö</strong>: –ª—É—á—à–µ–µ —Ä–µ—à–µ–Ω–∏–µ</li>
      <li><strong>–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è</strong>: L1, L2, Elastic Net</li>
      <li><strong>Dropout</strong>: –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π</li>
      <li><strong>Early Stopping</strong>: –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤–æ–≤—Ä–µ–º—è</li>
      <li><strong>Data Augmentation</strong>: –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö</li>
      <li><strong>–£–ø—Ä–æ—â–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏</strong>: –º–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</li>
      <li><strong>Cross-validation</strong>: –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è</li>
      <li><strong>Batch Normalization</strong>: –¥–ª—è –≥–ª—É–±–æ–∫–∏—Ö —Å–µ—Ç–µ–π</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 7. –†–µ—à–µ–Ω–∏–µ Underfitting</h2>
    <ul>
      <li><strong>–£—Å–ª–æ–∂–Ω–∏—Ç—å –º–æ–¥–µ–ª—å</strong>: –±–æ–ª—å—à–µ —Å–ª–æ—ë–≤/–Ω–µ–π—Ä–æ–Ω–æ–≤</li>
      <li><strong>–ë–æ–ª—å—à–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</strong>: feature engineering</li>
      <li><strong>–ú–µ–Ω—å—à–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏</strong>: –æ—Å–ª–∞–±–∏—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è</li>
      <li><strong>–ë–æ–ª—å—à–µ —ç–ø–æ—Ö</strong>: –¥–æ–ª—å—à–µ –æ–±—É—á–∞—Ç—å</li>
      <li><strong>–î—Ä—É–≥–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞</strong>: –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏</li>
      <li><strong>–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–∞–Ω–Ω—ã–µ</strong>: –º–æ–∂–µ—Ç –±—ã—Ç—å —à—É–º</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 8. –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è (–∫–æ–¥)</h2>
    <pre><code># L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è (Ridge)
from sklearn.linear_model import Ridge
model = Ridge(alpha=1.0)

# L1 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è (Lasso)
from sklearn.linear_model import Lasso
model = Lasso(alpha=1.0)

# Keras/TensorFlow
from tensorflow.keras import regularizers

model.add(Dense(
    64,
    kernel_regularizer=regularizers.l2(0.01),
    activation='relu'
))

# Dropout
from tensorflow.keras.layers import Dropout
model.add(Dropout(0.5))

# PyTorch
import torch.nn as nn
nn.Linear(128, 64)  # –¥–æ–±–∞–≤–ª—è–µ–º weight_decay –≤ optimizer
optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. Bias-Variance Tradeoff</h2>
    <table>
      <tr><th>–ú–µ—Ç—Ä–∏–∫–∞</th><th>High Bias</th><th>High Variance</th></tr>
      <tr><td><strong>–°–∏–Ω–æ–Ω–∏–º</strong></td><td>Underfitting</td><td>Overfitting</td></tr>
      <tr><td><strong>–û—à–∏–±–∫–∞</strong></td><td>–°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è</td><td>–°–ª—É—á–∞–π–Ω–∞—è</td></tr>
      <tr><td><strong>–†–µ—à–µ–Ω–∏–µ</strong></td><td>–£—Å–ª–æ–∂–Ω–∏—Ç—å –º–æ–¥–µ–ª—å</td><td>–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è</td></tr>
      <tr><td><strong>–î–∞–Ω–Ω—ã–µ</strong></td><td>–î–æ–±–∞–≤–∏—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏</td><td>–î–æ–±–∞–≤–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã</td></tr>
    </table>
    <p><strong>–§–æ—Ä–º—É–ª–∞:</strong></p>
    <pre><code>Error = Bias¬≤ + Variance + Irreducible Error

–¶–µ–ª—å: –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—É–º–º—É Bias –∏ Variance</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞</h2>
    <pre><code>def diagnose_model(train_loss, val_loss, train_acc, val_acc):
    """–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º –º–æ–¥–µ–ª–∏"""
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ overfitting
    if train_loss < 0.1 and val_loss > 0.3:
        print("‚ö†Ô∏è OVERFITTING –æ–±–Ω–∞—Ä—É–∂–µ–Ω!")
        print("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        print("  - –î–æ–±–∞–≤–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é")
        print("  - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Dropout")
        print("  - –ë–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö")
        print("  - Early Stopping")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ underfitting
    elif train_loss > 0.5 and val_loss > 0.5:
        print("‚ö†Ô∏è UNDERFITTING –æ–±–Ω–∞—Ä—É–∂–µ–Ω!")
        print("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        print("  - –£—Å–ª–æ–∂–Ω–∏—Ç—å –º–æ–¥–µ–ª—å")
        print("  - –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        print("  - –û–±—É—á–∞—Ç—å –¥–æ–ª—å—à–µ")
        print("  - –£–º–µ–Ω—å—à–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é")
    
    # –•–æ—Ä–æ—à–∞—è –º–æ–¥–µ–ª—å
    elif abs(train_loss - val_loss) < 0.1:
        print("‚úÖ –ú–æ–¥–µ–ª—å —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∞!")
    
    return

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
diagnose_model(train_loss=0.05, val_loss=0.35, 
               train_acc=0.95, val_acc=0.75)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. Learning Curves</h2>
    <pre><code>from sklearn.model_selection import learning_curve

# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫—Ä–∏–≤—ã—Ö –æ–±—É—á–µ–Ω–∏—è
train_sizes, train_scores, val_scores = learning_curve(
    model, X, y, 
    train_sizes=np.linspace(0.1, 1.0, 10),
    cv=5
)

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
plt.figure(figsize=(10, 6))
plt.plot(train_sizes, np.mean(train_scores, axis=1), label='Train')
plt.plot(train_sizes, np.mean(val_scores, axis=1), label='Validation')
plt.xlabel('Training Size')
plt.ylabel('Score')
plt.title('Learning Curves')
plt.legend()
plt.grid(True)
plt.show()

# –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:
# - –ë–æ–ª—å—à–æ–π —Ä–∞–∑—Ä—ã–≤ ‚Üí Overfitting
# - –û–±–µ –∫—Ä–∏–≤—ã–µ –Ω–∏–∑–∫–∏–µ ‚Üí Underfitting
# - –ö—Ä–∏–≤—ã–µ —Å—Ö–æ–¥—è—Ç—Å—è ‚Üí Good Fit</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 12. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å train vs val loss</li>
      <li>[ ] –ü–æ—Å—Ç—Ä–æ–∏—Ç—å learning curves</li>
      <li>[ ] –ü—Ä–∏ overfitting: —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è, dropout, –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö</li>
      <li>[ ] –ü—Ä–∏ underfitting: —É—Å–ª–æ–∂–Ω–∏—Ç—å –º–æ–¥–µ–ª—å, –±–æ–ª—å—à–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</li>
      <li>[ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å cross-validation</li>
      <li>[ ] –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å bias-variance tradeoff</li>
      <li>[ ] Early stopping –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è overfitting</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>¬´Overfitting ‚Äî –º–æ–¥–µ–ª—å —Å–ª–∏—à–∫–æ–º —Ö–æ—Ä–æ—à–æ –∑–∞–ø–æ–º–Ω–∏–ª–∞ –ø—Ä–∏–º–µ—Ä—ã, –Ω–æ –Ω–µ –Ω–∞—É—á–∏–ª–∞—Å—å –æ–±–æ–±—â–∞—Ç—å. Underfitting ‚Äî –º–æ–¥–µ–ª—å —Å–ª–∏—à–∫–æ–º –ø—Ä–æ—Å—Ç–∞—è –∏ –Ω–µ –º–æ–∂–µ—Ç —É–ª–æ–≤–∏—Ç—å –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏. –ù—É–∂–µ–Ω –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –Ω–∏–º–∏¬ª.</blockquote>
  </div>

</div>
</body>
</html>
