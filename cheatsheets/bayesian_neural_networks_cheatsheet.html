<!DOCTYPE html>
<html lang="ru">
<head><meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>–ë–∞–π–µ—Å–æ–≤—Å–∫–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
<style>@media screen{body{font-family:Arial,sans-serif;color:#333;background:#fafcff;padding:10px
        min-width: 900px;
      }}    .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }.block{break-inside:avoid;margin-bottom:1.2em;padding:12px;background:white;border-radius:6px;box-shadow:0 1px 3px rgba(0,0,0,0.05)}h1{font-size:1.6em;font-weight:700;color:#1a5fb4;text-align:center;margin:0 0 8px;column-span:all}.subtitle{text-align:center;color:#666;font-size:0.9em;margin-bottom:12px;column-span:all}h2{font-size:1.15em;font-weight:700;color:#1a5fb4;margin:0 0 8px;padding-bottom:4px;border-bottom:1px solid #e0e7ff}p,ul,ol{font-size:0.92em;margin:0.6em 0}ul,ol{padding-left:18px}li{margin-bottom:4px}code{font-family:Consolas,monospace;background-color:#f0f4ff;padding:1px 4px;border-radius:3px;font-size:0.88em}pre{background-color:#f0f4ff;padding:8px;border-radius:4px;overflow-x:auto;font-size:0.84em;margin:6px 0}pre code{padding:0;background:none;white-space:pre-wrap}table{width:100%;border-collapse:collapse;font-size:0.82em;margin:6px 0}th{background-color:#e6f0ff;text-align:left;padding:4px 6px;font-weight:600}td{padding:4px 6px;border-bottom:1px solid #f0f4ff}tr:nth-child(even){background-color:#f8fbff}blockquote{font-style:italic;margin:8px 0;padding:6px 10px;background:#f8fbff;border-left:2px solid #1a5fb4;font-size:0.88em}</style></head>
<body><div class="container"><h1>üé≤ –ë–∞–π–µ—Å–æ–≤—Å–∫–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏</h1>
<div class="subtitle">üìÖ 4 —è–Ω–≤–∞—Ä—è 2026</div>

<div class="block"><h2>üî∑ 1. –°—É—Ç—å</h2><ul>
<li><strong>–¶–µ–ª—å</strong>: –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö –Ω–µ–π—Ä–æ—Å–µ—Ç–∏</li>
<li><strong>–ò–¥–µ—è</strong>: –≤–µ—Å–∞ ‚Äî –Ω–µ —á–∏—Å–ª–∞, –∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è</li>
<li><strong>–û—Ç–ª–∏—á–∏–µ –æ—Ç –æ–±—ã—á–Ω—ã—Ö NN</strong>: –≤—ã–¥–∞—é—Ç mean + uncertainty</li>
<li><strong>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</strong>: –º–µ–¥–∏—Ü–∏–Ω–∞, —Ñ–∏–Ω–∞–Ω—Å—ã, autonomous vehicles</li>
<li><strong>–¢–∏–ø—ã uncertainty</strong>: aleatoric (—à—É–º –¥–∞–Ω–Ω—ã—Ö) –∏ epistemic (–Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏)</li></ul></div>

<div class="block"><h2>üî∑ 2. –û–±—ã—á–Ω—ã–µ NN vs –ë–∞–π–µ—Å–æ–≤—Å–∫–∏–µ</h2>
<table><tr><th>–ê—Å–ø–µ–∫—Ç</th><th>–û–±—ã—á–Ω—ã–µ NN</th><th>–ë–∞–π–µ—Å–æ–≤—Å–∫–∏–µ NN</th></tr>
<tr><td>–í–µ—Å–∞</td><td>–§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —á–∏—Å–ª–∞</td><td>–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è P(w)</td></tr>
<tr><td>–í—ã—Ö–æ–¥</td><td>–û–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ</td><td>–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ</td></tr>
<tr><td>Uncertainty</td><td>–ù–µ—Ç</td><td>–î–∞</td></tr>
<tr><td>–û–±—É—á–µ–Ω–∏–µ</td><td>–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫</td><td>Variational Inference</td></tr>
<tr><td>–°–∫–æ—Ä–æ—Å—Ç—å</td><td>–ë—ã—Å—Ç—Ä–æ</td><td>–ú–µ–¥–ª–µ–Ω–Ω–µ–µ</td></tr>
<tr><td>Robustness</td><td>–°—Ä–µ–¥–Ω—è—è</td><td>–í—ã—à–µ</td></tr></table></div>

<div class="block"><h2>üî∑ 3. –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Å–Ω–æ–≤–∞</h2>
<p><strong>–ë–∞–π–µ—Å–æ–≤—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥</strong>:</p>
<pre><code>P(w|D) = P(D|w) * P(w) / P(D)

–≥–¥–µ:
- P(w|D): posterior (–≤–µ—Å–∞ –ø–æ—Å–ª–µ –¥–∞–Ω–Ω—ã—Ö)
- P(D|w): likelihood (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö)
- P(w): prior (–∞–ø—Ä–∏–æ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)
- P(D): evidence (–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è)</code></pre>
<p><strong>–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ</strong>:</p>
<pre><code>P(y|x, D) = ‚à´ P(y|x, w) P(w|D) dw

–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ–º –ø–æ –≤—Å–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–º –≤–µ—Å–∞–º</code></pre></div>

<div class="block"><h2>üî∑ 4. Variational Inference</h2>
<p><strong>–ü—Ä–æ–±–ª–µ–º–∞</strong>: —Ç–æ—á–Ω—ã–π posterior P(w|D) –≤—ã—á–∏—Å–ª–∏—Ç—å –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ</p>
<p><strong>–†–µ—à–µ–Ω–∏–µ</strong>: –ø—Ä–∏–±–ª–∏–∑–∏—Ç—å –µ–≥–æ q(w|Œ∏)</p>
<pre><code># –ú–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ–º KL-–¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—é
KL(q(w|Œ∏) || P(w|D))

# –≠–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–æ –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏–∏ ELBO:
ELBO = E_q[log P(D|w)] - KL(q(w|Œ∏) || P(w))
       ‚Üë data fit         ‚Üë regularization</code></pre></div>

<div class="block"><h2>üî∑ 5. –ö–æ–¥ —Å TensorFlow Probability</h2>
<pre><code>import tensorflow as tf
import tensorflow_probability as tfp
tfd = tfp.distributions

# Bayesian Dense Layer
model = tf.keras.Sequential([
    tfp.layers.DenseVariational(
        units=64,
        make_prior_fn=lambda *args: tfd.Normal(0., 1.),
        make_posterior_fn=tfp.layers.default_mean_field_normal_fn(),
        kl_weight=1/len(X_train)
    ),
    tf.keras.layers.ReLU(),
    tfp.layers.DenseVariational(
        units=10,
        make_prior_fn=lambda *args: tfd.Normal(0., 1.),
        make_posterior_fn=tfp.layers.default_mean_field_normal_fn(),
        kl_weight=1/len(X_train)
    )
])

# –ö–æ–º–ø–∏–ª—è—Ü–∏—è
model.compile(
    optimizer='adam',
    loss=lambda y, p_y: -p_y.log_prob(y)
)

model.fit(X_train, y_train, epochs=10)</code></pre></div>

<div class="block"><h2>üî∑ 6. MC Dropout (–ø—Ä–æ—Å—Ç–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞)</h2>
<p><strong>–ò–¥–µ—è</strong>: Dropout –≤–æ –≤—Ä–µ–º—è inference = –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ Bayesian NN</p>
<pre><code>import tensorflow as tf

# –û–±—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å —Å Dropout
model = tf.keras.Sequential([
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(10)
])

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å uncertainty
def predict_with_uncertainty(X, n_samples=100):
    predictions = []
    for _ in range(n_samples):
        # training=True —á—Ç–æ–±—ã Dropout —Ä–∞–±–æ—Ç–∞–ª
        pred = model(X, training=True)
        predictions.append(pred)
    
    predictions = tf.stack(predictions)
    mean = tf.reduce_mean(predictions, axis=0)
    std = tf.math.reduce_std(predictions, axis=0)
    
    return mean, std

y_mean, y_std = predict_with_uncertainty(X_test)
print(f"Prediction: {y_mean[0]:.2f} ¬± {y_std[0]:.2f}")</code></pre></div>

<div class="block"><h2>üî∑ 7. Bayes by Backprop</h2>
<p><strong>–ê–ª–≥–æ—Ä–∏—Ç–º</strong>:</p><ol>
<li>–í–µ—Å–∞ w ‚àº N(Œº, œÉ¬≤)</li>
<li>Sample w –∏–∑ q(w|Œ∏)</li>
<li>Forward pass —Å —ç—Ç–∏–º–∏ –≤–µ—Å–∞–º–∏</li>
<li>Backprop –¥–ª—è Œº –∏ œÉ</li>
<li>–ü–æ–≤—Ç–æ—Ä–∏—Ç—å</li></ol>
<pre><code># PyTorch –∫–æ–¥
import torch
import torch.nn as nn

class BayesianLinear(nn.Module):
    def __init__(self, in_features, out_features):
        super().__init__()
        self.w_mu = nn.Parameter(torch.randn(out_features, in_features))
        self.w_rho = nn.Parameter(torch.randn(out_features, in_features))
        
    def forward(self, x):
        w_sigma = torch.log(1 + torch.exp(self.w_rho))
        w = self.w_mu + w_sigma * torch.randn_like(w_sigma)
        return F.linear(x, w)</code></pre></div>

<div class="block"><h2>üî∑ 8. –¢–∏–ø—ã Uncertainty</h2>
<table><tr><th>–¢–∏–ø</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th><th>–ò—Å—Ç–æ—á–Ω–∏–∫</th><th>–ö–∞–∫ —Å–Ω–∏–∑–∏—Ç—å</th></tr>
<tr><td>Aleatoric</td><td>–®—É–º –≤ –¥–∞–Ω–Ω—ã—Ö</td><td>–ò–∑–º–µ—Ä–µ–Ω–∏—è, —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–Ω–æ—Å—Ç—å</td><td>–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ (–ø—Ä–∏—Ä–æ–¥–∞ –¥–∞–Ω–Ω—ã—Ö)</td></tr>
<tr><td>Epistemic</td><td>–ù–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏</td><td>–ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö, –ø–ª–æ—Ö–∞—è –º–æ–¥–µ–ª—å</td><td>–ë–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö, –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å</td></tr></table>
<pre><code># –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ uncertainty
# Aleatoric: –∏–∑ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
# Epistemic: –∏–∑ –≤–∞—Ä–∏–∞—Ü–∏–∏ –≤–µ—Å–æ–≤ (MC Dropout)</code></pre></div>

<div class="block"><h2>üî∑ 9. Ensemble –∫–∞–∫ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ</h2>
<pre><code># –û–±—É—á–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π
models = []
for i in range(5):
    model = create_model()
    model.fit(X_train, y_train, epochs=10)
    models.append(model)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
predictions = [m.predict(X_test) for m in models]
mean_pred = np.mean(predictions, axis=0)
std_pred = np.std(predictions, axis=0)

# –≠—Ç–æ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ Bayesian posterior
# –ù–æ –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –≤–µ—Å–∞–º–∏</code></pre></div>

<div class="block"><h2>üî∑ 10. –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ uncertainty</h2>
<p><strong>–ü—Ä–æ–≤–µ—Ä–∫–∞</strong>: –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –≥–æ–≤–æ—Ä–∏—Ç 90% —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø—Ä–∞–≤–∞ –≤ 90% —Å–ª—É—á–∞–µ–≤</p>
<pre><code>from sklearn.calibration import calibration_curve

# –ü–æ–ª—É—á–∏—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∏ uncertainty
probs, uncertainties = predict_with_uncertainty(X_test)

# Calibration curve
prob_true, prob_pred = calibration_curve(
    y_test, probs, n_bins=10
)

plt.plot(prob_pred, prob_true, marker='o')
plt.plot([0, 1], [0, 1], linestyle='--')
plt.xlabel('Predicted probability')
plt.ylabel('True probability')
plt.title('Calibration Plot')
plt.show()</code></pre></div>

<div class="block"><h2>üî∑ 11. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è</h2><ul>
<li><strong>–ú–µ–¥–∏—Ü–∏–Ω–∞</strong>: –Ω–µ –¥–∞–≤–∞—Ç—å –¥–∏–∞–≥–Ω–æ–∑ –µ—Å–ª–∏ –Ω–µ—É–≤–µ—Ä–µ–Ω</li>
<li><strong>Autonomous driving</strong>: –ø–µ—Ä–µ–¥–∞—Ç—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —á–µ–ª–æ–≤–µ–∫—É</li>
<li><strong>–§–∏–Ω–∞–Ω—Å—ã</strong>: risk-aware —Ç–æ—Ä–≥–æ–≤–ª—è</li>
<li><strong>Active learning</strong>: –∑–∞–ø—Ä–æ—Å–∏—Ç—å –º–µ—Ç–∫—É –¥–ª—è –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤</li>
<li><strong>Out-of-distribution detection</strong>: –æ–±–Ω–∞—Ä—É–∂–∏—Ç—å —Å—Ç—Ä–∞–Ω–Ω—ã–µ –≤—Ö–æ–¥—ã</li></ul></div>

<div class="block"><h2>üî∑ 12. –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–µ—Ç–æ–¥—ã</h2>
<p><strong>SWAG (Stochastic Weight Averaging Gaussian)</strong>:</p>
<pre><code># –ê–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è posterior —á–µ—Ä–µ–∑ SWA
# –ü—Ä–æ—Å—Ç–æ–π –∏ –±—ã—Å—Ç—Ä—ã–π –º–µ—Ç–æ–¥</code></pre>
<p><strong>Laplace Approximation</strong>:</p>
<pre><code># –ì–∞—É—Å—Å–æ–≤—Å–∫–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ posterior
# –í–æ–∫—Ä—É–≥ MAP estimate</code></pre>
<p><strong>Hamiltonian Monte Carlo</strong>:</p>
<pre><code># –¢–æ—á–Ω–æ–µ —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
# –û—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ</code></pre></div>

<div class="block"><h2>üî∑ 13. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã</h2><ul>
<li><strong>–ù–∞—á–Ω–∏—Ç–µ —Å MC Dropout</strong>: –ø—Ä–æ—â–µ –≤—Å–µ–≥–æ</li>
<li><strong>–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ calibration</strong>: –ø—Ä–æ–≤–µ—Ä–∏—Ç—å uncertainty</li>
<li><strong>Prior –∏–º–µ–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ</strong>: –≤—ã–±–∏—Ä–∞–π—Ç–µ —Ä–∞–∑—É–º–Ω—ã–π</li>
<li><strong>KL weight</strong>: 1/N_train –¥–ª—è –±–∞–ª–∞–Ω—Å–∞</li>
<li><strong>Visualization</strong>: –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å uncertainty –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–∞—Ö</li>
<li><strong>Decision threshold</strong>: –Ω–µ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –µ—Å–ª–∏ uncertainty –≤—ã—Å–æ–∫–∞—è</li></ul></div>

<div class="block"><h2>üî∑ 14. –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å</h2><table>
<tr><th>–°–∏—Ç—É–∞—Ü–∏—è</th><th>–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è</th></tr>
<tr><td>–ö—Ä–∏—Ç–∏—á–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è (–º–µ–¥–∏—Ü–∏–Ω–∞)</td><td><strong>Bayesian NN –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ</strong></td></tr>
<tr><td>Autonomous systems</td><td>Bayesian NN</td></tr>
<tr><td>Active learning</td><td>Bayesian NN –∏–ª–∏ MC Dropout</td></tr>
<tr><td>–û–±—ã—á–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è</td><td>–ù–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ</td></tr>
<tr><td>–ú–∞–ª–æ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π</td><td>MC Dropout –∏–ª–∏ Ensemble</td></tr></table></div>

<div class="block"><h2>üî∑ 15. –ß–µ–∫-–ª–∏—Å—Ç</h2><ul>
<li>[ ] –í—ã–±—Ä–∞—Ç—å –º–µ—Ç–æ–¥ (MC Dropout –¥–ª—è –Ω–∞—á–∞–ª–∞)</li>
<li>[ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å uncertainty quantification</li>
<li>[ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å calibration</li>
<li>[ ] –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å uncertainty</li>
<li>[ ] –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å threshold –¥–ª—è –æ—Ç–∫–∞–∑–∞ –æ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è</li>
<li>[ ] –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ OOD –¥–∞–Ω–Ω—ã—Ö</li>
<li>[ ] –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å limitations</li></ul>
<blockquote>¬´–ë–∞–π–µ—Å–æ–≤—Å–∫–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –Ω–µ –ø—Ä–æ—Å—Ç–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—é—Ç, –Ω–æ –∏ –≥–æ–≤–æ—Ä—è—Ç –Ω–∞—Å–∫–æ–ª—å–∫–æ —É–≤–µ—Ä–µ–Ω—ã 
–≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏. –≠—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ –≤ –∑–∞–¥–∞—á–∞—Ö –≥–¥–µ —Ü–µ–Ω–∞ –æ—à–∏–±–∫–∏ –≤—ã—Å–æ–∫–∞. –ú–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ 
"–∑–Ω–∞—Ç—å —á—Ç–æ –æ–Ω–∞ –Ω–µ –∑–Ω–∞–µ—Ç" –∏ —É–º–µ—Ç—å —Å–∫–∞–∑–∞—Ç—å "—è –Ω–µ —É–≤–µ—Ä–µ–Ω–∞" –≤–º–µ—Å—Ç–æ –≤—ã–¥–∞—á–∏ –ª–æ–∂–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π¬ª.</blockquote></div>

</div></body></html>
