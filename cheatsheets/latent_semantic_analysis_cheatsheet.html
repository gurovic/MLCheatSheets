<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>–õ–∞—Ç–µ–Ω—Ç–Ω–æ-—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen { body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif; color: #333; background: #fafcff; padding: 10px; 
        min-width: 900px;
      } }
    @media print { body { background: white; padding: 0; } @page { size: A4 landscape; margin: 10mm; } }
        .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }
    .block { break-inside: avoid; margin-bottom: 1.2em; padding: 12px; background: white; border-radius: 6px; box-shadow: 0 1px 3px rgba(0,0,0,0.05); }
    h1 { font-size: 1.6em; font-weight: 700; color: #1a5fb4; text-align: center; margin: 0 0 8px; column-span: all; }
    .subtitle { text-align: center; color: #666; font-size: 0.9em; margin-bottom: 12px; column-span: all; }
    h2 { font-size: 1.15em; font-weight: 700; color: #1a5fb4; margin: 0 0 8px; padding-bottom: 4px; border-bottom: 1px solid #e0e7ff; }
    p, ul, ol { font-size: 0.92em; margin: 0.6em 0; }
    ul, ol { padding-left: 18px; }
    li { margin-bottom: 4px; }
    code { font-family: 'Consolas', 'Courier New', monospace; background-color: #f0f4ff; padding: 1px 4px; border-radius: 3px; font-size: 0.88em; }
    pre { background-color: #f0f4ff; padding: 8px; border-radius: 4px; overflow-x: auto; font-size: 0.84em; margin: 6px 0; }
    pre code { padding: 0; background: none; white-space: pre-wrap; }
    table { width: 100%; border-collapse: collapse; font-size: 0.82em; margin: 6px 0; }
    th { background-color: #e6f0ff; text-align: left; padding: 4px 6px; font-weight: 600; }
    td { padding: 4px 6px; border-bottom: 1px solid #f0f4ff; }
    tr:nth-child(even) { background-color: #f8fbff; }
    blockquote { font-style: italic; margin: 8px 0; padding: 6px 10px; background: #f8fbff; border-left: 2px solid #1a5fb4; font-size: 0.88em; }
  </style>
</head>
<body>
<div class="container">
  <h1>üìñ –õ–∞—Ç–µ–Ω—Ç–Ω–æ-—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑</h1>
  <div class="subtitle">üìÖ 5 —è–Ω–≤–∞—Ä—è 2026</div>

  <div class="block">
    <h2>üî∑ 1. –û—Å–Ω–æ–≤—ã LSA</h2>
    <ul>
      <li><strong>–¶–µ–ª—å</strong>: –≤—ã—è–≤–ª–µ–Ω–∏–µ —Å–∫—Ä—ã—Ç–æ–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –≤ —Ç–µ–∫—Å—Ç–∞—Ö</li>
      <li><strong>–ú–µ—Ç–æ–¥</strong>: Singular Value Decomposition (SVD)</li>
      <li><strong>–ò–¥–µ—è</strong>: —Å–ª–æ–≤–∞ –∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –Ω–∏–∑–∫–æ—Ä–∞–∑–º–µ—Ä–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ</li>
      <li><strong>LSI</strong>: Latent Semantic Indexing - –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ LSA –¥–ª—è –ø–æ–∏—Å–∫–∞</li>
      <li><strong>–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ</strong>: —Å–∏–Ω–æ–Ω–∏–º—ã –∏ –ø–æ–ª–∏—Å–µ–º–∏—è —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è</li>
    </ul>

    </div>
<div class="block">
    <h2>üî∑ 2. –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Å–Ω–æ–≤–∞</h2>
    <p><strong>SVD —Ä–∞–∑–ª–æ–∂–µ–Ω–∏–µ:</strong></p>
    <ul>
      <li>X = U √ó Œ£ √ó V^T</li>
      <li>X: term-document matrix (m √ó n)</li>
      <li>U: term-concept matrix (m √ó k)</li>
      <li>Œ£: diagonal singular values (k √ó k)</li>
      <li>V: document-concept matrix (n √ó k)</li>
      <li>k < min(m, n): —á–∏—Å–ª–æ –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 3. –ë–∞–∑–æ–≤–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è</h2>
    <pre><code>from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD

# TF-IDF matrix
vectorizer = TfidfVectorizer(
    max_features=1000,
    max_df=0.8,
    min_df=5,
    stop_words='english'
)
X = vectorizer.fit_transform(documents)

# LSA via SVD
n_components = 100
lsa = TruncatedSVD(
    n_components=n_components,
    random_state=42
)
X_lsa = lsa.fit_transform(X)

# Explained variance
print(f"Variance explained: {lsa.explained_variance_ratio_.sum():.2%}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. Similarity –≤ LSA –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ</h2>
    <pre><code>from sklearn.metrics.pairwise import cosine_similarity

# Similarity –º–µ–∂–¥—É –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
doc_similarities = cosine_similarity(X_lsa)

# Similarity query –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º
query = ["machine learning algorithms"]
query_vec = vectorizer.transform(query)
query_lsa = lsa.transform(query_vec)

similarities = cosine_similarity(query_lsa, X_lsa)[0]

# –¢–æ–ø –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
top_indices = similarities.argsort()[-5:][::-1]
for idx in top_indices:
    print(f"Doc {idx}: {documents[idx][:100]}...")
    print(f"Similarity: {similarities[idx]:.3f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. –í—ã–±–æ—Ä —á–∏—Å–ª–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç</h2>
    <table>
      <tr><th>–ú–µ—Ç–æ–¥</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th></tr>
      <tr><td>Explained Variance</td><td>–°—É–º–º–∞ –æ–±—ä—è—Å–Ω—ë–Ω–Ω–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–∏ ‚â• 80-90%</td></tr>
      <tr><td>Scree Plot</td><td>Elbow –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ singular values</td></tr>
      <tr><td>Cross-validation</td><td>–û—Ü–µ–Ω–∫–∞ –Ω–∞ downstream –∑–∞–¥–∞—á–µ</td></tr>
      <tr><td>Rule of thumb</td><td>100-300 –¥–ª—è –±–æ–ª—å—à–∏—Ö –∫–æ—Ä–ø—É—Å–æ–≤</td></tr>
    </table>
    <pre><code>import matplotlib.pyplot as plt

# Scree plot
plt.plot(range(1, len(lsa.explained_variance_ratio_)+1),
         lsa.explained_variance_ratio_)
plt.xlabel('Component')
plt.ylabel('Explained variance ratio')
plt.title('Scree Plot')
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è LSA</h2>
    <ul>
      <li><strong>–ü–æ–∏—Å–∫</strong>: semantic search, information retrieval</li>
      <li><strong>–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è</strong>: –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤</li>
      <li><strong>–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è</strong>: feature extraction –¥–ª—è ML</li>
      <li><strong>–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏</strong>: –∫–æ–Ω—Ç–µ–Ω—Ç-based filtering</li>
      <li><strong>–°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è</strong>: –≤—ã–¥–µ–ª–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π</li>
      <li><strong>–î–µ—Ç–µ–∫—Ü–∏—è –ø–ª–∞–≥–∏–∞—Ç–∞</strong>: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 7. LSA –¥–ª—è –ø–æ–∏—Å–∫–∞</h2>
    <pre><code>class LSASearchEngine:
    def __init__(self, n_components=100):
        self.vectorizer = TfidfVectorizer(
            max_features=5000,
            stop_words='english'
        )
        self.lsa = TruncatedSVD(n_components=n_components)
        
    def fit(self, documents):
        X = self.vectorizer.fit_transform(documents)
        self.doc_vectors = self.lsa.fit_transform(X)
        self.documents = documents
        return self
    
    def search(self, query, top_n=5):
        query_vec = self.vectorizer.transform([query])
        query_lsa = self.lsa.transform(query_vec)
        
        similarities = cosine_similarity(
            query_lsa, 
            self.doc_vectors
        )[0]
        
        top_indices = similarities.argsort()[-top_n:][::-1]
        results = [
            (self.documents[i], similarities[i])
            for i in top_indices
        ]
        return results

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
engine = LSASearchEngine(n_components=100)
engine.fit(documents)
results = engine.search("machine learning tutorial", top_n=10)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. –¢–æ–ø —Ç–µ—Ä–º—ã –¥–ª—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤</h2>
    <pre><code>def display_topics(lsa, vectorizer, n_top_words=10):
    terms = vectorizer.get_feature_names_out()
    
    for topic_idx, topic in enumerate(lsa.components_):
        top_indices = topic.argsort()[-n_top_words:][::-1]
        top_terms = [terms[i] for i in top_indices]
        print(f"Topic {topic_idx}: {', '.join(top_terms)}")

display_topics(lsa, vectorizer, n_top_words=15)

# –í–∞–∂–Ω–æ—Å—Ç—å —Ç–µ—Ä–º–æ–≤ –¥–ª—è –∫–æ–Ω—Ü–µ–ø—Ç–∞
def term_importance(lsa, vectorizer, concept_idx):
    terms = vectorizer.get_feature_names_out()
    weights = lsa.components_[concept_idx]
    term_weights = sorted(
        zip(terms, weights),
        key=lambda x: abs(x[1]),
        reverse=True
    )
    return term_weights[:20]</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. LSA vs LDA vs Word2Vec</h2>
    <table>
      <tr><th>–ú–µ—Ç–æ–¥</th><th>–ü–æ–¥—Ö–æ–¥</th><th>–ü–ª—é—Å—ã</th><th>–ú–∏–Ω—É—Å—ã</th></tr>
      <tr><td>LSA</td><td>SVD</td><td>–ë—ã—Å—Ç—Ä—ã–π, –ø—Ä–æ—Å—Ç–æ–π</td><td>–õ–∏–Ω–µ–π–Ω—ã–π</td></tr>
      <tr><td>LDA</td><td>Probabilistic</td><td>–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å</td><td>–ú–µ–¥–ª–µ–Ω–Ω–µ–µ</td></tr>
      <tr><td>Word2Vec</td><td>Neural</td><td>–ö–æ–Ω—Ç–µ–∫—Å—Ç, –∫–∞—á–µ—Å—Ç–≤–æ</td><td>–¢—Ä–µ–±—É–µ—Ç –¥–∞–Ω–Ω—ã—Ö</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 10. Incremental LSA</h2>
    <p><strong>–î–ª—è –ø–æ—Ç–æ–∫–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:</strong></p>
    <pre><code>from sklearn.decomposition import IncrementalPCA

# –ò–ª–∏ –æ–Ω–ª–∞–π–Ω SVD
class OnlineLSA:
    def __init__(self, n_components):
        self.n_components = n_components
        self.U = None
        self.S = None
        
    def partial_fit(self, X_new):
        if self.U is None:
            # Initial SVD
            U, S, Vt = np.linalg.svd(X_new, full_matrices=False)
            self.U = U[:, :self.n_components]
            self.S = S[:self.n_components]
        else:
            # Update with new data
            # Implementation of folding-in
            pass
        return self</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</h2>
    <ul>
      <li><strong>Sparse matrices</strong>: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã–µ –º–∞—Ç—Ä–∏—Ü—ã</li>
      <li><strong>Batch processing</strong>: –¥–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö –∫–æ—Ä–ø—É—Å–æ–≤</li>
      <li><strong>Random SVD</strong>: –±—ã—Å—Ç—Ä–µ–µ –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö</li>
      <li><strong>Vocabulary pruning</strong>: –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è</li>
    </ul>
    <pre><code># Random SVD –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
from sklearn.utils.extmath import randomized_svd

U, S, Vt = randomized_svd(
    X, 
    n_components=100,
    n_iter=5,
    random_state=42
)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 12. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è LSA –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞</h2>
    <pre><code>from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

# –°–Ω–∏–∂–µ–Ω–∏–µ –¥–æ 2D –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
tsne = TSNE(n_components=2, random_state=42)
X_2d = tsne.fit_transform(X_lsa)

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
plt.figure(figsize=(12, 8))
scatter = plt.scatter(
    X_2d[:, 0], 
    X_2d[:, 1],
    c=labels,  # –µ—Å–ª–∏ –µ—Å—Ç—å –º–µ—Ç–∫–∏
    cmap='tab10',
    alpha=0.6
)
plt.colorbar(scatter)
plt.title('LSA Document Space (2D projection)')
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 13. Gensim LSI</h2>
    <pre><code>from gensim import corpora, models

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞
texts = [doc.split() for doc in documents]
dictionary = corpora.Dictionary(texts)
corpus = [dictionary.doc2bow(text) for text in texts]

# LSI model
lsi = models.LsiModel(
    corpus, 
    id2word=dictionary, 
    num_topics=100
)

# Topics
for idx, topic in lsi.print_topics(num_topics=10):
    print(f"Topic {idx}: {topic}")

# Transform documents
doc_lsi = lsi[corpus]</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 14. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã</h2>
    <ul>
      <li>TF-IDF –ª—É—á—à–µ —á–µ–º raw counts –¥–ª—è LSA</li>
      <li>100-300 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è –±–æ–ª—å—à–∏—Ö –∫–æ—Ä–ø—É—Å–æ–≤</li>
      <li>–£–¥–∞–ª—è–π—Ç–µ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –∏ —Ä–µ–¥–∫–∏–µ —Ç–µ—Ä–º—ã</li>
      <li>–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤ –¥–ª—è cosine similarity</li>
      <li>LSA —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–∞ –∫ –¥–ª–∏–Ω–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞</li>
      <li>–î–ª—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ BERT</li>
    </ul>
    <blockquote>
      üí° <strong>–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:</strong> ¬´LSA –Ω–∞—Ö–æ–¥–∏—Ç —Å–∫—Ä—ã—Ç—ã–µ —Ç–µ–º—ã –≤ —Ç–µ–∫—Å—Ç–∞—Ö –∏—Å–ø–æ–ª—å–∑—É—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–ª–æ–∂–µ–Ω–∏–µ. –ü–æ–∑–≤–æ–ª—è–µ—Ç –Ω–∞—Ö–æ–¥–∏—Ç—å –ø–æ—Ö–æ–∂–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Ä–∞–∑–Ω—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø–æ–Ω—è—Ç–∏—è¬ª.
    </blockquote>
  </div>


</div>
</body>
</html>
