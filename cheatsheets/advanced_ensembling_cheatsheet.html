<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>Advanced Model Ensembling Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <meta charset="UTF-8">
  <title>–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Feature Importance) Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

    .container {
      column-count: 3;
      column-gap: 20px;
      max-width: 100%;
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>

</head>
<body>

<div class="container">

  <h1>üé≠ Advanced Model Ensembling Cheatsheet</h1>
  <div class="subtitle">–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–µ—Ç–æ–¥—ã –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è ‚Ä¢ Stacking, Blending ‚Ä¢ –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ñ–æ–∫—É—Å<br>üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. Stacking (Meta-Learning)</h2>
    <pre><code>from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

# Base models
estimators = [
    ('rf', RandomForestClassifier(n_estimators=100)),
    ('svm', SVC(probability=True)),
    ('lr', LogisticRegression())
]

# Meta-model
stacking = StackingClassifier(
    estimators=estimators,
    final_estimator=LogisticRegression(),
    cv=5  # Cross-validation –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è overfitting
)

stacking.fit(X_train, y_train)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 2. Blending</h2>
    <pre><code># Split data
X_train1, X_train2, y_train1, y_train2 = train_test_split(
    X_train, y_train, test_size=0.5
)

# Train base models –Ω–∞ –ø–µ—Ä–≤–æ–π —á–∞—Å—Ç–∏
models = [rf, svm, lr]
for model in models:
    model.fit(X_train1, y_train1)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –≤—Ç–æ—Ä–æ–π —á–∞—Å—Ç–∏
meta_features = np.column_stack([
    model.predict_proba(X_train2) for model in models
])

# Train meta-model
meta_model = LogisticRegression()
meta_model.fit(meta_features, y_train2)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 3. Weighted Averaging</h2>
    <pre><code>from scipy.optimize import minimize

def weighted_ensemble(predictions, weights):
    return np.average(predictions, axis=0, weights=weights)

def loss_func(weights, predictions, y_true):
    ensemble_pred = weighted_ensemble(predictions, weights)
    return -accuracy_score(y_true, ensemble_pred.argmax(axis=1))

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
result = minimize(
    loss_func,
    x0=[1/len(models)] * len(models),
    args=(val_predictions, y_val),
    bounds=[(0, 1)] * len(models),
    constraints={'type': 'eq', 'fun': lambda w: np.sum(w) - 1}
)

optimal_weights = result.x</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. Bagging —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –ø–æ–¥–≤—ã–±–æ—Ä–∫–∞–º–∏</h2>
    <ul>
      <li><strong>Bootstrap aggregating</strong>: —Å–ª—É—á–∞–π–Ω—ã–µ –ø–æ–¥–≤—ã–±–æ—Ä–∫–∏ —Å –≤–æ–∑–≤—Ä–∞—Ç–æ–º</li>
      <li><strong>Pasting</strong>: –±–µ–∑ –≤–æ–∑–≤—Ä–∞—Ç–∞</li>
      <li><strong>Random Subspaces</strong>: —Å–ª—É—á–∞–π–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏</li>
      <li><strong>Random Patches</strong>: —Å–ª—É—á–∞–π–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã + –ø—Ä–∏–∑–Ω–∞–∫–∏</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 5. Snapshot Ensembles</h2>
    <pre><code>import torch

class SnapshotEnsemble:
    def __init__(self, model, num_snapshots=5):
        self.model = model
        self.snapshots = []
        self.num_snapshots = num_snapshots
    
    def save_snapshot(self):
        snapshot = copy.deepcopy(self.model.state_dict())
        self.snapshots.append(snapshot)
    
    def predict(self, X):
        predictions = []
        for snapshot in self.snapshots:
            self.model.load_state_dict(snapshot)
            self.model.eval()
            with torch.no_grad():
                pred = self.model(X)
            predictions.append(pred)
        
        # Average predictions
        return torch.mean(torch.stack(predictions), dim=0)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. Diversity –≤ –∞–Ω—Å–∞–º–±–ª—è—Ö</h2>
    <ul>
      <li><strong>–†–∞–∑–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã</strong>: RF + GBM + NN</li>
      <li><strong>–†–∞–∑–Ω—ã–µ features</strong>: —Ä–∞–∑–Ω—ã–µ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</li>
      <li><strong>–†–∞–∑–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã</strong>: –≤–∞—Ä–∏–∞—Ü–∏–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫</li>
      <li><strong>–†–∞–∑–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è</strong>: –¥–ª—è NN</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 7. Multi-Level Stacking</h2>
    <pre><code># Level 0: –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
level0_models = [rf1, rf2, gbm1, gbm2, nn]

# Level 1: –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏
level1_models = [lr, ridge]

# Level 2: —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
final_model = LogisticRegression()

# –û–±—É—á–µ–Ω–∏–µ
for model in level0_models:
    model.fit(X_train, y_train)

level0_preds = [m.predict_proba(X_val) for m in level0_models]
X_level1 = np.column_stack(level0_preds)

for model in level1_models:
    model.fit(X_level1, y_val)

level1_preds = [m.predict_proba(X_level1) for m in level1_models]
X_level2 = np.column_stack(level1_preds)

final_model.fit(X_level2, y_val)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤</h2>
    <table>
      <tr><th>–ú–µ—Ç–æ–¥</th><th>Complexity</th><th>Overfitting —Ä–∏—Å–∫</th><th>–ö–∞—á–µ—Å—Ç–≤–æ</th></tr>
      <tr><td><strong>Voting</strong></td><td>–ù–∏–∑–∫–∞—è</td><td>–ù–∏–∑–∫–∏–π</td><td>–°—Ä–µ–¥–Ω–µ–µ</td></tr>
      <tr><td><strong>Bagging</strong></td><td>–°—Ä–µ–¥–Ω—è—è</td><td>–ù–∏–∑–∫–∏–π</td><td>–•–æ—Ä–æ—à–µ–µ</td></tr>
      <tr><td><strong>Stacking</strong></td><td>–í—ã—Å–æ–∫–∞—è</td><td>–°—Ä–µ–¥–Ω–∏–π</td><td>–û—Ç–ª–∏—á–Ω–æ–µ</td></tr>
      <tr><td><strong>Blending</strong></td><td>–°—Ä–µ–¥–Ω—è—è</td><td>–°—Ä–µ–¥–Ω–∏–π</td><td>–•–æ—Ä–æ—à–µ–µ</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 9. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ base models</li>
      <li>[ ] Cross-validation –¥–ª—è meta-model</li>
      <li>[ ] –ù–µ –ø–µ—Ä–µ–æ–±—É—á–∞—Ç—å –Ω–∞ train set</li>
      <li>[ ] –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å correlation –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏</li>
      <li>[ ] –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–µ—Å–∞ –º–æ–¥–µ–ª–µ–π</li>
      <li>[ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —É–ª—É—á—à–µ–Ω–∏–µ vs single model</li>
      <li>[ ] Balance complexity vs performance</li>
    </ul>
    <blockquote>
      ¬´–ê–Ω—Å–∞–º–±–ª–∏ —Ä–∞–±–æ—Ç–∞—é—Ç –ª—É—á—à–µ –∫–æ–≥–¥–∞ –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã –∏ –Ω–µ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω—ã. Diversity > –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π¬ª.
    </blockquote>
  </div>


</div>

</body>
</html>
