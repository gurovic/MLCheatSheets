<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>Kernel PCA Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

        .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üîÆ Kernel PCA</h1>
  <div class="subtitle">üìÖ 4 —è–Ω–≤–∞—Ä—è 2026</div>

  <div class="block">
    <h2>üî∑ 1. –°—É—Ç—å</h2>
    <ul>
      <li><strong>–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ PCA</strong>: –Ω–µ–ª–∏–Ω–µ–π–Ω–∞—è –≤–µ—Ä—Å–∏—è –æ–±—ã—á–Ω–æ–≥–æ PCA</li>
      <li><strong>Kernel Trick</strong>: –ø—Ä–æ–µ—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –≤—ã—Å–æ–∫–æ–º–µ—Ä–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ</li>
      <li><strong>–ù–µ–ª–∏–Ω–µ–π–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã</strong>: –Ω–∞—Ö–æ–¥–∏—Ç —Å–ª–æ–∂–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã</li>
      <li><strong>–ë–µ–∑ —è–≤–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è</strong>: —Ä–∞–±–æ—Ç–∞–µ—Ç —á–µ—Ä–µ–∑ —è–¥—Ä–∞</li>
      <li><strong>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</strong>: –¥–µ–Ω–æ–∏–∑–∏–Ω–≥, –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è, –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞</li>
    </ul>

  <div class="block">
    <h2>üî∑ 2. –ë–∞–∑–æ–≤—ã–π –∫–æ–¥</h2>
    <pre><code>from sklearn.decomposition import KernelPCA

# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
kpca = KernelPCA(
    n_components=2,
    kernel='rbf',
    gamma=0.1,
    fit_inverse_transform=True,
    random_state=42
)

# –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
X_transformed = kpca.fit_transform(X)

# –û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
X_reconstructed = kpca.inverse_transform(X_transformed)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 3. –ö–ª—é—á–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã</h2>
    <table>
      <tr><th>–ü–∞—Ä–∞–º–µ—Ç—Ä</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th><th>–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è</th></tr>
      <tr><td><code>n_components</code></td><td>–ß–∏—Å–ª–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç</td><td>2-10 –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏</td></tr>
      <tr><td><code>kernel</code></td><td>–¢–∏–ø —è–¥—Ä–∞</td><td>'rbf', 'poly', 'sigmoid', 'linear'</td></tr>
      <tr><td><code>gamma</code></td><td>–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–ª—è RBF/poly</td><td>1/n_features –∏–ª–∏ –ø–æ–¥–±–æ—Ä</td></tr>
      <tr><td><code>degree</code></td><td>–°—Ç–µ–ø–µ–Ω—å –¥–ª—è poly</td><td>2-4</td></tr>
      <tr><td><code>fit_inverse_transform</code></td><td>–û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ</td><td>True –¥–ª—è –¥–µ–Ω–æ–∏–∑–∏–Ω–≥–∞</td></tr>
      <tr><td><code>eigen_solver</code></td><td>–ú–µ—Ç–æ–¥ —Ä–µ—à–µ–Ω–∏—è</td><td>'auto', 'dense', 'arpack'</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 4. –¢–∏–ø—ã —è–¥–µ—Ä</h2>
    <p><strong>1. RBF (Gaussian)</strong>:</p>
    <pre><code>kpca = KernelPCA(kernel='rbf', gamma=0.1)
# K(x, y) = exp(-gamma * ||x - y||¬≤)</code></pre>
    <ul>
      <li>–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ —è–¥—Ä–æ</li>
      <li>–•–æ—Ä–æ—à–æ –¥–ª—è –æ–±—â–∏—Ö —Å–ª—É—á–∞–µ–≤</li>
    </ul>
    <p><strong>2. Polynomial</strong>:</p>
    <pre><code>kpca = KernelPCA(kernel='poly', 
                 degree=3, gamma=0.1, coef0=1)
# K(x, y) = (gamma*‚ü®x,y‚ü© + coef0)^degree</code></pre>
    <ul>
      <li>–î–ª—è –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π</li>
    </ul>
    <p><strong>3. Sigmoid</strong>:</p>
    <pre><code>kpca = KernelPCA(kernel='sigmoid', 
                 gamma=0.1, coef0=0)
# K(x, y) = tanh(gamma*‚ü®x,y‚ü© + coef0)</code></pre>
    <ul>
      <li>–ü–æ—Ö–æ–∂–µ –Ω–∞ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏</li>
    </ul>
    <p><strong>4. Linear</strong>:</p>
    <pre><code>kpca = KernelPCA(kernel='linear')
# –≠–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–æ –æ–±—ã—á–Ω–æ–º—É PCA</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö</h2>
    <p>‚úÖ <strong>–¶–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ</strong>:</p>
    <pre><code># Kernel PCA –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ü–µ–Ω—Ç—Ä–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ
# –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</code></pre>
    <p>‚úÖ <strong>–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è</strong>:</p>
    <pre><code>from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

kpca = KernelPCA(n_components=2, kernel='rbf')
X_transformed = kpca.fit_transform(X_scaled)</code></pre>
    <p>‚úÖ <strong>–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤</strong>:</p>
    <ul>
      <li>Kernel PCA —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ –≤—ã–±—Ä–æ—Å–∞–º</li>
      <li>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å RobustScaler –∏–ª–∏ —É–¥–∞–ª–∏—Ç—å –≤—ã–±—Ä–æ—Å—ã</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 6. –ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</h2>
    <pre><code>from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline

# Pipeline: Kernel PCA + Classifier
pipe = Pipeline([
    ('kpca', KernelPCA(n_components=10)),
    ('lr', LogisticRegression())
])

# –°–µ—Ç–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
params = {
    'kpca__kernel': ['rbf', 'poly'],
    'kpca__gamma': [0.01, 0.1, 1.0],
    'kpca__n_components': [5, 10, 20]
}

grid = GridSearchCV(pipe, params, cv=5)
grid.fit(X_train, y_train)

print(f"Best params: {grid.best_params_}")
print(f"Best score: {grid.best_score_:.4f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –æ–±—ã—á–Ω—ã–º PCA</h2>
    <table>
      <tr><th>–ê—Å–ø–µ–∫—Ç</th><th>PCA</th><th>Kernel PCA</th></tr>
      <tr><td>–õ–∏–Ω–µ–π–Ω–æ—Å—Ç—å</td><td>–õ–∏–Ω–µ–π–Ω—ã–π</td><td>–ù–µ–ª–∏–Ω–µ–π–Ω—ã–π</td></tr>
      <tr><td>–°–∫–æ—Ä–æ—Å—Ç—å</td><td>–ë—ã—Å—Ç—Ä–æ</td><td>–ú–µ–¥–ª–µ–Ω–Ω–µ–µ</td></tr>
      <tr><td>–ü–∞–º—è—Ç—å</td><td>O(n*d)</td><td>O(n¬≤)</td></tr>
      <tr><td>–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è</td><td>–õ–µ–≥–∫–æ</td><td>–°–ª–æ–∂–Ω–æ</td></tr>
      <tr><td>–ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ</td><td>transform()</td><td>–ù—É–∂–µ–Ω fit_inverse</td></tr>
      <tr><td>–°—Ç—Ä—É–∫—Ç—É—Ä—ã</td><td>–ü—Ä–æ—Å—Ç—ã–µ</td><td>–°–ª–æ–∂–Ω—ã–µ</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 8. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤</h2>
    <pre><code>import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# –û–±—ã—á–Ω—ã–π PCA
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)
axes[0].scatter(X_pca[:, 0], X_pca[:, 1], 
                c=y, cmap='viridis')
axes[0].set_title('Linear PCA')

# Kernel PCA (RBF)
kpca_rbf = KernelPCA(n_components=2, kernel='rbf')
X_kpca_rbf = kpca_rbf.fit_transform(X)
axes[1].scatter(X_kpca_rbf[:, 0], X_kpca_rbf[:, 1],
                c=y, cmap='viridis')
axes[1].set_title('Kernel PCA (RBF)')

# Kernel PCA (poly)
kpca_poly = KernelPCA(n_components=2, kernel='poly')
X_kpca_poly = kpca_poly.fit_transform(X)
axes[2].scatter(X_kpca_poly[:, 0], X_kpca_poly[:, 1],
                c=y, cmap='viridis')
axes[2].set_title('Kernel PCA (Poly)')
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. –î–µ–Ω–æ–∏–∑–∏–Ω–≥ —Å Kernel PCA</h2>
    <pre><code># –î–æ–±–∞–≤–ª—è–µ–º —à—É–º –∫ –¥–∞–Ω–Ω—ã–º
import numpy as np
X_noisy = X + 0.5 * np.random.randn(*X.shape)

# Kernel PCA –¥–ª—è –¥–µ–Ω–æ–∏–∑–∏–Ω–≥–∞
kpca = KernelPCA(
    n_components=50,
    kernel='rbf',
    gamma=0.1,
    fit_inverse_transform=True
)

# –ü—Ä–æ–µ—Ü–∏—Ä—É–µ–º –∏ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º
X_kpca = kpca.fit_transform(X_noisy)
X_denoised = kpca.inverse_transform(X_kpca)

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
import matplotlib.pyplot as plt
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
axes[0].imshow(X[0].reshape(28, 28), cmap='gray')
axes[0].set_title('Original')
axes[1].imshow(X_noisy[0].reshape(28, 28), cmap='gray')
axes[1].set_title('Noisy')
axes[2].imshow(X_denoised[0].reshape(28, 28), cmap='gray')
axes[2].set_title('Denoised')
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è</h2>
    <ul>
      <li><strong>–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è</strong>: –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ 2D/3D</li>
      <li><strong>–î–µ–Ω–æ–∏–∑–∏–Ω–≥</strong>: —É–¥–∞–ª–µ–Ω–∏–µ —à—É–º–∞ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π</li>
      <li><strong>–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞</strong>: –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏/—Ä–µ–≥—Ä–µ—Å—Å–∏–∏</li>
      <li><strong>–î–µ—Ç–µ–∫—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π</strong>: —á–µ—Ä–µ–∑ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—é</li>
      <li><strong>Feature extraction</strong>: –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏</li>
      <li><strong>–ö–æ–º–ø—Ä–µ—Å—Å–∏—è</strong>: –Ω–µ–ª–∏–Ω–µ–π–Ω–æ–µ —Å–∂–∞—Ç–∏–µ –¥–∞–Ω–Ω—ã—Ö</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 11. –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –•–æ—Ä–æ—à–æ</h3>
        <ul>
          <li>–ù–µ–ª–∏–Ω–µ–π–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –≤ –¥–∞–Ω–Ω—ã—Ö</li>
          <li>PCA –Ω–µ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è</li>
          <li>–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö (&lt;20K)</li>
          <li>–ù—É–∂–Ω–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏–ª–∏ –¥–µ–Ω–æ–∏–∑–∏–Ω–≥</li>
          <li>–ú–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å —è–¥—Ä–æ</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ùå –ü–ª–æ—Ö–æ</h3>
        <ul>
          <li>–û—á–µ–Ω—å –±–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ (&gt;50K)</li>
          <li>–õ–∏–Ω–µ–π–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (–ª—É—á—à–µ PCA)</li>
          <li>–ù—É–∂–Ω–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç</li>
          <li>–ß–∞—Å—Ç–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫ –Ω–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 12. –ü—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</h2>
    <table>
      <tr><th>–ü—Ä–æ–±–ª–µ–º–∞</th><th>–†–µ—à–µ–Ω–∏–µ</th></tr>
      <tr><td>–ú–µ–¥–ª–µ–Ω–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç</td><td>–£–º–µ–Ω—å—à–∏—Ç—å —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 'arpack'</td></tr>
      <tr><td>–í—ã—Å–æ–∫–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏</td><td>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å MiniBatchKernelPCA –∏–ª–∏ sampling</td></tr>
      <tr><td>–ü–ª–æ—Ö–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ</td><td>–ü–æ–¥–æ–±—Ä–∞—Ç—å gamma –∏ kernel —á–µ—Ä–µ–∑ CV</td></tr>
      <tr><td>–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ</td><td>–£–º–µ–Ω—å—à–∏—Ç—å n_components, —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è</td></tr>
      <tr><td>–ù–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö</td><td>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å fit_inverse_transform=True</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 13. –í—ã–±–æ—Ä —á–∏—Å–ª–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç</h2>
    <pre><code># –ü–æ–¥–±–æ—Ä —á–µ—Ä–µ–∑ cross-validation
from sklearn.model_selection import cross_val_score

n_components_range = [5, 10, 20, 50, 100]
scores = []

for n_comp in n_components_range:
    kpca = KernelPCA(n_components=n_comp, 
                     kernel='rbf', gamma=0.1)
    X_kpca = kpca.fit_transform(X_train)
    
    # –û—Ü–µ–Ω–∫–∞ —á–µ—Ä–µ–∑ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
    from sklearn.linear_model import LogisticRegression
    lr = LogisticRegression()
    score = cross_val_score(lr, X_kpca, y_train, 
                            cv=5).mean()
    scores.append(score)

# –í—ã–±–∏—Ä–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ
best_n = n_components_range[np.argmax(scores)]
print(f"Best n_components: {best_n}")

# –ì—Ä–∞—Ñ–∏–∫
plt.plot(n_components_range, scores, 'o-')
plt.xlabel('n_components')
plt.ylabel('CV Score')
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 14. –î–µ—Ç–µ–∫—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π</h2>
    <pre><code># –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–∫–∏ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
kpca = KernelPCA(
    n_components=10,
    kernel='rbf',
    gamma=0.1,
    fit_inverse_transform=True
)

X_kpca = kpca.fit_transform(X)
X_reconstructed = kpca.inverse_transform(X_kpca)

# –û—à–∏–±–∫–∞ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
reconstruction_error = np.sum(
    (X - X_reconstructed) ** 2, axis=1
)

# –ê–Ω–æ–º–∞–ª–∏–∏ = –≤—ã—Å–æ–∫–∞—è –æ—à–∏–±–∫–∞
threshold = np.percentile(reconstruction_error, 95)
anomalies = reconstruction_error > threshold

print(f"Found {anomalies.sum()} anomalies")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
plt.hist(reconstruction_error, bins=50)
plt.axvline(threshold, color='r', 
            linestyle='--', label='Threshold')
plt.xlabel('Reconstruction Error')
plt.legend()
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 15. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ (StandardScaler)</li>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å —Ç–∏–ø —è–¥—Ä–∞ (–Ω–∞—á–∞—Ç—å —Å 'rbf')</li>
      <li>[ ] –ü–æ–¥–æ–±—Ä–∞—Ç—å gamma —á–µ—Ä–µ–∑ GridSearchCV</li>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å n_components (–Ω–∞—á–∞—Ç—å —Å 10-50)</li>
      <li>[ ] –î–ª—è –¥–µ–Ω–æ–∏–∑–∏–Ω–≥–∞: fit_inverse_transform=True</li>
      <li>[ ] –°—Ä–∞–≤–Ω–∏—Ç—å —Å –æ–±—ã—á–Ω—ã–º PCA</li>
      <li>[ ] –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã</li>
      <li>[ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ downstream –∑–∞–¥–∞—á–µ</li>
      <li>[ ] –û—Ü–µ–Ω–∏—Ç—å –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—É—é —Å–ª–æ–∂–Ω–æ—Å—Ç—å</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´Kernel PCA ‚Äî —ç—Ç–æ —É–º–Ω–∞—è –≤–µ—Ä—Å–∏—è –æ–±—ã—á–Ω–æ–≥–æ PCA, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞—Ö–æ–¥–∏—Ç —Å–ª–æ–∂–Ω—ã–µ, –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ 
      –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –ª–µ–∂–∞—Ç –Ω–∞ –∏–∑–æ–≥–Ω—É—Ç–æ–π –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ ‚Äî 
      –æ–±—ã—á–Ω—ã–π PCA —É–≤–∏–¥–∏—Ç —Ç–æ–ª—å–∫–æ –ø–ª–æ—Å–∫—É—é –ø—Ä–æ–µ–∫—Ü–∏—é, –∞ Kernel PCA —É—á—Ç–µ—Ç –∏–∑–≥–∏–±—ã –∏ 
      –Ω–∞–π–¥–µ—Ç –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ¬ª.
    </blockquote>
  </div>

</div>

</div>
</body>
</html>
