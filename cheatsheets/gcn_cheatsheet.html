<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>Graph Convolutional Networks (GCN) Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen { body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif; color: #333; background: #fafcff; padding: 10px; } }
    @media print { body { background: white; padding: 0; } @page { size: A4 landscape; margin: 10mm; } }
    .container { column-count: 3; column-gap: 20px; max-width: 100%; }
    .block { break-inside: avoid; margin-bottom: 1.2em; padding: 12px; background: white; border-radius: 6px; box-shadow: 0 1px 3px rgba(0,0,0,0.05); }
    h1 { font-size: 1.6em; font-weight: 700; color: #1a5fb4; text-align: center; margin: 0 0 8px; column-span: all; }
    .subtitle { text-align: center; color: #666; font-size: 0.9em; margin-bottom: 12px; column-span: all; }
    h2 { font-size: 1.15em; font-weight: 700; color: #1a5fb4; margin: 0 0 8px; padding-bottom: 4px; border-bottom: 1px solid #e0e7ff; }
    p, ul, ol { font-size: 0.92em; margin: 0.6em 0; }
    ul, ol { padding-left: 18px; }
    li { margin-bottom: 4px; }
    code { font-family: 'Consolas', 'Courier New', monospace; background-color: #f0f4ff; padding: 1px 4px; border-radius: 3px; font-size: 0.88em; }
    pre { background-color: #f0f4ff; padding: 8px; border-radius: 4px; overflow-x: auto; font-size: 0.84em; margin: 6px 0; }
    pre code { padding: 0; background: none; white-space: pre-wrap; }
    table { width: 100%; border-collapse: collapse; font-size: 0.82em; margin: 6px 0; }
    th { background-color: #e6f0ff; text-align: left; padding: 4px 6px; font-weight: 600; }
    td { padding: 4px 6px; border-bottom: 1px solid #f0f4ff; }
    tr:nth-child(even) { background-color: #f8fbff; }
    .good-vs-bad { display: flex; flex-direction: column; gap: 8px; }
    .good-vs-bad div { flex: 1; padding: 6px 8px; border-radius: 4px; }
    .good { background-color: #f0f9f4; border-left: 3px solid #2e8b57; }
    .bad { background-color: #fdf0f2; border-left: 3px solid #d32f2f; }
    .good h3, .bad h3 { margin: 0 0 4px; font-size: 1em; font-weight: 700; }
    .good ul, .bad ul { padding-left: 20px; margin: 0; }
    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }
    blockquote { font-style: italic; margin: 8px 0; padding: 6px 10px; background: #f8fbff; border-left: 2px solid #1a5fb4; font-size: 0.88em; }
    @media print { .container { column-gap: 12px; } .block { box-shadow: none; } code, pre, table { font-size: 0.78em; } h1 { font-size: 1.4em; } h2 { font-size: 1em; } }
  </style>
</head>
<body>
<div class="container">
  <h1>üï∏Ô∏è Graph Convolutional Networks (GCN)</h1>
  <div class="subtitle">üìÖ 4 —è–Ω–≤–∞—Ä—è 2026</div>
  <div class="block">
    <h2>üî∑ 1. –°—É—Ç—å GCN</h2>
    <ul>
      <li><strong>–ü—Ä–æ–±–ª–µ–º–∞</strong>: –ø—Ä–∏–º–µ–Ω–∏—Ç—å CNN –∫ –≥—Ä–∞—Ñ–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º</li>
      <li><strong>–ò–¥–µ—è</strong>: —Å–≤–µ—Ä—Ç–∫–∞ –æ—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –≥—Ä–∞—Ñ–∞ (—Å–æ—Å–µ–¥–∏ —É–∑–ª–æ–≤)</li>
      <li><strong>–ê–≥—Ä–µ–≥–∞—Ü–∏—è</strong>: —É–∑–µ–ª –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ—Å–µ–¥–µ–π</li>
      <li><strong>Spectral basis</strong>: –æ—Å–Ω–æ–≤–∞ - —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–∞—è —Ç–µ–æ—Ä–∏—è –≥—Ä–∞—Ñ–æ–≤</li>
      <li><strong>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è</strong>: —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏, –º–æ–ª–µ–∫—É–ª—ã, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, citation networks</li>
    </ul>
  <div class="block">
    <h2>üî∑ 2. –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ GCN</h2>
    <p><strong>–ë–∞–∑–æ–≤–∞—è —Ñ–æ—Ä–º—É–ª–∞ GCN —Å–ª–æ—è:</strong></p>
    <p>H^(l+1) = œÉ(DÃÉ^(-1/2) √É DÃÉ^(-1/2) H^(l) W^(l))</p>
    <p>–≥–¥–µ:</p>
    <ul>
      <li>H^(l) - –º–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —É–∑–ª–æ–≤ —Å–ª–æ—è l</li>
      <li>A - –º–∞—Ç—Ä–∏—Ü–∞ —Å–º–µ–∂–Ω–æ—Å—Ç–∏ –≥—Ä–∞—Ñ–∞</li>
      <li>√É = A + I (–¥–æ–±–∞–≤–ª—è–µ–º self-loops)</li>
      <li>DÃÉ - –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ —Å—Ç–µ–ø–µ–Ω–µ–π –¥–ª—è √É</li>
      <li>W^(l) - –≤–µ—Å–∞ —Å–ª–æ—è l</li>
      <li>œÉ - —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏</li>
    </ul>
  </div>
  <div class="block">
    <h2>üî∑ 3. Intuition</h2>
    <p><strong>–®–∞–≥–∏ GCN —Å–ª–æ—è:</strong></p>
    <ol>
      <li><strong>Aggregate</strong>: —Å–æ–±—Ä–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ—Å–µ–¥–µ–π</li>
      <li><strong>Transform</strong>: –ø—Ä–∏–º–µ–Ω–∏—Ç—å –ª–∏–Ω–µ–π–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ</li>
      <li><strong>Normalize</strong>: –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–æ —Å—Ç–µ–ø–µ–Ω–∏ —É–∑–ª–æ–≤</li>
      <li><strong>Activate</strong>: –ø—Ä–∏–º–µ–Ω–∏—Ç—å –Ω–µ–ª–∏–Ω–µ–π–Ω—É—é –∞–∫—Ç–∏–≤–∞—Ü–∏—é</li>
    </ol>
    <p><strong>–ê–Ω–∞–ª–æ–≥–∏—è —Å CNN:</strong></p>
    <ul>
      <li>CNN: —Å–æ—Å–µ–¥–∏ = –ø–∏–∫—Å–µ–ª–∏ –≤ –æ–∫–Ω–µ</li>
      <li>GCN: —Å–æ—Å–µ–¥–∏ = —Å–º–µ–∂–Ω—ã–µ —É–∑–ª—ã –≤ –≥—Ä–∞—Ñ–µ</li>
    </ul>
  </div>
  <div class="block">
    <h2>üî∑ 4. –ë–∞–∑–æ–≤—ã–π –∫–æ–¥ PyTorch</h2>
    <pre><code>import torch
import torch.nn as nn
import torch.nn.functional as F

class GCNLayer(nn.Module):
    def __init__(self, in_features, out_features):
        super().__init__()
        self.linear = nn.Linear(in_features, out_features)
    
    def forward(self, X, A):
        # X: [N, in_features], A: [N, N]
        # A –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–∞
        support = self.linear(X)  # [N, out_features]
        output = torch.mm(A, support)  # –∞–≥—Ä–µ–≥–∞—Ü–∏—è
        return output

class GCN(nn.Module):
    def __init__(self, nfeat, nhid, nclass):
        super().__init__()
        self.gc1 = GCNLayer(nfeat, nhid)
        self.gc2 = GCNLayer(nhid, nclass)
    
    def forward(self, x, adj):
        x = F.relu(self.gc1(x, adj))
        x = F.dropout(x, training=self.training)
        x = self.gc2(x, adj)
        return F.log_softmax(x, dim=1)</code></pre>
  </div>
  <div class="block">
    <h2>üî∑ 5. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è adjacency matrix</h2>
    <pre><code>def normalize_adj(adj):
    # –î–æ–±–∞–≤–∏—Ç—å self-loops
    adj = adj + torch.eye(adj.size(0))
    
    # –í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ç–µ–ø–µ–Ω–∏ —É–∑–ª–æ–≤
    degree = adj.sum(1)  # [N]
    
    # D^(-1/2)
    d_inv_sqrt = degree.pow(-0.5)
    d_inv_sqrt[d_inv_sqrt == float('inf')] = 0.
    
    # D^(-1/2) @ A @ D^(-1/2)
    d_mat_inv_sqrt = torch.diag(d_inv_sqrt)
    normalized_adj = d_mat_inv_sqrt @ adj @ d_mat_inv_sqrt
    
    return normalized_adj

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
adj_norm = normalize_adj(adj)
output = model(features, adj_norm)</code></pre>
  </div>
  <div class="block">
    <h2>üî∑ 6. PyTorch Geometric (PyG)</h2>
    <pre><code>import torch_geometric.nn as pyg_nn
from torch_geometric.data import Data

class GCN(torch.nn.Module):
    def __init__(self, num_features, num_classes):
        super().__init__()
        self.conv1 = pyg_nn.GCNConv(num_features, 16)
        self.conv2 = pyg_nn.GCNConv(16, num_classes)
    
    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, training=self.training)
        x = self.conv2(x, edge_index)
        
        return F.log_softmax(x, dim=1)

# –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∞
edge_index = torch.tensor([[0, 1, 1, 2],
                           [1, 0, 2, 1]], dtype=torch.long)
x = torch.tensor([[1], [2], [3]], dtype=torch.float)
data = Data(x=x, edge_index=edge_index)</code></pre>
  </div>
  <div class="block">
    <h2>üî∑ 7. –û–±—É—á–µ–Ω–∏–µ</h2>
    <pre><code>model = GCN(num_features, num_classes)
optimizer = torch.optim.Adam(
    model.parameters(),
    lr=0.01,
    weight_decay=5e-4
)

def train():
    model.train()
    optimizer.zero_grad()
    out = model(data)
    loss = F.nll_loss(out[train_mask], labels[train_mask])
    loss.backward()
    optimizer.step()
    return loss.item()

def test():
    model.eval()
    with torch.no_grad():
        out = model(data)
        pred = out.argmax(dim=1)
        correct = (pred[test_mask] == labels[test_mask]).sum()
        acc = int(correct) / int(test_mask.sum())
    return acc

for epoch in range(200):
    loss = train()
    if epoch % 10 == 0:
        acc = test()
        print(f'Epoch {epoch}, Loss: {loss:.4f}, Acc: {acc:.4f}')</code></pre>
  </div>
  <div class="block">
    <h2>üî∑ 8. –ó–∞–¥–∞—á–∏ –Ω–∞ –≥—Ä–∞—Ñ–∞—Ö</h2>
    <table>
      <tr><th>–ó–∞–¥–∞—á–∞</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th><th>–ü—Ä–∏–º–µ—Ä</th></tr>
      <tr><td><strong>Node classification</strong></td><td>–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —É–∑–ª—ã</td><td>–¢–µ–º–∞—Ç–∏–∫–∞ —Å—Ç–∞—Ç—å–∏ –≤ citation network</td></tr>
      <tr><td><strong>Link prediction</strong></td><td>–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Ä–µ–±—Ä–∞</td><td>Friend recommendation</td></tr>
      <tr><td><strong>Graph classification</strong></td><td>–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –≥—Ä–∞—Ñ</td><td>–°–≤–æ–π—Å—Ç–≤–∞ –º–æ–ª–µ–∫—É–ª—ã</td></tr>
      <tr><td><strong>Node regression</strong></td><td>–†–µ–≥—Ä–µ—Å—Å–∏—è –Ω–∞ —É–∑–ª–∞—Ö</td><td>–¶–µ–Ω–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏</td></tr>
    </table>
  </div>
  <div class="block">
    <h2>üî∑ 9. –í–∞—Ä–∏–∞–Ω—Ç—ã GCN</h2>
    <table>
      <tr><th>–ú–µ—Ç–æ–¥</th><th>–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å</th></tr>
      <tr><td><strong>GCN</strong></td><td>–ë–∞–∑–æ–≤—ã–π, —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥</td></tr>
      <tr><td><strong>GraphSAGE</strong></td><td>Sampling neighbors, inductive</td></tr>
      <tr><td><strong>GAT</strong></td><td>Attention –º–µ—Ö–∞–Ω–∏–∑–º –Ω–∞ –≥—Ä–∞—Ñ–µ</td></tr>
      <tr><td><strong>GIN</strong></td><td>Graph Isomorphism Network, –±–æ–ª–µ–µ –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω—ã–π</td></tr>
      <tr><td><strong>ChebNet</strong></td><td>Chebyshev polynomials, –ª–æ–∫–∞–ª—å–Ω–æ—Å—Ç—å</td></tr>
    </table>
  </div>
  <div class="block">
    <h2>üî∑ 10. Oversmoothing –ø—Ä–æ–±–ª–µ–º–∞</h2>
    <p><strong>–ü—Ä–æ–±–ª–µ–º–∞</strong>: –ø–æ—Å–ª–µ –º–Ω–æ–≥–∏—Ö —Å–ª–æ–µ–≤ –≤—Å–µ —É–∑–ª—ã —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏</p>
    <p><strong>–ü—Ä–∏—á–∏–Ω–∞</strong>: –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è —Å–º–µ—à–∏–≤–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏</p>
    <p><strong>–†–µ—à–µ–Ω–∏—è</strong>:</p>
    <ul>
      <li>–ú–µ–Ω—å—à–µ —Å–ª–æ–µ–≤ (2-3 –æ–±—ã—á–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ)</li>
      <li>Residual connections</li>
      <li>Jumping Knowledge Networks</li>
      <li>DropEdge: —Å–ª—É—á–∞–π–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ —Ä–µ–±–µ—Ä</li>
      <li>PairNorm: –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</li>
    </ul>
    <pre><code># Residual connections
class GCNResidual(nn.Module):
    def forward(self, x, adj):
        h = F.relu(self.gc1(x, adj))
        h = h + x  # residual
        h = self.gc2(h, adj)
        return h</code></pre>
  </div>
  <div class="block">
    <h2>üî∑ 11. –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –±–æ–ª—å—à–∏–µ –≥—Ä–∞—Ñ—ã</h2>
    <p><strong>–ü—Ä–æ–±–ª–µ–º—ã</strong>:</p>
    <ul>
      <li>–ü–æ–ª–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ —Å–º–µ–∂–Ω–æ—Å—Ç–∏: O(N¬≤) –ø–∞–º—è—Ç—å</li>
      <li>–ü–æ–ª–Ω—ã–π –≥—Ä–∞—Ñ: O(N¬≤) –≤—ã—á–∏—Å–ª–µ–Ω–∏—è</li>
    </ul>
    <p><strong>–†–µ—à–µ–Ω–∏—è</strong>:</p>
    <ul>
      <li><strong>Mini-batch training</strong>: GraphSAINT, ClusterGCN</li>
      <li><strong>Sampling</strong>: GraphSAGE (sample k neighbors)</li>
      <li><strong>Simplification</strong>: SGC (Simple Graph Convolution)</li>
      <li><strong>Sparse matrices</strong>: —Ö—Ä–∞–Ω–∏—Ç—å —Ç–æ–ª—å–∫–æ –Ω–µ–Ω—É–ª–µ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã</li>
    </ul>
  </div>
  <div class="block">
    <h2>üî∑ 12. –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è</h2>
    <ul>
      <li><strong>Dropout</strong>: –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö —É–∑–ª–æ–≤</li>
      <li><strong>DropEdge</strong>: —Å–ª—É—á–∞–π–Ω–æ —É–¥–∞–ª—è—Ç—å —Ä–µ–±—Ä–∞ –∫–∞–∂–¥—É—é —ç–ø–æ—Ö—É</li>
      <li><strong>Weight decay</strong>: L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤</li>
      <li><strong>Early stopping</strong>: –ø–æ validation accuracy</li>
    </ul>
    <pre><code>class GCNWithDropout(nn.Module):
    def forward(self, x, adj):
        x = F.dropout(x, p=0.5, training=self.training)
        x = F.relu(self.gc1(x, adj))
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.gc2(x, adj)
        return x</code></pre>
  </div>
  <div class="block">
    <h2>üî∑ 13. Inductive vs Transductive</h2>
    <p><strong>Transductive</strong>: –æ–±—É—á–µ–Ω–∏–µ –∏ —Ç–µ—Å—Ç –Ω–∞ —Ç–æ–º –∂–µ –≥—Ä–∞—Ñ–µ</p>
    <ul>
      <li>GCN –Ω—É–∂–Ω–æ –∑–Ω–∞—Ç—å –≤–µ—Å—å –≥—Ä–∞—Ñ</li>
      <li>–ù–æ–≤—ã–µ —É–∑–ª—ã —Ç—Ä–µ–±—É—é—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è</li>
      <li>–ü—Ä–∏–º–µ—Ä: node classification –Ω–∞ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –≥—Ä–∞—Ñ–µ</li>
    </ul>
    <p><strong>Inductive</strong>: –º–æ–∂–µ—Ç –æ–±–æ–±—â–∞—Ç—å –Ω–∞ –Ω–æ–≤—ã–µ –≥—Ä–∞—Ñ—ã</p>
    <ul>
      <li>GraphSAGE –∏—Å–ø–æ–ª—å–∑—É–µ—Ç sampling</li>
      <li>–ù–æ–≤—ã–µ —É–∑–ª—ã –±–µ–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è</li>
      <li>–ü—Ä–∏–º–µ—Ä: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –Ω–æ–≤—ã—Ö –º–æ–ª–µ–∫—É–ª</li>
    </ul>
  </div>
  <div class="block">
    <h2>üî∑ 14. DGL –±–∏–±–ª–∏–æ—Ç–µ–∫–∞</h2>
    <pre><code>import dgl
import dgl.nn as dglnn

class GCN(nn.Module):
    def __init__(self, in_feats, hidden, num_classes):
        super().__init__()
        self.conv1 = dglnn.GraphConv(in_feats, hidden)
        self.conv2 = dglnn.GraphConv(hidden, num_classes)
    
    def forward(self, g, features):
        h = self.conv1(g, features)
        h = F.relu(h)
        h = self.conv2(g, h)
        return h

# –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∞
g = dgl.graph(([0, 1, 2], [1, 2, 0]))
g.ndata['feat'] = torch.randn(3, 10)

model = GCN(10, 16, 7)
output = model(g, g.ndata['feat'])</code></pre>
  </div>
  <div class="block">
    <h2>üî∑ 15. –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GCN</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –•–æ—Ä–æ—à–æ –¥–ª—è</h3>
        <ul>
          <li>–î–∞–Ω–Ω—ã–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –≥—Ä–∞—Ñ–æ–º</li>
          <li>–í–∞–∂–Ω—ã –æ—Ç–Ω–æ—à–µ–Ω–∏—è –º–µ–∂–¥—É –æ–±—ä–µ–∫—Ç–∞–º–∏</li>
          <li>Citation networks, social networks</li>
          <li>–ú–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã</li>
          <li>–ù–µ–±–æ–ª—å—à–∏–µ-—Å—Ä–µ–¥–Ω–∏–µ –≥—Ä–∞—Ñ—ã (&lt;100K —É–∑–ª–æ–≤)</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ùå –ü–ª–æ—Ö–æ –¥–ª—è</h3>
        <ul>
          <li>–î–∞–Ω–Ω—ã–µ –Ω–µ –≥—Ä–∞—Ñ–æ–≤—ã–µ</li>
          <li>–û—á–µ–Ω—å –±–æ–ª—å—à–∏–µ –≥—Ä–∞—Ñ—ã (–±–µ–∑ sampling)</li>
          <li>Dynamic graphs (—á–∞—Å—Ç–æ –º–µ–Ω—è—é—â–∏–µ—Å—è)</li>
          <li>–ù—É–∂–Ω–∞ –≥–ª—É–±–æ–∫–∞—è –∏–µ—Ä–∞—Ä—Ö–∏—è (oversmoothing)</li>
        </ul>
      </div>
    </div>
  </div>
  <div class="block">
    <h2>üî∑ 16. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –ü—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ –≥—Ä–∞—Ñ (—É–∑–ª—ã, —Ä–µ–±—Ä–∞, –ø—Ä–∏–∑–Ω–∞–∫–∏)</li>
      <li>[ ] –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –º–∞—Ç—Ä–∏—Ü—É —Å–º–µ–∂–Ω–æ—Å—Ç–∏</li>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å —á–∏—Å–ª–æ —Å–ª–æ–µ–≤ (–æ–±—ã—á–Ω–æ 2-3)</li>
      <li>[ ] –î–æ–±–∞–≤–∏—Ç—å dropout –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏</li>
      <li>[ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å weight decay</li>
      <li>[ ] –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å oversmoothing (validation accuracy)</li>
      <li>[ ] –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å sampling –¥–ª—è –±–æ–ª—å—à–∏—Ö –≥—Ä–∞—Ñ–æ–≤</li>
      <li>[ ] –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å embeddings (t-SNE, UMAP)</li>
    </ul>
    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´GCN ‚Äî —ç—Ç–æ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –¥–ª—è –≥—Ä–∞—Ñ–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –û–Ω–∏ —É—á–∞—Ç—Å—è, –ø–µ—Ä–µ–¥–∞–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –º–µ–∂–¥—É —Å–≤—è–∑–∞–Ω–Ω—ã–º–∏ —É–∑–ª–∞–º–∏, –∫–∞–∫ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ —Å–ª—É—Ö–æ–≤ –≤ —Å–æ—Ü–∏–∞–ª—å–Ω–æ–π —Å–µ—Ç–∏. –ö–∞–∂–¥—ã–π —É–∑–µ–ª –æ–±–Ω–æ–≤–ª—è–µ—Ç —Å–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ, —É—á–∏—Ç—ã–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ—Ç —Å–≤–æ–∏—Ö —Å–æ—Å–µ–¥–µ–π¬ª.
    </blockquote>
  </div>
</div>
</div>
</body>
</html>