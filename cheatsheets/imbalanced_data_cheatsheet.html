<!DOCTYPE html>
<html lang="ru">
<head>
<meta charset="UTF-8">
<title>Imbalanced Data Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
<style>@media screen{body{font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Helvetica,Arial,sans-serif;color:#333;background:#fafcff;padding:10px}}@media print{body{background:white;padding:0}@page{size:A4 landscape;margin:10mm}}    .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }.block{break-inside:avoid;margin-bottom:1.2em;padding:12px;background:white;border-radius:6px;box-shadow:0 1px 3px rgba(0,0,0,0.05)}h1{font-size:1.6em;font-weight:700;color:#1a5fb4;text-align:center;margin:0 0 8px;column-span:all}.subtitle{text-align:center;color:#666;font-size:0.9em;margin-bottom:12px;column-span:all}h2{font-size:1.15em;font-weight:700;color:#1a5fb4;margin:0 0 8px;padding-bottom:4px;border-bottom:1px solid #e0e7ff}p,ul,ol{font-size:0.92em;margin:0.6em 0}ul,ol{padding-left:18px}li{margin-bottom:4px}code{font-family:'Consolas','Courier New',monospace;background-color:#f0f4ff;padding:1px 4px;border-radius:3px;font-size:0.88em}pre{background-color:#f0f4ff;padding:8px;border-radius:4px;overflow-x:auto;font-size:0.84em;margin:6px 0}pre code{padding:0;background:none;white-space:pre-wrap}table{width:100%;border-collapse:collapse;font-size:0.82em;margin:6px 0}th{background-color:#e6f0ff;text-align:left;padding:4px 6px;font-weight:600}td{padding:4px 6px;border-bottom:1px solid #f0f4ff}tr:nth-child(even){background-color:#f8fbff}.good-vs-bad{display:flex;flex-direction:column;gap:8px}.good-vs-bad div{flex:1;padding:6px 8px;border-radius:4px}.good{background-color:#f0f9f4;border-left:3px solid #2e8b57}.bad{background-color:#fdf0f2;border-left:3px solid #d32f2f}.good h3,.bad h3{margin:0 0 4px;font-size:1em;font-weight:700}.good ul,.bad ul{padding-left:20px;margin:0}.good li::before{content:"‚úÖ ";font-weight:bold}.bad li::before{content:"‚ùå ";font-weight:bold}blockquote{font-style:italic;margin:8px 0;padding:6px 10px;background:#f8fbff;border-left:2px solid #1a5fb4;font-size:0.88em}a{color:#1a5fb4;text-decoration:none}a:hover{text-decoration:underline}@media print{.container{column-gap:12px}.block{box-shadow:none}code,pre,table{font-size:0.78em}h1{font-size:1.4em}h2{font-size:1em}}</style>
</head>
<body>
<div class="container">
<h1>‚öñÔ∏è Imbalanced Data</h1>
<div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>
<div class="block">
<h2>üî∑ 1. –°—É—Ç—å –ø—Ä–æ–±–ª–µ–º—ã</h2>
<ul>
<li><strong>–î–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤</strong>: —Å–∏–ª—å–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ –≤ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –ø—Ä–∏–º–µ—Ä–æ–≤</li>
<li><strong>–ü—Ä–æ–±–ª–µ–º–∞</strong>: –º–æ–¥–µ–ª—å –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç minority class</li>
<li><strong>–ü—Ä–∏–º–µ—Ä</strong>: fraud detection (99% –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö, 1% fraud)</li>
<li><strong>–†–µ—à–µ–Ω–∏–µ</strong>: —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ –∏ –º–µ—Ç—Ä–∏–∫–∏</li>
</ul>
<div class="block">
<h2>üî∑ 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞</h2>
<pre><code>import pandas as pd

# –ü–æ–¥—Å—á–µ—Ç –∫–ª–∞—Å—Å–æ–≤
class_counts = pd.Series(y).value_counts()
print(class_counts)
print(f"–°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ: {class_counts[0]/class_counts[1]:.2f}:1")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
import matplotlib.pyplot as plt
class_counts.plot(kind='bar')
plt.title('Class Distribution')
plt.xlabel('Class')
plt.ylabel('Count')
plt.show()

# –ü—Ä–∞–≤–∏–ª–æ: –¥–∏—Å–±–∞–ª–∞–Ω—Å > 10:1 —Ç—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è</code></pre>
</div>
<div class="block">
<h2>üî∑ 3. –ú–µ—Ç–æ–¥ 1: Class Weights</h2>
<pre><code>from sklearn.ensemble import RandomForestClassifier

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –≤–µ—Å–∞
model = RandomForestClassifier(
    class_weight='balanced',  # –∞–≤—Ç–æ–≤–µ—Å–∞
    random_state=42
)
model.fit(X_train, y_train)

# –†—É—á–Ω—ã–µ –≤–µ—Å–∞
from sklearn.utils.class_weight import compute_class_weight
import numpy as np

class_weights = compute_class_weight(
    'balanced',
    classes=np.unique(y_train),
    y=y_train
)
weights_dict = dict(enumerate(class_weights))

model = RandomForestClassifier(
    class_weight=weights_dict
)
model.fit(X_train, y_train)</code></pre>
</div>
<div class="block">
<h2>üî∑ 4. –ú–µ—Ç–æ–¥ 2: Oversampling (SMOTE)</h2>
<pre><code># –£—Å—Ç–∞–Ω–æ–≤–∫–∞
# pip install imbalanced-learn

from imblearn.over_sampling import SMOTE

# SMOTE: —Å–æ–∑–¥–∞–µ—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

# –ü—Ä–æ–≤–µ—Ä–∫–∞
print(f"Original: {pd.Series(y_train).value_counts()}")
print(f"After SMOTE: {pd.Series(y_resampled).value_counts()}")

# –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
model = RandomForestClassifier()
model.fit(X_resampled, y_resampled)

# –í–∞—Ä–∏–∞–Ω—Ç—ã SMOTE
from imblearn.over_sampling import ADASYN, BorderlineSMOTE

# ADASYN - –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π
adasyn = ADASYN(random_state=42)
X_res, y_res = adasyn.fit_resample(X_train, y_train)

# Borderline SMOTE - —Ñ–æ–∫—É—Å –Ω–∞ –≥—Ä–∞–Ω–∏—Ü–µ
bl_smote = BorderlineSMOTE(random_state=42)
X_res, y_res = bl_smote.fit_resample(X_train, y_train)</code></pre>
</div>
<div class="block">
<h2>üî∑ 5. –ú–µ—Ç–æ–¥ 3: Undersampling</h2>
<pre><code>from imblearn.under_sampling import RandomUnderSampler

# –°–ª—É—á–∞–π–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ majority class
rus = RandomUnderSampler(random_state=42)
X_resampled, y_resampled = rus.fit_resample(X_train, y_train)

# –¢–æ–º–µ–∫ –ª–∏–Ω–∫–∏ (—É–±–∏—Ä–∞–µ—Ç –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è)
from imblearn.under_sampling import TomekLinks

tl = TomekLinks()
X_res, y_res = tl.fit_resample(X_train, y_train)

# NearMiss (—É–º–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ)
from imblearn.under_sampling import NearMiss

nm = NearMiss(version=1)
X_res, y_res = nm.fit_resample(X_train, y_train)</code></pre>
</div>
<div class="block">
<h2>üî∑ 6. –ú–µ—Ç–æ–¥ 4: –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π</h2>
<pre><code>from imblearn.combine import SMOTETomek, SMOTEENN

# SMOTE + Tomek Links
smt = SMOTETomek(random_state=42)
X_resampled, y_resampled = smt.fit_resample(X_train, y_train)

# SMOTE + Edited Nearest Neighbours
smenn = SMOTEENN(random_state=42)
X_res, y_res = smenn.fit_resample(X_train, y_train)

# –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
# - –°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã (SMOTE)
# - –£–±–∏—Ä–∞–µ—Ç —à—É–º (Tomek/ENN)</code></pre>
</div>
<div class="block">
<h2>üî∑ 7. –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏</h2>
<pre><code>from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    roc_auc_score,
    precision_recall_curve,
    f1_score
)

# –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ accuracy!
# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ:

# 1. F1-score
f1 = f1_score(y_test, y_pred)

# 2. ROC AUC
auc = roc_auc_score(y_test, y_proba)

# 3. Precision & Recall
print(classification_report(y_test, y_pred))

# 4. Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print(cm)

# 5. PR AUC (–ª—É—á—à–µ ROC –¥–ª—è –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞)
from sklearn.metrics import average_precision_score
pr_auc = average_precision_score(y_test, y_proba)</code></pre>
</div>
<div class="block">
<h2>üî∑ 8. Pipeline —Å SMOTE</h2>
<pre><code>from imblearn.pipeline import Pipeline as ImbPipeline
from sklearn.preprocessing import StandardScaler

# Pipeline —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π
pipeline = ImbPipeline([
    ('scaler', StandardScaler()),
    ('smote', SMOTE(random_state=42)),
    ('classifier', RandomForestClassifier(random_state=42))
])

# –û–±—É—á–µ–Ω–∏–µ
pipeline.fit(X_train, y_train)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
y_pred = pipeline.predict(X_test)

# –í–ê–ñ–ù–û: SMOTE —Ç–æ–ª—å–∫–æ –Ω–∞ train!
# –ù–ï –ø—Ä–∏–º–µ–Ω—è—Ç—å –Ω–∞ test!</code></pre>
</div>
<div class="block">
<h2>üî∑ 9. Ensemble –º–µ—Ç–æ–¥—ã</h2>
<pre><code>from imblearn.ensemble import (
    BalancedRandomForestClassifier,
    EasyEnsembleClassifier,
    BalancedBaggingClassifier
)

# Balanced Random Forest
brf = BalancedRandomForestClassifier(
    n_estimators=100,
    random_state=42
)
brf.fit(X_train, y_train)

# Easy Ensemble (AdaBoost + undersampling)
eec = EasyEnsembleClassifier(
    n_estimators=10,
    random_state=42
)
eec.fit(X_train, y_train)

# Balanced Bagging
bbc = BalancedBaggingClassifier(
    n_estimators=10,
    random_state=42
)
bbc.fit(X_train, y_train)</code></pre>
</div>
<div class="block">
<h2>üî∑ 10. Threshold Moving</h2>
<pre><code># –ò–∑–º–µ–Ω–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
from sklearn.metrics import precision_recall_curve

# –ü–æ–ª—É—á–∏—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
y_proba = model.predict_proba(X_test)[:, 1]

# –ù–∞–π—Ç–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
precision, recall, thresholds = precision_recall_curve(y_test, y_proba)

# F1-–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
f1_scores = 2 * (precision * recall) / (precision + recall)
optimal_idx = np.argmax(f1_scores)
optimal_threshold = thresholds[optimal_idx]

print(f"Optimal threshold: {optimal_threshold:.3f}")

# –ü—Ä–∏–º–µ–Ω–∏—Ç—å –ø–æ—Ä–æ–≥
y_pred_adjusted = (y_proba >= optimal_threshold).astype(int)</code></pre>
</div>
<div class="block">
<h2>üî∑ 11. –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å</h2>
<div class="good-vs-bad">
<div class="good">
<h3>‚úÖ –•–æ—Ä–æ—à–æ</h3>
<ul>
<li>–î–∏—Å–±–∞–ª–∞–Ω—Å > 10:1</li>
<li>–í–∞–∂–µ–Ω minority class</li>
<li>Fraud detection</li>
<li>Medical diagnosis</li>
<li>Churn prediction</li>
</ul>
</div>
<div class="bad">
<h3>‚ùå –ü–ª–æ—Ö–æ</h3>
<ul>
<li>–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ</li>
<li>–ú–∞–ª—ã–π –¥–∞—Ç–∞—Å–µ—Ç (<1000)</li>
<li>–ü—Ä–∏–º–µ–Ω—è—Ç—å SMOTE –Ω–∞ test</li>
<li>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ accuracy</li>
</ul>
</div>
</div>
</div>
<div class="block">
<h2>üî∑ 12. –ß–µ–∫-–ª–∏—Å—Ç</h2>
<ul>
<li>[ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤</li>
<li>[ ] –í—ã–±—Ä–∞—Ç—å –º–µ—Ç–æ–¥: SMOTE, weights, ensemble</li>
<li>[ ] –ù–ï –ø—Ä–∏–º–µ–Ω—è—Ç—å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫—É –Ω–∞ test</li>
<li>[ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (F1, AUC)</li>
<li>[ ] –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å threshold moving</li>
<li>[ ] –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è —Å stratified split</li>
<li>[ ] –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å Precision-Recall –∫—Ä–∏–≤—É—é</li>
</ul>
<blockquote>
¬´–ü—Ä–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ –∫–ª–∞—Å—Å–æ–≤ –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å 99% accuracy, –ø—Ä–æ—Å—Ç–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—è majority class –≤—Å–µ–≥–¥–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ F1-score –∏ ROC AUC –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ minority class¬ª.
</blockquote>
</div>
<div class="block">
<h2>üîó –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏</h2>
<ul>
<li><a href="https://imbalanced-learn.org/" target="_blank">üìö Imbalanced-learn –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è</a></li>
<li><a href="https://github.com/scikit-learn-contrib/imbalanced-learn" target="_blank">üíª GitHub —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π</a></li>
<li><a href="https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/" target="_blank">üìñ SMOTE Tutorial</a></li>
<li><a href="https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets" target="_blank">üéØ Kaggle: Resampling Strategies</a></li>
<li><a href="https://arxiv.org/abs/1106.1813" target="_blank">üìÑ SMOTE –Ω–∞—É—á–Ω–∞—è —Å—Ç–∞—Ç—å—è</a></li>
</ul>
</div>
</div>
</div>
</body>
</html>
