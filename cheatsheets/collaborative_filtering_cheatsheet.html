<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>–ö–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

    .container {
      column-count: 3;
      column-gap: 20px;
      max-width: 100%;
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üé¨ –ö–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –ß—Ç–æ —Ç–∞–∫–æ–µ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è?</h2>
    <ul>
      <li><strong>–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ</strong>: –º–µ—Ç–æ–¥ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–≤–µ–¥–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π</li>
      <li><strong>–ò–¥–µ—è</strong>: –ø–æ—Ö–æ–∂–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –ª—é–±—è—Ç –ø–æ—Ö–æ–∂–∏–µ –≤–µ—â–∏</li>
      <li><strong>–î–∞–Ω–Ω—ã–µ</strong>: –º–∞—Ç—Ä–∏—Ü–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å-—Ç–æ–≤–∞—Ä —Å —Ä–µ–π—Ç–∏–Ω–≥–∞–º–∏</li>
      <li><strong>–¢–∏–ø—ã</strong>: User-based, Item-based, Model-based</li>
      <li><strong>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</strong>: Netflix, Amazon, Spotify</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 2. –¢–∏–ø—ã –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏</h2>
    <table>
      <tr><th>–¢–∏–ø</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th><th>–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å</th></tr>
      <tr>
        <td><strong>User-based</strong></td>
        <td>–ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π</td>
        <td>–ú–∞–ª–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –º–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤</td>
      </tr>
      <tr>
        <td><strong>Item-based</strong></td>
        <td>–ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏–µ —Ç–æ–≤–∞—Ä—ã</td>
        <td>–ú–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –º–∞–ª–æ —Ç–æ–≤–∞—Ä–æ–≤</td>
      </tr>
      <tr>
        <td><strong>Model-based</strong></td>
        <td>–ú–∞—Ç—Ä–∏—á–Ω–∞—è —Ñ–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è (SVD, ALS)</td>
        <td>–ë–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ, –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å</td>
      </tr>
      <tr>
        <td><strong>Memory-based</strong></td>
        <td>–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Å—é –º–∞—Ç—Ä–∏—Ü—É</td>
        <td>–ú–∞–ª—ã–µ –¥–∞–Ω–Ω—ã–µ, –ø—Ä–æ—Å—Ç–æ—Ç–∞</td>
      </tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 3. User-based CF</h2>
    <p>–ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç —Ç–æ, —á—Ç–æ –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å –∏–º:</p>
    <pre><code>import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# –ú–∞—Ç—Ä–∏—Ü–∞ user-item (–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ x —Ç–æ–≤–∞—Ä—ã)
# –°—Ç—Ä–æ–∫–∏ - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏, —Å—Ç–æ–ª–±—Ü—ã - —Ç–æ–≤–∞—Ä—ã
ratings = np.array([
    [5, 3, 0, 1],
    [4, 0, 0, 1],
    [1, 1, 0, 5],
    [0, 1, 5, 4]
])

# –í—ã—á–∏—Å–ª—è–µ–º similarity –º–µ–∂–¥—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏
user_similarity = cosine_similarity(ratings)

# –î–ª—è user 0 –Ω–∞—Ö–æ–¥–∏–º –ø–æ—Ö–æ–∂–∏—Ö
user_id = 0
similar_users = np.argsort(user_similarity[user_id])[::-1][1:]

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∞ –¥–ª—è item 2
item_id = 2
numerator = 0
denominator = 0

for similar_user in similar_users:
    if ratings[similar_user, item_id] > 0:
        sim = user_similarity[user_id, similar_user]
        numerator += sim * ratings[similar_user, item_id]
        denominator += sim

predicted_rating = numerator / denominator if denominator > 0 else 0
print(f"Predicted rating: {predicted_rating:.2f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. Item-based CF</h2>
    <p>–ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏–µ —Ç–æ–≤–∞—Ä—ã –Ω–∞ —Ç–µ, —á—Ç–æ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é:</p>
    <pre><code>import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# –¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä—É–µ–º –¥–ª—è item similarity
# –°—Ç—Ä–æ–∫–∏ —Ç–µ–ø–µ—Ä—å —Ç–æ–≤–∞—Ä—ã, —Å—Ç–æ–ª–±—Ü—ã - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏
ratings_T = ratings.T

# Similarity –º–µ–∂–¥—É —Ç–æ–≤–∞—Ä–∞–º–∏
item_similarity = cosine_similarity(ratings_T)

def predict_item_based(user_id, item_id, ratings, item_sim):
    # –ù–∞—Ö–æ–¥–∏–º —Ç–æ–≤–∞—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ user —É–∂–µ –æ—Ü–µ–Ω–∏–ª
    rated_items = np.where(ratings[user_id] > 0)[0]
    
    numerator = 0
    denominator = 0
    
    for rated_item in rated_items:
        if rated_item != item_id:
            sim = item_sim[item_id, rated_item]
            numerator += sim * ratings[user_id, rated_item]
            denominator += abs(sim)
    
    return numerator / denominator if denominator > 0 else 0

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
prediction = predict_item_based(0, 2, ratings, item_similarity)
print(f"Predicted rating: {prediction:.2f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. –ú–µ—Ç—Ä–∏–∫–∏ —Å—Ö–æ–¥—Å—Ç–≤–∞</h2>
    <table>
      <tr><th>–ú–µ—Ç—Ä–∏–∫–∞</th><th>–§–æ—Ä–º—É–ª–∞/–û–ø–∏—Å–∞–Ω–∏–µ</th><th>–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å</th></tr>
      <tr>
        <td><strong>Cosine</strong></td>
        <td>cos(Œ∏) = A¬∑B / (||A|| ||B||)</td>
        <td>–°–∞–º–∞—è –ø–æ–ø—É–ª—è—Ä–Ω–∞—è</td>
      </tr>
      <tr>
        <td><strong>Pearson</strong></td>
        <td>–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ü–∏—Ä—Å–æ–Ω–∞</td>
        <td>–£—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è</td>
      </tr>
      <tr>
        <td><strong>Jaccard</strong></td>
        <td>|A ‚à© B| / |A ‚à™ B|</td>
        <td>–ë–∏–Ω–∞—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ</td>
      </tr>
      <tr>
        <td><strong>Euclidean</strong></td>
        <td>sqrt(Œ£(a-b)¬≤)</td>
        <td>–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ</td>
      </tr>
    </table>
    <pre><code>from sklearn.metrics.pairwise import (
    cosine_similarity,
    euclidean_distances
)
from scipy.stats import pearsonr

# Cosine similarity
cos_sim = cosine_similarity(ratings)

# Pearson correlation
def pearson_similarity(ratings):
    n_users = ratings.shape[0]
    sim_matrix = np.zeros((n_users, n_users))
    
    for i in range(n_users):
        for j in range(n_users):
            if i != j:
                # –û–±—â–∏–µ –æ—Ü–µ–Ω–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã
                mask = (ratings[i] > 0) & (ratings[j] > 0)
                if mask.sum() > 0:
                    corr, _ = pearsonr(ratings[i][mask], 
                                       ratings[j][mask])
                    sim_matrix[i,j] = corr
    
    return sim_matrix</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ Surprise</h2>
    <p>–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:</p>
    <pre><code># –£—Å—Ç–∞–Ω–æ–≤–∫–∞
# pip install scikit-surprise

from surprise import Dataset, Reader
from surprise import KNNBasic, SVD
from surprise.model_selection import cross_validate
import pandas as pd

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
# –§–æ—Ä–º–∞—Ç: user_id, item_id, rating
df = pd.DataFrame({
    'user_id': [1, 1, 1, 2, 2, 3, 3, 3],
    'item_id': [1, 2, 3, 1, 3, 2, 3, 4],
    'rating': [5, 3, 4, 4, 5, 2, 4, 3]
})

reader = Reader(rating_scale=(1, 5))
data = Dataset.load_from_df(df[['user_id', 'item_id', 'rating']], 
                             reader)

# User-based CF
sim_options = {
    'name': 'cosine',
    'user_based': True
}
algo = KNNBasic(sim_options=sim_options)

# –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5)

# –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
trainset = data.build_full_trainset()
algo.fit(trainset)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
user_id = 1
item_id = 4
prediction = algo.predict(user_id, item_id)
print(f"Predicted rating: {prediction.est:.2f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. Item-based —Å Surprise</h2>
    <pre><code>from surprise import KNNBasic

# Item-based CF
sim_options = {
    'name': 'cosine',
    'user_based': False  # Item-based
}

algo = KNNBasic(k=40, sim_options=sim_options)
algo.fit(trainset)

# –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Ö–æ–∂–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤
inner_id = trainset.to_inner_iid(item_id)
neighbors = algo.get_neighbors(inner_id, k=10)

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –æ–±—Ä–∞—Ç–Ω–æ –≤ –≤–Ω–µ—à–Ω–∏–µ ID
similar_items = [trainset.to_raw_iid(inner_id) 
                 for inner_id in neighbors]
print(f"Similar items to {item_id}: {similar_items}")

# KNNWithMeans - —É—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ä–µ–¥–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∏
from surprise import KNNWithMeans

algo = KNNWithMeans(k=40, sim_options=sim_options)
algo.fit(trainset)

# KNNBaseline - —Å baseline estimates
from surprise import KNNBaseline

algo = KNNBaseline(k=40, sim_options=sim_options)
algo.fit(trainset)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. –ú–∞—Ç—Ä–∏—á–Ω–∞—è —Ñ–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è (SVD)</h2>
    <p>Model-based –ø–æ–¥—Ö–æ–¥, —Ä–∞–∑–ª–∞–≥–∞–µ—Ç –º–∞—Ç—Ä–∏—Ü—É –Ω–∞ –ª–∞—Ç–µ–Ω—Ç–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã:</p>
    <pre><code>from surprise import SVD
from surprise.model_selection import GridSearchCV

# SVD (Singular Value Decomposition)
algo = SVD(
    n_factors=100,     # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∞—Ç–µ–Ω—Ç–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤
    n_epochs=20,       # —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è
    lr_all=0.005,      # learning rate
    reg_all=0.02       # —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
)

algo.fit(trainset)
prediction = algo.predict(user_id, item_id)

# Grid Search –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
param_grid = {
    'n_factors': [50, 100, 150],
    'n_epochs': [20, 30],
    'lr_all': [0.002, 0.005],
    'reg_all': [0.02, 0.1]
}

gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)
gs.fit(data)

print(f"Best RMSE: {gs.best_score['rmse']:.3f}")
print(f"Best params: {gs.best_params['rmse']}")

# –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å
best_algo = gs.best_estimator['rmse']
best_algo.fit(trainset)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. SVD++ –∏ NMF</h2>
    <pre><code>from surprise import SVDpp, NMF

# SVD++ - —É—á–∏—Ç—ã–≤–∞–µ—Ç implicit feedback
svdpp = SVDpp(
    n_factors=20,
    n_epochs=20,
    lr_all=0.007,
    reg_all=0.02
)
svdpp.fit(trainset)

# NMF (Non-negative Matrix Factorization)
# –í—Å–µ —Ñ–∞–∫—Ç–æ—Ä—ã –Ω–µ–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ - –ª—É—á—à–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
nmf = NMF(
    n_factors=15,
    n_epochs=50,
    biased=True
)
nmf.fit(trainset)

# –ü–æ–ª—É—á–µ–Ω–∏–µ –ª–∞—Ç–µ–Ω—Ç–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤
user_factors = nmf.pu  # user factors
item_factors = nmf.qi  # item factors

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤—Ä—É—á–Ω—É—é
user_inner_id = trainset.to_inner_uid(user_id)
item_inner_id = trainset.to_inner_iid(item_id)

predicted = (user_factors[user_inner_id] @ 
             item_factors[item_inner_id].T)
print(f"Manual prediction: {predicted:.2f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. Implicit Feedback</h2>
    <p>–ö–æ–≥–¥–∞ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ —Ñ–∞–∫—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è (–∫–ª–∏–∫–∏, –ø—Ä–æ—Å–º–æ—Ç—Ä—ã), –±–µ–∑ —è–≤–Ω—ã—Ö —Ä–µ–π—Ç–∏–Ω–≥–æ–≤:</p>
    <pre><code># pip install implicit

import implicit
from scipy.sparse import csr_matrix

# –ú–∞—Ç—Ä–∏—Ü–∞ user-item (—Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–∞—è)
# –ó–Ω–∞—á–µ–Ω–∏—è - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π
user_items = csr_matrix(ratings)

# ALS (Alternating Least Squares)
model = implicit.als.AlternatingLeastSquares(
    factors=50,
    regularization=0.01,
    iterations=15
)

# –û–±—É—á–µ–Ω–∏–µ (—Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä—É–µ–º –¥–ª—è implicit)
model.fit(user_items.T)

# –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
user_id = 0
recommendations = model.recommend(
    user_id, 
    user_items[user_id],
    N=10,  # —Ç–æ–ø-10
    filter_already_liked_items=True
)

for item_id, score in recommendations:
    print(f"Item {item_id}: score {score:.3f}")

# –ü–æ—Ö–æ–∂–∏–µ —Ç–æ–≤–∞—Ä—ã
similar_items = model.similar_items(item_id, N=10)

# BM25 –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
model = implicit.bm25.BM25Recommender(K1=100, B=0.8)
model.fit(user_items.T)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. LightFM - –≥–∏–±—Ä–∏–¥–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏</h2>
    <pre><code># pip install lightfm

from lightfm import LightFM
from lightfm.data import Dataset
from lightfm.evaluation import precision_at_k

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
dataset = Dataset()
dataset.fit(users=user_ids, items=item_ids)

# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π
(interactions, weights) = dataset.build_interactions(
    [(user, item, rating) for user, item, rating in data]
)

# –ú–æ–¥–µ–ª—å (–∫–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç CF –∏ content-based)
model = LightFM(
    loss='warp',  # WARP loss –¥–ª—è implicit
    no_components=30
)

# –û–±—É—á–µ–Ω–∏–µ
model.fit(interactions, epochs=10, num_threads=4)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
scores = model.predict(user_ids, item_ids)

# –° features (–≥–∏–±—Ä–∏–¥–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è)
# User features
user_features_matrix = dataset.build_user_features([
    (user_id, ['age:25-34', 'gender:M'])
    for user_id in user_ids
])

# Item features
item_features_matrix = dataset.build_item_features([
    (item_id, ['category:electronics', 'brand:samsung'])
    for item_id in item_ids
])

model.fit(
    interactions,
    user_features=user_features_matrix,
    item_features=item_features_matrix,
    epochs=10
)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 12. –ü—Ä–æ–±–ª–µ–º–∞ —Ö–æ–ª–æ–¥–Ω–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞</h2>
    <p>–ù–æ–≤—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –∏–ª–∏ —Ç–æ–≤–∞—Ä—ã –±–µ–∑ –∏—Å—Ç–æ—Ä–∏–∏:</p>
    <ul>
      <li><strong>–ù–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å</strong>:
        <ul>
          <li>–ó–∞–ø—Ä–æ—Å–∏—Ç—å –ø–µ—Ä–≤–∏—á–Ω—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è</li>
          <li>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ</li>
          <li>–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã</li>
          <li>–ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥ (content-based)</li>
        </ul>
      </li>
      <li><strong>–ù–æ–≤—ã–π —Ç–æ–≤–∞—Ä</strong>:
        <ul>
          <li>Content-based —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è</li>
          <li>–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø–æ—Ö–æ–∂–∏–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º</li>
          <li>A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ</li>
          <li>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä–∞</li>
        </ul>
      </li>
    </ul>
    <pre><code># –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥
def hybrid_recommendation(user_id, n=10):
    # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–æ–≤—ã–π
    if user_history[user_id].sum() < 3:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ
        popular = ratings.sum(axis=0).argsort()[::-1]
        return popular[:n]
    else:
        # –ö–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
        return collaborative_filter(user_id, n)

# –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã –∫–∞–∫ baseline
def popular_items(ratings, n=10):
    item_counts = (ratings > 0).sum(axis=0)
    popular = item_counts.argsort()[::-1]
    return popular[:n]</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 13. –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏</h2>
    <pre><code>from surprise import accuracy
from surprise.model_selection import train_test_split

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
trainset, testset = train_test_split(data, test_size=0.2)

algo.fit(trainset)
predictions = algo.test(testset)

# RMSE –∏ MAE
rmse = accuracy.rmse(predictions)
mae = accuracy.mae(predictions)

# Precision@K –∏ Recall@K
from collections import defaultdict

def precision_recall_at_k(predictions, k=10, threshold=3.5):
    user_est_true = defaultdict(list)
    for uid, _, true_r, est, _ in predictions:
        user_est_true[uid].append((est, true_r))
    
    precisions = {}
    recalls = {}
    
    for uid, user_ratings in user_est_true.items():
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–º—É —Ä–µ–π—Ç–∏–Ω–≥—É
        user_ratings.sort(key=lambda x: x[0], reverse=True)
        
        # –¢–æ–ø-K –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)
        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])
        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))
                              for (est, true_r) in user_ratings[:k])
        
        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0
        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0
    
    return precisions, recalls

precisions, recalls = precision_recall_at_k(predictions, k=10)
print(f"Precision@10: {sum(precisions.values())/len(precisions):.3f}")
print(f"Recall@10: {sum(recalls.values())/len(recalls):.3f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 14. Diversity –∏ Serendipity</h2>
    <p>–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:</p>
    <pre><code>import numpy as np

def diversity(recommendations, item_similarity):
    """–°—Ä–µ–¥–Ω–µ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–º–∏ —Ç–æ–≤–∞—Ä–∞–º–∏"""
    n = len(recommendations)
    if n <= 1:
        return 0
    
    total_dissim = 0
    count = 0
    
    for i in range(n):
        for j in range(i+1, n):
            # 1 - similarity = dissimilarity
            dissim = 1 - item_similarity[recommendations[i], 
                                         recommendations[j]]
            total_dissim += dissim
            count += 1
    
    return total_dissim / count

def serendipity(recommendations, user_profile, item_similarity):
    """–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–æ—Å—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
    serendipity_score = 0
    
    for rec_item in recommendations:
        # –ù–∞—Å–∫–æ–ª—å–∫–æ —Ç–æ–≤–∞—Ä –Ω–µ–ø–æ—Ö–æ–∂ –Ω–∞ —Ç–æ, —á—Ç–æ user —É–∂–µ –≤–∏–¥–µ–ª
        max_sim = max([item_similarity[rec_item, profile_item] 
                       for profile_item in user_profile])
        serendipity_score += (1 - max_sim)
    
    return serendipity_score / len(recommendations)

# –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ accuracy –∏ diversity
def rerank_for_diversity(recommendations, scores, item_sim, lambda_=0.5):
    """MMR (Maximal Marginal Relevance) reranking"""
    reranked = []
    candidates = list(recommendations)
    
    # –ü–µ—Ä–≤—ã–π - —Å–∞–º—ã–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π
    best_idx = np.argmax([scores[i] for i in candidates])
    reranked.append(candidates.pop(best_idx))
    
    while candidates:
        mmr_scores = []
        for item in candidates:
            # Relevance - lambda * max_similarity_to_selected
            relevance = scores[item]
            max_sim = max([item_sim[item, selected] 
                          for selected in reranked])
            mmr = lambda_ * relevance - (1 - lambda_) * max_sim
            mmr_scores.append(mmr)
        
        best_idx = np.argmax(mmr_scores)
        reranked.append(candidates.pop(best_idx))
    
    return reranked</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 15. –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</h2>
    <ul>
      <li><strong>–†–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã–µ –º–∞—Ç—Ä–∏—Ü—ã</strong>: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ scipy.sparse</li>
      <li><strong>–ü—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–∏—è</strong>: –∫—ç—à–∏—Ä—É–π—Ç–µ similarity matrices</li>
      <li><strong>Approximate NN</strong>: Annoy, FAISS –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞</li>
      <li><strong>–ë–∞—Ç—á–∏–Ω–≥</strong>: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–π—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –±–∞—Ç—á–∞–º–∏</li>
      <li><strong>Sampling</strong>: negative sampling –¥–ª—è implicit feedback</li>
      <li><strong>Incremental updates</strong>: –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è</li>
    </ul>
    <pre><code># FAISS –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö
# pip install faiss-cpu

import faiss
import numpy as np

# –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
dimension = item_embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(item_embeddings.astype('float32'))

# –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ k –±–ª–∏–∂–∞–π—à–∏—Ö
k = 10
distances, indices = index.search(
    query_embedding.reshape(1, -1).astype('float32'), 
    k
)

# Approximate search (–±—ã—Å—Ç—Ä–µ–µ –Ω–∞ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö)
index = faiss.IndexIVFFlat(
    faiss.IndexFlatL2(dimension), 
    dimension, 
    100  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
)
index.train(item_embeddings.astype('float32'))
index.add(item_embeddings.astype('float32'))
index.nprobe = 10  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞

distances, indices = index.search(query_embedding, k)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 16. –û–Ω–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏–µ</h2>
    <pre><code># –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
class IncrementalCF:
    def __init__(self, n_factors=20, learning_rate=0.01):
        self.n_factors = n_factors
        self.lr = learning_rate
        self.user_factors = {}
        self.item_factors = {}
    
    def update(self, user_id, item_id, rating):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –µ—Å–ª–∏ –Ω–æ–≤—ã–π
        if user_id not in self.user_factors:
            self.user_factors[user_id] = np.random.randn(self.n_factors) * 0.01
        if item_id not in self.item_factors:
            self.item_factors[item_id] = np.random.randn(self.n_factors) * 0.01
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        pred = self.user_factors[user_id] @ self.item_factors[item_id]
        error = rating - pred
        
        # SGD update
        user_update = error * self.item_factors[item_id]
        item_update = error * self.user_factors[user_id]
        
        self.user_factors[user_id] += self.lr * user_update
        self.item_factors[item_id] += self.lr * item_update
    
    def predict(self, user_id, item_id):
        if user_id not in self.user_factors or item_id not in self.item_factors:
            return 0  # –∏–ª–∏ —Å—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥
        return self.user_factors[user_id] @ self.item_factors[item_id]

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
model = IncrementalCF()
for user, item, rating in new_interactions:
    model.update(user, item, rating)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 17. –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏</h2>
    <ul>
      <li><strong>–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è</strong>: —É—á–∏—Ç—ã–≤–∞–π—Ç–µ bias –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ —Ç–æ–≤–∞—Ä–æ–≤</li>
      <li><strong>–í—Ä–µ–º–µ–Ω–Ω–æ–π —Ñ–∞–∫—Ç–æ—Ä</strong>: —Å–≤–µ–∂–∏–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –≤–∞–∂–Ω–µ–µ</li>
      <li><strong>Implicit vs Explicit</strong>: –≤—ã–±–∏—Ä–∞–π—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥</li>
      <li><strong>–í–∞–ª–∏–¥–∞—Ü–∏—è</strong>: –≤—Ä–µ–º–µ–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è (–Ω–µ —Å–ª—É—á–∞–π–Ω–∞—è)</li>
      <li><strong>–•–æ–ª–æ–¥–Ω—ã–π —Å—Ç–∞—Ä—Ç</strong>: –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥</li>
      <li><strong>Diversity</strong>: –∏–∑–±–µ–≥–∞–π—Ç–µ filter bubble</li>
      <li><strong>A/B —Ç–µ—Å—Ç—ã</strong>: –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ –±–∏–∑–Ω–µ—Å–∞</li>
      <li><strong>–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥</strong>: –æ—Ç—Å–ª–µ–∂–∏–≤–∞–π—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –≤ production</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 18. –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –•–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç</h3>
        <ul>
          <li>–ú–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ –∏—Å—Ç–æ—Ä–∏–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π</li>
          <li>–¢–æ–≤–∞—Ä—ã/–∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ—Ö–æ–∂–∏ –ø–æ –ø—Ä–∏—Ä–æ–¥–µ</li>
          <li>–í–∞–∂–Ω–∞ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è</li>
          <li>E-commerce, —Å—Ç—Ä–∏–º–∏–Ω–≥, –Ω–æ–≤–æ—Å—Ç–∏</li>
          <li>–ï—Å—Ç—å explicit –∏–ª–∏ implicit feedback</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ùå –ü–ª–æ—Ö–æ –ø–æ–¥—Ö–æ–¥–∏—Ç</h3>
        <ul>
          <li>–ù–æ–≤–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ (—Ö–æ–ª–æ–¥–Ω—ã–π —Å—Ç–∞—Ä—Ç)</li>
          <li>–û—á–µ–Ω—å —Ä–∞–∑–Ω–æ—Ä–æ–¥–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç</li>
          <li>–ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö</li>
          <li>–ù—É–∂–Ω–∞ –æ–±—ä—è—Å–Ω–∏–º–æ—Å—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π</li>
          <li>–ö—Ä–∏—Ç–∏—á–Ω–∞ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å (trending)</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 19. –ß–µ–∫-–ª–∏—Å—Ç —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏</h2>
    <ul>
      <li>[ ] –°–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö</li>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å —Ç–∏–ø CF (user/item/model-based)</li>
      <li>[ ] –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö</li>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å –º–µ—Ç—Ä–∏–∫—É similarity</li>
      <li>[ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å baseline (–ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã)</li>
      <li>[ ] –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å CF</li>
      <li>[ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã</li>
      <li>[ ] –†–µ—à–∏—Ç—å –ø—Ä–æ–±–ª–µ–º—É —Ö–æ–ª–æ–¥–Ω–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞</li>
      <li>[ ] –î–æ–±–∞–≤–∏—Ç—å diversity –≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏</li>
      <li>[ ] –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö</li>
      <li>[ ] A/B —Ç–µ—Å—Ç –≤ production</li>
      <li>[ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –º–µ—Ç—Ä–∏–∫</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´–ö–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è ‚Äî —ç—Ç–æ –∫–∞–∫ —Å–∞—Ä–∞—Ñ–∞–Ω–Ω–æ–µ —Ä–∞–¥–∏–æ –≤ —Ü–∏—Ñ—Ä–æ–≤–æ–º –º–∏—Ä–µ: —Å–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç, —á—Ç–æ –Ω—Ä–∞–≤–∏—Ç—Å—è –ø–æ—Ö–æ–∂–∏–º –Ω–∞ –≤–∞—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º, –∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç –≤–∞–º —Ç–æ, —á—Ç–æ —Å –≤—ã—Å–æ–∫–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –ø–æ–Ω—Ä–∞–≤–∏—Ç—Å—è. –ò–º–µ–Ω–Ω–æ —Ç–∞–∫ —Ä–∞–±–æ—Ç–∞—é—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ Netflix –∏ Amazon¬ª.
    </blockquote>
  </div>

</div>

</body>
</html>
