<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>Memory Networks Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

    .container {
      column-count: 3;
      column-gap: 20px;
      max-width: 100%;
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üß† Memory Networks Cheatsheet</h1>
  <div class="subtitle">–ù–µ–π—Ä–æ—Å–µ—Ç–∏ —Å –≤–Ω–µ—à–Ω–µ–π –ø–∞–º—è—Ç—å—é ‚Ä¢ –ß—Ç–µ–Ω–∏–µ –∏ –∑–∞–ø–∏—Å—å<br>üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –û—Å–Ω–æ–≤–Ω–∞—è –∏–¥–µ—è</h2>
    <p><strong>Memory Networks:</strong> –ù–µ–π—Ä–æ—Å–µ—Ç–∏ —Å —è–≤–Ω–æ–π –≤–Ω–µ—à–Ω–µ–π –ø–∞–º—è—Ç—å—é, –∫–æ—Ç–æ—Ä—É—é –º–æ–∂–Ω–æ —á–∏—Ç–∞—Ç—å –∏ –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å.</p>
    <ul>
      <li><strong>–ü—Ä–æ–±–ª–µ–º–∞ RNN</strong>: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å (hidden state)</li>
      <li><strong>–†–µ—à–µ–Ω–∏–µ</strong>: –í–Ω–µ—à–Ω–∏–π memory bank</li>
      <li><strong>–ú–µ—Ö–∞–Ω–∏–∑–º</strong>: Attention –¥–ª—è —á—Ç–µ–Ω–∏—è</li>
      <li><strong>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</strong>: QA, reasoning, –¥–ª–∏–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 2. –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã</h2>
    <p><strong>4 –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–æ–¥—É–ª—è (Weston et al., 2014):</strong></p>
    <ul>
      <li><strong>I (Input)</strong>: –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤—Ö–æ–¥–∞ –≤ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ</li>
      <li><strong>G (Generalization)</strong>: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ –Ω–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π</li>
      <li><strong>O (Output)</strong>: –ß—Ç–µ–Ω–∏–µ –∏–∑ –ø–∞–º—è—Ç–∏</li>
      <li><strong>R (Response)</strong>: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞</li>
    </ul>
    <blockquote>
      Memory Networks = Neural Net + External Memory + Attention
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 3. End-to-End Memory Networks</h2>
    <p><strong>–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (Sukhbaatar et al., 2015):</strong></p>
    <pre><code>1. Embedding –≤—Ö–æ–¥–∞: u = Embed(question)
2. Embedding –ø–∞–º—è—Ç–∏: 
   m_i = Embed_A(memory_i)
   c_i = Embed_C(memory_i)
3. Attention weights:
   p_i = softmax(u^T m_i)
4. –ß—Ç–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏:
   o = Œ£ p_i * c_i
5. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞:
   u_next = u + o
6. Multi-hop: –ø–æ–≤—Ç–æ—Ä–∏—Ç—å —à–∞–≥–∏ 3-5
7. –û—Ç–≤–µ—Ç: answer = softmax(W(u_final))</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è</h2>
    <pre><code>import torch
import torch.nn as nn

class MemoryNetwork(nn.Module):
    def __init__(self, vocab_size, embed_dim, mem_slots, hops=3):
        super().__init__()
        self.hops = hops
        
        # Embeddings –¥–ª—è –ø–∞–º—è—Ç–∏ (A –∏ C)
        self.A = nn.ModuleList([
            nn.Embedding(vocab_size, embed_dim) 
            for _ in range(hops)
        ])
        self.C = nn.ModuleList([
            nn.Embedding(vocab_size, embed_dim) 
            for _ in range(hops)
        ])
        
        # Embedding –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞
        self.question_encoder = nn.Embedding(vocab_size, embed_dim)
        
        # Output
        self.W = nn.Linear(embed_dim, vocab_size)
    
    def forward(self, question, memories):
        # Encode question
        u = self.question_encoder(question).sum(1)  # [batch, embed]
        
        # Multi-hop reasoning
        for hop in range(self.hops):
            # Memory embeddings
            m = self.A[hop](memories).sum(2)  # [batch, mem_slots, embed]
            c = self.C[hop](memories).sum(2)
            
            # Attention
            p = torch.softmax(torch.bmm(m, u.unsqueeze(2)).squeeze(2), dim=1)
            
            # Read from memory
            o = torch.bmm(p.unsqueeze(1), c).squeeze(1)
            
            # Update query
            u = u + o
        
        # Generate answer
        return self.W(u)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. –í–∞—Ä–∏–∞–Ω—Ç—ã Memory Networks</h2>
    <table>
      <tr><th>–ú–æ–¥–µ–ª—å</th><th>–ì–æ–¥</th><th>–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å</th></tr>
      <tr><td><strong>MemNN</strong></td><td>2014</td><td>–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è, —Ç—Ä–µ–±—É–µ—Ç supervision</td></tr>
      <tr><td><strong>End-to-End MemNN</strong></td><td>2015</td><td>Differentiable, end-to-end</td></tr>
      <tr><td><strong>Key-Value MemNN</strong></td><td>2016</td><td>–†–∞–∑–¥–µ–ª—å–Ω—ã–µ key/value</td></tr>
      <tr><td><strong>Neural Turing Machine</strong></td><td>2014</td><td>Read/write operations</td></tr>
      <tr><td><strong>Differentiable Neural Computer</strong></td><td>2016</td><td>–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è NTM</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 6. Neural Turing Machine</h2>
    <p><strong>–ë–æ–ª–µ–µ –æ–±—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:</strong></p>
    <ul>
      <li><strong>Memory matrix</strong>: M ‚àà R^(N√óM) (N slots, M dim each)</li>
      <li><strong>Read heads</strong>: Attention-based —á—Ç–µ–Ω–∏–µ</li>
      <li><strong>Write heads</strong>: Erase + Add operations</li>
      <li><strong>Addressing</strong>: Content-based + location-based</li>
    </ul>
    <pre><code># Write operation
M_t[i] = M_{t-1}[i] * (1 - w_t[i] * e_t) + w_t[i] * a_t

–≥–¥–µ:
w_t - attention weights
e_t - erase vector
a_t - add vector</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. Addressing –º–µ—Ö–∞–Ω–∏–∑–º—ã</h2>
    <p><strong>Content-based addressing:</strong></p>
    <pre><code>w_t^c[i] = exp(Œ≤ * cosine(k_t, M_t[i])) / Z

–≥–¥–µ k_t - query key, Œ≤ - strength</code></pre>
    <p><strong>Location-based addressing:</strong></p>
    <ul>
      <li><strong>Interpolation</strong>: —Å–º–µ—à–∏–≤–∞–Ω–∏–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º w</li>
      <li><strong>Convolutional shift</strong>: —Å–¥–≤–∏–≥ attention</li>
      <li><strong>Sharpening</strong>: —É—Å–∏–ª–µ–Ω–∏–µ –ø–∏–∫–æ–≤</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 8. Differentiable Neural Computer</h2>
    <p><strong>–£–ª—É—á—à–µ–Ω–∏—è –Ω–∞–¥ NTM:</strong></p>
    <ul>
      <li><strong>Dynamic memory allocation</strong>: usage vector</li>
      <li><strong>Temporal links</strong>: –ø–æ–º–Ω–∏—Ç –ø–æ—Ä—è–¥–æ–∫ –∑–∞–ø–∏—Å–∏</li>
      <li><strong>Content linkage</strong>: —Å–≤—è–∑—ã–≤–∞–µ—Ç –ø–æ—Ö–æ–∂–∏–µ –∑–∞–ø–∏—Å–∏</li>
      <li><strong>Multiple read/write heads</strong></li>
    </ul>
    <blockquote>
      DNC –º–æ–∂–µ—Ç —É—á–∏—Ç—å—Å—è –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º: —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞, –ø–æ–∏—Å–∫ –≤ –≥—Ä–∞—Ñ–µ, etc.
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 9. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –ì–¥–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã</h3>
        <ul>
          <li>Question Answering (bAbI tasks)</li>
          <li>Reading comprehension</li>
          <li>Reasoning tasks</li>
          <li>Algorithmic tasks</li>
          <li>Few-shot learning</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è</h3>
        <ul>
          <li>–°–ª–æ–∂–Ω–∞—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞</li>
          <li>–ß–∏—Å–ª–µ–Ω–Ω–∞—è –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å</li>
          <li>–ú–µ–¥–ª–µ–Ω–Ω–µ–µ –æ–±—ã—á–Ω—ã—Ö —Å–µ—Ç–µ–π</li>
          <li>–¢—Ä—É–¥–Ω–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å –ø–∞–º—è—Ç—å</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 10. bAbI –¥–∞—Ç–∞—Å–µ—Ç</h2>
    <p><strong>Benchmark –¥–ª—è Memory Networks:</strong></p>
    <pre><code>–ü—Ä–∏–º–µ—Ä –∑–∞–¥–∞—á–∏:
Story:
  Mary moved to the bathroom.
  John went to the hallway.
Question: 
  Where is Mary?
Answer: 
  bathroom

20 —Ç–∏–ø–æ–≤ –∑–∞–¥–∞—á: —Ñ–∞–∫—Ç—ã, –∏–Ω–¥—É–∫—Ü–∏—è, –¥–µ–¥—É–∫—Ü–∏—è, counting</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å Transformers</h2>
    <table>
      <tr><th>–ê—Å–ø–µ–∫—Ç</th><th>Memory Networks</th><th>Transformers</th></tr>
      <tr><td>–ü–∞–º—è—Ç—å</td><td>–Ø–≤–Ω–∞—è external</td><td>–ù–µ—è–≤–Ω–∞—è (attention)</td></tr>
      <tr><td>–†–∞–∑–º–µ—Ä</td><td>–§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π</td><td>Sequence length</td></tr>
      <tr><td>–î–æ—Å—Ç—É–ø</td><td>Read/write</td><td>Read only (self-attn)</td></tr>
      <tr><td>–°–ª–æ–∂–Ω–æ—Å—Ç—å</td><td>–í—ã—à–µ</td><td>–ü—Ä–æ—â–µ</td></tr>
    </table>
    <p><strong>–°–µ–π—á–∞—Å:</strong> Transformers –¥–æ–º–∏–Ω–∏—Ä—É—é—Ç –∏–∑-–∑–∞ –ø—Ä–æ—Å—Ç–æ—Ç—ã –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏</p>
  </div>

  <div class="block">
    <h2>üî∑ 12. Key-Value Memory Networks</h2>
    <p><strong>–û–±–æ–±—â–µ–Ω–∏–µ MemNN:</strong></p>
    <pre><code># –†–∞–∑–¥–µ–ª—å–Ω—ã–µ key –∏ value
key_i = Embed_key(memory_i)
value_i = Embed_value(memory_i)

# Attention –ø–æ keys
p_i = softmax(query^T key_i)

# –ß—Ç–µ–Ω–∏–µ values
output = Œ£ p_i * value_i

–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: Knowledge bases, –≥–¥–µ —Ñ–∞–∫—Ç = (key, value)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 13. –°–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ</h2>
    <ul>
      <li><strong>–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –≤—ã—Ç–µ—Å–Ω–∏–ª–∏</strong>: –ü—Ä–æ—â–µ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ</li>
      <li><strong>–ù–æ –∏–¥–µ–∏ –∂–∏–≤—É—Ç</strong>: External memory –≤ Transformer-XL, Compressive Transformers</li>
      <li><strong>Retrieval-augmented</strong>: RAG models –∏—Å–ø–æ–ª—å–∑—É—é—Ç –ø–æ—Ö–æ–∂–∏–µ –∏–¥–µ–∏</li>
      <li><strong>–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è</strong>: Neurosymbolic AI –≤–æ–∑—Ä–æ–∂–¥–∞–µ—Ç –∏–Ω—Ç–µ—Ä–µ—Å</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 14. –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã</h2>
    <ul>
      <li>[ ] Memory Networks –¥–æ–±–∞–≤–ª—è—é—Ç <strong>—è–≤–Ω—É—é –ø–∞–º—è—Ç—å</strong></li>
      <li>[ ] –ò—Å–ø–æ–ª—å–∑—É—é—Ç <strong>attention</strong> –¥–ª—è —á—Ç–µ–Ω–∏—è</li>
      <li>[ ] –•–æ—Ä–æ—à–∏ –¥–ª—è <strong>reasoning</strong> –∑–∞–¥–∞—á</li>
      <li>[ ] <strong>–°–ª–æ–∂–Ω–µ–µ</strong> –æ–±—ã—á–Ω—ã—Ö –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π</li>
      <li>[ ] –í—ã—Ç–µ—Å–Ω–µ–Ω—ã <strong>Transformers</strong>, –Ω–æ –∏–¥–µ–∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´Memory Network ‚Äî —ç—Ç–æ –Ω–µ–π—Ä–æ—Å–µ—Ç—å —Å "–∑–∞–ø–∏—Å–Ω–æ–π –∫–Ω–∏–∂–∫–æ–π". –û–Ω–∞ –º–æ–∂–µ—Ç –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å —Ñ–∞–∫—Ç—ã –≤ –ø–∞–º—è—Ç—å –∏ –ø–æ—Ç–æ–º –∏—Å–∫–∞—Ç—å –Ω—É–∂–Ω—ã–µ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å. –ö–∞–∫ —Å—Ç—É–¥–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –≤–µ–¥—ë—Ç –∫–æ–Ω—Å–ø–µ–∫—Ç –∏ –ø–æ—Ç–æ–º –∏–º –ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–∞ —ç–∫–∑–∞–º–µ–Ω–µ¬ª.
    </blockquote>
  </div>

</div>

</body>
</html>
