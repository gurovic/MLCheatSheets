<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Adversarial Attacks Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      
        min-width: 900px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

        .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üéØ Adversarial Attacks</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –ß—Ç–æ —Ç–∞–∫–æ–µ adversarial attacks?</h2>
    <p><strong>Adversarial attack</strong> ‚Äî –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–∞–ª—ã—Ö –≤–æ–∑–º—É—â–µ–Ω–∏–π –∫ –≤—Ö–æ–¥–Ω—ã–º –¥–∞–Ω–Ω—ã–º –¥–ª—è –æ–±–º–∞–Ω–∞ –º–æ–¥–µ–ª–∏.</p>
    <ul>
      <li><strong>–¶–µ–ª—å</strong>: –≤—ã–∑–≤–∞—Ç—å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ</li>
      <li><strong>–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å</strong>: –≤–æ–∑–º—É—â–µ–Ω–∏—è –Ω–µ–∑–∞–º–µ—Ç–Ω—ã –¥–ª—è —á–µ–ª–æ–≤–µ–∫–∞</li>
      <li><strong>–£–≥—Ä–æ–∑–∞</strong>: –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å ML —Å–∏—Å—Ç–µ–º</li>
      <li><strong>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</strong>: CV, NLP, speech recognition</li>
    </ul>
    <blockquote>üí° "–ù–µ–±–æ–ª—å—à–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –º–æ–∂–µ—Ç –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å –ø–∞–Ω–¥—É –≤ –≥–∏–±–±–æ–Ω–∞"</blockquote>

    </div>

</div>
<div class="block">
    <h2>üî∑ 2. –¢–∏–ø—ã –∞—Ç–∞–∫</h2>
    <table>
      <tr><th>–¢–∏–ø</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th></tr>
      <tr>
        <td><strong>White-box</strong></td>
        <td>–ü–æ–ª–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ –º–æ–¥–µ–ª–∏ –∏ –≤–µ—Å–∞–º</td>
      </tr>
      <tr>
        <td><strong>Black-box</strong></td>
        <td>–î–æ—Å—Ç—É–ø —Ç–æ–ª—å–∫–æ –∫ –≤—ã—Ö–æ–¥–∞–º –º–æ–¥–µ–ª–∏</td>
      </tr>
      <tr>
        <td><strong>Gray-box</strong></td>
        <td>–ß–∞—Å—Ç–∏—á–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ</td>
      </tr>
      <tr>
        <td><strong>Targeted</strong></td>
        <td>–¶–µ–ª–µ–≤–∞—è –æ—à–∏–±–∫–∞ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∫–ª–∞—Å—Å</td>
      </tr>
      <tr>
        <td><strong>Untargeted</strong></td>
        <td>–õ—é–±–∞—è –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è</td>
      </tr>
      <tr>
        <td><strong>Physical</strong></td>
        <td>–ê—Ç–∞–∫–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –º–∏—Ä–µ (—Å—Ç–∏–∫–µ—Ä—ã)</td>
      </tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 3. FGSM (Fast Gradient Sign Method)</h2>
    <p>–ü—Ä–æ—Å—Ç–µ–π—à–∏–π –∏ –±—ã—Å—Ç—Ä—ã–π –º–µ—Ç–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ adversarial examples.</p>
    <p><strong>–§–æ—Ä–º—É–ª–∞</strong>: x_adv = x + Œµ √ó sign(‚àá_x L(Œ∏, x, y))</p>
    
    <pre><code>import torch
import torch.nn.functional as F

def fgsm_attack(model, x, y, epsilon=0.03):
    """
    FGSM –∞—Ç–∞–∫–∞ –Ω–∞ –º–æ–¥–µ–ª—å
    
    Args:
        model: –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å
        x: –≤—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        y: –∏—Å—Ç–∏–Ω–Ω–∞—è –º–µ—Ç–∫–∞
        epsilon: —Å–∏–ª–∞ –≤–æ–∑–º—É—â–µ–Ω–∏—è
    """
    # –¢—Ä–µ–±—É–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
    x.requires_grad = True
    
    # Forward pass
    output = model(x)
    loss = F.cross_entropy(output, y)
    
    # Backward pass
    model.zero_grad()
    loss.backward()
    
    # –ó–Ω–∞–∫ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞
    data_grad = x.grad.data
    
    # –°–æ–∑–¥–∞–µ–º adversarial example
    perturbed_x = x + epsilon * data_grad.sign()
    
    # –ö–ª–∏–ø–∏–Ω–≥ –∫ –≤–∞–ª–∏–¥–Ω–æ–º—É –¥–∏–∞–ø–∞–∑–æ–Ω—É
    perturbed_x = torch.clamp(perturbed_x, 0, 1)
    
    return perturbed_x

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
x_adv = fgsm_attack(model, image, label, epsilon=0.03)
pred_clean = model(image).argmax()
pred_adv = model(x_adv).argmax()
print(f"Clean: {pred_clean}, Adversarial: {pred_adv}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. PGD (Projected Gradient Descent)</h2>
    <p>–ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥, –±–æ–ª–µ–µ —Å–∏–ª—å–Ω—ã–π —á–µ–º FGSM.</p>
    <ul>
      <li>–ù–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ —Å –º–∞–ª—ã–º Œµ</li>
      <li>–ü—Ä–æ–µ–∫—Ü–∏—è –Ω–∞ –¥–æ–ø—É—Å—Ç–∏–º—É—é –æ–±–ª–∞—Å—Ç—å</li>
      <li>–°–ª—É—á–∞–π–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è</li>
    </ul>

    <pre><code>def pgd_attack(model, x, y, epsilon=0.03, 
               alpha=0.01, num_iter=40):
    """
    PGD –∞—Ç–∞–∫–∞ - –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π FGSM
    
    Args:
        alpha: —Ä–∞–∑–º–µ—Ä —à–∞–≥–∞
        num_iter: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π
    """
    # –°–ª—É—á–∞–π–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    delta = torch.zeros_like(x).uniform_(-epsilon, epsilon)
    delta.requires_grad = True
    
    for i in range(num_iter):
        # Forward
        output = model(x + delta)
        loss = F.cross_entropy(output, y)
        
        # Backward
        loss.backward()
        
        # Gradient ascent step
        delta.data = delta + alpha * delta.grad.sign()
        
        # –ü—Ä–æ–µ–∫—Ü–∏—è –Ω–∞ epsilon-—à–∞—Ä
        delta.data = torch.clamp(delta.data, -epsilon, epsilon)
        
        # –û–±–Ω—É–ª–∏—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
        delta.grad.zero_()
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–π adversarial example
    x_adv = torch.clamp(x + delta, 0, 1)
    return x_adv</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. C&W (Carlini & Wagner) Attack</h2>
    <p>–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –¥–ª—è –ø–æ–∏—Å–∫–∞ minimal perturbation.</p>
    <p><strong>–§–æ—Ä–º—É–ª–∞</strong>: minimize ||Œ¥||_p + c √ó f(x + Œ¥)</p>
    
    <pre><code>def cw_attack(model, x, target, c=1.0, 
              learning_rate=0.01, max_iter=1000):
    """
    C&W L2 –∞—Ç–∞–∫–∞ - –∏—â–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤–æ–∑–º—É—â–µ–Ω–∏–µ
    """
    # –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    delta = torch.zeros_like(x, requires_grad=True)
    optimizer = torch.optim.Adam([delta], lr=learning_rate)
    
    for i in range(max_iter):
        # Adversarial example
        x_adv = x + delta
        
        # Logits –º–æ–¥–µ–ª–∏
        logits = model(x_adv)
        
        # C&W loss function
        real = logits.gather(1, target.unsqueeze(1))
        other = logits.gather(1, 
            logits.argsort(descending=True)[:, 1:2])
        
        # f(x') = max(0, real - other + Œ∫)
        f = torch.clamp(real - other + 0.0, min=0)
        
        # Total loss: L2 norm + classification loss
        loss = torch.norm(delta, p=2) + c * f.sum()
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    
    return torch.clamp(x + delta, 0, 1)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. DeepFool</h2>
    <p>–ò—â–µ—Ç closest decision boundary –¥–ª—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –≤–æ–∑–º—É—â–µ–Ω–∏—è.</p>
    <ul>
      <li>–õ–∏–Ω–µ–∞—Ä–∏–∑–∞—Ü–∏—è –≥—Ä–∞–Ω–∏—Ü—ã —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ</li>
      <li>–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ l2 –≤–æ–∑–º—É—â–µ–Ω–∏–µ</li>
    </ul>

    <pre><code>def deepfool_attack(model, x, num_classes=10, 
                    max_iter=50, overshoot=0.02):
    """
    DeepFool –∞—Ç–∞–∫–∞ - minimal perturbation
    """
    x_adv = x.clone().detach()
    x_adv.requires_grad = True
    
    # –ò—Å—Ö–æ–¥–Ω—ã–π –∫–ª–∞—Å—Å
    logits = model(x_adv)
    pred_class = logits.argmax().item()
    
    for i in range(max_iter):
        logits = model(x_adv)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–ª—è –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤
        grads = []
        for k in range(num_classes):
            if k == pred_class:
                continue
            
            model.zero_grad()
            logits[0, k].backward(retain_graph=True)
            grads.append(x_adv.grad.clone())
            x_adv.grad.zero_()
        
        # –ù–∞—Ö–æ–¥–∏–º –±–ª–∏–∂–∞–π—à—É—é –≥—Ä–∞–Ω–∏—Ü—É
        min_dist = float('inf')
        best_grad = None
        
        for grad in grads:
            # –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ boundary
            w_norm = torch.norm(grad.flatten())
            dist = abs(logits[0, pred_class] - logits[0, k]) / w_norm
            
            if dist < min_dist:
                min_dist = dist
                best_grad = grad
        
        # –û–±–Ω–æ–≤–ª—è–µ–º x_adv
        perturbation = (1 + overshoot) * min_dist * best_grad / torch.norm(best_grad)
        x_adv = x_adv + perturbation
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∞
        if model(x_adv).argmax() != pred_class:
            break
    
    return x_adv</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. Universal Adversarial Perturbations</h2>
    <p>–û–¥–Ω–æ –≤–æ–∑–º—É—â–µ–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –º–Ω–æ–≥–∏—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö.</p>
    
    <pre><code>def universal_perturbation(model, dataloader, 
                           epsilon=0.1, max_iter=10):
    """
    –ù–∞—Ö–æ–¥–∏—Ç —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ –≤–æ–∑–º—É—â–µ–Ω–∏–µ
    """
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    v = torch.zeros(1, 3, 224, 224)
    
    for iteration in range(max_iter):
        print(f"Iteration {iteration+1}/{max_iter}")
        
        for batch_x, batch_y in dataloader:
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–µ–∫—É—â–µ–µ –≤–æ–∑–º—É—â–µ–Ω–∏–µ
            x_perturbed = batch_x + v
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            pred_clean = model(batch_x).argmax(dim=1)
            pred_perturbed = model(x_perturbed).argmax(dim=1)
            
            # –î–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö
            correct_mask = (pred_clean == batch_y)
            
            if correct_mask.sum() > 0:
                # –ù–∞—Ö–æ–¥–∏–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤–æ–∑–º—É—â–µ–Ω–∏–µ DeepFool
                for i in range(len(batch_x)):
                    if correct_mask[i]:
                        delta = deepfool_attack(
                            model, 
                            x_perturbed[i:i+1]
                        )
                        v += delta - x_perturbed[i:i+1]
                        
                        # –ü—Ä–æ–µ–∫—Ü–∏—è –Ω–∞ epsilon-—à–∞—Ä
                        v = torch.clamp(v, -epsilon, epsilon)
    
    return v</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. Black-box –∞—Ç–∞–∫–∏</h2>
    <p>–ê—Ç–∞–∫–∏ –±–µ–∑ –¥–æ—Å—Ç—É–ø–∞ –∫ –º–æ–¥–µ–ª–∏:</p>
    
    <p><strong>1. Transferability</strong>:</p>
    <ul>
      <li>–û–±—É—á–∞–µ–º surrogate –º–æ–¥–µ–ª—å</li>
      <li>–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞—Ç–∞–∫—É –Ω–∞ surrogate</li>
      <li>–ü—Ä–∏–º–µ–Ω—è–µ–º –∫ —Ü–µ–ª–µ–≤–æ–π –º–æ–¥–µ–ª–∏</li>
    </ul>

    <pre><code># Transfer attack
def transfer_attack(surrogate_model, target_model, x, y):
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞—Ç–∞–∫—É –Ω–∞ surrogate
    x_adv = pgd_attack(surrogate_model, x, y)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ target
    pred_clean = target_model(x).argmax()
    pred_adv = target_model(x_adv).argmax()
    
    success = (pred_clean != pred_adv)
    return x_adv, success</code></pre>

    <p><strong>2. Query-based –∞—Ç–∞–∫–∏</strong>:</p>
    <pre><code>def query_based_attack(model_query_fn, x, y, 
                       num_queries=1000):
    """
    –ê—Ç–∞–∫–∞ —Ç–æ–ª—å–∫–æ —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º
    """
    best_x = x.clone()
    best_loss = float('inf')
    
    for i in range(num_queries):
        # –°–ª—É—á–∞–π–Ω–æ–µ –≤–æ–∑–º—É—â–µ–Ω–∏–µ
        noise = torch.randn_like(x) * 0.01
        x_perturbed = torch.clamp(x + noise, 0, 1)
        
        # Query –º–æ–¥–µ–ª—å
        pred = model_query_fn(x_perturbed)
        loss = F.cross_entropy(pred, y)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à–µ–µ
        if loss < best_loss:
            best_loss = loss
            best_x = x_perturbed
    
    return best_x</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. –§–∏–∑–∏—á–µ—Å–∫–∏–µ –∞—Ç–∞–∫–∏</h2>
    <p>Adversarial examples –≤ —Ä–µ–∞–ª—å–Ω–æ–º –º–∏—Ä–µ:</p>
    <ul>
      <li><strong>Adversarial patches</strong>: —Å—Ç–∏–∫–µ—Ä—ã –Ω–∞ –æ–±—ä–µ–∫—Ç–∞—Ö</li>
      <li><strong>3D adversarial objects</strong>: —Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ –æ–±—ä–µ–∫—Ç—ã</li>
      <li><strong>Robust perturbations</strong>: —É—Å—Ç–æ–π—á–∏–≤—ã–µ –∫ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è–º</li>
    </ul>

    <pre><code>def adversarial_patch(model, target_class, 
                      patch_size=50, num_iter=1000):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç adversarial patch
    """
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ç—á–∞
    patch = torch.rand(3, patch_size, patch_size, 
                       requires_grad=True)
    optimizer = torch.optim.Adam([patch], lr=0.01)
    
    for i in range(num_iter):
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ç—á –∫ —Å–ª—É—á–∞–π–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
        images = get_random_images(batch_size=32)
        
        # –°–ª—É—á–∞–π–Ω–æ–µ —Ä–∞–∑–º–µ—â–µ–Ω–∏–µ –ø–∞—Ç—á–∞
        patched_images = apply_patch_random(images, patch)
        
        # Loss –¥–ª—è —Ü–µ–ª–µ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞
        logits = model(patched_images)
        target = torch.full((32,), target_class)
        loss = F.cross_entropy(logits, target)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # –ö–ª–∏–ø –ø–∞—Ç—á –∫ –≤–∞–ª–∏–¥–Ω–æ–º—É –¥–∏–∞–ø–∞–∑–æ–Ω—É
        patch.data = torch.clamp(patch.data, 0, 1)
    
    return patch</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. –ú–µ—Ç—Ä–∏–∫–∏ –∞—Ç–∞–∫</h2>
    <table>
      <tr><th>–ú–µ—Ç—Ä–∏–∫–∞</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th></tr>
      <tr>
        <td><strong>Attack Success Rate</strong></td>
        <td>–î–æ–ª—è —É—Å–ø–µ—à–Ω—ã—Ö –∞—Ç–∞–∫</td>
      </tr>
      <tr>
        <td><strong>L‚àû distance</strong></td>
        <td>–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –ø–∏–∫—Å–µ–ª—è</td>
      </tr>
      <tr>
        <td><strong>L2 distance</strong></td>
        <td>–ï–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ</td>
      </tr>
      <tr>
        <td><strong>L0 distance</strong></td>
        <td>–ß–∏—Å–ª–æ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø–∏–∫—Å–µ–ª–µ–π</td>
      </tr>
      <tr>
        <td><strong>SSIM</strong></td>
        <td>–°—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ</td>
      </tr>
      <tr>
        <td><strong>Robustness</strong></td>
        <td>–£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ –∞—Ç–∞–∫–∞–º</td>
      </tr>
    </table>

    <pre><code>def evaluate_attack(model, x_clean, x_adv, y_true):
    """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∞—Ç–∞–∫–∏"""
    
    # Success rate
    pred_clean = model(x_clean).argmax(dim=1)
    pred_adv = model(x_adv).argmax(dim=1)
    success = (pred_clean != pred_adv).float().mean()
    
    # Perturbation metrics
    l_inf = (x_adv - x_clean).abs().max()
    l_2 = torch.norm(x_adv - x_clean, p=2)
    l_0 = (x_adv != x_clean).float().sum()
    
    return {
        'success_rate': success.item(),
        'l_inf': l_inf.item(),
        'l_2': l_2.item(),
        'l_0': l_0.item()
    }</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. –ó–∞—â–∏—Ç–∞: Adversarial Training</h2>
    <p>–û–±—É—á–µ–Ω–∏–µ –Ω–∞ adversarial examples:</p>
    
    <pre><code>def adversarial_training(model, train_loader, 
                         epochs=10, epsilon=0.03):
    """
    Adversarial training –¥–ª—è robustness
    """
    optimizer = torch.optim.Adam(model.parameters())
    
    for epoch in range(epochs):
        for x, y in train_loader:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º adversarial examples
            x_adv = pgd_attack(model, x, y, epsilon=epsilon)
            
            # –°–º–µ—à–∏–≤–∞–µ–º clean –∏ adversarial
            x_mixed = torch.cat([x, x_adv], dim=0)
            y_mixed = torch.cat([y, y], dim=0)
            
            # –û–±—ã—á–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
            optimizer.zero_grad()
            output = model(x_mixed)
            loss = F.cross_entropy(output, y_mixed)
            loss.backward()
            optimizer.step()
        
        print(f"Epoch {epoch+1} completed")
    
    return model</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 12. Certified defenses</h2>
    <p>–ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å:</p>
    <ul>
      <li><strong>Randomized smoothing</strong></li>
      <li><strong>Interval bound propagation</strong></li>
      <li><strong>Lipschitz constraints</strong></li>
    </ul>

    <pre><code>import torch.nn.functional as F

class RandomizedSmoothing:
    """Certified defense —á–µ—Ä–µ–∑ —Å–ª—É—á–∞–π–Ω—ã–π —à—É–º"""
    
    def __init__(self, model, sigma=0.1, n_samples=100):
        self.model = model
        self.sigma = sigma
        self.n_samples = n_samples
    
    def predict(self, x):
        """Robust –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"""
        predictions = []
        
        # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å —à—É–º–æ–º
        for _ in range(self.n_samples):
            noise = torch.randn_like(x) * self.sigma
            x_noisy = x + noise
            pred = self.model(x_noisy).argmax()
            predictions.append(pred.item())
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º most common
        from collections import Counter
        return Counter(predictions).most_common(1)[0][0]
    
    def certify(self, x, pred_class, alpha=0.001):
        """–í—ã—á–∏—Å–ª—è–µ–º certified radius"""
        from scipy.stats import norm
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º votes
        counts = [0] * 10
        for _ in range(self.n_samples):
            noise = torch.randn_like(x) * self.sigma
            pred = self.model(x + noise).argmax()
            counts[pred.item()] += 1
        
        # –°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç
        p_a = counts[pred_class] / self.n_samples
        
        if p_a > 0.5:
            radius = self.sigma * norm.ppf(p_a)
            return radius
        else:
            return 0.0  # Not certified</code></pre>
  </div>



</body>
</html>
