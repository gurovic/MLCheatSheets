<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>Transfer Learning –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –ø–æ–¥—Ö–æ–¥—ã Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

    .container {
      column-count: 3;
      column-gap: 20px;
      max-width: 100%;
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üîÑ Transfer Learning: –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –ø–æ–¥—Ö–æ–¥—ã</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –ß—Ç–æ —Ç–∞–∫–æ–µ Transfer Learning?</h2>
    <ul>
      <li><strong>–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ</strong>: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∑–Ω–∞–Ω–∏–π –∏–∑ –æ–¥–Ω–æ–π –∑–∞–¥–∞—á–∏ –¥–ª—è –¥—Ä—É–≥–æ–π</li>
      <li><strong>–ò–¥–µ—è</strong>: –Ω–µ —É—á–∏—Ç—å—Å—è —Å –Ω—É–ª—è, –∞ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –≥–æ—Ç–æ–≤–æ–µ</li>
      <li><strong>–ó–∞—á–µ–º</strong>: —ç–∫–æ–Ω–æ–º–∏—è –¥–∞–Ω–Ω—ã—Ö, –≤—Ä–µ–º–µ–Ω–∏, –≤—ã—á–∏—Å–ª–µ–Ω–∏–π</li>
      <li><strong>–î–æ–º–µ–Ω—ã</strong>: source domain (–æ—Ç–∫—É–¥–∞) ‚Üí target domain (–∫—É–¥–∞)</li>
      <li><strong>–ó–∞–¥–∞—á–∏</strong>: source task ‚Üí target task</li>
    </ul>

  <div class="block">
    <h2>üî∑ 2. –¢–∏–ø—ã Transfer Learning</h2>
    <table>
      <tr><th>–¢–∏–ø</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th><th>–ü—Ä–∏–º–µ—Ä</th></tr>
      <tr>
        <td><strong>Inductive</strong></td>
        <td>–†–∞–∑–Ω—ã–µ –∑–∞–¥–∞—á–∏, –º–æ–∂–µ—Ç –±—ã—Ç—å —Ç–æ—Ç –∂–µ –¥–æ–º–µ–Ω</td>
        <td>ImageNet ‚Üí –º–µ–¥–∏—Ü–∏–Ω–∞</td>
      </tr>
      <tr>
        <td><strong>Transductive</strong></td>
        <td>–¢–∞ –∂–µ –∑–∞–¥–∞—á–∞, —Ä–∞–∑–Ω—ã–µ –¥–æ–º–µ–Ω—ã</td>
        <td>–û—Ç–∑—ã–≤—ã –∫–Ω–∏–≥ ‚Üí —Ñ–∏–ª—å–º—ã</td>
      </tr>
      <tr>
        <td><strong>Unsupervised</strong></td>
        <td>–ù–µ—Ç –º–µ—Ç–æ–∫ –≤ –æ–±–æ–∏—Ö –¥–æ–º–µ–Ω–∞—Ö</td>
        <td>–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è cross-domain</td>
      </tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 3. Feature-based Transfer</h2>
    <p>–ü–µ—Ä–µ–Ω–æ—Å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:</p>
    <pre><code>from sklearn.ensemble import RandomForestClassifier
from sklearn.decomposition import PCA

# Source domain - –±–æ–ª—å—à–æ–π –¥–∞—Ç–∞—Å–µ—Ç
rf_source = RandomForestClassifier(n_estimators=100)
rf_source.fit(X_source, y_source)

# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–ª–∏—Å—Ç—å—è –¥–µ—Ä–µ–≤—å–µ–≤ –∫–∞–∫ –ø—Ä–∏–∑–Ω–∞–∫–∏)
X_source_features = rf_source.apply(X_source)
X_target_features = rf_source.apply(X_target)

# PCA –Ω–∞ source
pca = PCA(n_components=50)
pca.fit(X_source_features)

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫ target
X_target_transformed = pca.transform(X_target_features)

# –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
model_target = RandomForestClassifier()
model_target.fit(X_target_transformed, y_target)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. Instance Transfer</h2>
    <p>–í–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ source domain:</p>
    <pre><code>import numpy as np
from sklearn.ensemble import GradientBoostingClassifier

# –û—Ü–µ–Ω–∫–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ –∏–∑ source
def importance_weighting(X_source, X_target):
    # –û–±—É—á–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ä–∞–∑–ª–∏—á–∞—Ç—å –¥–æ–º–µ–Ω—ã
    from sklearn.linear_model import LogisticRegression
    
    # –ú–µ—Ç–∫–∏: 0 = source, 1 = target
    X_combined = np.vstack([X_source, X_target])
    y_domain = np.hstack([
        np.zeros(len(X_source)),
        np.ones(len(X_target))
    ])
    
    domain_clf = LogisticRegression()
    domain_clf.fit(X_combined, y_domain)
    
    # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ target
    proba_target = domain_clf.predict_proba(X_source)[:, 1]
    proba_source = domain_clf.predict_proba(X_source)[:, 0]
    
    # –í–µ—Å–∞ = P(target) / P(source)
    weights = proba_target / (proba_source + 1e-10)
    return weights

weights = importance_weighting(X_source, X_target)

# –û–±—É—á–µ–Ω–∏–µ —Å –≤–µ—Å–∞–º–∏
model = GradientBoostingClassifier()
model.fit(X_source, y_source, sample_weight=weights)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. Parameter Transfer</h2>
    <pre><code># –ù–∞—á–∏–Ω–∞–µ–º —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ source –º–æ–¥–µ–ª–∏
from sklearn.linear_model import LogisticRegression

# –ú–æ–¥–µ–ª—å –Ω–∞ source
model_source = LogisticRegression(max_iter=1000)
model_source.fit(X_source, y_source)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è target –º–æ–¥–µ–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ source
model_target = LogisticRegression(
    max_iter=1000,
    warm_start=True
)

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞—á–∞–ª—å–Ω—ã—Ö –≤–µ—Å–æ–≤
model_target.coef_ = model_source.coef_.copy()
model_target.intercept_ = model_source.intercept_.copy()
model_target.classes_ = model_source.classes_

# Fine-tuning –Ω–∞ target
model_target.fit(X_target, y_target)

# –ò–ª–∏ —á–∞—Å—Ç–∏—á–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
from sklearn.linear_model import SGDClassifier

sgd = SGDClassifier(warm_start=True)
sgd.coef_ = model_source.coef_.copy()
sgd.intercept_ = model_source.intercept_.copy()

# –ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–µ –¥–æ–æ–±—É—á–µ–Ω–∏–µ
sgd.partial_fit(X_target, y_target, classes=np.unique(y_target))</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. Domain Adaptation</h2>
    <p>–ú–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è domain shift:</p>
    <pre><code># Maximum Mean Discrepancy (MMD)
def mmd_loss(X_source, X_target, kernel='rbf', gamma=1.0):
    from sklearn.metrics.pairwise import rbf_kernel
    
    n_source = len(X_source)
    n_target = len(X_target)
    
    # Kernel matrices
    K_ss = rbf_kernel(X_source, X_source, gamma)
    K_tt = rbf_kernel(X_target, X_target, gamma)
    K_st = rbf_kernel(X_source, X_target, gamma)
    
    # MMD^2
    mmd = (K_ss.sum() / (n_source ** 2) + 
           K_tt.sum() / (n_target ** 2) - 
           2 * K_st.sum() / (n_source * n_target))
    
    return mmd

# Feature alignment
from sklearn.preprocessing import StandardScaler

scaler_source = StandardScaler()
X_source_scaled = scaler_source.fit_transform(X_source)

scaler_target = StandardScaler()
X_target_scaled = scaler_target.fit_transform(X_target)

# Align distributions
from scipy.stats import wasserstein_distance

def align_features(X_source, X_target):
    X_aligned = X_target.copy()
    for i in range(X_target.shape[1]):
        # Match moments
        mean_s, std_s = X_source[:, i].mean(), X_source[:, i].std()
        mean_t, std_t = X_target[:, i].mean(), X_target[:, i].std()
        
        X_aligned[:, i] = (X_target[:, i] - mean_t) / std_t * std_s + mean_s
    
    return X_aligned

X_target_aligned = align_features(X_source_scaled, X_target_scaled)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. TrAdaBoost</h2>
    <p>Transfer AdaBoost –¥–ª—è domain adaptation:</p>
    <pre><code>from sklearn.tree import DecisionTreeClassifier
import numpy as np

class TrAdaBoost:
    def __init__(self, n_estimators=10):
        self.n_estimators = n_estimators
        self.models = []
        self.alphas = []
    
    def fit(self, X_source, y_source, X_target, y_target):
        n_source = len(X_source)
        n_target = len(X_target)
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        X_all = np.vstack([X_source, X_target])
        y_all = np.hstack([y_source, y_target])
        
        # –ù–∞—á–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞
        weights = np.ones(n_source + n_target)
        weights[:n_source] = 1.0 / n_source
        weights[n_source:] = 1.0 / n_target
        
        for t in range(self.n_estimators):
            # –û–±—É—á–µ–Ω–∏–µ —Å–ª–∞–±–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
            clf = DecisionTreeClassifier(max_depth=3)
            clf.fit(X_all, y_all, sample_weight=weights)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            y_pred = clf.predict(X_all)
            errors = (y_pred != y_all).astype(int)
            
            # –û—à–∏–±–∫–∞ –Ω–∞ target
            error_target = (weights[n_source:] * errors[n_source:]).sum()
            
            if error_target > 0.5 or error_target == 0:
                break
            
            # –ê–ª—å—Ñ–∞
            beta = error_target / (1 - error_target)
            alpha = np.log(1 / beta) / 2
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤
            # Source: —É–º–µ–Ω—å—à–∞–µ–º –≤–µ—Å –ø—Ä–∏ –æ—à–∏–±–∫–µ
            weights[:n_source] *= np.power(beta, -errors[:n_source])
            # Target: —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å –ø—Ä–∏ –æ—à–∏–±–∫–µ
            weights[n_source:] *= np.power(beta, errors[n_source:])
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            weights /= weights.sum()
            
            self.models.append(clf)
            self.alphas.append(alpha)
    
    def predict(self, X):
        predictions = np.zeros((len(X), len(self.models)))
        for i, (model, alpha) in enumerate(zip(self.models, self.alphas)):
            predictions[:, i] = model.predict(X) * alpha
        
        return (predictions.sum(axis=1) > 0).astype(int)

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
tradaboost = TrAdaBoost(n_estimators=10)
tradaboost.fit(X_source, y_source, X_target, y_target)
y_pred = tradaboost.predict(X_test)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. Self-training –¥–ª—è Transfer</h2>
    <pre><code>from sklearn.ensemble import RandomForestClassifier
import numpy as np

def self_training_transfer(X_source, y_source, X_target, 
                          confidence_threshold=0.9, max_iter=10):
    # –ù–∞—á–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–∞ source
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_source, y_source)
    
    # Unlabeled target data
    X_unlabeled = X_target.copy()
    X_labeled = X_source.copy()
    y_labeled = y_source.copy()
    
    for iteration in range(max_iter):
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ unlabeled
        proba = model.predict_proba(X_unlabeled)
        max_proba = proba.max(axis=1)
        
        # –í—ã—Å–æ–∫–æ—É–≤–µ—Ä–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        confident_mask = max_proba >= confidence_threshold
        
        if confident_mask.sum() == 0:
            break
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫ labeled
        X_new = X_unlabeled[confident_mask]
        y_new = model.predict(X_new)
        
        X_labeled = np.vstack([X_labeled, X_new])
        y_labeled = np.hstack([y_labeled, y_new])
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –∏–∑ unlabeled
        X_unlabeled = X_unlabeled[~confident_mask]
        
        # –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
        model.fit(X_labeled, y_labeled)
        
        print(f"Iteration {iteration+1}: added {confident_mask.sum()} samples")
    
    return model

model = self_training_transfer(X_source, y_source, X_target)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. Multi-task Learning</h2>
    <p>–û–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–∞–¥–∞—á–∞—Ö:</p>
    <pre><code>from sklearn.multioutput import MultiOutputClassifier
from sklearn.ensemble import RandomForestClassifier

# –ù–µ—Å–∫–æ–ª—å–∫–æ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
# y_task1, y_task2 - —Ä–∞–∑–Ω—ã–µ –∑–∞–¥–∞—á–∏
y_multi = np.column_stack([y_task1, y_task2])

# Multi-task –º–æ–¥–µ–ª—å
model = MultiOutputClassifier(
    RandomForestClassifier(n_estimators=100, random_state=42)
)

model.fit(X, y_multi)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –æ–±–µ–∏—Ö –∑–∞–¥–∞—á
predictions = model.predict(X_test)
pred_task1 = predictions[:, 0]
pred_task2 = predictions[:, 1]

# –ò–ª–∏ —Å —Ä–∞–∑–¥–µ–ª—è–µ–º—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
from sklearn.linear_model import MultiTaskLasso

# Lasso —Å –æ–±—â–∏–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
mtl = MultiTaskLasso(alpha=0.1)
mtl.fit(X_train, y_multi_train)

# –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –æ–±—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
shared_features = (mtl.coef_[:, :] != 0).sum(axis=0) > 1
print(f"Shared features: {shared_features.sum()}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è Transfer Learning</h2>
    <pre><code>from sklearn.metrics import accuracy_score

# A-distance - –º–µ—Ä–∞ —Ä–∞–∑–ª–∏—á–∏—è –¥–æ–º–µ–Ω–æ–≤
def a_distance(X_source, X_target):
    from sklearn.svm import LinearSVC
    
    X_combined = np.vstack([X_source, X_target])
    y_domain = np.hstack([
        np.zeros(len(X_source)),
        np.ones(len(X_target))
    ])
    
    clf = LinearSVC()
    from sklearn.model_selection import cross_val_score
    scores = cross_val_score(clf, X_combined, y_domain, cv=5)
    
    # A-distance ‚âà 2(1 - 2*error)
    error = 1 - scores.mean()
    a_dist = 2 * (1 - 2 * error)
    return a_dist

# Transfer ratio
def transfer_ratio(source_perf, target_perf, baseline_perf):
    # –ù–∞—Å–∫–æ–ª—å–∫–æ transfer –ø–æ–º–æ–≥ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å baseline
    return (target_perf - baseline_perf) / (source_perf - baseline_perf)

# Negative transfer detection
baseline_acc = accuracy_score(y_test, model_baseline.predict(X_test))
transfer_acc = accuracy_score(y_test, model_transfer.predict(X_test))

if transfer_acc < baseline_acc:
    print("Warning: Negative transfer detected!")
    print(f"Baseline: {baseline_acc:.3f}, Transfer: {transfer_acc:.3f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Transfer Learning</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –•–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç</h3>
        <ul>
          <li>–ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –≤ target domain</li>
          <li>Source –∏ target –ø–æ—Ö–æ–∂–∏</li>
          <li>–ï—Å—Ç—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è source –º–æ–¥–µ–ª—å</li>
          <li>–í—ã—Å–æ–∫–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ç–∫–∏</li>
          <li>–û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–µ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ùå –ù–µ –ø–æ–¥—Ö–æ–¥–∏—Ç</h3>
        <ul>
          <li>–î–æ–º–µ–Ω—ã —Å–∏–ª—å–Ω–æ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è</li>
          <li>–î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –≤ target</li>
          <li>–†–∏—Å–∫ negative transfer</li>
          <li>–ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–µ–π source –∑–∞–¥–∞—á–∏</li>
          <li>–¢—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 12. Fine-tuning —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏</h2>
    <ul>
      <li><strong>Full fine-tuning</strong>: –æ–±—É—á–∞–µ–º –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã</li>
      <li><strong>Frozen layers</strong>: –∑–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º —Ä–∞–Ω–Ω–∏–µ —Å–ª–æ–∏</li>
      <li><strong>Learning rate</strong>: –º–µ–Ω—å—à–µ –¥–ª—è source –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</li>
      <li><strong>Gradual unfreezing</strong>: —Ä–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ</li>
      <li><strong>Discriminative rates</strong>: —Ä–∞–∑–Ω—ã–µ LR –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–ª–æ–µ–≤</li>
    </ul>
    <pre><code># –ü—Ä–∏–º–µ—Ä —Å scikit-learn SGD
from sklearn.linear_model import SGDClassifier

# –ù–∞—á–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
source_model = SGDClassifier(max_iter=1000, random_state=42)
source_model.fit(X_source, y_source)

# Fine-tuning —Å –º–µ–Ω—å—à–∏–º learning rate
target_model = SGDClassifier(
    max_iter=100,
    learning_rate='constant',
    eta0=0.001,  # –º–µ–Ω—å—à–µ —á–µ–º –æ–±—ã—á–Ω–æ
    warm_start=True,
    random_state=42
)

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–µ—Å–æ–≤
target_model.coef_ = source_model.coef_.copy()
target_model.intercept_ = source_model.intercept_.copy()
target_model.classes_ = source_model.classes_

# –î–æ–æ–±—É—á–µ–Ω–∏–µ
target_model.fit(X_target, y_target)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 13. –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏</h2>
    <ul>
      <li><strong>–ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ similarity</strong> –º–µ–∂–¥—É source –∏ target</li>
      <li><strong>–ù–∞—á–∏–Ω–∞–π—Ç–µ —Å baseline</strong> –±–µ–∑ transfer</li>
      <li><strong>–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ negative transfer</strong> –≤–∞–∂–µ–Ω</li>
      <li><strong>–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ validation set</strong> –∏–∑ target domain</li>
      <li><strong>–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ</strong> —Å –∑–∞–º–æ—Ä–æ–∂–µ–Ω–Ω—ã–º–∏ —Å–ª–æ—è–º–∏</li>
      <li><strong>–ê–¥–∞–ø—Ç–∏—Ä—É–π—Ç–µ learning rate</strong> –¥–ª—è fine-tuning</li>
      <li><strong>–£—á–∏—Ç—ã–≤–∞–π—Ç–µ domain shift</strong> –≤ –º–µ—Ç—Ä–∏–∫–∞—Ö</li>
      <li><strong>–î–æ–∫—É–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ</strong> –∏—Å—Ç–æ—á–Ω–∏–∫ –∏ –ø—Ä–æ—Ü–µ—Å—Å transfer</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 14. –ß–µ–∫-–ª–∏—Å—Ç Transfer Learning</h2>
    <ul>
      <li>[ ] –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å source –∏ target domains</li>
      <li>[ ] –û—Ü–µ–Ω–∏—Ç—å similarity –¥–æ–º–µ–Ω–æ–≤</li>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å —Ç–∏–ø transfer (feature/instance/parameter)</li>
      <li>[ ] –û–±—É—á–∏—Ç—å baseline –º–æ–¥–µ–ª—å –Ω–∞ target</li>
      <li>[ ] –û–±—É—á–∏—Ç—å/–∑–∞–≥—Ä—É–∑–∏—Ç—å source –º–æ–¥–µ–ª—å</li>
      <li>[ ] –ü—Ä–∏–º–µ–Ω–∏—Ç—å transfer learning</li>
      <li>[ ] –°—Ä–∞–≤–Ω–∏—Ç—å —Å baseline</li>
      <li>[ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ negative transfer</li>
      <li>[ ] Fine-tune –µ—Å–ª–∏ –Ω—É–∂–Ω–æ</li>
      <li>[ ] –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ target domain</li>
      <li>[ ] –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´Transfer Learning ‚Äî —ç—Ç–æ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –æ–ø—ã—Ç–∞ –≤—Ä–∞—á–∞ –∏–∑ –æ–¥–Ω–æ–π —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏ –≤ —Å–º–µ–∂–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏. –ú–æ–¥–µ–ª—å, –æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ –±–æ–ª—å—à–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ, —É–∂–µ –∑–Ω–∞–µ—Ç –æ–±—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –∏ –Ω–∞–º –Ω—É–∂–Ω–æ –ª–∏—à—å –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–∏ –∑–Ω–∞–Ω–∏—è –ø–æ–¥ –Ω–∞—à—É –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∑–∞–¥–∞—á—É, —ç–∫–æ–Ω–æ–º—è –≤—Ä–µ–º—è –∏ –¥–∞–Ω–Ω—ã–µ¬ª.
    </blockquote>
  </div>

</div>

</div>
</body>
</html>
