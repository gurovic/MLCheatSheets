<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>–•—Ä–æ–Ω–æ–ª–æ–≥–∏—è –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

    .container {
      column-count: 3;
      column-gap: 20px;
      max-width: 100%;
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üìÖ –•—Ä–æ–Ω–æ–ª–æ–≥–∏—è –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è Cheatsheet</h1>
  <div class="subtitle">–ò—Å—Ç–æ—Ä–∏—è –∏ –∫–ª—é—á–µ–≤—ã–µ –≤–µ—Ö–∏ —Ä–∞–∑–≤–∏—Ç–∏—è Deep Learning ‚Ä¢ –û—Ç –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω–∞ –¥–æ LLM<br>üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –≠—Ä–∞ –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω–æ–≤ (1940-1969)</h2>
    <p><strong>–ù–∞—á–∞–ª–æ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π</strong></p><ul><li>1943: McCulloch-Pitts –Ω–µ–π—Ä–æ–Ω</li><li>1958: –†–æ–∑–µ–Ω–±–ª–∞—Ç—Ç —Å–æ–∑–¥–∞–µ—Ç –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω</li><li>1969: –ú–∏–Ω—Å–∫–∏–π –∏ –ü–µ–π–ø–µ—Ä—Ç - –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω–∞</li><li>–ü–µ—Ä–≤–∞—è –∑–∏–º–∞ AI (1970-–µ)</li></ul><blockquote>üí° "–ü–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω - —ç—Ç–æ –ø–µ—Ä–≤—ã–π —à–∞–≥ –∫ –º—ã—Å–ª—è—â–∏–º –º–∞—à–∏–Ω–∞–º" - –†–æ–∑–µ–Ω–±–ª–∞—Ç—Ç</blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 2. Backpropagation –∏ –≤—Ç–æ—Ä–∞—è –ø–æ–ø—ã—Ç–∫–∞ (1970-1986)</h2>
    <p><strong>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è</strong></p><ul><li>1974: Werbos - backpropagation (PhD thesis)</li><li>1982: Hopfield networks</li><li>1986: Rumelhart, Hinton, Williams - –ø–æ–ø—É–ª—è—Ä–∏–∑–∞—Ü–∏—è backprop</li><li>–ù–∞—á–∞–ª–æ –≤—Ç–æ—Ä–æ–π –≤–æ–ª–Ω—ã –∏–Ω—Ç–µ—Ä–µ—Å–∞ –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç—è–º</li></ul><pre><code># –ò–¥–µ—è backpropagation
# –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è—é—Ç—Å—è –Ω–∞–∑–∞–¥:
# Œ¥L/Œ¥w = (Œ¥L/Œ¥y) √ó (Œ¥y/Œ¥w)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 3. –ü—Ä–æ—Ä—ã–≤ –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö (1989-1998)</h2>
    <p><strong>LeNet –∏ –ø–µ—Ä–≤—ã–µ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —É—Å–ø–µ—Ö–∏</strong></p><ul><li>1989: LeCun - —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–µ —Å–µ—Ç–∏ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ü–∏—Ñ—Ä</li><li>1997: LSTM (Hochreiter & Schmidhuber)</li><li>1998: LeNet-5 - —á—Ç–µ–Ω–∏–µ —á–µ–∫–æ–≤ –≤ –±–∞–Ω–∫–∞—Ö</li><li>–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–µ –∑–∞—Ç—É—Ö–∞–Ω–∏–µ –≤—Å–µ –µ—â–µ –ø—Ä–æ–±–ª–µ–º–∞</li></ul><blockquote>üéØ LeNet-5 –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–ª–∞ –º–∏–ª–ª–∏–æ–Ω—ã —á–µ–∫–æ–≤ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ</blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 4. –í—Ç–æ—Ä–∞—è –∑–∏–º–∞ AI –∏ –¥—Ä—É–≥–∏–µ –ø–æ–¥—Ö–æ–¥—ã (1995-2005)</h2>
    <p><strong>–î–æ–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ SVM –∏ Random Forest</strong></p><ul><li>SVM –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –Ω–∞ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ –∑–∞–¥–∞—á</li><li>–ü—Ä–æ–±–ª–µ–º—ã –æ–±—É—á–µ–Ω–∏—è –≥–ª—É–±–æ–∫–∏—Ö —Å–µ—Ç–µ–π</li><li>–†–∞–∑–≤–∏—Ç–∏–µ kernel methods</li><li>–ù–µ–π—Ä–æ—Å–µ—Ç–∏ —Ç–µ—Ä—è—é—Ç –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å</li></ul><p><strong>–ü–æ—á–µ–º—É –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–ª–∏?</strong></p><ul><li>–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö</li><li>–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–π –º–æ—â–Ω–æ—Å—Ç–∏</li><li>–ü–ª–æ—Ö–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤</li><li>Gradient vanishing</li></ul>
  </div>

  <div class="block">
    <h2>üî∑ 5. Deep Learning Renaissance (2006-2012)</h2>
    <p><strong>–í–æ–∑—Ä–æ–∂–¥–µ–Ω–∏–µ —á–µ—Ä–µ–∑ unsupervised pretraining</strong></p><ul><li>2006: Hinton - Deep Belief Networks (DBN)</li><li>2006: Greedy layer-wise pretraining</li><li>2009: –í–≤–µ–¥–µ–Ω–∏–µ —Ç–µ—Ä–º–∏–Ω–∞ "Deep Learning"</li><li>2010: ReLU activation (Nair & Hinton)</li><li>2012: AlexNet –≤—ã–∏–≥—Ä—ã–≤–∞–µ—Ç ImageNet</li></ul><pre><code># ReLU - –ø—Ä–æ—Å—Ç–æ—Ç–∞ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
def relu(x):
    return max(0, x)</code></pre><blockquote>üöÄ AlexNet —Å–Ω–∏–∑–∏–ª –æ—à–∏–±–∫—É ImageNet —Å 26% –¥–æ 15%!</blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 6. ImageNet —ç—Ä–∞ (2012-2015)</h2>
    <p><strong>–†–µ–≤–æ–ª—é—Ü–∏—è –≤ computer vision</strong></p><ul><li>2012: AlexNet (Krizhevsky et al.) - –ø—Ä–æ—Ä—ã–≤</li><li>2013: ZFNet —É–ª—É—á—à–∞–µ—Ç AlexNet</li><li>2014: VGGNet (–æ—á–µ–Ω—å –≥–ª—É–±–æ–∫–∏–µ —Å–µ—Ç–∏)</li><li>2014: GoogLeNet (Inception modules)</li><li>2015: ResNet (skip connections) - 152 —Å–ª–æ—è!</li><li>2015: Batch Normalization</li></ul><p><strong>–ö–ª—é—á–µ–≤—ã–µ –∏–Ω–Ω–æ–≤–∞—Ü–∏–∏</strong>:</p><ul><li>GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ (CUDA)</li><li>Dropout regularization</li><li>Data augmentation</li><li>Transfer learning</li></ul>
  </div>

  <div class="block">
    <h2>üî∑ 7. RNN –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (2014-2017)</h2>
    <p><strong>–û—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∫ —è–∑—ã–∫—É</strong></p><ul><li>2014: Seq2seq (Sutskever et al.)</li><li>2014: Attention mechanism (Bahdanau et al.)</li><li>2015: Neural Machine Translation</li><li>2016: Google Neural Machine Translation</li><li>2016: WaveNet (—Å–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏)</li></ul><pre><code># Attention idea
context = sum(alpha_i * h_i)
where alpha_i = softmax(score(query, key_i))</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. Transformers —Ä–µ–≤–æ–ª—é—Ü–∏—è (2017-2020)</h2>
    <p><strong>"Attention is All You Need"</strong></p><ul><li>2017: Transformer (Vaswani et al.)</li><li>2018: BERT (Google) - bidirectional encoding</li><li>2018: GPT-1 (OpenAI) - autoregressive generation</li><li>2019: GPT-2 (1.5B parameters)</li><li>2019: ALBERT, RoBERTa, XLNet</li><li>2020: GPT-3 (175B parameters)</li></ul><blockquote>üî• Transformers –≤—ã—Ç–µ—Å–Ω–∏–ª–∏ RNN –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –≤–µ–∑–¥–µ</blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 9. Large Language Models (2020-2023)</h2>
    <p><strong>–≠—Ä–∞ –≥–∏–≥–∞–Ω—Ç—Å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π</strong></p><ul><li>2020: GPT-3 - few-shot learning</li><li>2021: DALL-E - text-to-image</li><li>2022: ChatGPT - –¥–∏–∞–ª–æ–≥–æ–≤—ã–π AI</li><li>2022: Stable Diffusion - –æ—Ç–∫—Ä—ã—Ç–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è</li><li>2023: GPT-4 - –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å</li><li>2023: LLaMA, Falcon - open-source LLM</li></ul><p><strong>Scaling laws</strong>:</p><ul><li>–ë–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö = –ª—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ</li><li>–ë–æ–ª—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ = –ª—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ</li><li>Emergence of abilities –ø—Ä–∏ scale-up</li></ul>
  </div>

  <div class="block">
    <h2>üî∑ 10. –°–æ–≤—Ä–µ–º–µ–Ω–Ω–æ—Å—Ç—å –∏ –±—É–¥—É—â–µ–µ (2023+)</h2>
    <p><strong>–¢–µ–∫—É—â–∏–µ —Ç—Ä–µ–Ω–¥—ã</strong></p><ul><li>–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: mixture of experts, sparse models</li><li>–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å: GPT-4V, Gemini</li><li>Alignment: RLHF, constitutional AI</li><li>Open source –¥–≤–∏–∂–µ–Ω–∏–µ: LLaMA, Mistral</li><li>Edge AI: –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è, –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏—è</li></ul><p><strong>–ë—É–¥—É—â–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è</strong>:</p><ul><li>AGI research</li><li>Embodied AI</li><li>Neuromorphic computing</li><li>–ö–≤–∞–Ω—Ç–æ–≤–æ–µ ML</li><li>–ë–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω—ã–µ —Å–µ—Ç–∏</li></ul><blockquote>üöÄ "–ú—ã —Ç–æ–ª—å–∫–æ –≤ –Ω–∞—á–∞–ª–µ –ø—É—Ç–∏" - Yann LeCun</blockquote>
  </div>


</div>

</body>
</html>
