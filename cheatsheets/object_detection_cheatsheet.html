<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>–î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

    .container {
      column-count: 3;
      column-gap: 20px;
      max-width: 100%;
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üì¶ –î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –ó–∞–¥–∞—á–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏</h2>
    <p><strong>Object Detection</strong> ‚Äî –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –∏ –∏—Ö bounding boxes –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.</p>
    
    <p><strong>–í—ã—Ö–æ–¥ –º–æ–¥–µ–ª–∏:</strong></p>
    <ul>
      <li><strong>Bounding box</strong>: (x, y, w, h) –∏–ª–∏ (x1, y1, x2, y2)</li>
      <li><strong>–ö–ª–∞—Å—Å –æ–±—ä–µ–∫—Ç–∞</strong>: "—á–µ–ª–æ–≤–µ–∫", "–º–∞—à–∏–Ω–∞", –∏ —Ç.–¥.</li>
      <li><strong>Confidence score</strong>: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–µ—Ç–µ–∫—Ü–∏–∏</li>
    </ul>
    
    <p><strong>–ú–µ—Ç—Ä–∏–∫–∏:</strong></p>
    <ul>
      <li><strong>mAP</strong> (mean Average Precision) ‚Äî –æ—Å–Ω–æ–≤–Ω–∞—è</li>
      <li><strong>IoU</strong> (Intersection over Union) ‚Äî –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –±–æ–∫—Å–æ–≤</li>
      <li><strong>FPS</strong> ‚Äî —Å–∫–æ—Ä–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 2. –°–µ–º–µ–π—Å—Ç–≤–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤</h2>
    <table>
      <tr><th>–¢–∏–ø</th><th>–ê–ª–≥–æ—Ä–∏—Ç–º—ã</th><th>–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å</th></tr>
      <tr><td><strong>Two-stage</strong></td><td>R-CNN, Fast R-CNN, Faster R-CNN</td><td>–í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å, –º–µ–¥–ª–µ–Ω–Ω–æ</td></tr>
      <tr><td><strong>One-stage</strong></td><td>YOLO, SSD, RetinaNet</td><td>–ë—ã—Å—Ç—Ä–æ, lower accuracy</td></tr>
      <tr><td><strong>Anchor-free</strong></td><td>CenterNet, FCOS</td><td>–ë–µ–∑ anchor boxes</td></tr>
      <tr><td><strong>Transformer</strong></td><td>DETR, Deformable DETR</td><td>–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 3. Faster R-CNN</h2>
    <p><strong>–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:</strong></p>
    <ol>
      <li><strong>Backbone</strong>: ResNet/VGG –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</li>
      <li><strong>RPN</strong> (Region Proposal Network): –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π</li>
      <li><strong>RoI Pooling</strong>: –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Ä–µ–≥–∏–æ–Ω–æ–≤</li>
      <li><strong>Head</strong>: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è + —Ä–µ–≥—Ä–µ—Å—Å–∏—è bbox</li>
    </ol>
    
    <p><strong>Region Proposal Network (RPN):</strong></p>
    <ul>
      <li>–°–∫–æ–ª—å–∑—è—â–µ–µ –æ–∫–Ω–æ –ø–æ feature map</li>
      <li>9 anchor boxes —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤/—Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–π</li>
      <li>–ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: –æ–±—ä–µ–∫—Ç/—Ñ–æ–Ω</li>
      <li>–†–µ–≥—Ä–µ—Å—Å–∏—è bbox –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 4. Faster R-CNN –∫–æ–¥</h2>
    <pre><code>import torchvision
from torchvision.models.detection import fasterrcnn_resnet50_fpn

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
model = fasterrcnn_resnet50_fpn(pretrained=True)
model.eval()

# Inference
import torch
from PIL import Image
import torchvision.transforms as T

image = Image.open('image.jpg')
transform = T.Compose([T.ToTensor()])
image_tensor = transform(image)

with torch.no_grad():
    predictions = model([image_tensor])

# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
boxes = predictions[0]['boxes']     # –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
labels = predictions[0]['labels']   # –∫–ª–∞—Å—Å—ã
scores = predictions[0]['scores']   # —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å

# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ threshold
threshold = 0.5
keep = scores > threshold
boxes = boxes[keep]
labels = labels[keep]
scores = scores[keep]</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. –û–±—É—á–µ–Ω–∏–µ Faster R-CNN</h2>
    <pre><code>from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torch.utils.data import DataLoader

# –ú–æ–¥–µ–ª—å —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∫–ª–∞—Å—Å–æ–≤
num_classes = 91  # COCO: 80 + background
model = fasterrcnn_resnet50_fpn(
    pretrained=True,
    num_classes=num_classes
)

# –ó–∞–º–µ–Ω–∞ head –¥–ª—è —Å–≤–æ–∏—Ö –∫–ª–∞—Å—Å–æ–≤
num_classes = 10  # –≤–∞—à–∏ –∫–ª–∞—Å—Å—ã + background
in_features = model.roi_heads.box_predictor.cls_score.in_features
model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

# Optimizer
params = [p for p in model.parameters() if p.requires_grad]
optimizer = torch.optim.SGD(
    params,
    lr=0.005,
    momentum=0.9,
    weight_decay=0.0005
)

# Training loop
model.train()
for epoch in range(num_epochs):
    for images, targets in dataloader:
        # targets = [{'boxes': ..., 'labels': ...}, ...]
        
        loss_dict = model(images, targets)
        losses = sum(loss for loss in loss_dict.values())
        
        optimizer.zero_grad()
        losses.backward()
        optimizer.step()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. SSD (Single Shot Detector)</h2>
    <p><strong>–û—Å–Ω–æ–≤–Ω–∞—è –∏–¥–µ—è:</strong> –¥–µ—Ç–µ–∫—Ü–∏—è –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –º–∞—Å—à—Ç–∞–±–∞—Ö feature maps.</p>
    
    <p><strong>–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:</strong></p>
    <ul>
      <li><strong>Base network</strong>: VGG16 –∏–ª–∏ ResNet</li>
      <li><strong>Multi-scale feature maps</strong>: 6 —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤</li>
      <li><strong>Default boxes</strong>: anchor boxes —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤</li>
      <li><strong>Prediction heads</strong>: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è + bbox –Ω–∞ –∫–∞–∂–¥–æ–º —É—Ä–æ–≤–Ω–µ</li>
    </ul>
    
    <p><strong>–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:</strong></p>
    <ul>
      <li>–ë—ã—Å—Ç—Ä–µ–µ Faster R-CNN (59 FPS vs 7 FPS)</li>
      <li>–î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤</li>
      <li>–ü—Ä–æ—Å—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞</li>
    </ul>
    
    <p><strong>–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:</strong></p>
    <ul>
      <li>–•—É–∂–µ –Ω–∞ –º–∞–ª—ã—Ö –æ–±—ä–µ–∫—Ç–∞—Ö</li>
      <li>–¢—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ anchor boxes</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 7. SSD –∫–æ–¥</h2>
    <pre><code>import torchvision
from torchvision.models.detection import ssd300_vgg16

# –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
model = ssd300_vgg16(pretrained=True)
model.eval()

# Inference
predictions = model([image_tensor])

# –î–ª—è –æ–±—É—á–µ–Ω–∏—è
model = ssd300_vgg16(
    pretrained=True,
    num_classes=num_classes
)

# –ó–∞–º–µ–Ω–∞ head
in_channels = model.head.classification_head.in_channels
num_anchors = model.head.classification_head.num_anchors

model.head.classification_head = SSDClassificationHead(
    in_channels=in_channels,
    num_anchors=num_anchors,
    num_classes=num_classes
)

# Training –∫–∞–∫ –≤ Faster R-CNN
optimizer = torch.optim.SGD(
    model.parameters(),
    lr=0.001,
    momentum=0.9,
    weight_decay=0.0005
)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. RetinaNet</h2>
    <p><strong>Focal Loss</strong> ‚Äî —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É class imbalance:</p>
    <pre><code>FL(p_t) = -(1 - p_t)^Œ≥ * log(p_t)

–≥–¥–µ:
- p_t - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞
- Œ≥ - focusing parameter (–æ–±—ã—á–Ω–æ 2)</code></pre>
    
    <p><strong>–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:</strong></p>
    <ul>
      <li><strong>Backbone</strong>: ResNet + FPN (Feature Pyramid Network)</li>
      <li><strong>Two subnetworks</strong>: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏ bbox —Ä–µ–≥—Ä–µ—Å—Å–∏—è</li>
      <li><strong>Anchor boxes</strong>: 9 –Ω–∞ –∫–∞–∂–¥–æ–π –ø–æ–∑–∏—Ü–∏–∏</li>
    </ul>
    
    <p><strong>Feature Pyramid Network (FPN):</strong></p>
    <ul>
      <li>–ö–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç –Ω–∏–∑–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–µ –∏ –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏</li>
      <li>Top-down pathway + lateral connections</li>
      <li>–£–ª—É—á—à–∞–µ—Ç –¥–µ—Ç–µ–∫—Ü–∏—é –º–∞–ª—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 9. RetinaNet –∫–æ–¥</h2>
    <pre><code># –¢—Ä–µ–±—É–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏ detectron2
# pip install detectron2

from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
cfg = get_cfg()
cfg.merge_from_file(
    model_zoo.get_config_file(
        "COCO-Detection/retinanet_R_50_FPN_3x.yaml"
    )
)
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(
    "COCO-Detection/retinanet_R_50_FPN_3x.yaml"
)
cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.5

# Predictor
predictor = DefaultPredictor(cfg)

# Inference
import cv2
image = cv2.imread('image.jpg')
predictions = predictor(image)

# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
instances = predictions['instances']
boxes = instances.pred_boxes.tensor.cpu().numpy()
scores = instances.scores.cpu().numpy()
classes = instances.pred_classes.cpu().numpy()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. Non-Maximum Suppression (NMS)</h2>
    <p><strong>NMS</strong> ‚Äî —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è –¥–µ—Ç–µ–∫—Ü–∏–π:</p>
    
    <p><strong>–ê–ª–≥–æ—Ä–∏—Ç–º:</strong></p>
    <ol>
      <li>–°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å boxes –ø–æ confidence score</li>
      <li>–í—ã–±—Ä–∞—Ç—å box —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º score</li>
      <li>–£–¥–∞–ª–∏—Ç—å –≤—Å–µ boxes —Å IoU > threshold (0.5)</li>
      <li>–ü–æ–≤—Ç–æ—Ä–∏—Ç—å –¥–ª—è –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è</li>
    </ol>
    
    <pre><code>from torchvision.ops import nms

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ NMS
keep_indices = nms(
    boxes,              # (N, 4)
    scores,             # (N,)
    iou_threshold=0.5
)

boxes = boxes[keep_indices]
scores = scores[keep_indices]
labels = labels[keep_indices]

# Soft-NMS (–±–æ–ª–µ–µ –º—è–≥–∫–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ)
from torchvision.ops import batched_nms

keep = batched_nms(
    boxes,
    scores,
    labels,
    iou_threshold=0.5
)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. IoU (Intersection over Union)</h2>
    <p><strong>IoU</strong> ‚Äî –º–µ—Ç—Ä–∏–∫–∞ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è bbox:</p>
    <pre><code>IoU = Area(A ‚à© B) / Area(A ‚à™ B)

# –†–µ–∞–ª–∏–∑–∞—Ü–∏—è
def calculate_iou(box1, box2):
    # box format: [x1, y1, x2, y2]
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])
    
    intersection = max(0, x2 - x1) * max(0, y2 - y1)
    
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    union = area1 + area2 - intersection
    
    return intersection / union if union > 0 else 0

# PyTorch –≤–µ—Ä—Å–∏—è
from torchvision.ops import box_iou

iou_matrix = box_iou(boxes1, boxes2)  # (N, M)</code></pre>
    
    <p><strong>–í–∞—Ä–∏–∞–Ω—Ç—ã IoU:</strong></p>
    <ul>
      <li><strong>GIoU</strong> (Generalized): —É—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –±–æ–∫—Å–∞–º–∏</li>
      <li><strong>DIoU</strong> (Distance): –¥–æ–±–∞–≤–ª—è–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ —Ü–µ–Ω—Ç—Ä–æ–≤</li>
      <li><strong>CIoU</strong> (Complete): + aspect ratio</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 12. mAP –º–µ—Ç—Ä–∏–∫–∞</h2>
    <p><strong>mean Average Precision</strong> ‚Äî –æ—Å–Ω–æ–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏:</p>
    
    <p><strong>–í—ã—á–∏—Å–ª–µ–Ω–∏–µ:</strong></p>
    <ol>
      <li>–î–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞:
        <ul>
          <li>–°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø–æ confidence</li>
          <li>–í—ã—á–∏—Å–ª–∏—Ç—å Precision –∏ Recall</li>
          <li>–ü–æ—Å—Ç—Ä–æ–∏—Ç—å PR-–∫—Ä–∏–≤—É—é</li>
          <li>AP = –ø–ª–æ—â–∞–¥—å –ø–æ–¥ –∫—Ä–∏–≤–æ–π</li>
        </ul>
      </li>
      <li>mAP = —Å—Ä–µ–¥–Ω–µ–µ AP –ø–æ –≤—Å–µ–º –∫–ª–∞—Å—Å–∞–º</li>
    </ol>
    
    <p><strong>mAP –≤–∞—Ä–∏–∞–Ω—Ç—ã:</strong></p>
    <ul>
      <li><strong>mAP@0.5</strong>: IoU threshold = 0.5</li>
      <li><strong>mAP@0.75</strong>: IoU threshold = 0.75</li>
      <li><strong>mAP@[0.5:0.95]</strong>: —Å—Ä–µ–¥–Ω–µ–µ –ø–æ IoU –æ—Ç 0.5 –¥–æ 0.95</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 13. Data Augmentation</h2>
    <p><strong>–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏</strong> –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏:</p>
    <pre><code>import albumentations as A

transform = A.Compose([
    # Geometric
    A.HorizontalFlip(p=0.5),
    A.RandomRotate90(p=0.5),
    A.ShiftScaleRotate(
        shift_limit=0.0625,
        scale_limit=0.1,
        rotate_limit=15,
        p=0.5
    ),
    
    # Color
    A.RandomBrightnessContrast(p=0.3),
    A.HueSaturationValue(p=0.3),
    
    # Blur/Noise
    A.GaussianBlur(p=0.2),
    A.GaussNoise(p=0.2),
    
    # Cutout/Mixup
    A.CoarseDropout(
        max_holes=8,
        max_height=32,
        max_width=32,
        p=0.2
    ),
    
    # Normalize
    A.Normalize(mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225])
], bbox_params=A.BboxParams(
    format='pascal_voc',  # [x1, y1, x2, y2]
    label_fields=['class_labels']
))

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ
transformed = transform(
    image=image,
    bboxes=bboxes,
    class_labels=labels
)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 14. EfficientDet</h2>
    <p><strong>–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞</strong> –Ω–∞ –±–∞–∑–µ EfficientNet:</p>
    
    <p><strong>–ö–ª—é—á–µ–≤—ã–µ –∏–¥–µ–∏:</strong></p>
    <ul>
      <li><strong>BiFPN</strong> (Bidirectional FPN): —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Å–ª–∏—è–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</li>
      <li><strong>Compound scaling</strong>: —Å–æ–≤–º–µ—Å—Ç–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ backbone, BiFPN, head</li>
      <li><strong>EfficientNet backbone</strong>: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Å–≤–µ—Ä—Ç–æ—á–Ω–∞—è —Å–µ—Ç—å</li>
    </ul>
    
    <p><strong>–í–∞—Ä–∏–∞–Ω—Ç—ã:</strong></p>
    <table>
      <tr><th>–ú–æ–¥–µ–ª—å</th><th>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã</th><th>mAP</th><th>FPS</th></tr>
      <tr><td>EfficientDet-D0</td><td>3.9M</td><td>33.8</td><td>98</td></tr>
      <tr><td>EfficientDet-D3</td><td>12.0M</td><td>45.8</td><td>15</td></tr>
      <tr><td>EfficientDet-D7</td><td>52.0M</td><td>52.2</td><td>5</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 15. Anchor boxes</h2>
    <p><strong>Anchor boxes</strong> ‚Äî –ø—Ä–µ–¥–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ bbox —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤:</p>
    
    <p><strong>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:</strong></p>
    <ul>
      <li><strong>Sizes</strong>: [32, 64, 128, 256, 512] –ø–∏–∫—Å–µ–ª–µ–π</li>
      <li><strong>Aspect ratios</strong>: [0.5, 1.0, 2.0]</li>
      <li><strong>Scales</strong>: [1.0, 1.26, 1.59]</li>
    </ul>
    
    <p><strong>–ì–µ–Ω–µ—Ä–∞—Ü–∏—è anchors:</strong></p>
    <pre><code>import torch

def generate_anchors(sizes, ratios, scales):
    anchors = []
    for size in sizes:
        for ratio in ratios:
            h = size / torch.sqrt(torch.tensor(ratio))
            w = size * torch.sqrt(torch.tensor(ratio))
            
            for scale in scales:
                anchors.append([
                    -w * scale / 2,
                    -h * scale / 2,
                    w * scale / 2,
                    h * scale / 2
                ])
    
    return torch.tensor(anchors)

# –ü—Ä–∏–º–µ—Ä
sizes = [32, 64, 128]
ratios = [0.5, 1.0, 2.0]
scales = [1.0, 1.26, 1.59]

anchors = generate_anchors(sizes, ratios, scales)
# Shape: (27, 4) - 3 sizes √ó 3 ratios √ó 3 scales</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 16. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏</h3>
        <ul>
          <li><strong>–ù–∞—á–Ω–∏—Ç–µ —Å Faster R-CNN</strong> –¥–ª—è –≤—ã—Å–æ–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏</li>
          <li><strong>YOLO/SSD</strong> –¥–ª—è real-time –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π</li>
          <li><strong>Transfer learning</strong> —Å COCO –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏–µ–º</li>
          <li><strong>Data augmentation</strong> –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞</li>
          <li><strong>NMS threshold</strong>: 0.5 –¥–ª—è –ø–ª–æ—Ç–Ω—ã—Ö —Å—Ü–µ–Ω</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ö†Ô∏è –ß–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏</h3>
        <ul>
          <li>–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç bbox (x,y,w,h vs x1,y1,x2,y2)</li>
          <li>–ó–∞–±—ã–ª–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã</li>
          <li>–°–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏–π confidence threshold</li>
          <li>–ù–µ —É—á–ª–∏ aspect ratio –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 17. Inference optimization</h2>
    <p><strong>–£—Å–∫–æ—Ä–µ–Ω–∏–µ inference:</strong></p>
    <ul>
      <li><strong>TensorRT</strong>: –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è NVIDIA GPU</li>
      <li><strong>ONNX</strong>: —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç</li>
      <li><strong>Pruning</strong>: —É–¥–∞–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤</li>
      <li><strong>Quantization</strong>: FP16 –∏–ª–∏ INT8</li>
      <li><strong>Batch inference</strong>: –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π</li>
    </ul>
    
    <pre><code># –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX
torch.onnx.export(
    model,
    dummy_input,
    'model.onnx',
    input_names=['image'],
    output_names=['boxes', 'labels', 'scores'],
    dynamic_axes={
        'image': {0: 'batch_size'},
        'boxes': {0: 'batch_size'},
    }
)

# TensorRT –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
import tensorrt as trt
# ... TensorRT conversion code ...</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 18. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –í—ã–±—Ä–∞–ª–∏ –∞–ª–≥–æ—Ä–∏—Ç–º (Faster R-CNN / SSD / YOLO)</li>
      <li>[ ] –ü–æ–¥–≥–æ—Ç–æ–≤–∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ</li>
      <li>[ ] –ü—Ä–∏–º–µ–Ω–∏–ª–∏ data augmentation</li>
      <li>[ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ transfer learning</li>
      <li>[ ] –ù–∞—Å—Ç—Ä–æ–∏–ª–∏ anchor boxes –ø–æ–¥ —Å–≤–æ—é –∑–∞–¥–∞—á—É</li>
      <li>[ ] –ü–æ–¥–æ–±—Ä–∞–ª–∏ NMS threshold</li>
      <li>[ ] –ù–∞—Å—Ç—Ä–æ–∏–ª–∏ confidence threshold</li>
      <li>[ ] –í—ã—á–∏—Å–ª–∏–ª–∏ mAP –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏</li>
      <li>[ ] –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–ª–∏ –¥–ª—è inference (ONNX/TensorRT)</li>
      <li>[ ] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–ª–∏ –Ω–∞ edge cases</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´–î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ ‚Äî —ç—Ç–æ –∫–∞–∫ –Ω–∞—É—á–∏—Ç—å –∫–æ–º–ø—å—é—Ç–µ—Ä –Ω–∞—Ö–æ–¥–∏—Ç—å –∏ –æ–±–≤–æ–¥–∏—Ç—å —Ä–∞–º–∫–∞–º–∏ –Ω—É–∂–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –Ω–∞ —Ñ–æ—Ç–æ. Faster R-CNN —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ—á–Ω–µ–µ, –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ (–¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞), –∞ YOLO –±—ã—Å—Ç—Ä–µ–µ, –Ω–æ —á—É—Ç—å –º–µ–Ω–µ–µ —Ç–æ—á–µ–Ω (–¥–ª—è –≤–∏–¥–µ–æ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏)¬ª.
    </blockquote>
  </div>

</div>

</body>
</html>
