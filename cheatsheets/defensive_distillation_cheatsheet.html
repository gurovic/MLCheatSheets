<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>Defensive Distillation Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

    .container {
      column-count: 3;
      column-gap: 20px;
      max-width: 100%;
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üõ°Ô∏è Defensive Distillation</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –°—É—Ç—å –º–µ—Ç–æ–¥–∞</h2>
    <ul>
      <li><strong>Defensive Distillation</strong>: —Ç–µ—Ö–Ω–∏–∫–∞ –∑–∞—â–∏—Ç—ã –æ—Ç adversarial –ø—Ä–∏–º–µ—Ä–æ–≤</li>
      <li><strong>–û—Å–Ω–æ–≤–∞</strong>: knowledge distillation —Å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–æ–π</li>
      <li><strong>–ò–¥–µ—è</strong>: —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –º–æ–¥–µ–ª–∏</li>
      <li><strong>–†–µ–∑—É–ª—å—Ç–∞—Ç</strong>: —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ gradient-based –∞—Ç–∞–∫–∞–º</li>
    </ul>
    <blockquote>
      –ú–µ—Ç–æ–¥ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ "–º—è–≥–∫–∏—Ö" –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è—Ö –≤–º–µ—Å—Ç–æ –∂—ë—Å—Ç–∫–∏—Ö –º–µ—Ç–æ–∫.
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 2. –ü—Ä–æ–±–ª–µ–º–∞ adversarial –ø—Ä–∏–º–µ—Ä–æ–≤</h2>
    <p><strong>Adversarial –∞—Ç–∞–∫–∏</strong>:</p>
    <ul>
      <li>–ú–∞–ª—ã–µ –≤–æ–∑–º—É—â–µ–Ω–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö</li>
      <li>–ò–∑–º–µ–Ω—è—é—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏</li>
      <li>–ù–µ–∑–∞–º–µ—Ç–Ω—ã –¥–ª—è —á–µ–ª–æ–≤–µ–∫–∞</li>
      <li>–≠–∫—Å–ø–ª—É–∞—Ç–∏—Ä—É—é—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã</li>
    </ul>

    <pre><code># –ü—Ä–∏–º–µ—Ä FGSM –∞—Ç–∞–∫–∏
perturbation = Œµ * sign(‚àá_x L(Œ∏, x, y))
x_adv = x + perturbation

# –ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–µ–≤–µ—Ä–Ω–æ –Ω–∞ x_adv</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 3. Knowledge Distillation</h2>
    <p><strong>–û–±—ã—á–Ω–∞—è –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏—è</strong>:</p>
    <ul>
      <li>Teacher model (–±–æ–ª—å—à–∞—è –º–æ–¥–µ–ª—å)</li>
      <li>Student model (–º–∞–ª–µ–Ω—å–∫–∞—è –º–æ–¥–µ–ª—å)</li>
      <li>–ü–µ—Ä–µ–¥–∞—á–∞ "—Ç—ë–º–Ω–æ–≥–æ –∑–Ω–∞–Ω–∏—è"</li>
    </ul>

    <pre><code># Softmax —Å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–æ–π
def softmax_with_temperature(logits, T):
    return softmax(logits / T)

# Loss –¥–ª—è distillation
L = Œ±L_hard + (1-Œ±)L_soft_kl</code></pre>

    <table>
      <tr><th>–ü–∞—Ä–∞–º–µ—Ç—Ä</th><th>–ó–Ω–∞—á–µ–Ω–∏–µ</th></tr>
      <tr><td>–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ T</td><td>–û–±—ã—á–Ω–æ 20-100</td></tr>
      <tr><td>Œ± (–≤–µ—Å hard loss)</td><td>0.1 - 0.3</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 4. Defensive Distillation –ø—Ä–æ—Ü–µ—Å—Å</h2>
    <p><strong>–≠—Ç–∞–ø 1: –û–±—É—á–µ–Ω–∏–µ teacher</strong>:</p>
    <pre><code># –û–±—É—á–∞–µ–º –ø–µ—Ä–≤—É—é –º–æ–¥–µ–ª—å —Å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–æ–π
teacher = Model()
for x, y in data:
    logits = teacher(x)
    probs = softmax(logits / T)
    loss = cross_entropy(probs, y)
    optimize(loss)</code></pre>

    <p><strong>–≠—Ç–∞–ø 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è soft labels</strong>:</p>
    <pre><code># –ü–æ–ª—É—á–∞–µ–º –º—è–≥–∫–∏–µ –º–µ—Ç–∫–∏ –æ—Ç teacher
soft_labels = []
for x in data:
    logits = teacher(x)
    soft_labels.append(softmax(logits / T))</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. –û–±—É—á–µ–Ω–∏–µ –∑–∞—â–∏—â—ë–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏</h2>
    <p><strong>–≠—Ç–∞–ø 3: Distillation</strong>:</p>
    <pre><code># –û–±—É—á–∞–µ–º student –Ω–∞ soft labels
student = Model()
for x, soft_y in zip(data, soft_labels):
    logits = student(x)
    probs = softmax(logits / T)
    
    # KL divergence loss
    loss = KL(probs || soft_y)
    optimize(loss)

# Inference –±–µ–∑ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã
predictions = softmax(student(x) / 1.0)</code></pre>

    <blockquote>
      –ö–ª—é—á–µ–≤–∞—è –∏–¥–µ—è: –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è—Ö –¥–µ–ª–∞–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –º–µ–Ω–µ–µ —Ä–µ–∑–∫–∏–º–∏.
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 6. –ü–æ—á–µ–º—É —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç</h2>
    <ul>
      <li><strong>Gradient masking</strong>: –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –º–µ–Ω—å—à–µ</li>
      <li><strong>Smoother decision boundaries</strong>: –≥—Ä–∞–Ω–∏—Ü—ã —Ä–µ—à–µ–Ω–∏–π —Å–≥–ª–∞–∂–∏–≤–∞—é—Ç—Å—è</li>
      <li><strong>–ú–µ–Ω—å—à–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏</strong>: –º–æ–¥–µ–ª—å –Ω–µ –¥–∞—ë—Ç —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π</li>
      <li><strong>–õ—É—á—à–µ–µ –æ–±–æ–±—â–µ–Ω–∏–µ</strong>: —É—á—ë—Ç –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤</li>
    </ul>

    <table>
      <tr><th>–°–≤–æ–π—Å—Ç–≤–æ</th><th>–î–æ</th><th>–ü–æ—Å–ª–µ</th></tr>
      <tr><td>Max prob</td><td>~0.999</td><td>~0.85</td></tr>
      <tr><td>||‚àáL||</td><td>–ë–æ–ª—å—à–æ–π</td><td>–ú–∞–ª—ã–π</td></tr>
      <tr><td>Robustness</td><td>–ù–∏–∑–∫–∞—è</td><td>–í—ã—Å–æ–∫–∞—è</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 7. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –≤ PyTorch</h2>
    <pre><code>import torch
import torch.nn as nn
import torch.nn.functional as F

class DefensiveDistillation:
    def __init__(self, model, T=20):
        self.teacher = model
        self.student = copy.deepcopy(model)
        self.T = T
    
    def train_teacher(self, train_loader):
        for x, y in train_loader:
            logits = self.teacher(x)
            loss = F.cross_entropy(
                logits / self.T, y
            )
            loss.backward()
            optimizer.step()
    
    def distill(self, train_loader):
        for x, _ in train_loader:
            # Teacher soft labels
            with torch.no_grad():
                teacher_logits = self.teacher(x)
                soft_labels = F.softmax(
                    teacher_logits / self.T, dim=1
                )
            
            # Student training
            student_logits = self.student(x)
            student_probs = F.softmax(
                student_logits / self.T, dim=1
            )
            
            loss = F.kl_div(
                student_probs.log(),
                soft_labels,
                reduction='batchmean'
            )
            loss.backward()
            optimizer.step()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø—Ä–æ—Ç–∏–≤ –∞—Ç–∞–∫</h2>
    <table>
      <tr><th>–ê—Ç–∞–∫–∞</th><th>Baseline</th><th>Defensive Distillation</th></tr>
      <tr><td>FGSM</td><td>~90% —É—Å–ø–µ—Ö</td><td>~5% —É—Å–ø–µ—Ö</td></tr>
      <tr><td>BIM</td><td>~95% —É—Å–ø–µ—Ö</td><td>~10% —É—Å–ø–µ—Ö</td></tr>
      <tr><td>C&W</td><td>~98% —É—Å–ø–µ—Ö</td><td>~40% —É—Å–ø–µ—Ö</td></tr>
      <tr><td>PGD</td><td>~95% —É—Å–ø–µ—Ö</td><td>~30% —É—Å–ø–µ—Ö</td></tr>
    </table>

    <blockquote>
      Defensive distillation –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞ –ø—Ä–æ—Ç–∏–≤ gradient-based –∞—Ç–∞–∫.
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 9. –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –º–µ—Ç–æ–¥–∞</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞</h3>
        <ul>
          <li>–ü—Ä–æ—Å—Ç–æ—Ç–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏</li>
          <li>–ú–∞–ª—ã–µ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞—Ç—Ä–∞—Ç—ã</li>
          <li>–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏</li>
          <li>–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø—Ä–æ—Ç–∏–≤ FGSM/BIM</li>
        </ul>
      </div>
      
      <div class="bad">
        <h3>‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏</h3>
        <ul>
          <li>–ù–µ –∑–∞—â–∏—â–∞–µ—Ç –æ—Ç C&W –∞—Ç–∞–∫</li>
          <li>Gradient obfuscation –ø—Ä–æ–±–ª–µ–º–∞</li>
          <li>–£—è–∑–≤–∏–º –∫ adaptive attacks</li>
          <li>–õ–æ–∂–Ω–æ–µ —á—É–≤—Å—Ç–≤–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 10. –£–ª—É—á—à–µ–Ω–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã</h2>
    <p><strong>Ensemble distillation</strong>:</p>
    <ul>
      <li>–ù–µ—Å–∫–æ–ª—å–∫–æ teacher –º–æ–¥–µ–ª–µ–π</li>
      <li>–£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ soft labels</li>
      <li>–ë–æ–ª—å—à–∞—è —Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—å</li>
    </ul>

    <p><strong>Adversarial distillation</strong>:</p>
    <pre><code># –ö–æ–º–±–∏–Ω–∞—Ü–∏—è —Å adversarial training
for x, y in data:
    # Clean examples
    loss_clean = distillation_loss(x, y)
    
    # Adversarial examples
    x_adv = generate_adversarial(x)
    loss_adv = distillation_loss(x_adv, y)
    
    loss = loss_clean + Œª * loss_adv</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã</h2>
    <table>
      <tr><th>–ü–∞—Ä–∞–º–µ—Ç—Ä</th><th>–¢–∏–ø–∏—á–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ</th><th>–í–ª–∏—è–Ω–∏–µ</th></tr>
      <tr><td>–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ T</td><td>20-100</td><td>–°—Ç–µ–ø–µ–Ω—å —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è</td></tr>
      <tr><td>Learning rate</td><td>0.001-0.01</td><td>–°–∫–æ—Ä–æ—Å—Ç—å —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏</td></tr>
      <tr><td>Epochs</td><td>50-200</td><td>–ö–∞—á–µ—Å—Ç–≤–æ –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏</td></tr>
      <tr><td>Batch size</td><td>64-256</td><td>–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è</td></tr>
    </table>

    <blockquote>
      –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∑–∞–¥–∞—á–∏ –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏.
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 12. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã</h2>
    <ul>
      <li><strong>–í—ã–±–æ—Ä T</strong>: –Ω–∞—á–Ω–∏—Ç–µ —Å T=20, —É–≤–µ–ª–∏—á–∏–≤–∞–π—Ç–µ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏</li>
      <li><strong>–í–∞–ª–∏–¥–∞—Ü–∏—è</strong>: –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ –Ω–∞ adversarial –ø—Ä–∏–º–µ—Ä–∞—Ö</li>
      <li><strong>–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ</strong>: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å –¥—Ä—É–≥–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –∑–∞—â–∏—Ç—ã</li>
      <li><strong>–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥</strong>: —Å–ª–µ–¥–∏—Ç–µ –∑–∞ accuracy –Ω–∞ —á–∏—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö</li>
      <li><strong>Adaptive attacks</strong>: —Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –Ω–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –∞—Ç–∞–∫–∞—Ö</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 13. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞–º–∏</h2>
    <table>
      <tr><th>–ú–µ—Ç–æ–¥</th><th>–†–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—å</th><th>Accuracy</th><th>–°–∫–æ—Ä–æ—Å—Ç—å</th></tr>
      <tr><td>Defensive Distillation</td><td>–°—Ä–µ–¥–Ω—è—è</td><td>–í—ã—Å–æ–∫–∞—è</td><td>–ë—ã—Å—Ç—Ä–æ</td></tr>
      <tr><td>Adversarial Training</td><td>–í—ã—Å–æ–∫–∞—è</td><td>–°—Ä–µ–¥–Ω—è—è</td><td>–ú–µ–¥–ª–µ–Ω–Ω–æ</td></tr>
      <tr><td>Input Transformation</td><td>–ù–∏–∑–∫–∞—è</td><td>–í—ã—Å–æ–∫–∞—è</td><td>–ë—ã—Å—Ç—Ä–æ</td></tr>
      <tr><td>Certified Defense</td><td>–ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è</td><td>–ù–∏–∑–∫–∞—è</td><td>–ú–µ–¥–ª–µ–Ω–Ω–æ</td></tr>
    </table>
  </div>

</div>

</body>
</html>
