<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>Information Bottleneck Theory Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

        .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üîç Information Bottleneck Theory</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –û—Å–Ω–æ–≤–Ω–∞—è –∏–¥–µ—è</h2>
    <p><strong>Information Bottleneck (IB):</strong> –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Å–∂–∞—Ç–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ X –≤ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ T, —Å–æ—Ö—Ä–∞–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–ª—è Y.</p>
    <pre><code>–¶–µ–ª—å: –Ω–∞–π—Ç–∏ T, –∫–æ—Ç–æ—Ä—ã–π:
1. –ú–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ—Ç I(T; Y) - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ü–µ–ª–∏
2. –ú–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ—Ç I(T; X) - —Å–∂–∞—Ç–∏–µ –≤—Ö–æ–¥–∞

L_IB = I(T; Y) - Œ≤¬∑I(T; X)

–≥–¥–µ Œ≤ - tradeoff parameter</code></pre>

  <div class="block">
    <h2>üî∑ 2. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞</h2>
    <p><strong>Markov chain:</strong> X ‚Üí T ‚Üí ≈∂</p>
    <ul>
      <li><strong>X</strong>: –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ</li>
      <li><strong>T</strong>: –°–∫—Ä—ã—Ç–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ (hidden layer)</li>
      <li><strong>Y</strong>: –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è</li>
      <li><strong>I(T;Y)</strong>: –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏–ª–∞</li>
      <li><strong>I(T;X)</strong>: –°–ª–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è</li>
    </ul>
    <blockquote>
      –•–æ—Ä–æ—à–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∫—Ä–∏–≤–æ–π IB: –º–∏–Ω–∏–º—É–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ X, –º–∞–∫—Å–∏–º—É–º –æ Y
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 3. –§–∞–∑—ã –æ–±—É—á–µ–Ω–∏—è (Tishby, 2017)</h2>
    <table>
      <tr><th>–§–∞–∑–∞</th><th>–ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç</th><th>I(T;X)</th><th>I(T;Y)</th></tr>
      <tr><td><strong>1. Fitting</strong></td><td>–ó–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö</td><td>‚Üë –†–∞—Å—Ç—ë—Ç</td><td>‚Üë –†–∞—Å—Ç—ë—Ç</td></tr>
      <tr><td><strong>2. Compression</strong></td><td>–°–∂–∞—Ç–∏–µ, –∑–∞–±—ã–≤–∞–Ω–∏–µ –ª–∏—à–Ω–µ–≥–æ</td><td>‚Üì –ü–∞–¥–∞–µ—Ç</td><td>‚Üí –°—Ç–∞–±–∏–ª—å–Ω–æ</td></tr>
    </table>
    <p><strong>–ò–Ω—Å–∞–π—Ç:</strong> –ì–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—è = compression —Ñ–∞–∑–∞!</p>
  </div>

  <div class="block">
    <h2>üî∑ 4. Information Plane</h2>
    <p><strong>–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è:</strong></p>
    <pre><code>I(T;Y)  ‚ñ≤
        |     / (–æ–ø—Ç–∏–º–∞–ª—å–Ω–∞—è IB –∫—Ä–∏–≤–∞—è)
        |    /
        |   /‚Ä¢  ‚Üê –º–æ–¥–µ–ª—å –¥–≤–∏–≥–∞–µ—Ç—Å—è —Å—é–¥–∞
        |  / ‚Ä¢
        | /  ‚Ä¢
        |/___‚Ä¢______________________
                              I(T;X)</code></pre>
    <ul>
      <li>–û—Å—å X: I(T;X) - —Å–∫–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤—Ö–æ–¥–µ</li>
      <li>–û—Å—å Y: I(T;Y) - —Å–∫–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤—ã—Ö–æ–¥–µ</li>
      <li>–¢—Ä–∞–µ–∫—Ç–æ—Ä–∏—è: –û–±—É—á–µ–Ω–∏–µ –¥–≤–∏–∂–µ—Ç—Å—è –ø–æ –ø–ª–æ—Å–∫–æ—Å—Ç–∏</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 5. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤–∑–∞–∏–º–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏</h2>
    <pre><code>import numpy as np
from sklearn.feature_selection import mutual_info_regression

# Mutual information
def compute_MI(X, Y, bins=10):
    """I(X;Y) = H(X) + H(Y) - H(X,Y)"""
    # –î–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏—è –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    pxy, _, _ = np.histogram2d(X, Y, bins=bins)
    pxy = pxy / np.sum(pxy)
    
    px = np.sum(pxy, axis=1)
    py = np.sum(pxy, axis=0)
    
    # –≠–Ω—Ç—Ä–æ–ø–∏–∏
    H_X = -np.sum(px * np.log2(px + 1e-10))
    H_Y = -np.sum(py * np.log2(py + 1e-10))
    H_XY = -np.sum(pxy * np.log2(pxy + 1e-10))
    
    MI = H_X + H_Y - H_XY
    return MI

# –î–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π: MI –º–µ–∂–¥—É –∞–∫—Ç–∏–≤–∞—Ü–∏—è–º–∏
def track_information_plane(model, data_loader):
    activations = get_layer_activations(model, data_loader)
    X, Y = data_loader.dataset.tensors
    
    for layer_idx, T in enumerate(activations):
        I_TX = compute_MI(T, X)
        I_TY = compute_MI(T, Y)
        print(f"Layer {layer_idx}: I(T;X)={I_TX:.3f}, I(T;Y)={I_TY:.3f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. –°–≤—è–∑—å —Å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π</h2>
    <p><strong>IB –∫–∞–∫ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä:</strong></p>
    <pre><code>Variational IB:
L = -I(T;Y) + Œ≤¬∑I(T;X)
  ‚âà -E[log p(y|T)] + Œ≤¬∑KL(p(T|x) || p(T))

–≥–¥–µ Œ≤ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç —Å–∂–∞—Ç–∏–µ</code></pre>
    <ul>
      <li><strong>Œ≤ ‚Üí 0</strong>: –ù–µ—Ç —Å–∂–∞—Ç–∏—è (–ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ)</li>
      <li><strong>Œ≤ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ</strong>: –ë–∞–ª–∞–Ω—Å</li>
      <li><strong>Œ≤ ‚Üí ‚àû</strong>: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Å–∂–∞—Ç–∏–µ (–Ω–µ–¥–æ–æ–±—É—á–µ–Ω–∏–µ)</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 7. –ö—Ä–∏—Ç–∏–∫–∞ —Ç–µ–æ—Ä–∏–∏</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –ß—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç</h3>
        <ul>
          <li>–ö—Ä–∞—Å–∏–≤–∞—è –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å</li>
          <li>–û–±—ä—è—Å–Ω—è–µ—Ç compression phase</li>
          <li>–°–≤—è–∑—å —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ùå –ü—Ä–æ–±–ª–µ–º—ã</h3>
        <ul>
          <li>–†–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è tanh, –Ω–µ –¥–ª—è ReLU</li>
          <li>–ó–∞–≤–∏—Å–∏—Ç –æ—Ç binning</li>
          <li>Compression —Ñ–∞–∑–∞ –Ω–µ –≤—Å–µ–≥–¥–∞ –µ—Å—Ç—å</li>
          <li>–ü—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤—ã–µ —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 8. –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–±–æ—Ç—ã</h2>
    <ul>
      <li><strong>Saxe et al. (2019)</strong>: IB –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è ReLU, —Ç–æ–ª—å–∫–æ –¥–ª—è saturating activations</li>
      <li><strong>Goldfeld et al. (2020)</strong>: Compression –¥–ª—è –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö</li>
      <li><strong>Shwartz-Ziv & LeCun (2020)</strong>: Compression –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∞–∫—Ç–∏–≤–∞—Ü–∏–∏</li>
      <li><strong>Achille & Soatto (2018)</strong>: Effective information –∫–∞–∫ –º–µ—Ä–∞</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 9. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</h2>
    <table>
      <tr><th>–ú–µ—Ç–æ–¥</th><th>–°–≤—è–∑—å —Å IB</th></tr>
      <tr><td><strong>Dropout</strong></td><td>–î–æ–±–∞–≤–ª—è–µ—Ç —à—É–º ‚Üí —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç I(T;X)</td></tr>
      <tr><td><strong>Weight decay</strong></td><td>–£–º–µ–Ω—å—à–∞–µ—Ç capacity ‚Üí —Å–∂–∞—Ç–∏–µ</td></tr>
      <tr><td><strong>VAE</strong></td><td>–Ø–≤–Ω–∞—è IB —Ü–µ–ª—å —á–µ—Ä–µ–∑ KL</td></tr>
      <tr><td><strong>Contrastive learning</strong></td><td>–ú–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏—è I(T_1;T_2)</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 10. Variational IB</h2>
    <pre><code>import torch
import torch.nn as nn

class VariationalIBLayer(nn.Module):
    def __init__(self, input_dim, latent_dim, beta=0.1):
        super().__init__()
        self.beta = beta
        self.encoder = nn.Linear(input_dim, latent_dim * 2)
        
    def forward(self, x):
        # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        params = self.encoder(x)
        mu, logvar = torch.chunk(params, 2, dim=-1)
        
        # Reparameterization trick
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        z = mu + eps * std
        
        # KL divergence (compression term)
        kl = -0.5 * torch.sum(1 + logvar - mu**2 - logvar.exp())
        
        return z, self.beta * kl

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
class IBNetwork(nn.Module):
    def __init__(self):
        super().__init__()
        self.ib_layer = VariationalIBLayer(784, 128, beta=0.001)
        self.classifier = nn.Linear(128, 10)
        
    def forward(self, x):
        z, kl_loss = self.ib_layer(x)
        logits = self.classifier(z)
        return logits, kl_loss</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. Deep Variational IB</h2>
    <p><strong>–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –Ω–∞ –≥–ª—É–±–æ–∫–∏–µ —Å–µ—Ç–∏:</strong></p>
    <ul>
      <li><strong>–ö–∞–∂–¥—ã–π —Å–ª–æ–π</strong>: –°–≤–æ—è IB —Ü–µ–ª—å</li>
      <li><strong>–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ —Å–∂–∞—Ç–∏–µ</strong>: X ‚Üí T‚ÇÅ ‚Üí T‚ÇÇ ‚Üí ... ‚Üí Y</li>
      <li><strong>Total loss</strong>: Œ£[-I(T_i;Y) + Œ≤_i¬∑I(T_i;T_{i-1})]</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 12. –°–≤—è–∑—å —Å –¥—Ä—É–≥–∏–º–∏ —Ç–µ–æ—Ä–∏—è–º–∏</h2>
    <ul>
      <li><strong>Rate-Distortion Theory</strong>: IB = rate-distortion –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è</li>
      <li><strong>Minimal Sufficient Statistics</strong>: IB –∏—â–µ—Ç MSS –¥–ª—è Y</li>
      <li><strong>PAC-Bayes</strong>: KL term –ø–æ—è–≤–ª—è–µ—Ç—Å—è –≤ –æ–±–µ–∏—Ö —Ç–µ–æ—Ä–∏—è—Ö</li>
      <li><strong>Compression bounds</strong>: –õ—É—á—à–µ–µ —Å–∂–∞—Ç–∏–µ ‚Üí –ª—É—á—à–∞—è –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—è</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 13. –ò–∑–º–µ—Ä–µ–Ω–∏–µ –≤ –ø—Ä–∞–∫—Ç–∏–∫–µ</h2>
    <pre><code># –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ information plane
import matplotlib.pyplot as plt

def visualize_information_plane(model, train_loader, epochs=100):
    I_XT_history = []
    I_TY_history = []
    
    for epoch in range(epochs):
        # –ü–æ–ª—É—á–∏—Ç—å –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
        activations, labels = get_activations(model, train_loader)
        
        # –í—ã—á–∏—Å–ª–∏—Ç—å MI
        I_XT = estimate_mutual_information(train_loader.dataset.data, activations)
        I_TY = estimate_mutual_information(activations, labels)
        
        I_XT_history.append(I_XT)
        I_TY_history.append(I_TY)
        
        train_one_epoch(model, train_loader)
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    plt.plot(I_XT_history, I_TY_history, 'o-')
    plt.xlabel('I(X;T)')
    plt.ylabel('I(T;Y)')
    plt.title('Information Plane Trajectory')
    plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 14. –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã</h2>
    <ul>
      <li>[ ] IB –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç <strong>–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π –≤–∑–≥–ª—è–¥</strong> –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ</li>
      <li>[ ] Compression phase <strong>—Å–ø–æ—Ä–Ω–∞</strong> —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏</li>
      <li>[ ] –†–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è <strong>tanh</strong>, –Ω–µ –≤—Å–µ–≥–¥–∞ –¥–ª—è ReLU</li>
      <li>[ ] –ü–æ–ª–µ–∑–Ω–∞ –¥–ª—è <strong>VAE –∏ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è</strong></li>
      <li>[ ] –°–≤—è–∑—ã–≤–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ —Å <strong>—Ç–µ–æ—Ä–∏–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏</strong></li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´Information Bottleneck ‚Äî —ç—Ç–æ –∏–¥–µ—è, —á—Ç–æ –Ω–µ–π—Ä–æ—Å–µ—Ç—å –¥–æ–ª–∂–Ω–∞ —Å–∂–∞—Ç—å –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–æ —Å–∞–º–æ–≥–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–≥–æ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏. –ö–∞–∫ —Ö–æ—Ä–æ—à–∏–π –∫–æ–Ω—Å–ø–µ–∫—Ç –ª–µ–∫—Ü–∏–∏: –≤—ã–∫–∏–Ω—É—Ç—å –≤—Å—ë –ª–∏—à–Ω–µ–µ, –æ—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ –≤–∞–∂–Ω–æ–µ. –¢–µ–æ—Ä–∏—è –∫—Ä–∞—Å–∏–≤–∞—è, –Ω–æ –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–µ –≤—Å–µ–≥–¥–∞¬ª.
    </blockquote>
  </div>

</div>

</div>
</body>
</html>
