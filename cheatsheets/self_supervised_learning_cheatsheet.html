<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>Self-Supervised Learning Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

        .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üéì Self-Supervised Learning</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –ß—Ç–æ —Ç–∞–∫–æ–µ Self-Supervised Learning</h2>
    <ul>
      <li><strong>–¶–µ–ª—å</strong>: —É—á–∏—Ç—å—Å—è –Ω–∞ –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö</li>
      <li><strong>–ò–¥–µ—è</strong>: —Å–æ–∑–¥–∞—Ç—å –∑–∞–¥–∞—á—É –∏–∑ —Å–∞–º–∏—Ö –¥–∞–Ω–Ω—ã—Ö (pretext task)</li>
      <li><strong>–†–µ–∑—É–ª—å—Ç–∞—Ç</strong>: —Ö–æ—Ä–æ—à–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è downstream –∑–∞–¥–∞—á</li>
      <li><strong>–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ</strong>: –Ω–µ –Ω—É–∂–Ω–∞ —Ä–∞–∑–º–µ—Ç–∫–∞</li>
      <li><strong>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</strong>: CV, NLP, audio, video</li>
    </ul>

  <div class="block">
    <h2>üî∑ 2. –¢–∏–ø—ã pretext –∑–∞–¥–∞—á</h2>
    <p><strong>Computer Vision</strong>:</p>
    <ul>
      <li><strong>Rotation Prediction</strong>: —É–≥–æ–ª –ø–æ–≤–æ—Ä–æ—Ç–∞ (0¬∞, 90¬∞, 180¬∞, 270¬∞)</li>
      <li><strong>Jigsaw Puzzles</strong>: —Å–æ–±—Ä–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –ø–∞—Ç—á–µ–π</li>
      <li><strong>Colorization</strong>: —Ä–∞—Å–∫—Ä–∞—Å–∏—Ç—å grayscale –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ</li>
      <li><strong>Inpainting</strong>: –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–∫—Ä—ã—Ç—ã–µ –æ–±–ª–∞—Å—Ç–∏</li>
      <li><strong>Contrastive</strong>: —Ä–∞–∑–ª–∏—á–∞—Ç—å augmentations</li>
    </ul>
    <p><strong>NLP</strong>:</p>
    <ul>
      <li><strong>Masked Language Model</strong>: –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ (BERT)</li>
      <li><strong>Next Sentence Prediction</strong>: —Å–≤—è–∑–∞–Ω—ã –ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è</li>
      <li><strong>Autoregressive</strong>: –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Å–ª–µ–¥—É—é—â–µ–µ —Å–ª–æ–≤–æ (GPT)</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 3. Rotation Prediction</h2>
    <pre><code>import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision import models

class RotationPredictor(nn.Module):
    def __init__(self, base_encoder):
        super().__init__()
        self.encoder = base_encoder
        # 4 –∫–ª–∞—Å—Å–∞: 0¬∞, 90¬∞, 180¬∞, 270¬∞
        self.classifier = nn.Linear(2048, 4)
    
    def forward(self, x):
        features = self.encoder(x)
        return self.classifier(features)

# Data augmentation —Å –ø–æ–≤–æ—Ä–æ—Ç–∞–º–∏
class RotationDataset(torch.utils.data.Dataset):
    def __init__(self, images):
        self.images = images
        self.transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        image = self.images[idx]
        image = self.transform(image)
        
        # –°–ª—É—á–∞–π–Ω—ã–π –ø–æ–≤–æ—Ä–æ—Ç
        rotation = torch.randint(0, 4, (1,)).item()
        
        # –ü–æ–≤–æ—Ä–æ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if rotation == 1:  # 90¬∞
            image = torch.rot90(image, k=1, dims=[1, 2])
        elif rotation == 2:  # 180¬∞
            image = torch.rot90(image, k=2, dims=[1, 2])
        elif rotation == 3:  # 270¬∞
            image = torch.rot90(image, k=3, dims=[1, 2])
        
        return image, rotation

# –û–±—É—á–µ–Ω–∏–µ
model = RotationPredictor(models.resnet50(pretrained=False))
model = model.cuda()

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

model.train()
for epoch in range(100):
    for images, rotations in dataloader:
        images = images.cuda()
        rotations = rotations.cuda()
        
        outputs = model(images)
        loss = criterion(outputs, rotations)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    
    print(f'Epoch {epoch}, Loss: {loss.item():.4f}')</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. Jigsaw Puzzles</h2>
    <pre><code>import random

class JigsawDataset(torch.utils.data.Dataset):
    def __init__(self, images, num_patches=9, num_permutations=100):
        self.images = images
        self.num_patches = num_patches  # 3x3 = 9 –ø–∞—Ç—á–µ–π
        self.patch_per_side = int(num_patches ** 0.5)
        
        # –ü—Ä–µ–¥–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∏
        self.permutations = self._generate_permutations(
            num_permutations
        )
        
        self.transform = transforms.Compose([
            transforms.Resize(255),
            transforms.CenterCrop(225),  # 225 = 75*3
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])
    
    def _generate_permutations(self, n):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è n —Ä–∞–∑–Ω—ã—Ö –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–æ–∫"""
        perms = []
        base = list(range(self.num_patches))
        for _ in range(n):
            perm = base.copy()
            random.shuffle(perm)
            perms.append(perm)
        return perms
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        image = self.transform(self.images[idx])
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø–∞—Ç—á–∏
        patch_size = 75
        patches = []
        for i in range(self.patch_per_side):
            for j in range(self.patch_per_side):
                patch = image[
                    :,
                    i*patch_size:(i+1)*patch_size,
                    j*patch_size:(j+1)*patch_size
                ]
                patches.append(patch)
        
        # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—É—é –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫—É
        perm_idx = random.randint(0, len(self.permutations) - 1)
        permutation = self.permutations[perm_idx]
        
        # –ü–µ—Ä–µ—Å—Ç–∞–≤–ª—è–µ–º –ø–∞—Ç—á–∏
        permuted_patches = [patches[i] for i in permutation]
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ
        rows = []
        for i in range(self.patch_per_side):
            row_patches = permuted_patches[
                i*self.patch_per_side:(i+1)*self.patch_per_side
            ]
            rows.append(torch.cat(row_patches, dim=2))
        
        permuted_image = torch.cat(rows, dim=1)
        
        return permuted_image, perm_idx


class JigsawModel(nn.Module):
    def __init__(self, base_encoder, num_permutations=100):
        super().__init__()
        self.encoder = base_encoder
        self.classifier = nn.Linear(2048, num_permutations)
    
    def forward(self, x):
        features = self.encoder(x)
        return self.classifier(features)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. Colorization</h2>
    <pre><code>class ColorizationModel(nn.Module):
    def __init__(self):
        super().__init__()
        
        # Encoder (–ø—Ä–∏–Ω–∏–º–∞–µ—Ç grayscale L channel)
        self.encoder = models.resnet18(pretrained=False)
        self.encoder.conv1 = nn.Conv2d(
            1, 64, kernel_size=7, stride=2, padding=3, bias=False
        )
        self.encoder.fc = nn.Identity()
        
        # Decoder (–ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç ab channels)
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(512, 256, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(256, 128, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 2, 4, 2, 1),  # 2 channels (ab)
            nn.Tanh()
        )
    
    def forward(self, x):
        # x: grayscale (B, 1, H, W)
        features = self.encoder(x)
        features = features.view(features.size(0), 512, 1, 1)
        ab = self.decoder(features)  # (B, 2, H, W)
        return ab

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (RGB -> LAB)
from skimage import color

def rgb_to_lab(rgb_image):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è RGB -> LAB"""
    lab = color.rgb2lab(rgb_image)
    L = lab[:, :, 0]
    ab = lab[:, :, 1:]
    return L, ab

# Training
model = ColorizationModel().cuda()
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

for epoch in range(100):
    for rgb_images in dataloader:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ LAB
        L_channels = []
        ab_channels = []
        
        for img in rgb_images:
            L, ab = rgb_to_lab(img.numpy().transpose(1, 2, 0))
            L_channels.append(torch.FloatTensor(L).unsqueeze(0))
            ab_channels.append(torch.FloatTensor(ab).permute(2, 0, 1))
        
        L = torch.stack(L_channels).cuda()
        ab_true = torch.stack(ab_channels).cuda()
        
        # Forward
        ab_pred = model(L)
        loss = criterion(ab_pred, ab_true)
        
        # Backward
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    
    print(f'Epoch {epoch}, Loss: {loss.item():.4f}')</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. Context Prediction</h2>
    <pre><code>class ContextPredictionModel(nn.Module):
    def __init__(self, base_encoder):
        super().__init__()
        self.encoder = base_encoder
        
        # –î–≤–µ –≤–µ—Ç–≤–∏ –¥–ª—è –¥–≤—É—Ö –ø–∞—Ç—á–µ–π
        self.branch1 = nn.Linear(2048, 512)
        self.branch2 = nn.Linear(2048, 512)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è
        # 8 –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø–æ–ª–æ–∂–µ–Ω–∏–π –≤–æ–∫—Ä—É–≥ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –ø–∞—Ç—á–∞
        self.classifier = nn.Linear(1024, 8)
    
    def forward(self, patch_center, patch_context):
        # –≠–Ω–∫–æ–¥–∏–º –æ–±–∞ –ø–∞—Ç—á–∞
        feat_center = self.encoder(patch_center)
        feat_context = self.encoder(patch_context)
        
        # –ü—Ä–æ–µ–∫—Ü–∏–∏
        z_center = self.branch1(feat_center)
        z_context = self.branch2(feat_context)
        
        # –ö–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è
        combined = torch.cat([z_center, z_context], dim=1)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è
        return self.classifier(combined)


class ContextDataset(torch.utils.data.Dataset):
    def __init__(self, images, patch_size=64):
        self.images = images
        self.patch_size = patch_size
        self.transform = transforms.Compose([
            transforms.Resize(256),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])
        
        # 8 –ø–æ–∑–∏—Ü–∏–π –≤–æ–∫—Ä—É–≥ —Ü–µ–Ω—Ç—Ä–∞
        self.positions = [
            (-1, -1), (-1, 0), (-1, 1),
            (0, -1),           (0, 1),
            (1, -1),  (1, 0),  (1, 1)
        ]
    
    def __getitem__(self, idx):
        image = self.transform(self.images[idx])
        
        # –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –ø–∞—Ç—á
        h, w = image.shape[1:]
        center_y = h // 2
        center_x = w // 2
        ps = self.patch_size
        
        patch_center = image[
            :,
            center_y-ps//2:center_y+ps//2,
            center_x-ps//2:center_x+ps//2
        ]
        
        # –°–ª—É—á–∞–π–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –ø–∞—Ç—á–∞
        pos_idx = random.randint(0, 7)
        dy, dx = self.positions[pos_idx]
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –ø–∞—Ç—á
        context_y = center_y + dy * ps
        context_x = center_x + dx * ps
        
        patch_context = image[
            :,
            context_y-ps//2:context_y+ps//2,
            context_x-ps//2:context_x+ps//2
        ]
        
        return (patch_center, patch_context), pos_idx</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. Masked Autoencoder (MAE)</h2>
    <p>–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –¥–ª—è Vision (Facebook AI, 2021):</p>
    <pre><code>class MaskedAutoencoder(nn.Module):
    def __init__(self, image_size=224, patch_size=16, 
                 embed_dim=768, mask_ratio=0.75):
        super().__init__()
        self.patch_size = patch_size
        self.mask_ratio = mask_ratio
        
        num_patches = (image_size // patch_size) ** 2
        
        # Patch embedding
        self.patch_embed = nn.Conv2d(
            3, embed_dim, 
            kernel_size=patch_size, 
            stride=patch_size
        )
        
        # Positional embeddings
        self.pos_embed = nn.Parameter(
            torch.zeros(1, num_patches, embed_dim)
        )
        
        # Encoder (Vision Transformer)
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embed_dim, 
            nhead=12,
            dim_feedforward=embed_dim*4
        )
        self.encoder = nn.TransformerEncoder(
            encoder_layer, 
            num_layers=12
        )
        
        # Decoder
        decoder_layer = nn.TransformerDecoderLayer(
            d_model=embed_dim,
            nhead=12,
            dim_feedforward=embed_dim*4
        )
        self.decoder = nn.TransformerDecoder(
            decoder_layer,
            num_layers=8
        )
        
        # Reconstruction head
        self.head = nn.Linear(
            embed_dim, 
            patch_size * patch_size * 3
        )
    
    def random_masking(self, x):
        """Random masking –ø–∞—Ç—á–µ–π"""
        N, L, D = x.shape  # batch, length, dim
        
        len_keep = int(L * (1 - self.mask_ratio))
        
        # –°–ª—É—á–∞–π–Ω–æ–µ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ
        noise = torch.rand(N, L, device=x.device)
        ids_shuffle = torch.argsort(noise, dim=1)
        ids_restore = torch.argsort(ids_shuffle, dim=1)
        
        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ unmask –ø–∞—Ç—á–∏ –¥–ª—è encoder
        ids_keep = ids_shuffle[:, :len_keep]
        x_masked = torch.gather(
            x, dim=1, 
            index=ids_keep.unsqueeze(-1).repeat(1, 1, D)
        )
        
        # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É
        mask = torch.ones([N, L], device=x.device)
        mask[:, :len_keep] = 0
        mask = torch.gather(mask, dim=1, index=ids_restore)
        
        return x_masked, mask, ids_restore
    
    def forward(self, x):
        # Patch embedding
        x = self.patch_embed(x)  # (B, D, H/p, W/p)
        x = x.flatten(2).transpose(1, 2)  # (B, N, D)
        
        # Add positional embedding
        x = x + self.pos_embed
        
        # Random masking
        x, mask, ids_restore = self.random_masking(x)
        
        # Encoder (—Ç–æ–ª—å–∫–æ unmask –ø–∞—Ç—á–∏)
        x = self.encoder(x)
        
        # Decoder (–≤—Å–µ –ø–∞—Ç—á–∏)
        # –î–æ–±–∞–≤–ª—è–µ–º mask tokens
        mask_tokens = nn.Parameter(
            torch.zeros(1, 1, x.shape[-1])
        ).to(x.device)
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–ª–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        x_full = torch.cat([x, mask_tokens.repeat(
            x.shape[0], ids_restore.shape[1] - x.shape[1], 1
        )], dim=1)
        
        x_full = torch.gather(
            x_full, dim=1,
            index=ids_restore.unsqueeze(-1).repeat(1, 1, x.shape[2])
        )
        
        # Decoder
        x = self.decoder(x_full, x)
        
        # Reconstruction
        x = self.head(x)
        
        return x, mask</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤</h2>
    <table>
      <tr><th>–ú–µ—Ç–æ–¥</th><th>–î–æ–º–µ–Ω</th><th>–°–ª–æ–∂–Ω–æ—Å—Ç—å</th><th>–ö–∞—á–µ—Å—Ç–≤–æ</th></tr>
      <tr><td><strong>Rotation</strong></td><td>CV</td><td>–ù–∏–∑–∫–∞—è</td><td>–°—Ä–µ–¥–Ω–µ</td></tr>
      <tr><td><strong>Jigsaw</strong></td><td>CV</td><td>–°—Ä–µ–¥–Ω—è—è</td><td>–•–æ—Ä–æ—à–æ</td></tr>
      <tr><td><strong>Colorization</strong></td><td>CV</td><td>–°—Ä–µ–¥–Ω—è—è</td><td>–•–æ—Ä–æ—à–æ</td></tr>
      <tr><td><strong>Contrastive</strong></td><td>CV/NLP</td><td>–í—ã—Å–æ–∫–∞—è</td><td>–û—Ç–ª–∏—á–Ω–æ</td></tr>
      <tr><td><strong>MAE</strong></td><td>CV</td><td>–í—ã—Å–æ–∫–∞—è</td><td>–û—Ç–ª–∏—á–Ω–æ</td></tr>
      <tr><td><strong>Masked LM</strong></td><td>NLP</td><td>–°—Ä–µ–¥–Ω—è—è</td><td>–û—Ç–ª–∏—á–Ω–æ</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 9. Transfer –∫ downstream –∑–∞–¥–∞—á–∞–º</h2>
    <pre><code># 1. Feature extraction (freeze encoder)
pretrained_encoder = model.encoder
for param in pretrained_encoder.parameters():
    param.requires_grad = False

classifier = nn.Sequential(
    pretrained_encoder,
    nn.Linear(2048, num_classes)
).cuda()

# 2. Fine-tuning (train all)
pretrained_encoder = model.encoder
classifier = nn.Sequential(
    pretrained_encoder,
    nn.Linear(2048, num_classes)
).cuda()

# –û–±—É—á–∞–µ–º –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
optimizer = torch.optim.Adam(
    classifier.parameters(), 
    lr=0.0001  # –ú–µ–Ω—å—à–∏–π LR
)

# 3. Progressive unfreezing
# –ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —Ä–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º —Å–ª–æ–∏
layers = list(pretrained_encoder.children())

# –°–Ω–∞—á–∞–ª–∞ —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–ª–æ–∏
for layer in layers[:-2]:
    for param in layer.parameters():
        param.requires_grad = False

# –û–±—É—á–µ–Ω–∏–µ
for epoch in range(10):
    # train...
    pass

# –†–∞–∑–º–æ—Ä–æ–∑–∫–∞ —Å–ª–µ–¥—É—é—â–∏—Ö —Å–ª–æ–µ–≤
for layer in layers[:-4]:
    for param in layer.parameters():
        param.requires_grad = False</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã</h2>
    <ul>
      <li><strong>–í—ã–±–æ—Ä pretext –∑–∞–¥–∞—á–∏</strong>: –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –¥–æ–º–µ–Ω–∞ –∏ –¥–∞–Ω–Ω—ã—Ö</li>
      <li><strong>Augmentations</strong>: –∫—Ä–∏—Ç–∏—á–Ω—ã –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞</li>
      <li><strong>Batch size</strong>: –±–æ–ª—å—à–µ = –ª—É—á—à–µ (–æ—Å–æ–±–µ–Ω–Ω–æ –¥–ª—è contrastive)</li>
      <li><strong>–û–±—É—á–µ–Ω–∏–µ</strong>: –¥–æ–ª–≥–æ (100-1000 —ç–ø–æ—Ö)</li>
      <li><strong>–û—Ü–µ–Ω–∫–∞</strong>: linear probe + fine-tuning</li>
      <li><strong>–î–∞–Ω–Ω—ã–µ</strong>: —á–µ–º –±–æ–ª—å—à–µ unlabeled, —Ç–µ–º –ª—É—á—à–µ</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 11. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –•–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç</h3>
        <ul>
          <li>–ü—Ä–µ–¥–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –±–æ–ª—å—à–∏—Ö unlabeled –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö</li>
          <li>Transfer learning –¥–ª—è –º–∞–ª—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤</li>
          <li>Few-shot learning</li>
          <li>Domain adaptation</li>
          <li>Representation learning</li>
          <li>Anomaly detection</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ùå –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è</h3>
        <ul>
          <li>–¢—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤</li>
          <li>–î–æ–ª–≥–æ–µ –æ–±—É—á–µ–Ω–∏–µ</li>
          <li>–ù—É–∂–µ–Ω –±–æ–ª—å—à–æ–π unlabeled –¥–∞—Ç–∞—Å–µ—Ç</li>
          <li>–°–ª–æ–∂–Ω–æ –ø–æ–¥–æ–±—Ä–∞—Ç—å pretext –∑–∞–¥–∞—á—É</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 12. –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ frameworks</h2>
    <pre><code># Lightly AI - –≥–æ—Ç–æ–≤–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞
# pip install lightly

from lightly.models import SimCLR
from lightly.transforms import SimCLRTransform

# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
model = SimCLR(
    backbone='resnet-18',
    num_ftrs=512,
    out_dim=128
)

# Augmentations
transform = SimCLRTransform(
    input_size=224,
    cj_prob=0.8,
    cj_bright=0.4,
    cj_contrast=0.4,
    cj_sat=0.4,
    cj_hue=0.1
)

# Solo-learn - –º—É–ª—å—Ç–∏-–º–µ—Ç–æ–¥ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫
# pip install solo-learn

from solo.methods import BarlowTwins, BYOL, SimCLR

model = BarlowTwins(
    backbone="resnet18",
    proj_hidden_dim=2048,
    proj_output_dim=2048,
    lamb=0.0051
)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 13. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å –ø–æ–¥—Ö–æ–¥—è—â—É—é pretext –∑–∞–¥–∞—á—É</li>
      <li>[ ] –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –±–æ–ª—å—à–æ–π unlabeled –¥–∞—Ç–∞—Å–µ—Ç</li>
      <li>[ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å —Å–∏–ª—å–Ω—ã–µ augmentations</li>
      <li>[ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–æ–π batch size</li>
      <li>[ ] –û–±—É—á–∞—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–æ–ª–≥–æ (100+ —ç–ø–æ—Ö)</li>
      <li>[ ] –û—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —á–µ—Ä–µ–∑ linear probe</li>
      <li>[ ] Fine-tune –Ω–∞ —Ü–µ–ª–µ–≤–æ–π –∑–∞–¥–∞—á–µ</li>
      <li>[ ] –°—Ä–∞–≤–Ω–∏—Ç—å —Å supervised baseline</li>
      <li>[ ] –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å —Ä–∞–∑–Ω—ã–º–∏ pretext –∑–∞–¥–∞—á–∞–º–∏</li>
      <li>[ ] –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ representations</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´Self-Supervised Learning –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª–∏ —É—á–∏—Ç—å—Å—è –Ω–∞ –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, —Ä–µ—à–∞—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –∑–∞–¥–∞—á–∏ –≤—Ä–æ–¥–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ–≤–æ—Ä–æ—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —Ü–≤–µ—Ç–∞ ‚Äî —ç—Ç–æ –¥–∞–µ—Ç —Ö–æ—Ä–æ—à–∏–µ –±–∞–∑–æ–≤—ã–µ –∑–Ω–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ—Ç–æ–º –º–æ–∂–Ω–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á¬ª.
    </blockquote>
  </div>

</div>

</div>
</body>
</html>
