<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>–ë–ª–µ–Ω–¥–∏–Ω–≥ (Blending) Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      
        min-width: 900px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

        .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üéØ –ë–ª–µ–Ω–¥–∏–Ω–≥ (Blending)</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –°—É—Ç—å</h2>
    <ul>
      <li><strong>Blending</strong>: –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π</li>
      <li><strong>Holdout set</strong>: –æ—Ç–¥–µ–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏</li>
      <li><strong>–ü—Ä–æ—Å—Ç–æ—Ç–∞</strong>: –ø—Ä–æ—â–µ —á–µ–º —Å—Ç–µ–∫–∏–Ω–≥, –Ω–µ—Ç –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏</li>
      <li><strong>–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å</strong>: —á–∞—Å—Ç–æ –ø–æ–±–µ–∂–¥–∞–µ—Ç –≤ Kaggle</li>
      <li><strong>–ì–∏–±–∫–æ—Å—Ç—å</strong>: –º–æ–∂–Ω–æ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å –ª—é–±—ã–µ –º–æ–¥–µ–ª–∏</li>
    </ul>

    </div>
<div class="block">
    <h2>üî∑ 2. –ë–ª–µ–Ω–¥–∏–Ω–≥ vs –°—Ç–µ–∫–∏–Ω–≥</h2>
    <table>
      <tr><th>–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞</th><th>–ë–ª–µ–Ω–¥–∏–Ω–≥</th><th>–°—Ç–µ–∫–∏–Ω–≥</th></tr>
      <tr><td><strong>–î–∞–Ω–Ω—ã–µ</strong></td><td>Train/Holdout/Test</td><td>Train/Test + CV</td></tr>
      <tr><td><strong>–ú–µ—Ç–∞-–º–æ–¥–µ–ª—å</strong></td><td>–ù–∞ holdout</td><td>–ù–∞ out-of-fold</td></tr>
      <tr><td><strong>–°–ª–æ–∂–Ω–æ—Å—Ç—å</strong></td><td>–ü—Ä–æ—Å—Ç–∞—è</td><td>–°–ª–æ–∂–Ω–∞—è</td></tr>
      <tr><td><strong>–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ</strong></td><td>–ú–µ–Ω—å—à–µ —Ä–∏—Å–∫</td><td>–ë–æ–ª—å—à–µ —Ä–∏—Å–∫</td></tr>
      <tr><td><strong>–î–∞–Ω–Ω—ã–µ</strong></td><td>–¢–µ—Ä—è–µ–º holdout</td><td>–ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 3. –ë–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä</h2>
    <pre><code>from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import numpy as np

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö: train (50%) / holdout (25%) / test (25%)
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42
)
X_train, X_holdout, y_train, y_holdout = train_test_split(
    X_temp, y_temp, test_size=0.33, random_state=42
)

# –ë–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
model1 = RandomForestClassifier(n_estimators=100, random_state=42)
model2 = GradientBoostingClassifier(n_estimators=100, random_state=42)

# –û–±—É—á–µ–Ω–∏–µ –Ω–∞ train
model1.fit(X_train, y_train)
model2.fit(X_train, y_train)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ holdout (–¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏)
holdout_pred1 = model1.predict_proba(X_holdout)[:, 1]
holdout_pred2 = model2.predict_proba(X_holdout)[:, 1]
holdout_features = np.column_stack([holdout_pred1, holdout_pred2])

# –ú–µ—Ç–∞-–º–æ–¥–µ–ª—å (–±–ª–µ–Ω–¥–µ—Ä)
meta_model = LogisticRegression()
meta_model.fit(holdout_features, y_holdout)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ test
test_pred1 = model1.predict_proba(X_test)[:, 1]
test_pred2 = model2.predict_proba(X_test)[:, 1]
test_features = np.column_stack([test_pred1, test_pred2])

# –§–∏–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
final_predictions = meta_model.predict(test_features)
accuracy = accuracy_score(y_test, final_predictions)
print(f"Blending Accuracy: {accuracy:.4f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. –ü—Ä–æ—Å—Ç–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ</h2>
    <pre><code># –ü—Ä–æ—Å—Ç–æ–µ —Å—Ä–µ–¥–Ω–µ–µ (–ø—Ä–æ—Å—Ç–µ–π—à–∏–π –±–ª–µ–Ω–¥–∏–Ω–≥)
def simple_average_blend(predictions_list):
    return np.mean(predictions_list, axis=0)

# –ü—Ä–∏–º–µ—Ä
pred1 = model1.predict_proba(X_test)[:, 1]
pred2 = model2.predict_proba(X_test)[:, 1]
pred3 = model3.predict_proba(X_test)[:, 1]

final_pred = simple_average_blend([pred1, pred2, pred3])
final_class = (final_pred > 0.5).astype(int)

# –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ
def weighted_average_blend(predictions_list, weights):
    weighted_sum = np.zeros_like(predictions_list[0])
    for pred, weight in zip(predictions_list, weights):
        weighted_sum += pred * weight
    return weighted_sum / sum(weights)

# –í–µ—Å–∞ –ø–æ–¥–æ–±—Ä–∞–Ω—ã –Ω–∞ holdout
weights = [0.5, 0.3, 0.2]
final_pred = weighted_average_blend([pred1, pred2, pred3], weights)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤</h2>
    <pre><code>from scipy.optimize import minimize

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–æ–≤
def optimize_weights(predictions_list, y_true):
    def loss_function(weights):
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ—Å–∞
        weights = np.array(weights) / np.sum(weights)
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ
        blended = np.zeros_like(predictions_list[0])
        for pred, weight in zip(predictions_list, weights):
            blended += pred * weight
        
        # –õ–æ–≥-–ª–æ—Å—Å
        from sklearn.metrics import log_loss
        return log_loss(y_true, blended)
    
    # –ù–∞—á–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞ (—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–µ)
    initial_weights = [1.0] * len(predictions_list)
    
    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è: –≤—Å–µ –≤–µ—Å–∞ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ
    bounds = [(0.0, 1.0)] * len(predictions_list)
    
    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
    result = minimize(
        loss_function,
        initial_weights,
        method='SLSQP',
        bounds=bounds
    )
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞
    optimal_weights = result.x / np.sum(result.x)
    return optimal_weights

# –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –Ω–∞ holdout
holdout_preds = [
    model1.predict_proba(X_holdout)[:, 1],
    model2.predict_proba(X_holdout)[:, 1],
    model3.predict_proba(X_holdout)[:, 1]
]

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
optimal_weights = optimize_weights(holdout_preds, y_holdout)
print(f"Optimal weights: {optimal_weights}")

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –Ω–∞ test
test_preds = [
    model1.predict_proba(X_test)[:, 1],
    model2.predict_proba(X_test)[:, 1],
    model3.predict_proba(X_test)[:, 1]
]
final_pred = weighted_average_blend(test_preds, optimal_weights)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. Rank averaging</h2>
    <pre><code>from scipy.stats import rankdata

# Rank averaging - —Ä–æ–±–∞—Å—Ç–Ω—ã–π –∫ –≤—ã–±—Ä–æ—Å–∞–º
def rank_average_blend(predictions_list):
    # –†–∞–Ω–∂–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –Ω–∞–±–æ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    ranked_predictions = []
    for pred in predictions_list:
        ranked = rankdata(pred) / len(pred)
        ranked_predictions.append(ranked)
    
    # –£—Å—Ä–µ–¥–Ω—è–µ–º —Ä–∞–Ω–≥–∏
    return np.mean(ranked_predictions, axis=0)

# –ü—Ä–∏–º–µ—Ä
pred1 = model1.predict_proba(X_test)[:, 1]
pred2 = model2.predict_proba(X_test)[:, 1]
pred3 = model3.predict_proba(X_test)[:, 1]

final_pred = rank_average_blend([pred1, pred2, pred3])

# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –æ–±—Ä–∞—Ç–Ω–æ –≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
# –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å —Ä–∞–Ω–≥–∏ –¥–ª—è ranking –∑–∞–¥–∞—á</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ</h2>
    <pre><code># –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ
def geometric_mean_blend(predictions_list):
    product = np.ones_like(predictions_list[0])
    for pred in predictions_list:
        # –ò–∑–±–µ–≥–∞–µ–º log(0)
        pred_safe = np.clip(pred, 1e-15, 1 - 1e-15)
        product *= pred_safe
    return np.power(product, 1.0 / len(predictions_list))

# –ü—Ä–∏–º–µ—Ä
pred1 = model1.predict_proba(X_test)[:, 1]
pred2 = model2.predict_proba(X_test)[:, 1]
pred3 = model3.predict_proba(X_test)[:, 1]

final_pred = geometric_mean_blend([pred1, pred2, pred3])

# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ —á–µ—Ä–µ–∑ –ª–æ–≥–∞—Ä–∏—Ñ–º—ã (—á–∏—Å–ª–µ–Ω–Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ)
def geometric_mean_blend_log(predictions_list):
    log_sum = np.zeros_like(predictions_list[0])
    for pred in predictions_list:
        pred_safe = np.clip(pred, 1e-15, 1 - 1e-15)
        log_sum += np.log(pred_safe)
    return np.exp(log_sum / len(predictions_list))</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. –ú–µ—Ç–∞-–ø—Ä–∏–∑–Ω–∞–∫–∏</h2>
    <pre><code># –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –º–µ—Ç–∞-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤
def create_meta_features(base_predictions, X_original):
    meta_features = []
    
    # 1. –ë–∞–∑–æ–≤—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    for pred in base_predictions:
        meta_features.append(pred)
    
    # 2. –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    for i in range(len(base_predictions)):
        for j in range(i + 1, len(base_predictions)):
            # –ü—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ
            meta_features.append(base_predictions[i] * base_predictions[j])
            # –†–∞–∑–Ω–æ—Å—Ç—å
            meta_features.append(np.abs(base_predictions[i] - base_predictions[j]))
    
    # 3. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    meta_features.append(np.mean(base_predictions, axis=0))
    meta_features.append(np.std(base_predictions, axis=0))
    meta_features.append(np.min(base_predictions, axis=0))
    meta_features.append(np.max(base_predictions, axis=0))
    
    # 4. –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –≤–∞–∂–Ω—ã–µ –∏—Å—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    
    return np.column_stack(meta_features)

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
holdout_preds = [
    model1.predict_proba(X_holdout)[:, 1],
    model2.predict_proba(X_holdout)[:, 1],
    model3.predict_proba(X_holdout)[:, 1]
]

meta_features_holdout = create_meta_features(holdout_preds, X_holdout)

# –û–±—É—á–µ–Ω–∏–µ –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏ –Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
from sklearn.ensemble import GradientBoostingClassifier
meta_model = GradientBoostingClassifier(n_estimators=100)
meta_model.fit(meta_features_holdout, y_holdout)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –±–ª–µ–Ω–¥–∏–Ω–≥</h2>
    <pre><code># –î–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤—ã–π –±–ª–µ–Ω–¥–∏–Ω–≥
# –£—Ä–æ–≤–µ–Ω—å 1: –Ω–µ—Å–∫–æ–ª—å–∫–æ –≥—Ä—É–ø–ø –º–æ–¥–µ–ª–µ–π
group1_models = [RandomForestClassifier(), GradientBoostingClassifier()]
group2_models = [LogisticRegression(), SVC(probability=True)]

# –û–±—É—á–µ–Ω–∏–µ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –≥—Ä—É–ø–ø—ã 1
group1_preds_holdout = []
group1_preds_test = []
for model in group1_models:
    model.fit(X_train, y_train)
    group1_preds_holdout.append(model.predict_proba(X_holdout)[:, 1])
    group1_preds_test.append(model.predict_proba(X_test)[:, 1])

# –ë–ª–µ–Ω–¥–∏–Ω–≥ –≥—Ä—É–ø–ø—ã 1
group1_blend_holdout = np.mean(group1_preds_holdout, axis=0)
group1_blend_test = np.mean(group1_preds_test, axis=0)

# –¢–æ –∂–µ –¥–ª—è –≥—Ä—É–ø–ø—ã 2
group2_preds_holdout = []
group2_preds_test = []
for model in group2_models:
    model.fit(X_train, y_train)
    group2_preds_holdout.append(model.predict_proba(X_holdout)[:, 1])
    group2_preds_test.append(model.predict_proba(X_test)[:, 1])

group2_blend_holdout = np.mean(group2_preds_holdout, axis=0)
group2_blend_test = np.mean(group2_preds_test, axis=0)

# –£—Ä–æ–≤–µ–Ω—å 2: –±–ª–µ–Ω–¥–∏–Ω–≥ –≥—Ä—É–ø–ø
meta_features_holdout = np.column_stack([group1_blend_holdout, group2_blend_holdout])
meta_features_test = np.column_stack([group1_blend_test, group2_blend_test])

meta_model = LogisticRegression()
meta_model.fit(meta_features_holdout, y_holdout)
final_pred = meta_model.predict(meta_features_test)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. –ë–ª–µ–Ω–¥–∏–Ω–≥ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏</h2>
    <pre><code>from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error

# –ë–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
model1 = RandomForestRegressor(n_estimators=100, random_state=42)
model2 = GradientBoostingRegressor(n_estimators=100, random_state=42)
model3 = Ridge(alpha=1.0)

# –û–±—É—á–µ–Ω–∏–µ
model1.fit(X_train, y_train)
model2.fit(X_train, y_train)
model3.fit(X_train, y_train)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ holdout
holdout_pred1 = model1.predict(X_holdout)
holdout_pred2 = model2.predict(X_holdout)
holdout_pred3 = model3.predict(X_holdout)
holdout_features = np.column_stack([holdout_pred1, holdout_pred2, holdout_pred3])

# –ú–µ—Ç–∞-–º–æ–¥–µ–ª—å (Ridge —Ä–µ–≥—Ä–µ—Å—Å–∏—è –¥–ª—è –±–ª–µ–Ω–¥–∏–Ω–≥–∞)
meta_model = Ridge(alpha=0.1)
meta_model.fit(holdout_features, y_holdout)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ test
test_pred1 = model1.predict(X_test)
test_pred2 = model2.predict(X_test)
test_pred3 = model3.predict(X_test)
test_features = np.column_stack([test_pred1, test_pred2, test_pred3])

# –§–∏–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
final_predictions = meta_model.predict(test_features)
rmse = np.sqrt(mean_squared_error(y_test, final_predictions))
print(f"Blending RMSE: {rmse:.4f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã</h2>
    <ul>
      <li><strong>–†–∞–∑–º–µ—Ä holdout</strong>: 15-33% –æ—Ç train –¥–∞–Ω–Ω—ã—Ö</li>
      <li><strong>–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –º–æ–¥–µ–ª–µ–π</strong>: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã (tree, linear, neural)</li>
      <li><strong>–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è</strong>: –º–æ–¥–µ–ª–∏ –¥–æ–ª–∂–Ω—ã –æ—à–∏–±–∞—Ç—å—Å—è –ø–æ-—Ä–∞–∑–Ω–æ–º—É</li>
      <li><strong>–ù–∞—á–Ω–∏—Ç–µ —Å –ø—Ä–æ—Å—Ç–æ–≥–æ</strong>: –ø—Ä–æ—Å—Ç–æ–µ —Å—Ä–µ–¥–Ω–µ–µ —á–∞—Å—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ</li>
      <li><strong>–ú–µ—Ç–∞-–º–æ–¥–µ–ª—å</strong>: –Ω–∞—á–Ω–∏—Ç–µ —Å –ª–∏–Ω–µ–π–Ω–æ–π (Logistic/Ridge)</li>
      <li><strong>–ü—Ä–æ–≤–µ—Ä–∫–∞</strong>: –≤–∞–ª–∏–¥–∏—Ä—É–π—Ç–µ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–º test set</li>
      <li><strong>–í—Ä–µ–º—è</strong>: –±–ª–µ–Ω–¥–∏–Ω–≥ –±—ã—Å—Ç—Ä–µ–µ —Å—Ç–µ–∫–∏–Ω–≥–∞</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 12. –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –•–æ—Ä–æ—à–æ</h3>
        <ul>
          <li>–°–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è (Kaggle)</li>
          <li>–ú–Ω–æ–∂–µ—Å—Ç–≤–æ –≥–æ—Ç–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π</li>
          <li>–û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è</li>
          <li>–ü—Ä–æ—Å—Ç–æ—Ç–∞ –≤–∞–∂–Ω–µ–µ —Ç–æ—á–Ω–æ—Å—Ç–∏</li>
          <li>–ë–æ–ª—å—à–æ–π dataset</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ùå –ü–ª–æ—Ö–æ</h3>
        <ul>
          <li>–û—á–µ–Ω—å –º–∞–ª—ã–π dataset</li>
          <li>–ù—É–∂–Ω–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å</li>
          <li>Production —Å –∂–µ—Å—Ç–∫–∏–º–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏</li>
          <li>–ù–µ–ª—å–∑—è —Ç–µ—Ä—è—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ holdout</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 13. –¢–∏–ø–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏</h2>
    <ul>
      <li><strong>–£—Ç–µ—á–∫–∞ –¥–∞–Ω–Ω—ã—Ö</strong>: holdout –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω</li>
      <li><strong>–°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π holdout</strong>: < 10% = –Ω–µ–Ω–∞–¥–µ–∂–Ω—ã–µ –≤–µ—Å–∞</li>
      <li><strong>–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏</strong>: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é</li>
      <li><strong>–ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏</strong>: –ø–æ—Ö–æ–∂–∏–µ –º–æ–¥–µ–ª–∏ –Ω–µ —É–ª—É—á—à–∞—é—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li><strong>–°–ª–æ–∂–Ω–∞—è –º–µ—Ç–∞-–º–æ–¥–µ–ª—å</strong>: –Ω–∞—á–Ω–∏—Ç–µ —Å –ø—Ä–æ—Å—Ç–æ–π</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 14. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –†–∞–∑–¥–µ–ª–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ train/holdout/test</li>
      <li>[ ] –û–±—É—á–∏—Ç—å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –Ω–∞ train</li>
      <li>[ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–µ–π</li>
      <li>[ ] –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ holdout</li>
      <li>[ ] –û–±—É—á–∏—Ç—å –º–µ—Ç–∞-–º–æ–¥–µ–ª—å –Ω–∞ holdout</li>
      <li>[ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ test set</li>
      <li>[ ] –°—Ä–∞–≤–Ω–∏—Ç—å —Å –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏</li>
      <li>[ ] –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã –±–ª–µ–Ω–¥–∏–Ω–≥–∞</li>
      <li>[ ] –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–µ—Å–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´–ë–ª–µ–Ω–¥–∏–Ω–≥ ‚Äî —ç—Ç–æ –∫–∞–∫ –∫–æ–Ω—Å–∏–ª–∏—É–º –≤—Ä–∞—á–µ–π: –∫–∞–∂–¥—ã–π —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –¥–∞–µ—Ç —Å–≤–æ–π –¥–∏–∞–≥–Ω–æ–∑, –∞ –≥–ª–∞–≤–≤—Ä–∞—á (–º–µ—Ç–∞-–º–æ–¥–µ–ª—å) –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ, —É—á–∏—Ç—ã–≤–∞—è –º–Ω–µ–Ω–∏—è –≤—Å–µ—Ö. –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–¥–µ–ª—å–Ω—É—é –≥—Ä—É–ø–ø—É –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤ (holdout), —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å, –∫–æ–º—É –∏–∑ –≤—Ä–∞—á–µ–π —Å—Ç–æ–∏—Ç –±–æ–ª—å—à–µ –¥–æ–≤–µ—Ä—è—Ç—å¬ª.
    </blockquote>
  </div>



</div>
</body>
</html>
