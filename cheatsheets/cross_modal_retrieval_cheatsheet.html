<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>Cross-modal Retrieval Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

    .container {
      column-count: 3;
      column-gap: 20px;
      max-width: 100%;
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üîç Cross-modal Retrieval</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –°—É—Ç—å</h2>
    <ul>
      <li><strong>–ó–∞–¥–∞—á–∞</strong>: –ø–æ–∏—Å–∫ –º–µ–∂–¥—É —Ä–∞–∑–Ω—ã–º–∏ –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—è–º–∏</li>
      <li><strong>–ü—Ä–∏–º–µ—Ä—ã</strong>: —Ç–µ–∫—Å—Ç‚Üí–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –∞—É–¥–∏–æ‚Üí–≤–∏–¥–µ–æ, —Å–∫–µ—Ç—á‚Üí—Ñ–æ—Ç–æ</li>
      <li><strong>–ö–ª—é—á</strong>: –æ–±—â–µ–µ embedding –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ</li>
      <li><strong>–¶–µ–ª—å</strong>: —Å—Ö–æ–∂–∏–µ –æ–±—ä–µ–∫—Ç—ã –±–ª–∏–∑–∫–∏, —Ä–∞–∑–Ω—ã–µ ‚Äî –¥–∞–ª–µ–∫–æ</li>
    </ul>

  <div class="block">
    <h2>üî∑ 2. –¢–∏–ø—ã –∑–∞–¥–∞—á</h2>
    <table>
      <tr><th>–¢–∏–ø</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th><th>–ü—Ä–∏–º–µ—Ä</th></tr>
      <tr><td><strong>Image-Text</strong></td><td>–ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–µ–∫—Å—Ç—É</td><td>Google Images</td></tr>
      <tr><td><strong>Audio-Visual</strong></td><td>–ü–æ–∏—Å–∫ –≤–∏–¥–µ–æ –ø–æ –∑–≤—É–∫—É</td><td>–ü–æ–∏—Å–∫ –ø–æ –º—É–∑—ã–∫–µ</td></tr>
      <tr><td><strong>Sketch-Photo</strong></td><td>–ü–æ–∏—Å–∫ —Ñ–æ—Ç–æ –ø–æ –Ω–∞–±—Ä–æ—Å–∫—É</td><td>–î–∏–∑–∞–π–Ω –ø–æ–∏—Å–∫</td></tr>
      <tr><td><strong>Text-Video</strong></td><td>–ü–æ–∏—Å–∫ –≤–∏–¥–µ–æ –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é</td><td>YouTube search</td></tr>
      <tr><td><strong>3D-2D</strong></td><td>–ü–æ–∏—Å–∫ 3D –º–æ–¥–µ–ª–µ–π –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º</td><td>CAD –ø–æ–∏—Å–∫</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 3. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞</h2>
    <pre><code>import torch
import torch.nn as nn
import torch.nn.functional as F

class CrossModalRetrieval(nn.Module):
    def __init__(self, embedding_dim=512):
        super().__init__()
        # Encoder –¥–ª—è –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏ A
        self.encoder_a = nn.Sequential(
            nn.Linear(2048, 1024),
            nn.ReLU(),
            nn.Linear(1024, embedding_dim)
        )
        # Encoder –¥–ª—è –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏ B
        self.encoder_b = nn.Sequential(
            nn.Linear(768, 512),
            nn.ReLU(),
            nn.Linear(512, embedding_dim)
        )
    
    def forward(self, modal_a, modal_b):
        emb_a = F.normalize(self.encoder_a(modal_a))
        emb_b = F.normalize(self.encoder_b(modal_b))
        return emb_a, emb_b
    
    def similarity(self, emb_a, emb_b):
        return emb_a @ emb_b.T  # Cosine similarity</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. –§—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å</h2>
    <p><strong>Contrastive Loss</strong></p>
    <pre><code>def contrastive_loss(emb_a, emb_b, temperature=0.07):
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    emb_a = F.normalize(emb_a, dim=-1)
    emb_b = F.normalize(emb_b, dim=-1)
    
    # Similarity matrix
    sim_matrix = (emb_a @ emb_b.T) / temperature
    
    # Labels (–¥–∏–∞–≥–æ–Ω–∞–ª—å - –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –ø–∞—Ä—ã)
    labels = torch.arange(len(emb_a))
    
    # Symmetric loss
    loss_a2b = F.cross_entropy(sim_matrix, labels)
    loss_b2a = F.cross_entropy(sim_matrix.T, labels)
    
    return (loss_a2b + loss_b2a) / 2</code></pre>
    <p><strong>Triplet Loss</strong></p>
    <pre><code>def triplet_loss(anchor, positive, negative, margin=0.2):
    pos_dist = F.pairwise_distance(anchor, positive)
    neg_dist = F.pairwise_distance(anchor, negative)
    loss = F.relu(pos_dist - neg_dist + margin)
    return loss.mean()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. Hard Negative Mining</h2>
    <p><strong>–ü—Ä–æ–±–ª–µ–º–∞</strong>: –Ω–µ –≤—Å–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –ø–æ–ª–µ–∑–Ω—ã</p>
    <p><strong>–†–µ—à–µ–Ω–∏–µ</strong>: –≤—ã–±–∏—Ä–∞—Ç—å —Å–ª–æ–∂–Ω—ã–µ –Ω–µ–≥–∞—Ç–∏–≤—ã</p>
    <pre><code>def hard_negative_mining(anchor, positives, negatives, k=5):
    """–í—ã–±–æ—Ä k —Å–∞–º—ã—Ö —Å–ª–æ–∂–Ω—ã—Ö –Ω–µ–≥–∞—Ç–∏–≤–æ–≤"""
    # –†–∞—Å—Å—Ç–æ—è–Ω–∏—è –¥–æ –≤—Å–µ—Ö –Ω–µ–≥–∞—Ç–∏–≤–æ–≤
    neg_dists = torch.cdist(anchor, negatives)
    
    # –ë–µ—Ä–µ–º k –±–ª–∏–∂–∞–π—à–∏—Ö (—Å–ª–æ–∂–Ω—ã—Ö) –Ω–µ–≥–∞—Ç–∏–≤–æ–≤
    hard_neg_idx = neg_dists.topk(k, largest=False).indices
    hard_negatives = negatives[hard_neg_idx]
    
    return hard_negatives

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –æ–±—É—á–µ–Ω–∏–∏
for batch in dataloader:
    anchor, pos, all_negs = batch
    hard_negs = hard_negative_mining(anchor, pos, all_negs)
    loss = triplet_loss(anchor, pos, hard_negs)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞</h2>
    <table>
      <tr><th>–ú–µ—Ç—Ä–∏–∫–∞</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th></tr>
      <tr><td><strong>Recall@K</strong></td><td>–î–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –≤ —Ç–æ–ø-K —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤</td></tr>
      <tr><td><strong>MRR</strong></td><td>Mean Reciprocal Rank (—Å—Ä–µ–¥–Ω–∏–π –æ–±—Ä–∞—Ç–Ω—ã–π —Ä–∞–Ω–≥)</td></tr>
      <tr><td><strong>MAP</strong></td><td>Mean Average Precision</td></tr>
      <tr><td><strong>NDCG@K</strong></td><td>Normalized Discounted Cumulative Gain</td></tr>
      <tr><td><strong>mAP@R</strong></td><td>Mean Average Precision at R (–ø–æ –≤—Å–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º)</td></tr>
    </table>
    <pre><code>def recall_at_k(similarities, k=5):
    """Recall@K –¥–ª—è batch"""
    # similarities: [batch, batch] –º–∞—Ç—Ä–∏—Ü–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏
    batch_size = similarities.size(0)
    # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –¥–∏–∞–≥–æ–Ω–∞–ª–∏
    correct = torch.arange(batch_size)
    # –¢–æ–ø-k –∏–Ω–¥–µ–∫—Å—ã
    top_k = similarities.topk(k, dim=1).indices
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
    hits = (top_k == correct.unsqueeze(1)).any(dim=1)
    return hits.float().mean().item()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. CLIP-style retrieval</h2>
    <pre><code>from transformers import CLIPModel, CLIPProcessor

# –ó–∞–≥—Ä—É–∑–∫–∞ CLIP
model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

# –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –±–∞–∑—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
def index_images(image_paths):
    embeddings = []
    for path in image_paths:
        image = Image.open(path)
        inputs = processor(images=image, return_tensors="pt")
        with torch.no_grad():
            image_emb = model.get_image_features(**inputs)
        embeddings.append(image_emb)
    return torch.cat(embeddings)

# –ü–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –∑–∞–ø—Ä–æ—Å—É
def search(query_text, image_embeddings, k=10):
    inputs = processor(text=[query_text], return_tensors="pt")
    with torch.no_grad():
        text_emb = model.get_text_features(**inputs)
    
    # –ö–æ—Å–∏–Ω—É—Å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å
    similarities = F.cosine_similarity(text_emb, image_embeddings)
    top_k = similarities.topk(k)
    
    return top_k.indices, top_k.values</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–∞</h2>
    <p><strong>–ü—Ä–æ–±–ª–µ–º–∞</strong>: –ø–æ–∏—Å–∫ –ø–æ –º–∏–ª–ª–∏–æ–Ω–∞–º –æ–±—ä–µ–∫—Ç–æ–≤ –º–µ–¥–ª–µ–Ω–Ω—ã–π</p>
    <p><strong>–†–µ—à–µ–Ω–∏—è</strong>:</p>
    <ul>
      <li><strong>FAISS</strong>: –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –æ—Ç Facebook –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞</li>
      <li><strong>Annoy</strong>: approximate nearest neighbors</li>
      <li><strong>ScaNN</strong>: –æ—Ç Google</li>
      <li><strong>HNSW</strong>: hierarchical navigable small world</li>
    </ul>
    <pre><code>import faiss
import numpy as np

# –°–æ–∑–¥–∞–Ω–∏–µ FAISS –∏–Ω–¥–µ–∫—Å–∞
d = 512  # —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
index = faiss.IndexFlatIP(d)  # Inner Product (cosine –¥–ª—è normalized)

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
embeddings_np = embeddings.cpu().numpy()
embeddings_np = embeddings_np / np.linalg.norm(embeddings_np, axis=1, keepdims=True)
index.add(embeddings_np)

# –ü–æ–∏—Å–∫
query_emb = query_emb.cpu().numpy()
query_emb = query_emb / np.linalg.norm(query_emb)
D, I = index.search(query_emb, k=10)  # D - distances, I - indices</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. Multi-modal fusion</h2>
    <p><strong>–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞</strong></p>
    <pre><code>class MultiModalRetrieval(nn.Module):
    def __init__(self):
        super().__init__()
        self.text_encoder = TextEncoder()
        self.image_encoder = ImageEncoder()
        self.audio_encoder = AudioEncoder()
        # Fusion layer
        self.fusion = nn.Linear(512*3, 512)
    
    def encode_query(self, text=None, image=None, audio=None):
        embeds = []
        if text is not None:
            embeds.append(self.text_encoder(text))
        if image is not None:
            embeds.append(self.image_encoder(image))
        if audio is not None:
            embeds.append(self.audio_encoder(audio))
        
        # Concatenate –∏ –ø—Ä–æ–µ—Ü–∏—Ä—É–µ–º
        fused = torch.cat(embeds, dim=-1)
        return self.fusion(fused)

# –ü–æ–∏—Å–∫ —Å —Ç–µ–∫—Å—Ç–æ–º –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
query_emb = model.encode_query(
    text="red sports car",
    image=sketch_image
)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. Query expansion</h2>
    <p><strong>–£–ª—É—á—à–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ pseudo-relevance feedback</strong></p>
    <pre><code>def query_expansion(query_emb, index, alpha=0.5, top_k=5):
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ —Ç–æ–ø-K —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    """
    # –ü–µ—Ä–≤–∏—á–Ω—ã–π –ø–æ–∏—Å–∫
    D, I = index.search(query_emb, k=top_k)
    
    # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Ç–æ–ø-K
    top_embeddings = index.reconstruct_batch(I[0])
    
    # –£—Å—Ä–µ–¥–Ω—è–µ–º —Å –∏—Å—Ö–æ–¥–Ω—ã–º –∑–∞–ø—Ä–æ—Å–æ–º
    expanded_query = (1-alpha) * query_emb + alpha * top_embeddings.mean(axis=0, keepdims=True)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
    expanded_query = expanded_query / np.linalg.norm(expanded_query)
    
    # –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
    D, I = index.search(expanded_query, k=100)
    return I</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è</h3>
        <ul>
          <li>Pre-trained —ç–Ω–∫–æ–¥–µ—Ä—ã (CLIP, ALIGN)</li>
          <li>L2 –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤</li>
          <li>Hard negative mining</li>
          <li>Data augmentation –¥–ª—è –æ–±–µ–∏—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π</li>
          <li>FAISS –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è</li>
          <li>Temperature scaling –≤ contrastive loss</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ùå –ò–∑–±–µ–≥–∞—Ç—å</h3>
        <ul>
          <li>–û–±—É—á–µ–Ω–∏–µ –±–µ–∑ pre-training</li>
          <li>–ú–∞–ª–µ–Ω—å–∫–∏–π batch size (&lt;128)</li>
          <li>–ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–∞—Ä –¥–∞–Ω–Ω—ã—Ö</li>
          <li>Euclidean distance –±–µ–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏</li>
          <li>Random negatives –≤ triplet loss</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 12. –î–∞—Ç–∞—Å–µ—Ç—ã</h2>
    <table>
      <tr><th>–î–∞—Ç–∞—Å–µ—Ç</th><th>–ú–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏</th><th>–†–∞–∑–º–µ—Ä</th></tr>
      <tr><td><strong>MSCOCO</strong></td><td>Image-Text</td><td>330K –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π</td></tr>
      <tr><td><strong>Flickr30K</strong></td><td>Image-Text</td><td>31K –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π</td></tr>
      <tr><td><strong>Conceptual Captions</strong></td><td>Image-Text</td><td>3.3M –ø–∞—Ä</td></tr>
      <tr><td><strong>AudioCaps</strong></td><td>Audio-Text</td><td>50K –∞—É–¥–∏–æ</td></tr>
      <tr><td><strong>MSR-VTT</strong></td><td>Video-Text</td><td>10K –≤–∏–¥–µ–æ</td></tr>
      <tr><td><strong>Sketchy</strong></td><td>Sketch-Photo</td><td>75K —Ñ–æ—Ç–æ</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 13. Re-ranking —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏</h2>
    <p><strong>–£–ª—É—á—à–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ—Å–ª–µ –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞</strong></p>
    <ul>
      <li><strong>Reciprocal Rank Fusion</strong>: –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–µ—Ç–æ–¥–æ–≤</li>
      <li><strong>Query expansion</strong>: —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞</li>
      <li><strong>Cross-modal verification</strong>: –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è</li>
      <li><strong>Learned re-ranking</strong>: –æ–±—É—á–∞–µ–º–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø–µ—Ä–µ-—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 14. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è</h2>
    <ul>
      <li><strong>E-commerce</strong>: –ø–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –∏–ª–∏ –æ–ø–∏—Å–∞–Ω–∏—é</li>
      <li><strong>–ú–µ–¥–∏–∞</strong>: –ø–æ–∏—Å–∫ –≤–∏–¥–µ–æ, –º—É–∑—ã–∫–∏, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π</li>
      <li><strong>–î–∏–∑–∞–π–Ω</strong>: –ø–æ–∏—Å–∫ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–æ–≤ –ø–æ –Ω–∞–±—Ä–æ—Å–∫–∞–º</li>
      <li><strong>–ú–µ–¥–∏—Ü–∏–Ω–∞</strong>: –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Å–ª—É—á–∞–µ–≤ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è + —Ç–µ–∫—Å—Ç)</li>
      <li><strong>–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ</strong>: –ø–æ–∏—Å–∫ —É—á–µ–±–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤</li>
      <li><strong>–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å</strong>: –ø–æ–∏—Å–∫ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´–°–∏—Å—Ç–µ–º–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–∫–∞—Ç—å, –∏—Å–ø–æ–ª—å–∑—É—è —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã –∑–∞–ø—Ä–æ—Å–æ–≤. –ù–∞–ø—Ä–∏–º–µ—Ä, –Ω–∞–π—Ç–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ 
      –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é, –∏–ª–∏ –Ω–∞–π—Ç–∏ –≤–∏–¥–µ–æ –ø–æ –∑–≤—É–∫—É. –ú–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è –ø–æ–Ω–∏–º–∞—Ç—å —Å–º—ã—Å–ª –≤ —Ä–∞–∑–Ω—ã—Ö 
      —Ñ–æ—Ä–º–∞—Ç–∞—Ö –∏ –Ω–∞—Ö–æ–¥–∏—Ç—å –ø–æ—Ö–æ–∂–µ–µ, –¥–∞–∂–µ –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –≤ –æ–¥–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ, –∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ‚Äî –≤ –¥—Ä—É–≥–æ–º¬ª.
    </blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 15. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–∞—Ä—ã –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π</li>
      <li>[ ] –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å aligned –¥–∞—Ç–∞—Å–µ—Ç</li>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å pre-trained —ç–Ω–∫–æ–¥–µ—Ä—ã</li>
      <li>[ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å contrastive/triplet loss</li>
      <li>[ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å hard negative mining</li>
      <li>[ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ (Recall@K, MRR)</li>
      <li>[ ] –°–æ–∑–¥–∞—Ç—å FAISS –∏–Ω–¥–µ–∫—Å –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è</li>
      <li>[ ] –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å inference (batch processing)</li>
      <li>[ ] –î–æ–±–∞–≤–∏—Ç—å re-ranking —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏</li>
    </ul>
  </div>

</div>

</div>
</body>
</html>
