<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>XGBoost Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      
        min-width: 900px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

        .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üéØ XGBoost</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –°—É—Ç—å</h2>
    <ul>
      <li><strong>XGBoost</strong> = eXtreme Gradient Boosting</li>
      <li><strong>–ò–¥–µ—è</strong>: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–µ—Ä–µ–≤—å–µ–≤, –∫–∞–∂–¥–æ–µ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –æ—à–∏–±–∫–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö</li>
      <li><strong>–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</strong>: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫ –≤—Ç–æ—Ä–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞</li>
      <li><strong>–°–∫–æ—Ä–æ—Å—Ç—å</strong>: –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ, –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ</li>
      <li><strong>–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è</strong>: –≤—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è L1/L2</li>
    </ul>

    </div>
<div class="block">
    <h2>üî∑ 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞</h2>
    <pre><code># pip
pip install xgboost

# conda
conda install -c conda-forge xgboost

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏
import xgboost as xgb
print(xgb.__version__)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 3. –ë–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä (–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è)</h2>
    <pre><code>import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# –ú–æ–¥–µ–ª—å
model = xgb.XGBClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    random_state=42
)

# –û–±—É—á–µ–Ω–∏–µ
model.fit(X_train, y_train)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
y_pred = model.predict(X_test)
y_proba = model.predict_proba(X_test)

# –û—Ü–µ–Ω–∫–∞
acc = accuracy_score(y_test, y_pred)
print(f"Accuracy: {acc:.3f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. –ë–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä (–†–µ–≥—Ä–µ—Å—Å–∏—è)</h2>
    <pre><code>from sklearn.metrics import mean_squared_error
import numpy as np

# –ú–æ–¥–µ–ª—å
model = xgb.XGBRegressor(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    random_state=42
)

# –û–±—É—á–µ–Ω–∏–µ
model.fit(X_train, y_train)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
y_pred = model.predict(X_test)

# –û—Ü–µ–Ω–∫–∞
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
print(f"RMSE: {rmse:.3f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. –ö–ª—é—á–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã</h2>
    <table>
      <tr><th>–ü–∞—Ä–∞–º–µ—Ç—Ä</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th><th>–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏</th></tr>
      <tr><td><code>n_estimators</code></td><td>–ß–∏—Å–ª–æ –¥–µ—Ä–µ–≤—å–µ–≤</td><td>100-1000</td></tr>
      <tr><td><code>max_depth</code></td><td>–ì–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞</td><td>3-10</td></tr>
      <tr><td><code>learning_rate</code></td><td>–¢–µ–º–ø –æ–±—É—á–µ–Ω–∏—è (eta)</td><td>0.01-0.3</td></tr>
      <tr><td><code>subsample</code></td><td>–î–æ–ª—è –≤—ã–±–æ—Ä–∫–∏</td><td>0.5-1.0</td></tr>
      <tr><td><code>colsample_bytree</code></td><td>–î–æ–ª—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</td><td>0.5-1.0</td></tr>
      <tr><td><code>gamma</code></td><td>–ú–∏–Ω. —É–º–µ–Ω—å—à–µ–Ω–∏–µ loss</td><td>0-5</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 6. –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è</h2>
    <table>
      <tr><th>–ü–∞—Ä–∞–º–µ—Ç—Ä</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th><th>–ó–Ω–∞—á–µ–Ω–∏–µ</th></tr>
      <tr><td><code>reg_alpha</code></td><td>L1 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è</td><td>0-1</td></tr>
      <tr><td><code>reg_lambda</code></td><td>L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è</td><td>1 (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)</td></tr>
      <tr><td><code>max_depth</code></td><td>–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –≥–ª—É–±–∏–Ω—ã</td><td>3-10</td></tr>
      <tr><td><code>min_child_weight</code></td><td>–ú–∏–Ω. –≤–µ—Å –ª–∏—Å—Ç–∞</td><td>1-10</td></tr>
      <tr><td><code>gamma</code></td><td>–°–ª–æ–∂–Ω–æ—Å—Ç—å —Ä–∞–∑–±–∏–µ–Ω–∏—è</td><td>0-5</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 7. Early Stopping</h2>
    <pre><code># –° eval_set –¥–ª—è early stopping
model = xgb.XGBClassifier(
    n_estimators=1000,
    learning_rate=0.1,
    early_stopping_rounds=10
)

model.fit(
    X_train, y_train,
    eval_set=[(X_train, y_train), (X_test, y_test)],
    verbose=True
)

# –õ—É—á—à–∞—è –∏—Ç–µ—Ä–∞—Ü–∏—è
print(f"Best iteration: {model.best_iteration}")
print(f"Best score: {model.best_score:.4f}")

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ntree_limit –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏
y_pred = model.predict(X_test, 
                       iteration_range=(0, model.best_iteration))</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</h2>
    <pre><code>import matplotlib.pyplot as plt

# –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å
model.fit(X_train, y_train)

# –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
importance = model.feature_importances_

# –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
indices = np.argsort(importance)[::-1]

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
plt.figure(figsize=(10, 6))
plt.bar(range(len(importance)), importance[indices])
plt.xticks(range(len(importance)), 
           [feature_names[i] for i in indices], 
           rotation=90)
plt.xlabel('–ü—Ä–∏–∑–Ω–∞–∫–∏')
plt.ylabel('–í–∞–∂–Ω–æ—Å—Ç—å')
plt.title('Feature Importance')
plt.tight_layout()
plt.show()

# –ò–ª–∏ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π plot
xgb.plot_importance(model, max_num_features=15)
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. Cross-Validation</h2>
    <pre><code># Sklearn CV
from sklearn.model_selection import cross_val_score

scores = cross_val_score(
    model, X, y,
    cv=5,
    scoring='accuracy'
)
print(f"CV Accuracy: {scores.mean():.3f} ¬± {scores.std():.3f}")

# XGBoost –Ω–∞—Ç–∏–≤–Ω—ã–π CV
dtrain = xgb.DMatrix(X_train, label=y_train)
params = {
    'objective': 'binary:logistic',
    'max_depth': 6,
    'eta': 0.1,
    'eval_metric': 'auc'
}

cv_results = xgb.cv(
    params,
    dtrain,
    num_boost_round=100,
    nfold=5,
    early_stopping_rounds=10,
    metrics='auc',
    seed=42
)

print(cv_results)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. Grid Search –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</h2>
    <pre><code>from sklearn.model_selection import GridSearchCV

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞
param_grid = {
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.3],
    'n_estimators': [100, 200, 300],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0]
}

# Grid Search
grid = GridSearchCV(
    xgb.XGBClassifier(random_state=42),
    param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)

grid.fit(X_train, y_train)

print(f"Best params: {grid.best_params_}")
print(f"Best score: {grid.best_score_:.3f}")

# –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å
best_model = grid.best_estimator_</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. DMatrix (–Ω–∞—Ç–∏–≤–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)</h2>
    <pre><code># –°–æ–∑–¥–∞–Ω–∏–µ DMatrix –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
params = {
    'objective': 'binary:logistic',
    'max_depth': 6,
    'eta': 0.1,
    'eval_metric': 'auc'
}

# –û–±—É—á–µ–Ω–∏–µ
evals = [(dtrain, 'train'), (dtest, 'test')]
model = xgb.train(
    params,
    dtrain,
    num_boost_round=100,
    evals=evals,
    early_stopping_rounds=10,
    verbose_eval=10
)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
y_pred = model.predict(dtest)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 12. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</h2>
    <pre><code># –° –≤–µ—Ä—Å–∏–∏ 1.6.0 - –Ω–∞—Ç–∏–≤–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞
model = xgb.XGBClassifier(
    enable_categorical=True,
    tree_method='hist'
)

# –î–∞–Ω–Ω—ã–µ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ category
import pandas as pd
df['cat_column'] = df['cat_column'].astype('category')

model.fit(df, y)

# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: Label Encoding
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
X['cat_column'] = le.fit_transform(X['cat_column'])

# –ò–ª–∏ One-Hot Encoding
X_encoded = pd.get_dummies(X, columns=['cat_column'])</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 13. –†–∞–±–æ—Ç–∞ —Å –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏</h2>
    <pre><code># scale_pos_weight
from collections import Counter

# –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –±–∞–ª–∞–Ω—Å
counter = Counter(y_train)
scale = counter[0] / counter[1]

model = xgb.XGBClassifier(
    scale_pos_weight=scale,
    max_depth=6,
    learning_rate=0.1
)

model.fit(X_train, y_train)

# –ò–ª–∏ sample_weight –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
from sklearn.utils.class_weight import compute_sample_weight
sample_weights = compute_sample_weight('balanced', y_train)

model.fit(X_train, y_train, sample_weight=sample_weights)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 14. –ú—É–ª—å—Ç–∏–∫–ª–∞—Å—Å–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è</h2>
    <pre><code># –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
model = xgb.XGBClassifier(
    objective='multi:softmax',  # –∏–ª–∏ 'multi:softprob'
    num_class=3,  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
    max_depth=6
)

model.fit(X_train, y_train)

# softmax - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–ª–∞—Å—Å
# softprob - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
y_pred = model.predict(X_test)
y_proba = model.predict_proba(X_test)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 15. –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –•–æ—Ä–æ—à–æ</h3>
        <ul>
          <li>–¢–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ</li>
          <li>–°–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è (Kaggle)</li>
          <li>–°—Ä–µ–¥–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—ã (< 1M —Å—Ç—Ä–æ–∫)</li>
          <li>–°–º–µ—Å—å —á–∏—Å–ª–æ–≤—ã—Ö –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</li>
          <li>–ù—É–∂–Ω–∞ –≤—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å</li>
          <li>–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å –≤–∞–∂–Ω–∞</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ùå –ü–ª–æ—Ö–æ</h3>
        <ul>
          <li>–û—á–µ–Ω—å –±–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ LightGBM)</li>
          <li>–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Ç–µ–∫—Å—Ç (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ DL)</li>
          <li>–ù—É–∂–Ω–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å</li>
          <li>–û–Ω–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏–µ</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 16. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏</h2>
    <pre><code># –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
model.save_model('xgboost_model.json')

# –ò–ª–∏ pickle
import pickle
with open('model.pkl', 'wb') as f:
    pickle.dump(model, f)

# –ó–∞–≥—Ä—É–∑–∫–∞
model = xgb.XGBClassifier()
model.load_model('xgboost_model.json')

# –ò–ª–∏ –∏–∑ pickle
with open('model.pkl', 'rb') as f:
    model = pickle.load(f)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 17. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –¥—Ä—É–≥–∏–º–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞–º–∏</h2>
    <table>
      <tr><th>–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞</th><th>–°–∫–æ—Ä–æ—Å—Ç—å</th><th>–ü–∞–º—è—Ç—å</th><th>–¢–æ—á–Ω–æ—Å—Ç—å</th></tr>
      <tr><td><strong>XGBoost</strong></td><td>–°—Ä–µ–¥–Ω—è—è</td><td>–°—Ä–µ–¥–Ω—è—è</td><td>–í—ã—Å–æ–∫–∞—è</td></tr>
      <tr><td><strong>LightGBM</strong></td><td>–ë—ã—Å—Ç—Ä–∞—è</td><td>–ù–∏–∑–∫–∞—è</td><td>–í—ã—Å–æ–∫–∞—è</td></tr>
      <tr><td><strong>CatBoost</strong></td><td>–ú–µ–¥–ª–µ–Ω–Ω–∞—è</td><td>–°—Ä–µ–¥–Ω—è—è</td><td>–û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è</td></tr>
      <tr><td><strong>Sklearn GB</strong></td><td>–ú–µ–¥–ª–µ–Ω–Ω–∞—è</td><td>–í—ã—Å–æ–∫–∞—è</td><td>–°—Ä–µ–¥–Ω—è—è</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 18. –¢–∏–ø–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏</h2>
    <ul>
      <li><strong>–°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π learning_rate</strong> ‚Äî —É–º–µ–Ω—å—à–∏—Ç—å –¥–æ 0.01-0.1</li>
      <li><strong>–°–ª–∏—à–∫–æ–º –≥–ª—É–±–æ–∫–∏–µ –¥–µ—Ä–µ–≤—å—è</strong> ‚Äî –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ, —É–º–µ–Ω—å—à–∏—Ç—å max_depth</li>
      <li><strong>–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å early_stopping</strong> ‚Äî –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–æ–±—É—á–∞–µ—Ç—Å—è</li>
      <li><strong>–ó–∞–±—ã—Ç—å –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ</strong> ‚Äî –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è XGBoost, –Ω–æ –º–æ–∂–µ—Ç –ø–æ–º–æ—á—å</li>
      <li><strong>–ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å class_weight</strong> ‚Äî –ø–ª–æ—Ö–æ –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 19. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –ù–∞—á–∞—Ç—å —Å –±–∞–∑–æ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</li>
      <li>[ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å early_stopping_rounds</li>
      <li>[ ] –ü–æ–¥–æ–±—Ä–∞—Ç—å learning_rate –∏ n_estimators</li>
      <li>[ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å max_depth (3-10)</li>
      <li>[ ] –î–æ–±–∞–≤–∏—Ç—å subsample –∏ colsample_bytree</li>
      <li>[ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å reg_alpha/reg_lambda –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏</li>
      <li>[ ] –î–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: scale_pos_weight</li>
      <li>[ ] –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</li>
      <li>[ ] –°—Ä–∞–≤–Ω–∏—Ç—å —Å LightGBM –∏ CatBoost</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´XGBoost ‚Äî —ç—Ç–æ –æ—á–µ–Ω—å –º–æ—â–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º, –∫–æ—Ç–æ—Ä—ã–π —Å—Ç—Ä–æ–∏—Ç –º–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—ã—Ö –º–æ–¥–µ–ª–µ–π (–¥–µ—Ä–µ–≤—å–µ–≤ —Ä–µ—à–µ–Ω–∏–π) –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏—Ö. –ö–∞–∂–¥–æ–µ –Ω–æ–≤–æ–µ –¥–µ—Ä–µ–≤–æ —É—á–∏—Ç—Å—è –Ω–∞ –æ—à–∏–±–∫–∞—Ö –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö. –≠—Ç–æ –∫–∞–∫ –∫–æ–º–∞–Ω–¥–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤, –≥–¥–µ –∫–∞–∂–¥—ã–π —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –æ—à–∏–±–æ–∫ –∫–æ–ª–ª–µ–≥¬ª.
    </blockquote>
  </div>



</div>
</body>
</html>
