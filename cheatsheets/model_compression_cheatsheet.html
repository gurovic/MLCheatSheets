<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>–°–∂–∞—Ç–∏–µ –º–æ–¥–µ–ª–µ–π Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen { body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif; color: #333; background: #fafcff; padding: 10px; } }
    @media print { body { background: white; padding: 0; } @page { size: A4 landscape; margin: 10mm; } }
    .container { column-count: 3; column-gap: 20px; max-width: 100%; }
    .block { break-inside: avoid; margin-bottom: 1.2em; padding: 12px; background: white; border-radius: 6px; box-shadow: 0 1px 3px rgba(0,0,0,0.05); }
    h1 { font-size: 1.6em; font-weight: 700; color: #1a5fb4; text-align: center; margin: 0 0 8px; column-span: all; }
    .subtitle { text-align: center; color: #666; font-size: 0.9em; margin-bottom: 12px; column-span: all; }
    h2 { font-size: 1.15em; font-weight: 700; color: #1a5fb4; margin: 0 0 8px; padding-bottom: 4px; border-bottom: 1px solid #e0e7ff; }
    p, ul, ol { font-size: 0.92em; margin: 0.6em 0; }
    ul, ol { padding-left: 18px; }
    li { margin-bottom: 4px; }
    code { font-family: 'Consolas', 'Courier New', monospace; background-color: #f0f4ff; padding: 1px 4px; border-radius: 3px; font-size: 0.88em; }
    pre { background-color: #f0f4ff; padding: 8px; border-radius: 4px; overflow-x: auto; font-size: 0.84em; margin: 6px 0; }
    pre code { padding: 0; background: none; white-space: pre-wrap; }
    table { width: 100%; border-collapse: collapse; font-size: 0.82em; margin: 6px 0; }
    th { background-color: #e6f0ff; text-align: left; padding: 4px 6px; font-weight: 600; }
    td { padding: 4px 6px; border-bottom: 1px solid #f0f4ff; }
    tr:nth-child(even) { background-color: #f8fbff; }
    .good-vs-bad { display: flex; flex-direction: column; gap: 8px; }
    .good-vs-bad div { flex: 1; padding: 6px 8px; border-radius: 4px; }
    .good { background-color: #f0f9f4; border-left: 3px solid #2e8b57; }
    .bad { background-color: #fdf0f2; border-left: 3px solid #d32f2f; }
    .good h3, .bad h3 { margin: 0 0 4px; font-size: 1em; font-weight: 700; }
    .good ul, .bad ul { padding-left: 20px; margin: 0; }
    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }
    blockquote { font-style: italic; margin: 8px 0; padding: 6px 10px; background: #f8fbff; border-left: 2px solid #1a5fb4; font-size: 0.88em; }
    @media print { .container { column-gap: 12px; } .block { box-shadow: none; } code, pre, table { font-size: 0.78em; } h1 { font-size: 1.4em; } h2 { font-size: 1em; } }
  </style>
</head>
<body>

<div class="container">

  <h1>üóúÔ∏è –°–∂–∞—Ç–∏–µ –º–æ–¥–µ–ª–µ–π</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –ó–∞—á–µ–º —Å–∂–∏–º–∞—Ç—å –º–æ–¥–µ–ª–∏?</h2>
    <p><strong>–ü—Ä–æ–±–ª–µ–º—ã –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π:</strong></p>
    <ul>
      <li>–ë–æ–ª—å—à–æ–π —Ä–∞–∑–º–µ—Ä (GB) ‚Üí —Å–ª–æ–∂–Ω–æ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞—Ç—å</li>
      <li>–ú–µ–¥–ª–µ–Ω–Ω—ã–π inference</li>
      <li>–í—ã—Å–æ–∫–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏</li>
      <li>–ù–µ —Ä–∞–±–æ—Ç–∞—é—Ç –Ω–∞ –º–æ–±–∏–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö</li>
    </ul>
    
    <p><strong>–ú–µ—Ç–æ–¥—ã —Å–∂–∞—Ç–∏—è:</strong></p>
    <table>
      <tr><th>–ú–µ—Ç–æ–¥</th><th>–°–∂–∞—Ç–∏–µ</th><th>–¢–æ—á–Ω–æ—Å—Ç—å</th></tr>
      <tr><td><strong>–ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è</strong></td><td>4x</td><td>-0.1-1%</td></tr>
      <tr><td><strong>–ü—Ä—É–Ω–∏–Ω–≥</strong></td><td>2-10x</td><td>-0.5-2%</td></tr>
      <tr><td><strong>Knowledge Distillation</strong></td><td>3-10x</td><td>-1-3%</td></tr>
      <tr><td><strong>Low-rank decomposition</strong></td><td>2-3x</td><td>-0.5-1%</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 2. –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è</h2>
    <p><strong>Quantization</strong> ‚Äî —Å–Ω–∏–∂–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –≤–µ—Å–æ–≤ —Å FP32 –¥–æ INT8/INT4.</p>
    
    <p><strong>–¢–∏–ø—ã:</strong></p>
    <ul>
      <li><strong>Post-training quantization</strong>: –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è</li>
      <li><strong>Quantization-aware training</strong>: –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è</li>
      <li><strong>Dynamic quantization</strong>: —Ç–æ–ª—å–∫–æ –≤–µ—Å–∞</li>
      <li><strong>Static quantization</strong>: –≤–µ—Å–∞ + –∞–∫—Ç–∏–≤–∞—Ü–∏–∏</li>
    </ul>
    
    <p><strong>–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:</strong></p>
    <ul>
      <li>–ú–æ–¥–µ–ª—å –º–µ–Ω—å—à–µ –≤ 4 —Ä–∞–∑–∞ (FP32‚ÜíINT8)</li>
      <li>Inference –±—ã—Å—Ç—Ä–µ–µ –≤ 2-4 —Ä–∞–∑–∞</li>
      <li>–ú–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏</li>
      <li>–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–æ—Ç–µ—Ä—è —Ç–æ—á–Ω–æ—Å—Ç–∏</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 3. –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è PyTorch</h2>
    <pre><code>import torch
import torch.quantization as quantization

# 1. Dynamic Quantization (–ø—Ä–æ—â–µ –≤—Å–µ–≥–æ)
model_fp32 = MyModel()
model_int8 = torch.quantization.quantize_dynamic(
    model_fp32,
    {torch.nn.Linear, torch.nn.LSTM},  # –∫–∞–∫–∏–µ —Å–ª–æ–∏
    dtype=torch.qint8
)

# 2. Post-Training Static Quantization
model = MyModel()
model.eval()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏
model.qconfig = torch.quantization.get_default_qconfig('fbgemm')
torch.quantization.prepare(model, inplace=True)

# Calibration (–ø—Ä–æ–≥–Ω–∞—Ç—å –¥–∞–Ω–Ω—ã–µ)
with torch.no_grad():
    for batch in calibration_loader:
        model(batch)

# –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è
torch.quantization.convert(model, inplace=True)

# 3. Quantization-Aware Training
model = MyModel()
model.train()

# Prepare –¥–ª—è QAT
model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')
model_prepared = torch.quantization.prepare_qat(model)

# –û–±—É—á–µ–Ω–∏–µ
for epoch in range(num_epochs):
    train_one_epoch(model_prepared)

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
model_quantized = torch.quantization.convert(model_prepared.eval())</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. –ü—Ä—É–Ω–∏–Ω–≥ (Pruning)</h2>
    <p><strong>Pruning</strong> ‚Äî —É–¥–∞–ª–µ–Ω–∏–µ –º–∞–ª–æ–∑–Ω–∞—á–∏–º—ã—Ö –≤–µ—Å–æ–≤.</p>
    
    <p><strong>–¢–∏–ø—ã:</strong></p>
    <ul>
      <li><strong>Unstructured</strong>: —É–¥–∞–ª–µ–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –≤–µ—Å–æ–≤</li>
      <li><strong>Structured</strong>: —É–¥–∞–ª–µ–Ω–∏–µ —Ü–µ–ª—ã—Ö –∫–∞–Ω–∞–ª–æ–≤/–Ω–µ–π—Ä–æ–Ω–æ–≤</li>
      <li><strong>Magnitude-based</strong>: –ø–æ –∞–±—Å–æ–ª—é—Ç–Ω–æ–π –≤–µ–ª–∏—á–∏–Ω–µ</li>
      <li><strong>Gradient-based</strong>: –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤</li>
    </ul>
    
    <pre><code>import torch.nn.utils.prune as prune

# Unstructured pruning
model = MyModel()

# –ü—Ä—É–Ω–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ —Å–ª–æ—è (30% –≤–µ—Å–æ–≤)
prune.l1_unstructured(
    module=model.conv1,
    name='weight',
    amount=0.3
)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –ø—Ä—É–Ω–∏–Ω–≥ (20% –≤—Å–µ—Ö –≤–µ—Å–æ–≤)
parameters_to_prune = []
for module in model.modules():
    if isinstance(module, torch.nn.Conv2d):
        parameters_to_prune.append((module, 'weight'))

prune.global_unstructured(
    parameters_to_prune,
    pruning_method=prune.L1Unstructured,
    amount=0.2
)

# –°–¥–µ–ª–∞—Ç—å –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–º
for module, _ in parameters_to_prune:
    prune.remove(module, 'weight')</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. Structured Pruning</h2>
    <pre><code># –£–¥–∞–ª–µ–Ω–∏–µ —Ü–µ–ª—ã—Ö –∫–∞–Ω–∞–ª–æ–≤
prune.ln_structured(
    module=model.conv1,
    name='weight',
    amount=0.3,
    n=2,  # L2 norm
    dim=0  # –≤—ã—Ö–æ–¥–Ω—ã–µ –∫–∞–Ω–∞–ª—ã
)

# Iterative pruning —Å fine-tuning
def iterative_pruning(model, amount, epochs):
    for step in range(5):  # 5 –∏—Ç–µ—Ä–∞—Ü–∏–π
        # –ü—Ä—É–Ω–∏–Ω–≥
        for module in model.modules():
            if isinstance(module, torch.nn.Conv2d):
                prune.ln_structured(
                    module, 'weight',
                    amount=amount/5,  # –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ
                    n=2, dim=0
                )
        
        # Fine-tuning
        for epoch in range(epochs):
            train_one_epoch(model)
    
    # –£–¥–∞–ª–∏—Ç—å –º–∞—Å–∫–∏
    for module in model.modules():
        if isinstance(module, torch.nn.Conv2d):
            prune.remove(module, 'weight')
    
    return model

pruned_model = iterative_pruning(model, amount=0.5, epochs=10)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. Knowledge Distillation</h2>
    <p><strong>Distillation</strong> ‚Äî –æ–±—É—á–µ–Ω–∏–µ –º–∞–ª–µ–Ω—å–∫–æ–π –º–æ–¥–µ–ª–∏ (student) –Ω–∞ –≤—ã—Ö–æ–¥–∞—Ö –±–æ–ª—å—à–æ–π (teacher).</p>
    
    <p><strong>–ò–¥–µ—è:</strong></p>
    <ul>
      <li>Teacher: –±–æ–ª—å—à–∞—è —Ç–æ—á–Ω–∞—è –º–æ–¥–µ–ª—å</li>
      <li>Student: –º–∞–ª–µ–Ω—å–∫–∞—è –±—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å</li>
      <li>Student —É—á–∏—Ç—Å—è –Ω–∞ soft targets –æ—Ç teacher</li>
    </ul>
    
    <pre><code># Teacher model (–±–æ–ª—å—à–∞—è)
teacher = LargeModel()
teacher.load_state_dict(torch.load('teacher.pth'))
teacher.eval()

# Student model (–º–∞–ª–µ–Ω—å–∫–∞—è)
student = SmallModel()

# Distillation loss
class DistillationLoss(nn.Module):
    def __init__(self, temperature=3.0, alpha=0.5):
        super().__init__()
        self.temperature = temperature
        self.alpha = alpha
        self.ce_loss = nn.CrossEntropyLoss()
        self.kl_loss = nn.KLDivLoss(reduction='batchmean')
    
    def forward(self, student_logits, teacher_logits, labels):
        # Hard targets (ground truth)
        hard_loss = self.ce_loss(student_logits, labels)
        
        # Soft targets (–æ—Ç teacher)
        soft_loss = self.kl_loss(
            F.log_softmax(student_logits / self.temperature, dim=1),
            F.softmax(teacher_logits / self.temperature, dim=1)
        ) * (self.temperature ** 2)
        
        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π loss
        return self.alpha * hard_loss + (1 - self.alpha) * soft_loss

# Training
criterion = DistillationLoss(temperature=3.0, alpha=0.5)
optimizer = optim.Adam(student.parameters(), lr=1e-3)

for batch in dataloader:
    images, labels = batch
    
    # Teacher predictions (no grad)
    with torch.no_grad():
        teacher_logits = teacher(images)
    
    # Student predictions
    student_logits = student(images)
    
    # Distillation loss
    loss = criterion(student_logits, teacher_logits, labels)
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()</code></pre>
  </div>

  <div class="block">
    <h2>ÔøΩÔøΩ 7. TensorFlow Lite</h2>
    <p><strong>–ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤:</strong></p>
    <pre><code>import tensorflow as tf

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ TFLite
converter = tf.lite.TFLiteConverter.from_keras_model(model)

# Post-training quantization (INT8)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

# –ü–æ–ª–Ω–∞—è INT8 –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è
def representative_dataset():
    for data in calibration_dataset.take(100):
        yield [data]

converter.representative_dataset = representative_dataset
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8
converter.inference_output_type = tf.int8

tflite_quant_model = converter.convert()

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
with open('model_quant.tflite', 'wb') as f:
    f.write(tflite_quant_model)

# Inference
interpreter = tf.lite.Interpreter(model_path='model_quant.tflite')
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

interpreter.set_tensor(input_details[0]['index'], input_data)
interpreter.invoke()
output = interpreter.get_tensor(output_details[0]['index'])</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. ONNX Runtime</h2>
    <pre><code># –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX
torch.onnx.export(
    model,
    dummy_input,
    'model.onnx',
    input_names=['input'],
    output_names=['output'],
    dynamic_axes={'input': {0: 'batch_size'}}
)

# –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è ONNX
from onnxruntime.quantization import quantize_dynamic, QuantType

quantize_dynamic(
    'model.onnx',
    'model_quant.onnx',
    weight_type=QuantType.QUInt8
)

# Inference —Å ONNX Runtime
import onnxruntime as ort

session = ort.InferenceSession('model_quant.onnx')
outputs = session.run(
    None,
    {'input': input_data.numpy()}
)

# TensorRT (NVIDIA GPU)
import tensorrt as trt

# ... TensorRT optimization ...
# –î–æ—Å—Ç–∏–≥–∞–µ—Ç—Å—è 5-10x —É—Å–∫–æ—Ä–µ–Ω–∏–µ!</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. Mixed Precision Training</h2>
    <pre><code># PyTorch AMP (Automatic Mixed Precision)
from torch.cuda.amp import autocast, GradScaler

model = MyModel().cuda()
optimizer = optim.Adam(model.parameters())
scaler = GradScaler()

for batch in dataloader:
    optimizer.zero_grad()
    
    # Forward —Å FP16
    with autocast():
        outputs = model(inputs)
        loss = criterion(outputs, targets)
    
    # Backward —Å –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()

# TensorFlow Mixed Precision
from tensorflow.keras import mixed_precision

policy = mixed_precision.Policy('mixed_float16')
mixed_precision.set_global_policy(policy)

model = create_model()
optimizer = tf.keras.optimizers.Adam()
optimizer = mixed_precision.LossScaleOptimizer(optimizer)

# Training as usual</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. Low-Rank Decomposition</h2>
    <p><strong>–†–∞–∑–ª–æ–∂–µ–Ω–∏–µ –≤–µ—Å–æ–≤</strong> –Ω–∞ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–Ω–≥–∞:</p>
    <pre><code># SVD decomposition –¥–ª—è —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–≥–æ —Å–ª–æ—è
import torch.nn as nn

def decompose_conv_layer(layer, rank_ratio=0.5):
    # –ü–æ–ª—É—á–∏—Ç—å –≤–µ—Å–∞
    weight = layer.weight.data  # (out_ch, in_ch, kh, kw)
    out_ch, in_ch, kh, kw = weight.shape
    
    # Reshape –¥–ª—è SVD
    W = weight.view(out_ch, -1)  # (out_ch, in_ch*kh*kw)
    
    # SVD
    U, S, V = torch.svd(W)
    
    # –í—ã–±—Ä–∞—Ç—å —Ä–∞–Ω–≥
    rank = int(rank_ratio * min(out_ch, in_ch*kh*kw))
    U_reduced = U[:, :rank]
    S_reduced = torch.diag(S[:rank])
    V_reduced = V[:, :rank].t()
    
    # –°–æ–∑–¥–∞—Ç—å –¥–≤–∞ –Ω–æ–≤—ã—Ö —Å–ª–æ—è
    layer1 = nn.Conv2d(in_ch, rank, 1, bias=False)
    layer2 = nn.Conv2d(rank, out_ch, (kh, kw), 
                      stride=layer.stride,
                      padding=layer.padding,
                      bias=layer.bias is not None)
    
    # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤–µ—Å–∞
    layer1.weight.data = V_reduced.view(rank, in_ch, 1, 1)
    layer2.weight.data = (U_reduced @ S_reduced).view(out_ch, rank, kh, kw)
    
    return nn.Sequential(layer1, layer2)

# –ü—Ä–∏–º–µ–Ω–∏—Ç—å –∫ –º–æ–¥–µ–ª–∏
for name, module in model.named_children():
    if isinstance(module, nn.Conv2d):
        setattr(model, name, decompose_conv_layer(module, rank_ratio=0.5))</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. Model Optimization Pipeline</h2>
    <ol>
      <li><strong>Baseline</strong>: –æ–±—É—á–∏—Ç—å –ø–æ–ª–Ω—É—é –º–æ–¥–µ–ª—å</li>
      <li><strong>Pruning</strong>: —É–¥–∞–ª–∏—Ç—å 30-50% –≤–µ—Å–æ–≤</li>
      <li><strong>Fine-tuning</strong>: –¥–æ–æ–±—É—á–∏—Ç—å 5-10 —ç–ø–æ—Ö</li>
      <li><strong>Quantization</strong>: INT8 –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è</li>
      <li><strong>Validation</strong>: –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å</li>
      <li><strong>Export</strong>: ONNX/TFLite/TensorRT</li>
    </ol>
    
    <pre><code>def optimize_model(model, train_loader, val_loader):
    # 1. Baseline
    print("Baseline accuracy:", evaluate(model, val_loader))
    
    # 2. Pruning
    prune_model(model, amount=0.5)
    
    # 3. Fine-tuning
    fine_tune(model, train_loader, epochs=10)
    print("After pruning:", evaluate(model, val_loader))
    
    # 4. Quantization
    model_quant = quantize_model(model, val_loader)
    print("After quantization:", evaluate(model_quant, val_loader))
    
    # 5. Export
    torch.save(model_quant.state_dict(), 'optimized_model.pth')
    
    return model_quant</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 12. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤</h2>
    <table>
      <tr><th>–ú–µ—Ç–æ–¥</th><th>–°–∂–∞—Ç–∏–µ</th><th>–°–∫–æ—Ä–æ—Å—Ç—å</th><th>–°–ª–æ–∂–Ω–æ—Å—Ç—å</th></tr>
      <tr><td>–ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è INT8</td><td>4x</td><td>2-4x</td><td>–õ–µ–≥–∫–æ</td></tr>
      <tr><td>–ü—Ä—É–Ω–∏–Ω–≥ 50%</td><td>2x</td><td>1.5x</td><td>–°—Ä–µ–¥–Ω–µ</td></tr>
      <tr><td>Distillation</td><td>10x</td><td>10x</td><td>–°–ª–æ–∂–Ω–æ</td></tr>
      <tr><td>Low-rank</td><td>2-3x</td><td>1.5-2x</td><td>–õ–µ–≥–∫–æ</td></tr>
      <tr><td>–ö–æ–º–±–∏–Ω–∞—Ü–∏—è</td><td>20x+</td><td>10x+</td><td>–°–ª–æ–∂–Ω–æ</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 13. –ú–µ—Ç—Ä–∏–∫–∏</h2>
    <pre><code># –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏
import os

def get_model_size(model_path):
    size_mb = os.path.getsize(model_path) / (1024 * 1024)
    return f"{size_mb:.2f} MB"

# –°–∫–æ—Ä–æ—Å—Ç—å inference
import time

def measure_inference_time(model, inputs, num_runs=100):
    model.eval()
    with torch.no_grad():
        # Warmup
        for _ in range(10):
            _ = model(inputs)
        
        # –ò–∑–º–µ—Ä–µ–Ω–∏–µ
        start = time.time()
        for _ in range(num_runs):
            _ = model(inputs)
        end = time.time()
    
    avg_time = (end - start) / num_runs * 1000
    return f"{avg_time:.2f} ms"

# –¢–æ—á–Ω–æ—Å—Ç—å
def evaluate_accuracy(model, test_loader):
    model.eval()
    correct = 0
    total = 0
    
    with torch.no_grad():
        for images, labels in test_loader:
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    
    return correct / total * 100

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
print("Original:", get_model_size('original.pth'))
print("Compressed:", get_model_size('compressed.pth'))
print("Compression ratio:", ...)
print("Inference time:", measure_inference_time(model, dummy_input))
print("Accuracy:", evaluate_accuracy(model, test_loader))</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 14. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ Best Practices</h3>
        <ul>
          <li>–ù–∞—á–Ω–∏—Ç–µ —Å <strong>–∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏</strong> (—Å–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥)</li>
          <li><strong>QAT</strong> –ª—É—á—à–µ post-training –¥–ª—è critical applications</li>
          <li>–ö–æ–º–±–∏–Ω–∏—Ä—É–π—Ç–µ –º–µ—Ç–æ–¥—ã –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —ç—Ñ—Ñ–µ–∫—Ç–∞</li>
          <li>–í—Å–µ–≥–¥–∞ –≤–∞–ª–∏–¥–∏—Ä—É–π—Ç–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ</li>
          <li>–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ <strong>mixed precision</strong> –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ö†Ô∏è –ß–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏</h3>
        <ul>
          <li>–°–ª–∏—à–∫–æ–º –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ —Å–∂–∞—Ç–∏–µ ‚Üí –±–æ–ª—å—à–∞—è –ø–æ—Ç–µ—Ä—è —Ç–æ—á–Ω–æ—Å—Ç–∏</li>
          <li>–ó–∞–±—ã–ª–∏ calibration –ø—Ä–∏ static quantization</li>
          <li>–ù–µ –ø—Ä–æ–≤–µ—Ä–∏–ª–∏ –Ω–∞ —Ü–µ–ª–µ–≤–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ</li>
          <li>Pruning –±–µ–∑ fine-tuning</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 15. –ú–æ–±–∏–ª—å–Ω—ã–µ deployment</h2>
    <pre><code># iOS (Core ML)
import coremltools as ct

model_coreml = ct.convert(
    model,
    inputs=[ct.ImageType(shape=(1, 3, 224, 224))]
)
model_coreml.save('model.mlmodel')

# Android (TFLite)
# –°–º. —Ä–∞–∑–¥–µ–ª TFLite –≤—ã—à–µ

# Edge devices (ONNX Runtime)
# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è ARM/x86
# –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è INT8 –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 16. –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ frameworks</h2>
    <ul>
      <li><strong>TVM</strong>: –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –ª—é–±–æ–≥–æ hardware</li>
      <li><strong>TensorRT</strong>: NVIDIA GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li><strong>OpenVINO</strong>: Intel –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li><strong>Neural Compressor</strong>: Intel –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è</li>
      <li><strong>Brevitas</strong>: PyTorch quantization</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 17. –ß–µ–∫-–ª–∏—Å—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏</h2>
    <ul>
      <li>[ ] –ò–∑–º–µ—Ä–∏–ª–∏ baseline (—Ä–∞–∑–º–µ—Ä, —Å–∫–æ—Ä–æ—Å—Ç—å, —Ç–æ—á–Ω–æ—Å—Ç—å)</li>
      <li>[ ] –ü—Ä–∏–º–µ–Ω–∏–ª–∏ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é (INT8 –∏–ª–∏ FP16)</li>
      <li>[ ] –ü–æ–ø—Ä–æ–±–æ–≤–∞–ª–∏ pruning —Å fine-tuning</li>
      <li>[ ] –†–∞—Å—Å–º–æ—Ç—Ä–µ–ª–∏ knowledge distillation</li>
      <li>[ ] –ü—Ä–æ–≤–µ—Ä–∏–ª–∏ —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ validation set</li>
      <li>[ ] –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–ª–∏ –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (ONNX/TFLite)</li>
      <li>[ ] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–ª–∏ –Ω–∞ —Ü–µ–ª–µ–≤–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ</li>
      <li>[ ] –ò–∑–º–µ—Ä–∏–ª–∏ —Ä–µ–∞–ª—å–Ω–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ</li>
      <li>[ ] –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–ª–∏ trade-offs</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´–°–∂–∞—Ç–∏–µ –º–æ–¥–µ–ª–∏ ‚Äî –∫–∞–∫ —É–ø–∞–∫–æ–≤–∫–∞ —á–µ–º–æ–¥–∞–Ω–∞ –¥–ª—è –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è. –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è ‚Äî —ç—Ç–æ –≤–∑—è—Ç—å –∫–æ–º–ø–∞–∫—Ç–Ω—É—é –≤–µ—Ä—Å–∏—é –≤–µ—â–µ–π –≤–º–µ—Å—Ç–æ –±–æ–ª—å—à–∏—Ö. –ü—Ä—É–Ω–∏–Ω–≥ ‚Äî –≤—ã–±—Ä–æ—Å–∏—Ç—å –Ω–µ–Ω—É–∂–Ω–æ–µ. Distillation ‚Äî –Ω–∞—É—á–∏—Ç—å –º–∞–ª–µ–Ω—å–∫—É—é –º–æ–¥–µ–ª—å –¥–µ–ª–∞—Ç—å —Ç–æ –∂–µ, —á—Ç–æ –±–æ–ª—å—à–∞—è. –í –∏—Ç–æ–≥–µ –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 10 —Ä–∞–∑ –±—ã—Å—Ç—Ä–µ–µ –∏ –∑–∞–Ω–∏–º–∞–µ—Ç –≤ 4 —Ä–∞–∑–∞ –º–µ–Ω—å—à–µ –º–µ—Å—Ç–∞¬ª.
    </blockquote>
  </div>

</div>

</body>
</html>
