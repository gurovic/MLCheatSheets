<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>CNN Visualization Techniques Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

    .container {
      column-count: 3;
      column-gap: 20px;
      max-width: 100%;
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üëÅÔ∏è CNN Visualization Techniques</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –ó–∞—á–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å CNN?</h2>
    <ul>
      <li><strong>–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å</strong>: –ø–æ–Ω—è—Ç—å, —á—Ç–æ –≤–∏–¥–∏—Ç —Å–µ—Ç—å</li>
      <li><strong>–û—Ç–ª–∞–¥–∫–∞</strong>: –Ω–∞–π—Ç–∏ –ø—Ä–æ–±–ª–µ–º—ã –≤ –æ–±—É—á–µ–Ω–∏–∏</li>
      <li><strong>–î–æ–≤–µ—Ä–∏–µ</strong>: –æ–±—ä—è—Å–Ω–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è</li>
      <li><strong>–£–ª—É—á—à–µ–Ω–∏–µ</strong>: –∏–¥–µ–∏ –¥–ª—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã</li>
      <li><strong>–ù–∞—É—á–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ</strong>: –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç deep learning</li>
    </ul>

  <div class="block">
    <h2>üî∑ 2. –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –º–µ—Ç–æ–¥–æ–≤</h2>
    <table>
      <tr><th>–ú–µ—Ç–æ–¥</th><th>–ß—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç</th><th>–°–ª–æ–∂–Ω–æ—Å—Ç—å</th></tr>
      <tr><td><strong>–§–∏–ª—å—Ç—Ä—ã</strong></td><td>–ß—Ç–æ –¥–µ—Ç–µ–∫—Ç–∏—Ä—É—é—Ç –ø–µ—Ä–≤—ã–µ —Å–ª–æ–∏</td><td>–ù–∏–∑–∫–∞—è</td></tr>
      <tr><td><strong>Feature Maps</strong></td><td>–ê–∫—Ç–∏–≤–∞—Ü–∏–∏ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Å–ª–æ—è—Ö</td><td>–ù–∏–∑–∫–∞—è</td></tr>
      <tr><td><strong>Grad-CAM</strong></td><td>–í–∞–∂–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ –¥–ª—è –∫–ª–∞—Å—Å–∞</td><td>–°—Ä–µ–¥–Ω—è—è</td></tr>
      <tr><td><strong>Saliency Maps</strong></td><td>–í–ª–∏—è–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –ø–∏–∫—Å–µ–ª—è</td><td>–°—Ä–µ–¥–Ω—è—è</td></tr>
      <tr><td><strong>DeepDream</strong></td><td>–ß—Ç–æ —Å–µ—Ç—å "–≤–∏–¥–∏—Ç" –≤ —à—É–º–µ</td><td>–í—ã—Å–æ–∫–∞—è</td></tr>
      <tr><td><strong>Neural Style</strong></td><td>–ö–æ–º–±–∏–Ω–∞—Ü–∏—è —Å—Ç–∏–ª—è –∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞</td><td>–í—ã—Å–æ–∫–∞—è</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 3. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–∏–ª—å—Ç—Ä–æ–≤ (–≤–µ—Å–æ–≤)</h2>
    <pre><code>import torch
import matplotlib.pyplot as plt
import torchvision.models as models

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
model = models.vgg16(pretrained=True)

# –ü–æ–ª—É—á–∏—Ç—å –≤–µ—Å–∞ –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ—è
first_layer = model.features[0]
filters = first_layer.weight.data.cpu()

# filters: (64, 3, 3, 3) = (out_ch, in_ch, H, W)
print(f"Filter shape: {filters.shape}")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
fig, axes = plt.subplots(8, 8, figsize=(12, 12))
for i, ax in enumerate(axes.flat):
    if i < filters.shape[0]:
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        f = filters[i].permute(1, 2, 0)  # (3, 3, 3) ‚Üí (3, 3, 3)
        f = (f - f.min()) / (f.max() - f.min())
        ax.imshow(f)
    ax.axis('off')
plt.tight_layout()
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è Feature Maps</h2>
    <pre><code>import torch
import torchvision.transforms as transforms
from PIL import Image

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
img = Image.open('cat.jpg')
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                        std=[0.229, 0.224, 0.225])
])
img_tensor = transform(img).unsqueeze(0)

# Hook –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏–π
activations = {}
def get_activation(name):
    def hook(model, input, output):
        activations[name] = output.detach()
    return hook

# –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è hook
model.features[0].register_forward_hook(get_activation('conv1'))
model.features[5].register_forward_hook(get_activation('conv2'))

# –ü—Ä–æ–≥–æ–Ω –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
model.eval()
with torch.no_grad():
    output = model(img_tensor)

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
conv1_act = activations['conv1'].squeeze()
fig, axes = plt.subplots(8, 8, figsize=(12, 12))
for i, ax in enumerate(axes.flat):
    if i < conv1_act.shape[0]:
        ax.imshow(conv1_act[i], cmap='viridis')
    ax.axis('off')
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. Saliency Maps (Vanilla Gradient)</h2>
    <p><strong>–ò–¥–µ—è</strong>: –≤—ã—á–∏—Å–ª–∏—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç –≤—ã—Ö–æ–¥–∞ –ø–æ –≤—Ö–æ–¥—É</p>
    <pre><code>def compute_saliency_map(model, image, target_class):
    """
    –í—ã—á–∏—Å–ª–∏—Ç—å saliency map –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    """
    # –í–∫–ª—é—á–∏—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–ª—è –≤—Ö–æ–¥–∞
    image.requires_grad = True
    
    # Forward pass
    model.eval()
    output = model(image)
    
    # Backward –æ—Ç —Ü–µ–ª–µ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞
    model.zero_grad()
    target = output[0, target_class]
    target.backward()
    
    # –ì—Ä–∞–¥–∏–µ–Ω—Ç –ø–æ –≤—Ö–æ–¥—É
    saliency = image.grad.data.abs()
    saliency = saliency.max(dim=1)[0]  # max –ø–æ –∫–∞–Ω–∞–ª–∞–º
    
    return saliency.squeeze().cpu()

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
img_tensor.requires_grad = True
saliency = compute_saliency_map(model, img_tensor, target_class=281)

plt.figure(figsize=(10, 5))
plt.subplot(121)
plt.imshow(img)
plt.title('Original')
plt.subplot(122)
plt.imshow(saliency, cmap='hot')
plt.title('Saliency Map')
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. Grad-CAM (Class Activation Mapping)</h2>
    <p><strong>–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ</strong>: –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤–∞–∂–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞</p>
    <pre><code>import torch.nn.functional as F

def grad_cam(model, image, target_class, target_layer):
    """
    –í—ã—á–∏—Å–ª–∏—Ç—å Grad-CAM
    """
    # –ó–∞—Ö–≤–∞—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–π
    gradients = []
    activations = []
    
    def backward_hook(module, grad_input, grad_output):
        gradients.append(grad_output[0])
    
    def forward_hook(module, input, output):
        activations.append(output)
    
    # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è hooks
    handle_fw = target_layer.register_forward_hook(forward_hook)
    handle_bw = target_layer.register_full_backward_hook(backward_hook)
    
    # Forward
    model.eval()
    output = model(image)
    
    # Backward –æ—Ç —Ü–µ–ª–µ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞
    model.zero_grad()
    target = output[0, target_class]
    target.backward()
    
    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ Grad-CAM
    grads = gradients[0].cpu().data
    acts = activations[0].cpu().data
    
    # –í–µ—Å–∞ = —Å—Ä–µ–¥–Ω–µ–µ –ø–æ spatial dims
    weights = grads.mean(dim=(2, 3), keepdim=True)
    
    # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏–π
    cam = (weights * acts).sum(dim=1, keepdim=True)
    cam = F.relu(cam)  # ReLU
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ resize
    cam = F.interpolate(cam, size=(224, 224), mode='bilinear')
    cam = cam - cam.min()
    cam = cam / cam.max()
    
    handle_fw.remove()
    handle_bw.remove()
    
    return cam.squeeze().numpy()

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
target_layer = model.features[-1]  # –ø–æ—Å–ª–µ–¥–Ω–∏–π conv —Å–ª–æ–π
cam = grad_cam(model, img_tensor, target_class=281, 
               target_layer=target_layer)

# –ù–∞–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
plt.figure(figsize=(10, 5))
plt.subplot(121)
plt.imshow(img)
plt.subplot(122)
plt.imshow(img)
plt.imshow(cam, cmap='jet', alpha=0.5)
plt.title('Grad-CAM')
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. Guided Grad-CAM</h2>
    <p><strong>–ö–æ–º–±–∏–Ω–∞—Ü–∏—è</strong>: Grad-CAM √ó Guided Backpropagation</p>
    <ul>
      <li>Grad-CAM: –≥–¥–µ –≤–∞–∂–Ω–æ (coarse)</li>
      <li>Guided Backprop: —á—Ç–æ –≤–∞–∂–Ω–æ (fine)</li>
      <li>–ö–æ–º–±–∏–Ω–∞—Ü–∏—è: —á–µ—Ç–∫–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–∂–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π</li>
    </ul>
    <pre><code>def guided_backprop(model, image, target_class):
    """
    Guided Backpropagation
    """
    # –ó–∞–º–µ–Ω–∏—Ç—å ReLU –Ω–∞ Guided ReLU
    class GuidedReLU(torch.autograd.Function):
        @staticmethod
        def forward(ctx, input):
            return input.clamp(min=0)
        
        @staticmethod
        def backward(ctx, grad_output):
            # –ü—Ä–æ–ø—É—Å–∫–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
            return grad_output.clamp(min=0)
    
    # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å (—É–ø—Ä–æ—â–µ–Ω–Ω–æ)
    image.requires_grad = True
    output = model(image)
    
    model.zero_grad()
    target = output[0, target_class]
    target.backward()
    
    # –ì—Ä–∞–¥–∏–µ–Ω—Ç —Å guided backprop
    guided_grads = image.grad.data
    
    return guided_grads

# Guided Grad-CAM = Grad-CAM * Guided Backprop
guided_grads = guided_backprop(model, img_tensor, 281)
guided_cam = cam * guided_grads.cpu().numpy()

plt.imshow(guided_cam.transpose(1, 2, 0))
plt.title('Guided Grad-CAM')
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. Occlusion Sensitivity</h2>
    <p><strong>–ò–¥–µ—è</strong>: –∑–∞–∫—Ä—ã–≤–∞—Ç—å —á–∞—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è</p>
    <pre><code>def occlusion_sensitivity(model, image, target_class, 
                          patch_size=32, stride=8):
    """
    –í—ã—á–∏—Å–ª–∏—Ç—å Occlusion Sensitivity
    """
    model.eval()
    H, W = image.shape[2:]
    
    # –ë–∞–∑–æ–≤—ã–π score
    with torch.no_grad():
        base_output = model(image)
        base_score = base_output[0, target_class].item()
    
    heatmap = torch.zeros((H // stride, W // stride))
    
    # –ó–∞–∫—Ä—ã–≤–∞—Ç—å –ø–∞—Ç—á–∏
    for i in range(0, H - patch_size, stride):
        for j in range(0, W - patch_size, stride):
            # –ö–æ–ø–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            occluded = image.clone()
            # –ó–∞–∫—Ä—ã—Ç—å –ø–∞—Ç—á (—Å–µ—Ä—ã–º –∏–ª–∏ —á–µ—Ä–Ω—ã–º)
            occluded[:, :, i:i+patch_size, j:j+patch_size] = 0.5
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            with torch.no_grad():
                output = model(occluded)
                score = output[0, target_class].item()
            
            # –†–∞–∑–Ω–∏—Ü–∞
            heatmap[i//stride, j//stride] = base_score - score
    
    return heatmap.numpy()

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
occlusion_map = occlusion_sensitivity(model, img_tensor, 281)
plt.imshow(occlusion_map, cmap='hot')
plt.title('Occlusion Sensitivity')
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. DeepDream</h2>
    <p><strong>–ò–¥–µ—è</strong>: –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –Ω–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–º —Å–ª–æ–µ</p>
    <pre><code>def deep_dream(model, image, layer, iterations=20, lr=0.01):
    """
    DeepDream visualization
    """
    image = image.clone().requires_grad_(True)
    
    # Hook –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏–π
    activations = []
    def hook(module, input, output):
        activations.append(output)
    handle = layer.register_forward_hook(hook)
    
    for i in range(iterations):
        activations.clear()
        model.zero_grad()
        
        # Forward
        output = model(image)
        
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—É–º–º—É –∞–∫—Ç–∏–≤–∞—Ü–∏–π
        loss = activations[0].norm()
        loss.backward()
        
        # Gradient ascent
        with torch.no_grad():
            image += lr * image.grad
            image.grad.zero_()
    
    handle.remove()
    
    return image.detach()

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
dreamed = deep_dream(model, img_tensor, model.features[10])

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
dreamed_img = dreamed.squeeze().permute(1, 2, 0).cpu()
dreamed_img = (dreamed_img - dreamed_img.min()) / \
              (dreamed_img.max() - dreamed_img.min())
plt.imshow(dreamed_img)
plt.title('DeepDream')
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏</h2>
    <table>
      <tr><th>–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞</th><th>–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏</th><th>–£—Å—Ç–∞–Ω–æ–≤–∫–∞</th></tr>
      <tr><td><strong>Captum</strong></td><td>–û—Ç PyTorch, –º–Ω–æ–≥–æ –º–µ—Ç–æ–¥–æ–≤</td><td><code>pip install captum</code></td></tr>
      <tr><td><strong>pytorch-grad-cam</strong></td><td>–ü—Ä–æ—Å—Ç–∞—è –≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏</td><td><code>pip install grad-cam</code></td></tr>
      <tr><td><strong>torchcam</strong></td><td>CAM –º–µ—Ç–æ–¥—ã</td><td><code>pip install torchcam</code></td></tr>
      <tr><td><strong>tf-keras-vis</strong></td><td>–î–ª—è TensorFlow/Keras</td><td><code>pip install tf-keras-vis</code></td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 11. Captum –ø—Ä–∏–º–µ—Ä</h2>
    <pre><code>from captum.attr import (
    IntegratedGradients,
    GradientShap,
    Occlusion,
    LayerGradCam
)

# Integrated Gradients
ig = IntegratedGradients(model)
attributions = ig.attribute(img_tensor, target=281, n_steps=50)

# Gradient SHAP
gs = GradientShap(model)
baseline = torch.zeros_like(img_tensor)
attributions = gs.attribute(img_tensor, baselines=baseline, target=281)

# Layer Grad-CAM
layer_gc = LayerGradCam(model, model.features[-1])
attributions = layer_gc.attribute(img_tensor, target=281)

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
from captum.attr import visualization as viz

viz.visualize_image_attr(
    attributions.squeeze().cpu().permute(1, 2, 0).numpy(),
    original_image=img,
    method='blended_heat_map',
    sign='positive',
    show_colorbar=True
)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 12. pytorch-grad-cam –ø—Ä–∏–º–µ—Ä</h2>
    <pre><code>from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM
from pytorch_grad_cam.utils.image import show_cam_on_image
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget

# –í—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞
cam = GradCAM(model=model, target_layers=[model.features[-1]])
# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã:
# cam = HiResCAM(...)
# cam = ScoreCAM(...)

# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ CAM
targets = [ClassifierOutputTarget(281)]
grayscale_cam = cam(input_tensor=img_tensor, targets=targets)

# –ù–∞–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
grayscale_cam = grayscale_cam[0, :]
rgb_img = np.array(img) / 255.0
visualization = show_cam_on_image(rgb_img, grayscale_cam, 
                                  use_rgb=True)

plt.imshow(visualization)
plt.title('Grad-CAM visualization')
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 13. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤</h2>
    <table>
      <tr><th>–ú–µ—Ç–æ–¥</th><th>–°–∫–æ—Ä–æ—Å—Ç—å</th><th>–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è</th><th>Class-specific</th></tr>
      <tr><td>Vanilla Gradient</td><td>–ë—ã—Å—Ç—Ä–æ</td><td>–í—ã—Å–æ–∫–∞—è</td><td>–î–∞</td></tr>
      <tr><td>Grad-CAM</td><td>–ë—ã—Å—Ç—Ä–æ</td><td>–ù–∏–∑–∫–∞—è</td><td>–î–∞</td></tr>
      <tr><td>Guided Grad-CAM</td><td>–°—Ä–µ–¥–Ω–µ</td><td>–í—ã—Å–æ–∫–∞—è</td><td>–î–∞</td></tr>
      <tr><td>Occlusion</td><td>–ú–µ–¥–ª–µ–Ω–Ω–æ</td><td>–°—Ä–µ–¥–Ω—è—è</td><td>–î–∞</td></tr>
      <tr><td>Integrated Gradients</td><td>–ú–µ–¥–ª–µ–Ω–Ω–æ</td><td>–í—ã—Å–æ–∫–∞—è</td><td>–î–∞</td></tr>
      <tr><td>DeepDream</td><td>–ú–µ–¥–ª–µ–Ω–Ω–æ</td><td>N/A</td><td>–ù–µ—Ç</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 14. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] <strong>–ù–∞—á–∞—Ç—å —Å –ø—Ä–æ—Å—Ç–æ–≥–æ</strong>: —Ñ–∏–ª—å—Ç—Ä—ã –∏ feature maps</li>
      <li>[ ] <strong>Grad-CAM</strong> –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –≤–∞–∂–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π</li>
      <li>[ ] <strong>Saliency maps</strong> –¥–ª—è –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏</li>
      <li>[ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å <strong>–±–∏–±–ª–∏–æ—Ç–µ–∫–∏</strong> (Captum, grad-cam)</li>
      <li>[ ] <strong>–í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ —Å–ª–æ–∏</strong>: —Ä–∞–Ω–Ω–∏–µ vs –ø–æ–∑–¥–Ω–∏–µ</li>
      <li>[ ] <strong>–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –∫–ª–∞—Å—Å–∞—Ö</strong></li>
      <li>[ ] <strong>–°—Ä–∞–≤–Ω–∏—Ç—å –º–µ—Ç–æ–¥—ã</strong> –Ω–∞ –æ–¥–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏</li>
      <li>[ ] <strong>–î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞—Ö–æ–¥–∫–∏</strong> –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º–æ–¥–µ–ª–∏</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è CNN ‚Äî —ç—Ç–æ –∫–∞–∫ —Ä–µ–Ω—Ç–≥–µ–Ω –¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏: –º—ã –º–æ–∂–µ–º —É–≤–∏–¥–µ—Ç—å, –Ω–∞ –∫–∞–∫–∏–µ —á–∞—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –º–æ–¥–µ–ª—å –æ–±—Ä–∞—â–∞–µ—Ç –≤–Ω–∏–º–∞–Ω–∏–µ –ø—Ä–∏ –ø—Ä–∏–Ω—è—Ç–∏–∏ —Ä–µ—à–µ–Ω–∏—è. –≠—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –º–æ–¥–µ–ª—å —Ñ–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –≤–µ—â–∞—Ö, –∞ –Ω–µ –Ω–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞—Ö¬ª.
    </blockquote>
  </div>

</div>

</div>
</body>
</html>
