<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>1D-CNN and 3D-CNN Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

    .container {
      column-count: 3;
      column-gap: 20px;
      max-width: 100%;
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üî∑ 1D-CNN and 3D-CNN</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –û–±–∑–æ—Ä —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π</h2>
    <table>
      <tr><th>–¢–∏–ø</th><th>–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ</th><th>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</th></tr>
      <tr><td><strong>1D-CNN</strong></td><td>(batch, channels, length)</td><td>–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã, —Ç–µ–∫—Å—Ç, –∞—É–¥–∏–æ</td></tr>
      <tr><td><strong>2D-CNN</strong></td><td>(batch, channels, H, W)</td><td>–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è</td></tr>
      <tr><td><strong>3D-CNN</strong></td><td>(batch, channels, D, H, W)</td><td>–í–∏–¥–µ–æ, –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ 3D —Å–Ω–∏–º–∫–∏</td></tr>
    </table>
    <p><strong>D</strong> ‚Äî –≥–ª—É–±–∏–Ω–∞ (depth), <strong>H</strong> ‚Äî –≤—ã—Å–æ—Ç–∞, <strong>W</strong> ‚Äî —à–∏—Ä–∏–Ω–∞</p>

  <div class="block">
    <h2>üî∑ 2. 1D-CNN: –û—Å–Ω–æ–≤—ã</h2>
    <ul>
      <li><strong>–ò–¥–µ—è</strong>: —Å–≤—ë—Ä—Ç–∫–∞ –≤–¥–æ–ª—å –æ–¥–Ω–æ–π –æ—Å–∏ (–≤—Ä–µ–º–µ–Ω–∏)</li>
      <li><strong>Kernel</strong>: —Å–∫–æ–ª—å–∑–∏—Ç –ø–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏</li>
      <li><strong>–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞</strong>: –±—ã—Å—Ç—Ä–µ–µ RNN, –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑—É–µ—Ç—Å—è</li>
      <li><strong>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</strong>: –∞–Ω–∞–ª–∏–∑ —Å–∏–≥–Ω–∞–ª–æ–≤, NLP, –±–∏–æ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞</li>
    </ul>
    <p><strong>–§–æ—Ä–º—É–ª–∞ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞</strong>:</p>
    <pre><code>output_length = (input_length + 2*padding - kernel_size) / stride + 1</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 3. 1D-CNN –≤ PyTorch</h2>
    <pre><code>import torch
import torch.nn as nn

class CNN1D(nn.Module):
    def __init__(self, input_channels=1, num_classes=10):
        super(CNN1D, self).__init__()
        
        self.conv1 = nn.Conv1d(
            in_channels=input_channels,
            out_channels=64,
            kernel_size=7,
            stride=1,
            padding=3
        )
        self.bn1 = nn.BatchNorm1d(64)
        self.relu = nn.ReLU()
        self.pool = nn.MaxPool1d(kernel_size=2)
        
        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, padding=2)
        self.bn2 = nn.BatchNorm1d(128)
        
        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm1d(256)
        
        self.global_pool = nn.AdaptiveAvgPool1d(1)
        self.fc = nn.Linear(256, num_classes)
    
    def forward(self, x):
        # x: (batch, channels, length)
        x = self.relu(self.bn1(self.conv1(x)))
        x = self.pool(x)
        
        x = self.relu(self.bn2(self.conv2(x)))
        x = self.pool(x)
        
        x = self.relu(self.bn3(self.conv3(x)))
        x = self.pool(x)
        
        x = self.global_pool(x)  # (batch, 256, 1)
        x = x.squeeze(-1)         # (batch, 256)
        x = self.fc(x)
        return x

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
model = CNN1D(input_channels=1, num_classes=10)
x = torch.randn(32, 1, 1000)  # batch, channels, length
output = model(x)
print(output.shape)  # (32, 10)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. 1D-CNN: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã</h3>
        <ul>
          <li>–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ</li>
          <li>–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ø—Ä–æ—Å–∞</li>
          <li>–°–µ–Ω—Å–æ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ IoT</li>
          <li>–≠–ö–ì, –≠–≠–ì —Å–∏–≥–Ω–∞–ª—ã</li>
        </ul>
      </div>
      <div class="good">
        <h3>‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞</h3>
        <ul>
          <li>–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤</li>
          <li>Sentiment analysis</li>
          <li>Named Entity Recognition</li>
          <li>–ë—ã—Å—Ç—Ä–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ RNN</li>
        </ul>
      </div>
    </div>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ</h3>
        <ul>
          <li>–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏</li>
          <li>–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–≤—É–∫–æ–≤</li>
          <li>–î–µ—Ç–µ–∫—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤</li>
        </ul>
      </div>
      <div class="good">
        <h3>‚úÖ –ë–∏–æ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞</h3>
        <ul>
          <li>–ê–Ω–∞–ª–∏–∑ –î–ù–ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π</li>
          <li>–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –±–µ–ª–∫–æ–≤</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 5. 1D-CNN —Å Keras/TensorFlow</h2>
    <pre><code>from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (
    Conv1D, MaxPooling1D, GlobalAveragePooling1D,
    Dense, Dropout, BatchNormalization
)

model = Sequential([
    # –ü–µ—Ä–≤—ã–π –±–ª–æ–∫
    Conv1D(64, kernel_size=7, activation='relu', 
           padding='same', input_shape=(1000, 1)),
    BatchNormalization(),
    MaxPooling1D(pool_size=2),
    
    # –í—Ç–æ—Ä–æ–π –±–ª–æ–∫
    Conv1D(128, kernel_size=5, activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling1D(pool_size=2),
    
    # –¢—Ä–µ—Ç–∏–π –±–ª–æ–∫
    Conv1D(256, kernel_size=3, activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling1D(pool_size=2),
    
    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
    GlobalAveragePooling1D(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(10, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. Dilated (Atrous) Convolutions</h2>
    <ul>
      <li><strong>–ò–¥–µ—è</strong>: —É–≤–µ–ª–∏—á–µ–Ω–∏–µ receptive field –±–µ–∑ —É–≤–µ–ª–∏—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</li>
      <li><strong>Dilation rate</strong>: —à–∞–≥ –º–µ–∂–¥—É —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏ —è–¥—Ä–∞</li>
      <li><strong>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</strong>: WaveNet, TCN</li>
    </ul>
    <pre><code># PyTorch
conv_dilated = nn.Conv1d(
    in_channels=64,
    out_channels=128,
    kernel_size=3,
    dilation=2  # —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏
)

# Keras
from tensorflow.keras.layers import Conv1D
Conv1D(128, kernel_size=3, dilation_rate=2)

# Receptive field —Å dilation:
# dilation=1: kernel –≤–∏–¥–∏—Ç 3 —Ç–æ—á–∫–∏ –ø–æ–¥—Ä—è–¥
# dilation=2: kernel –≤–∏–¥–∏—Ç 3 —Ç–æ—á–∫–∏ —Å —à–∞–≥–æ–º 2 (5 –ø–æ–∑–∏—Ü–∏–π)
# dilation=4: kernel –≤–∏–¥–∏—Ç 3 —Ç–æ—á–∫–∏ —Å —à–∞–≥–æ–º 4 (9 –ø–æ–∑–∏—Ü–∏–π)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. 3D-CNN: –û—Å–Ω–æ–≤—ã</h2>
    <ul>
      <li><strong>–ò–¥–µ—è</strong>: —Å–≤—ë—Ä—Ç–∫–∞ –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –∏ –≤—Ä–µ–º–µ–Ω–∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ</li>
      <li><strong>Kernel</strong>: 3D –∫—É–± (–≥–ª—É–±–∏–Ω–∞ √ó –≤—ã—Å–æ—Ç–∞ √ó —à–∏—Ä–∏–Ω–∞)</li>
      <li><strong>–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ</strong>: –∑–∞—Ö–≤–∞—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–Ω–∞–º–∏–∫–∏</li>
      <li><strong>–ù–µ–¥–æ—Å—Ç–∞—Ç–æ–∫</strong>: –º–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –º–µ–¥–ª–µ–Ω–Ω–µ–µ</li>
    </ul>
    <p><strong>–§–æ—Ä–º–∞ –≤—Ö–æ–¥–∞</strong>: <code>(batch, channels, depth, height, width)</code></p>
    <p>–î–ª—è –≤–∏–¥–µ–æ: <strong>depth = –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤</strong></p>
  </div>

  <div class="block">
    <h2>üî∑ 8. 3D-CNN –≤ PyTorch</h2>
    <pre><code>import torch
import torch.nn as nn

class CNN3D(nn.Module):
    def __init__(self, num_classes=400):
        super(CNN3D, self).__init__()
        
        self.conv1 = nn.Conv3d(
            in_channels=3,     # RGB
            out_channels=64,
            kernel_size=(3, 7, 7),  # (depth, height, width)
            stride=(1, 2, 2),
            padding=(1, 3, 3)
        )
        self.bn1 = nn.BatchNorm3d(64)
        self.relu = nn.ReLU()
        self.pool = nn.MaxPool3d(kernel_size=(1, 2, 2))
        
        self.conv2 = nn.Conv3d(64, 128, kernel_size=(3, 5, 5), 
                              stride=(1, 1, 1), padding=(1, 2, 2))
        self.bn2 = nn.BatchNorm3d(128)
        
        self.conv3 = nn.Conv3d(128, 256, kernel_size=(3, 3, 3), 
                              stride=(1, 1, 1), padding=(1, 1, 1))
        self.bn3 = nn.BatchNorm3d(256)
        
        self.global_pool = nn.AdaptiveAvgPool3d((1, 1, 1))
        self.fc = nn.Linear(256, num_classes)
    
    def forward(self, x):
        # x: (batch, channels, depth, height, width)
        x = self.relu(self.bn1(self.conv1(x)))
        x = self.pool(x)
        
        x = self.relu(self.bn2(self.conv2(x)))
        x = self.pool(x)
        
        x = self.relu(self.bn3(self.conv3(x)))
        x = self.pool(x)
        
        x = self.global_pool(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
model = CNN3D(num_classes=400)
# batch=2, RGB, 16 frames, 224x224
x = torch.randn(2, 3, 16, 224, 224)
output = model(x)
print(output.shape)  # (2, 400)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. 3D-CNN: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏–π –≤ –≤–∏–¥–µ–æ</h3>
        <ul>
          <li>C3D, I3D, R(2+1)D</li>
          <li>–°–ø–æ—Ä—Ç–∏–≤–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞</li>
          <li>–°–∏—Å—Ç–µ–º—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏</li>
        </ul>
      </div>
      <div class="good">
        <h3>‚úÖ –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è</h3>
        <ul>
          <li>CT, MRI —Å–∫–∞–Ω—ã (3D –æ–±—ä—ë–º—ã)</li>
          <li>–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –æ–ø—É—Ö–æ–ª–µ–π</li>
          <li>–î–µ—Ç–µ–∫—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π</li>
        </ul>
      </div>
    </div>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ</h3>
        <ul>
          <li>–î–µ—Ç–µ–∫—Ü–∏—è —Å–æ–±—ã—Ç–∏–π</li>
          <li>–í—Ä–µ–º–µ–Ω–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è</li>
          <li>Video captioning</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 10. –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ 3D –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã</h2>
    <table>
      <tr><th>–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞</th><th>–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏</th><th>–ì–æ–¥</th></tr>
      <tr><td><strong>C3D</strong></td><td>–ë–∞–∑–æ–≤–∞—è 3D CNN, 3√ó3√ó3 —è–¥—Ä–∞</td><td>2014</td></tr>
      <tr><td><strong>I3D</strong></td><td>Inflated 2D ‚Üí 3D, ImageNet pretrain</td><td>2017</td></tr>
      <tr><td><strong>R(2+1)D</strong></td><td>–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ 2D spatial + 1D temporal</td><td>2018</td></tr>
      <tr><td><strong>SlowFast</strong></td><td>–î–≤–∞ –ø—É—Ç–∏: –º–µ–¥–ª–µ–Ω–Ω—ã–π (spatial) + –±—ã—Å—Ç—Ä—ã–π (temporal)</td><td>2019</td></tr>
      <tr><td><strong>X3D</strong></td><td>–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è 3D CNN —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º</td><td>2020</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 11. R(2+1)D: Decomposed Convolution</h2>
    <p><strong>–ò–¥–µ—è</strong>: —Ä–∞–∑–¥–µ–ª–∏—Ç—å 3D —Å–≤—ë—Ä—Ç–∫—É –Ω–∞ 2D spatial + 1D temporal</p>
    <ul>
      <li>3D conv (3√ó3√ó3) ‚Üí 2D conv (1√ó3√ó3) + 1D conv (3√ó1√ó1)</li>
      <li>–ú–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</li>
      <li>–ë–æ–ª—å—à–µ –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç–µ–π (–±–æ–ª—å—à–µ ReLU)</li>
      <li>–õ—É—á—à–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å</li>
    </ul>
    <pre><code># –í–º–µ—Å—Ç–æ –æ–¥–Ω–æ–π 3D —Å–≤—ë—Ä—Ç–∫–∏
nn.Conv3d(in_ch, out_ch, kernel_size=(3, 3, 3))

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–≤–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ
nn.Sequential(
    nn.Conv3d(in_ch, mid_ch, kernel_size=(1, 3, 3)),  # spatial
    nn.ReLU(),
    nn.Conv3d(mid_ch, out_ch, kernel_size=(3, 1, 1))  # temporal
)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 12. I3D (Inflated 3D ConvNet)</h2>
    <p><strong>–ò–¥–µ—è</strong>: "—Ä–∞–∑–¥—É—Ç—å" 2D CNN –≤ 3D</p>
    <ul>
      <li>–í–∑—è—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é 2D CNN (Inception)</li>
      <li>–ü–æ–≤—Ç–æ—Ä–∏—Ç—å 2D –≤–µ—Å–∞ N —Ä–∞–∑ –≤–¥–æ–ª—å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –æ—Å–∏</li>
      <li>–†–∞–∑–¥–µ–ª–∏—Ç—å –Ω–∞ N –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—ã—Ö–æ–¥–æ–≤</li>
      <li>Fine-tune –Ω–∞ –≤–∏–¥–µ–æ –¥–∞–Ω–Ω—ã—Ö</li>
    </ul>
    <pre><code># –ü—Ä–∏–º–µ—Ä –∏–Ω—Ñ–ª–∏—Ä–æ–≤–∞–Ω–∏—è
# 2D —Ñ–∏–ª—å—Ç—Ä: K √ó K
# 3D —Ñ–∏–ª—å—Ç—Ä: N √ó K √ó K (–ø–æ–≤—Ç–æ—Ä N —Ä–∞–∑)

# –í–µ—Å–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏:
# w_3d[t, i, j] = w_2d[i, j] / N  –¥–ª—è –≤—Å–µ—Ö t</code></pre>
    <p><strong>–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ</strong>: transfer learning –∏–∑ ImageNet</p>
  </div>

  <div class="block">
    <h2>üî∑ 13. 1D vs 3D CNN: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ</h2>
    <table>
      <tr><th>–ê—Å–ø–µ–∫—Ç</th><th>1D-CNN</th><th>3D-CNN</th></tr>
      <tr><td><strong>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã</strong></td><td>–ú–∞–ª–æ</td><td>–ú–Ω–æ–≥–æ</td></tr>
      <tr><td><strong>–°–∫–æ—Ä–æ—Å—Ç—å</strong></td><td>–ë—ã—Å—Ç—Ä–æ</td><td>–ú–µ–¥–ª–µ–Ω–Ω–æ</td></tr>
      <tr><td><strong>–ü–∞–º—è—Ç—å</strong></td><td>–ù–∏–∑–∫–∞—è</td><td>–í—ã—Å–æ–∫–∞—è</td></tr>
      <tr><td><strong>Receptive field</strong></td><td>1D (–≤—Ä–µ–º—è)</td><td>3D (–≤—Ä–µ–º—è+–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ)</td></tr>
      <tr><td><strong>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</strong></td><td>–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏</td><td>–í–∏–¥–µ–æ, 3D –¥–∞–Ω–Ω—ã–µ</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 14. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è 3D-CNN</h2>
    <ul>
      <li><strong>–°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è</strong>: 112√ó112 –≤–º–µ—Å—Ç–æ 224√ó224</li>
      <li><strong>–ú–µ–Ω—å—à–µ –∫–∞–¥—Ä–æ–≤</strong>: 8-16 –≤–º–µ—Å—Ç–æ 32-64</li>
      <li><strong>Temporal downsampling</strong>: stride>1 –ø–æ –≤—Ä–µ–º–µ–Ω–∏</li>
      <li><strong>Mixed precision</strong>: FP16 –≤–º–µ—Å—Ç–æ FP32</li>
      <li><strong>Gradient checkpointing</strong>: —ç–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏</li>
      <li><strong>Decomposed conv</strong>: (2+1)D –≤–º–µ—Å—Ç–æ 3D</li>
    </ul>
    <pre><code># Gradient checkpointing –≤ PyTorch
from torch.utils.checkpoint import checkpoint

class OptimizedBlock(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv = nn.Conv3d(64, 128, 3, padding=1)
        self.bn = nn.BatchNorm3d(128)
        self.relu = nn.ReLU()
    
    def forward(self, x):
        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å checkpointing –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
        return checkpoint(self._forward, x)
    
    def _forward(self, x):
        return self.relu(self.bn(self.conv(x)))</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 15. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∏–¥–µ–æ</h2>
    <pre><code>import cv2
import numpy as np

def load_video_clip(video_path, num_frames=16, size=(224, 224)):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –≤–∏–¥–µ–æ –∫–ª–∏–ø"""
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # –†–∞–≤–Ω–æ–º–µ—Ä–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –∫–∞–¥—Ä–æ–≤
    frame_indices = np.linspace(0, total_frames-1, num_frames, dtype=int)
    
    frames = []
    for idx in frame_indices:
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if ret:
            frame = cv2.resize(frame, size)
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frames.append(frame)
    
    cap.release()
    
    # (num_frames, H, W, C) ‚Üí (C, num_frames, H, W)
    video = np.array(frames).transpose(3, 0, 1, 2)
    video = video / 255.0  # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    
    return video

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
video_clip = load_video_clip('video.mp4', num_frames=16)
print(video_clip.shape)  # (3, 16, 224, 224)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 16. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <h3>–î–ª—è 1D-CNN:</h3>
    <ul>
      <li>[ ] –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ</li>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å kernel size (3, 5, 7, 9)</li>
      <li>[ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å dilated conv –¥–ª—è –±–æ–ª—å—à–æ–≥–æ context</li>
      <li>[ ] BatchNormalization –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —Å–≤—ë—Ä—Ç–∫–∏</li>
      <li>[ ] Global pooling –ø–µ—Ä–µ–¥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–º</li>
    </ul>
    <h3>–î–ª—è 3D-CNN:</h3>
    <ul>
      <li>[ ] –°–Ω–∏–∑–∏—Ç—å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ (112√ó112 –∏–ª–∏ 128√ó128)</li>
      <li>[ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 8-16 –∫–∞–¥—Ä–æ–≤</li>
      <li>[ ] –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å (2+1)D –≤–º–µ—Å—Ç–æ 3D</li>
      <li>[ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ (I3D)</li>
      <li>[ ] Mixed precision training</li>
      <li>[ ] Gradient checkpointing –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´1D-CNN –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö (–∫–∞–∫ —Ç—Ä–µ–Ω–¥—ã –≤–æ –≤—Ä–µ–º–µ–Ω–∏), –∞ 3D-CNN –≤–∏–¥–∏—Ç –≤–∏–¥–µ–æ —Ü–µ–ª–∏–∫–æ–º ‚Äî –Ω–µ —Ç–æ–ª—å–∫–æ —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ –∫–∞–∂–¥–æ–º –∫–∞–¥—Ä–µ, –Ω–æ –∏ –∫–∞–∫ –æ–±—ä–µ–∫—Ç—ã –¥–≤–∏–∂—É—Ç—Å—è –º–µ–∂–¥—É –∫–∞–¥—Ä–∞–º–∏¬ª.
    </blockquote>
  </div>

</div>

</div>
</body>
</html>
