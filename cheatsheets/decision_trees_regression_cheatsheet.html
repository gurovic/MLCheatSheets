<!DOCTYPE html><html lang="ru"><head><meta charset="UTF-8"><title>–î–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title><style>@media screen{body{font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Helvetica,Arial,sans-serif;color:#333;background:#fafcff;padding:10px}}@media print{body{background:white;padding:0}@page{size:A4 landscape;margin:10mm}}.container{column-count:3;column-gap:20px;max-width:100%}.block{break-inside:avoid;margin-bottom:1.2em;padding:12px;background:white;border-radius:6px;box-shadow:0 1px 3px rgba(0,0,0,0.05)}h1{font-size:1.6em;font-weight:700;color:#1a5fb4;text-align:center;margin:0 0 8px;column-span:all}.subtitle{text-align:center;color:#666;font-size:0.9em;margin-bottom:12px;column-span:all}h2{font-size:1.15em;font-weight:700;color:#1a5fb4;margin:0 0 8px;padding-bottom:4px;border-bottom:1px solid #e0e7ff}p,ul,ol{font-size:0.92em;margin:0.6em 0}ul,ol{padding-left:18px}li{margin-bottom:4px}code{font-family:'Consolas','Courier New',monospace;background-color:#f0f4ff;padding:1px 4px;border-radius:3px;font-size:0.88em}pre{background-color:#f0f4ff;padding:8px;border-radius:4px;overflow-x:auto;font-size:0.84em;margin:6px 0}pre code{padding:0;background:none;white-space:pre-wrap}table{width:100%;border-collapse:collapse;font-size:0.82em;margin:6px 0}th{background-color:#e6f0ff;text-align:left;padding:4px 6px;font-weight:600}td{padding:4px 6px;border-bottom:1px solid #f0f4ff}tr:nth-child(even){background-color:#f8fbff}.good-vs-bad{display:flex;flex-direction:column;gap:8px}.good-vs-bad div{flex:1;padding:6px 8px;border-radius:4px}.good{background-color:#f0f9f4;border-left:3px solid #2e8b57}.bad{background-color:#fdf0f2;border-left:3px solid #d32f2f}.good h3,.bad h3{margin:0 0 4px;font-size:1em;font-weight:700}.good ul,.bad ul{padding-left:20px;margin:0}.good li::before{content:"‚úÖ ";font-weight:bold}.bad li::before{content:"‚ùå ";font-weight:bold}blockquote{font-style:italic;margin:8px 0;padding:6px 10px;background:#f8fbff;border-left:2px solid #1a5fb4;font-size:0.88em}.formula{text-align:center;font-family:'Cambria Math',serif;font-size:1em;margin:10px 0;padding:8px;background:#f8fbff;border-radius:4px}@media print{.container{column-gap:12px}.block{box-shadow:none}code,pre,table{font-size:0.78em}h1{font-size:1.4em}h2{font-size:1em}}</style></head><body><div class="container"><h1>üå≤ –î–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏</h1><div class="subtitle">üìÖ 3 —è–Ω–≤–∞—Ä—è 2026</div><div class="block"><h2>üî∑ 1. –°—É—Ç—å</h2><ul><li><strong>–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π</strong>: –Ω–µ –∫–ª–∞—Å—Å—ã, –∞ —á–∏—Å–ª–∞</li><li><strong>–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ</strong>: –¥–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π</li><li><strong>–°—Ä–µ–¥–Ω–µ–µ –≤ –ª–∏—Å—Ç—å—è—Ö</strong>: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ = —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –ª–∏—Å—Ç–µ</li><li><strong>–ö—Ä–∏—Ç–µ—Ä–∏–π</strong>: –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è MSE –∏–ª–∏ MAE</li></ul></div><div class="block"><h2>üî∑ 2. –ë–∞–∑–æ–≤—ã–π –∫–æ–¥</h2><pre><code>from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score

# –ú–æ–¥–µ–ª—å
model = DecisionTreeRegressor(
    max_depth=5,
    random_state=42
)
model.fit(X_train, y_train)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
y_pred = model.predict(X_test)

# –û—Ü–µ–Ω–∫–∞
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"MSE: {mse:.3f}, R¬≤: {r2:.3f}")</code></pre></div><div class="block"><h2>üî∑ 3. –ö–ª—é—á–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã</h2><table><tr><th>–ü–∞—Ä–∞–º–µ—Ç—Ä</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th><th>–°–æ–≤–µ—Ç</th></tr><tr><td><code>max_depth</code></td><td>–ú–∞–∫—Å. –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞</td><td>3-10 –¥–ª—è –Ω–∞—á–∞–ª–∞</td></tr><tr><td><code>min_samples_split</code></td><td>–ú–∏–Ω. –æ–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è</td><td>2-20, —É–≤–µ–ª–∏—á–∏—Ç—å –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏</td></tr><tr><td><code>min_samples_leaf</code></td><td>–ú–∏–Ω. –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –ª–∏—Å—Ç–µ</td><td>1-10, —É–≤–µ–ª–∏—á–∏—Ç—å –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è</td></tr><tr><td><code>criterion</code></td><td>–ö—Ä–∏—Ç–µ—Ä–∏–π —Ä–∞–∑–±–∏–µ–Ω–∏—è</td><td>'squared_error', 'absolute_error'</td></tr><tr><td><code>max_features</code></td><td>–ú–∞–∫—Å. –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ —Ä–∞–∑–±–∏–µ–Ω–∏–µ</td><td>None, 'sqrt', 'log2', int</td></tr></table></div><div class="block"><h2>üî∑ 4. –ö—Ä–∏—Ç–µ—Ä–∏–∏ —Ä–∞–∑–±–∏–µ–Ω–∏—è</h2><ul><li><code>squared_error</code>: MSE (Mean Squared Error) - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é</li><li><code>absolute_error</code>: MAE (Mean Absolute Error) - —É—Å—Ç–æ–π—á–∏–≤ –∫ –≤—ã–±—Ä–æ—Å–∞–º</li><li><code>friedman_mse</code>: —É–ª—É—á—à–µ–Ω–Ω—ã–π MSE —Å –§—Ä–∏–¥–º–∞–Ω</li><li><code>poisson</code>: –¥–ª—è —Å—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö</li></ul><pre><code># –í—ã–±–æ—Ä –∫—Ä–∏—Ç–µ—Ä–∏—è
model = DecisionTreeRegressor(
    criterion='absolute_error',  # —É—Å—Ç–æ–π—á–∏–≤ –∫ –≤—ã–±—Ä–æ—Å–∞–º
    max_depth=5
)
model.fit(X_train, y_train)</code></pre></div><div class="block"><h2>üî∑ 5. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ä–µ–≤–∞</h2><pre><code>from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

plt.figure(figsize=(20, 10))
plot_tree(
    model,
    feature_names=feature_names,
    filled=True,
    rounded=True,
    fontsize=10
)
plt.show()

# –ò–ª–∏ —ç–∫—Å–ø–æ—Ä—Ç –≤ —Ç–µ–∫—Å—Ç
from sklearn.tree import export_text
tree_rules = export_text(model, feature_names=feature_names)
print(tree_rules)</code></pre></div><div class="block"><h2>üî∑ 6. –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</h2><pre><code># –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
importances = model.feature_importances_
indices = np.argsort(importances)[::-1]

print("–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
for i in indices:
    print(f"{feature_names[i]}: {importances[i]:.3f}")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
plt.figure(figsize=(10, 6))
plt.bar(range(len(importances)), importances[indices])
plt.xticks(range(len(importances)), 
           [feature_names[i] for i in indices], 
           rotation=45)
plt.title('–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤')
plt.show()</code></pre></div><div class="block"><h2>üî∑ 7. –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –∏ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è</h2><pre><code># –ë–µ–∑ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ - –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ!
bad_model = DecisionTreeRegressor()  # –Ω–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
bad_model.fit(X_train, y_train)
print(f"Train R¬≤: {bad_model.score(X_train, y_train):.3f}")
print(f"Test R¬≤: {bad_model.score(X_test, y_test):.3f}")

# –° —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π
good_model = DecisionTreeRegressor(
    max_depth=5,
    min_samples_split=20,
    min_samples_leaf=10
)
good_model.fit(X_train, y_train)
print(f"Train R¬≤: {good_model.score(X_train, y_train):.3f}")
print(f"Test R¬≤: {good_model.score(X_test, y_test):.3f}")</code></pre></div><div class="block"><h2>üî∑ 8. –ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</h2><pre><code>from sklearn.model_selection import GridSearchCV

param_grid = {
    'max_depth': [3, 5, 7, 10],
    'min_samples_split': [2, 10, 20],
    'min_samples_leaf': [1, 5, 10],
    'criterion': ['squared_error', 'absolute_error']
}

grid = GridSearchCV(
    DecisionTreeRegressor(random_state=42),
    param_grid,
    cv=5,
    scoring='r2'
)
grid.fit(X_train, y_train)

print(f"Best params: {grid.best_params_}")
print(f"Best R¬≤: {grid.best_score_:.3f}")</code></pre></div><div class="block"><h2>üî∑ 9. –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏</h2><div class="good-vs-bad"><div class="good"><h3>‚úÖ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞</h3><ul><li>–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å</li><li>–ù–µ —Ç—Ä–µ–±—É–µ—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è</li><li>–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç–∏</li><li>–†–∞–±–æ—Ç–∞–µ—Ç —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏</li><li>–£—Å—Ç–æ–π—á–∏–≤ –∫ –≤—ã–±—Ä–æ—Å–∞–º (—Å MAE)</li></ul></div><div class="bad"><h3>‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏</h3><ul><li>–°–∫–ª–æ–Ω–Ω–æ—Å—Ç—å –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é</li><li>–ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å (—á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ –¥–∞–Ω–Ω—ã–º)</li><li>–°—Ç—É–ø–µ–Ω—á–∞—Ç—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è</li><li>–ü–ª–æ—Ö–æ —ç–∫—Å—Ç—Ä–∞–ø–æ–ª–∏—Ä—É–µ—Ç</li><li>–ú–µ–Ω–µ–µ —Ç–æ—á–µ–Ω —á–µ–º –∞–Ω—Å–∞–º–±–ª–∏</li></ul></div></div></div><div class="block"><h2>üî∑ 10. –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å</h2><div class="good-vs-bad"><div class="good"><h3>‚úÖ –•–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç</h3><ul><li>–ù—É–∂–Ω–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å</li><li>–ù–µ–ª–∏–Ω–µ–π–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏</li><li>–°–º–µ—à–∞–Ω–Ω—ã–µ —Ç–∏–ø—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</li><li>–ë—ã—Å—Ç—Ä–æ–µ –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏–µ</li><li>–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π</li></ul></div><div class="bad"><h3>‚ùå –ü–ª–æ—Ö–æ –ø–æ–¥—Ö–æ–¥–∏—Ç</h3><ul><li>–ù—É–∂–Ω–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ RF/GB)</li><li>–õ–∏–Ω–µ–π–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ª–∏–Ω–µ–π–Ω—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é)</li><li>–≠–∫—Å—Ç—Ä–∞–ø–æ–ª—è—Ü–∏—è –∑–∞ –ø—Ä–µ–¥–µ–ª—ã –¥–∞–Ω–Ω—ã—Ö</li><li>–û—á–µ–Ω—å –∑–∞—à—É–º–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ</li></ul></div></div></div><div class="block"><h2>üî∑ 11. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å Random Forest</h2><pre><code>from sklearn.ensemble import RandomForestRegressor

# Decision Tree
dt = DecisionTreeRegressor(max_depth=5, random_state=42)
dt.fit(X_train, y_train)
dt_score = dt.score(X_test, y_test)

# Random Forest (–∞–Ω—Å–∞–º–±–ª—å –¥–µ—Ä–µ–≤—å–µ–≤)
rf = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)
rf.fit(X_train, y_train)
rf_score = rf.score(X_test, y_test)

print(f"Decision Tree R¬≤: {dt_score:.3f}")
print(f"Random Forest R¬≤: {rf_score:.3f}")</code></pre></div><div class="block"><h2>üî∑ 12. –°—Ç—É–ø–µ–Ω—á–∞—Ç—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è</h2><p><strong>–ü—Ä–æ–±–ª–µ–º–∞:</strong> –¥–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π –¥–∞–µ—Ç —Å—Ç—É–ø–µ–Ω—á–∞—Ç—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (—Å—Ä–µ–¥–Ω–µ–µ –≤ –∫–∞–∂–¥–æ–º –ª–∏—Å—Ç–µ)</p><pre><code># –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
plt.figure(figsize=(10, 6))
plt.scatter(X_test, y_test, alpha=0.5, label='–ò—Å—Ç–∏–Ω–Ω—ã–µ')
plt.scatter(X_test, y_pred, alpha=0.5, label='–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è')
plt.legend()
plt.title('–°—Ç—É–ø–µ–Ω—á–∞—Ç—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è')
plt.show()</code></pre><p><strong>–†–µ—à–µ–Ω–∏–µ:</strong> –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Random Forest –∏–ª–∏ Gradient Boosting –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è</p></div><div class="block"><h2>üî∑ 13. –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤</h2><pre><code># MAE –±–æ–ª–µ–µ —É—Å—Ç–æ–π—á–∏–≤ –∫ –≤—ã–±—Ä–æ—Å–∞–º —á–µ–º MSE
model_robust = DecisionTreeRegressor(
    criterion='absolute_error',  # MAE
    max_depth=5
)
model_robust.fit(X_train, y_train)

# –ò–ª–∏ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
y_pred = model.predict(X_test)
y_pred_clipped = np.clip(y_pred, 
                          y_train.min(), 
                          y_train.max())</code></pre></div><div class="block"><h2>üî∑ 14. –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è</h2><pre><code>from sklearn.model_selection import cross_val_score

scores = cross_val_score(
    DecisionTreeRegressor(max_depth=5, random_state=42),
    X, y,
    cv=5,
    scoring='r2'
)

print(f"R¬≤ scores: {scores}")
print(f"Mean R¬≤: {scores.mean():.3f} (+/- {scores.std()*2:.3f})")</code></pre></div><div class="block"><h2>üî∑ 15. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã</h2><ul><li><strong>–ù–∞—á–Ω–∏—Ç–µ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π</strong>: max_depth=5, min_samples_split=20</li><li><strong>–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é</strong>: –¥–ª—è –≤—ã–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</li><li><strong>–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –¥–µ—Ä–µ–≤–æ</strong>: –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –ª–æ–≥–∏–∫–∏</li><li><strong>–°—Ä–∞–≤–Ω–∏—Ç–µ —Å –∞–Ω—Å–∞–º–±–ª—è–º–∏</strong>: RF, Gradient Boosting –æ–±—ã—á–Ω–æ —Ç–æ—á–Ω–µ–µ</li><li><strong>MAE –¥–ª—è –≤—ã–±—Ä–æ—Å–æ–≤</strong>: –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –≤—ã–±—Ä–æ—Å—ã</li></ul></div><div class="block"><h2>üî∑ 16. –ß–µ–∫-–ª–∏—Å—Ç</h2><ul><li>[ ] –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ (–Ω–µ –Ω—É–∂–Ω–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ)</li><li>[ ] –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å max_depth –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏</li><li>[ ] –í—ã–±—Ä–∞—Ç—å criterion (MSE –∏–ª–∏ MAE)</li><li>[ ] –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å</li><li>[ ] –û—Ü–µ–Ω–∏—Ç—å –Ω–∞ train –∏ test (–ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ)</li><li>[ ] –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–µ—Ä–µ–≤–æ</li><li>[ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤</li><li>[ ] –°—Ä–∞–≤–Ω–∏—Ç—å —Å Random Forest</li></ul><blockquote>¬´–î–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ ‚Äî –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã–π –∏ –±—ã—Å—Ç—Ä—ã–π –º–µ—Ç–æ–¥, –Ω–æ —Å–∫–ª–æ–Ω–Ω—ã –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é –∏–ª–∏ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ –∞–Ω—Å–∞–º–±–ª—è–º –¥–ª—è –ª—É—á—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏¬ª.</blockquote></div><div class="block"><h2>üîó –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏</h2><ul><li><a href="https://scikit-learn.org/stable/modules/tree.html#regression" target="_blank">üìö Scikit-learn: Decision Trees Regression</a></li><li><a href="https://en.wikipedia.org/wiki/Decision_tree_learning" target="_blank">üìù Wikipedia: Decision tree learning</a></li></ul></div></div></body></html>
