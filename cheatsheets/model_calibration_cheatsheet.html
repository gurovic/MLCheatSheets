<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –º–æ–¥–µ–ª–µ–π Cheatsheet</title>
  <style>
    @media screen { body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif; color: #333; background: #fafcff; padding: 10px; }}
    .container { column-count: 3; column-gap: 20px; max-width: 100%; }
    .block { break-inside: avoid; margin-bottom: 1.2em; padding: 12px; background: white; border-radius: 6px; box-shadow: 0 1px 3px rgba(0,0,0,0.05); }
    h1 { font-size: 1.6em; font-weight: 700; color: #1a5fb4; text-align: center; margin: 0 0 8px; column-span: all; }
    .subtitle { text-align: center; color: #666; font-size: 0.9em; margin-bottom: 12px; column-span: all; }
    h2 { font-size: 1.15em; font-weight: 700; color: #1a5fb4; margin: 0 0 8px; padding-bottom: 4px; border-bottom: 1px solid #e0e7ff; }
    p, ul, ol { font-size: 0.92em; margin: 0.6em 0; }
    ul, ol { padding-left: 18px; }
    li { margin-bottom: 4px; }
    code { font-family: 'Consolas', 'Courier New', monospace; background-color: #f0f4ff; padding: 1px 4px; border-radius: 3px; font-size: 0.88em; }
    pre { background-color: #f0f4ff; padding: 8px; border-radius: 4px; overflow-x: auto; font-size: 0.84em; margin: 6px 0; }
    pre code { padding: 0; background: none; white-space: pre-wrap; }
    table { width: 100%; border-collapse: collapse; font-size: 0.82em; margin: 6px 0; }
    th { background-color: #e6f0ff; text-align: left; padding: 4px 6px; font-weight: 600; }
    td { padding: 4px 6px; border-bottom: 1px solid #f0f4ff; }
    tr:nth-child(even) { background-color: #f8fbff; }
  </style>
</head>
<body>
<div class="container">
  <h1>üéØ –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –º–æ–¥–µ–ª–µ–π</h1>
  <div class="subtitle">–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ñ–æ–∫—É—Å ‚Ä¢ üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ –ß—Ç–æ —Ç–∞–∫–æ–µ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞</h2>
    <ul>
      <li><strong>–¶–µ–ª—å</strong>: —Å–¥–µ–ª–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –Ω–∞–¥–µ–∂–Ω—ã–º–∏</li>
      <li><strong>–ü—Ä–æ–±–ª–µ–º–∞</strong>: predict_proba –Ω–µ –≤—Å–µ–≥–¥–∞ —Ç–æ—á–Ω—ã</li>
      <li><strong>–ö–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏</strong>: –æ—Ç—Ä–∞–∂–∞—é—Ç –∏—Å—Ç–∏–Ω–Ω—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å</li>
      <li><strong>–ü—Ä–∏–º–µ—Ä</strong>: –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –≥–æ–≤–æ—Ä–∏—Ç 70%, —Ç–æ –≤ 70% —Å–ª—É—á–∞–µ–≤ —ç—Ç–æ –ø—Ä–∞–≤–¥–∞</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ –ó–∞—á–µ–º –Ω—É–∂–Ω–∞</h2>
    <ul>
      <li>–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π</li>
      <li>Cost-sensitive —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–ú–µ–¥–∏—Ü–∏–Ω–∞, —Ñ–∏–Ω–∞–Ω—Å—ã</li>
      <li>–ê–Ω—Å–∞–º–±–ª–∏ –º–æ–¥–µ–ª–µ–π</li>
      <li>–ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ –ë–∞–∑–æ–≤–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞</h2>
    <pre><code>from sklearn.calibration import CalibratedClassifierCV

# –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, SVM –ø–ª–æ—Ö–æ –∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω)
from sklearn.svm import SVC
base_model = SVC(probability=True)

# –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞
calibrated = CalibratedClassifierCV(
    base_model,
    method='sigmoid',  # –∏–ª–∏ 'isotonic'
    cv=5
)

calibrated.fit(X_train, y_train)

# –ö–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
proba_calibrated = calibrated.predict_proba(X_test)
print(proba_calibrated[:5])</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ –ú–µ—Ç–æ–¥—ã –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏</h2>
    <table>
      <tr><th>–ú–µ—Ç–æ–¥</th><th>–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å</th></tr>
      <tr><td><strong>Platt Scaling</strong> (sigmoid)</td><td>–ú–∞–ª—ã–µ –¥–∞–Ω–Ω—ã–µ, –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ —Å–∏–≥–º–æ–∏–¥—ã</td></tr>
      <tr><td><strong>Isotonic Regression</strong></td><td>–ë–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö, –Ω–µ—Ç –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–π</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ Calibration Curve</h2>
    <pre><code>from sklearn.calibration import calibration_curve
import matplotlib.pyplot as plt

# –î–æ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
prob_true, prob_pred = calibration_curve(
    y_test,
    base_model.predict_proba(X_test)[:, 1],
    n_bins=10
)

# –ü–æ—Å–ª–µ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
prob_true_cal, prob_pred_cal = calibration_curve(
    y_test,
    calibrated.predict_proba(X_test)[:, 1],
    n_bins=10
)

# –ì—Ä–∞—Ñ–∏–∫
plt.figure(figsize=(10, 6))
plt.plot([0, 1], [0, 1], 'k--', label='–ò–¥–µ–∞–ª—å–Ω–æ –∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω–∞—è')
plt.plot(prob_pred, prob_true, 's-', label='–î–æ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏')
plt.plot(prob_pred_cal, prob_true_cal, 's-', label='–ü–æ—Å–ª–µ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏')
plt.xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å')
plt.ylabel('–ò—Å—Ç–∏–Ω–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å')
plt.legend()
plt.grid(True)
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ Brier Score</h2>
    <p>–ú–µ—Ç—Ä–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏</p>
    <pre><code>from sklearn.metrics import brier_score_loss

# –î–æ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
brier_before = brier_score_loss(
    y_test,
    base_model.predict_proba(X_test)[:, 1]
)

# –ü–æ—Å–ª–µ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
brier_after = brier_score_loss(
    y_test,
    calibrated.predict_proba(X_test)[:, 1]
)

print(f"Brier Score –¥–æ: {brier_before:.3f}")
print(f"Brier Score –ø–æ—Å–ª–µ: {brier_after:.3f}")
# –ß–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ –ö–∞–∫–∏–µ –º–æ–¥–µ–ª–∏ –Ω—É–∂–Ω–æ –∫–∞–ª–∏–±—Ä–æ–≤–∞—Ç—å</h2>
    <table>
      <tr><th>–ú–æ–¥–µ–ª—å</th><th>–ù—É–∂–Ω–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞?</th></tr>
      <tr><td>Logistic Regression</td><td>–û–±—ã—á–Ω–æ –Ω–µ—Ç ‚úÖ</td></tr>
      <tr><td>Random Forest</td><td>–î–∞ ‚ùå</td></tr>
      <tr><td>Gradient Boosting</td><td>–î–∞ ‚ùå</td></tr>
      <tr><td>SVM</td><td>–î–∞ ‚ùå</td></tr>
      <tr><td>Naive Bayes</td><td>–ò–Ω–æ–≥–¥–∞</td></tr>
      <tr><td>Neural Networks</td><td>–î–∞ ‚ùå</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ –ü–æ–ª–Ω–∞—è –æ—Ü–µ–Ω–∫–∞</h2>
    <pre><code>from sklearn.calibration import calibration_curve
from sklearn.metrics import log_loss, brier_score_loss

def evaluate_calibration(y_true, y_proba):
    """–ü–æ–ª–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏"""
    
    # Brier Score
    brier = brier_score_loss(y_true, y_proba)
    print(f"Brier Score: {brier:.3f}")
    
    # Log Loss
    logloss = log_loss(y_true, y_proba)
    print(f"Log Loss: {logloss:.3f}")
    
    # Calibration curve
    prob_true, prob_pred = calibration_curve(y_true, y_proba, n_bins=10)
    
    # –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç –∏–¥–µ–∞–ª—å–Ω–æ–π –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
    calibration_error = np.abs(prob_true - prob_pred).mean()
    print(f"Calibration Error: {calibration_error:.3f}")
    
    return brier, logloss, calibration_error

evaluate_calibration(y_test, calibrated.predict_proba(X_test)[:, 1])</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ —É–∂–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏</h2>
    <pre><code># –£ –≤–∞—Å —É–∂–µ –µ—Å—Ç—å –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
trained_model = RandomForestClassifier()
trained_model.fit(X_train, y_train)

# –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–º –Ω–∞–±–æ—Ä–µ (holdout)
from sklearn.calibration import CalibratedClassifierCV

calibrated = CalibratedClassifierCV(
    trained_model,
    method='isotonic',
    cv='prefit'  # –º–æ–¥–µ–ª—å —É–∂–µ –æ–±—É—á–µ–Ω–∞!
)

# –ö–∞–ª–∏–±—Ä—É–µ–º –Ω–∞ –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ
calibrated.fit(X_calib, y_calib)

# –ò—Å–ø–æ–ª—å–∑—É–µ–º
y_proba = calibrated.predict_proba(X_test)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏</h2>
    <ul>
      <li><strong>–û—Ç–¥–µ–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä</strong>: cv='prefit' + holdout –¥–∞–Ω–Ω—ã–µ</li>
      <li><strong>–î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö</strong>: isotonic —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö</li>
      <li><strong>–ü—Ä–æ–≤–µ—Ä–∫–∞</strong>: –≤—Å–µ–≥–¥–∞ —Å—Ç—Ä–æ–π—Ç–µ calibration curve</li>
      <li><strong>–ú–µ—Ç—Ä–∏–∫–∏</strong>: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Brier Score –∏ Log Loss</li>
      <li><strong>–ü—Ä–æ—Å—Ç—ã–µ –º–æ–¥–µ–ª–∏</strong>: LogReg –æ–±—ã—á–Ω–æ –Ω–µ –Ω—É–∂–¥–∞–µ—Ç—Å—è</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ –ü—Ä–∏–º–µ—Ä workflow</h2>
    <pre><code># 1. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3)
X_calib, X_test, y_calib, y_test = train_test_split(X_temp, y_temp, test_size=0.5)

# 2. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
model = RandomForestClassifier()
model.fit(X_train, y_train)

# 3. –û—Ü–µ–Ω–∫–∞ –¥–æ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
y_proba_before = model.predict_proba(X_test)[:, 1]
print(f"Brier –¥–æ: {brier_score_loss(y_test, y_proba_before):.3f}")

# 4. –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞
calibrated = CalibratedClassifierCV(model, cv='prefit', method='isotonic')
calibrated.fit(X_calib, y_calib)

# 5. –û—Ü–µ–Ω–∫–∞ –ø–æ—Å–ª–µ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
y_proba_after = calibrated.predict_proba(X_test)[:, 1]
print(f"Brier –ø–æ—Å–ª–µ: {brier_score_loss(y_test, y_proba_after):.3f}")

# 6. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
plt.figure(figsize=(10, 6))
plt.plot([0, 1], [0, 1], 'k--')
for name, proba in [('–î–æ', y_proba_before), ('–ü–æ—Å–ª–µ', y_proba_after)]:
    prob_true, prob_pred = calibration_curve(y_test, proba, n_bins=10)
    plt.plot(prob_pred, prob_true, 's-', label=name)
plt.legend()
plt.show()</code></pre>
  </div>

</div>
</body>
</html>
