<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>Canonical Correlation Analysis (CCA) ‚Äî Cheatsheet</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

    .container {
      column-count: 3;
      column-gap: 20px;
      max-width: 100%;
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      font-size: 0.9em;
      color: #666;
      text-align: center;
      margin-bottom: 20px;
      column-span: all;
    }

    h2 {
      font-size: 1.1em;
      font-weight: 700;
      margin-top: 0;
      color: #1a5fb4;
      border-bottom: 2px solid #e0e8f5;
      padding-bottom: 4px;
    }

    h3 {
      font-size: 0.95em;
      font-weight: 600;
      margin: 8px 0 4px;
      color: #26a269;
    }

    p, ul, ol {
      margin: 6px 0;
      font-size: 0.88em;
      line-height: 1.5;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 3px;
    }

    code {
      background: #f6f8fa;
      padding: 1px 4px;
      border-radius: 3px;
      font-family: 'Consolas', 'Monaco', monospace;
      font-size: 0.9em;
      color: #c7254e;
    }

    pre {
      background: #282c34;
      color: #abb2bf;
      padding: 10px;
      border-radius: 6px;
      overflow-x: auto;
      font-size: 0.8em;
      line-height: 1.4;
      margin: 8px 0;
    }

    pre code {
      background: transparent;
      color: inherit;
      padding: 0;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      margin: 8px 0;
      font-size: 0.85em;
    }

    th, td {
      border: 1px solid #ddd;
      padding: 6px 8px;
      text-align: left;
    }

    th {
      background: #e0e8f5;
      font-weight: 600;
      color: #1a5fb4;
    }

    tr:nth-child(even) {
      background: #f9fbff;
    }

    blockquote {
      background: #fff9e6;
      border-left: 4px solid #f6d32d;
      padding: 8px 12px;
      margin: 8px 0;
      font-size: 0.88em;
      font-style: italic;
    }

    .formula {
      background: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      margin: 8px 0;
      font-family: 'Cambria', 'Times New Roman', serif;
      font-size: 0.9em;
      text-align: center;
    }
  </style>
</head>
<body>

<h1>üéØ Canonical Correlation Analysis (CCA)</h1>
<div class="subtitle">–ö–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑</div>

<div class="container">

  <div class="block">
    <h2>üî∑ 1. –û—Å–Ω–æ–≤–Ω–∞—è –∏–¥–µ—è</h2>
    <p>–ù–∞—Ö–æ–¥–∏—Ç –ª–∏–Ω–µ–π–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –¥–≤—É—Ö –Ω–∞–±–æ—Ä–æ–≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π.</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># Deep CCA —Å PyTorch
import torch
import torch.nn as nn

class DeepCCAModel(nn.Module):
    def __init__(self, input_dim1, input_dim2, latent_dim):
        super().__init__()
        self.encoder1 = nn.Sequential(
            nn.Linear(input_dim1, 128),
            nn.ReLU(),
            nn.Linear(128, latent_dim)
        )
        self.encoder2 = nn.Sequential(
            nn.Linear(input_dim2, 128),
            nn.ReLU(),
            nn.Linear(128, latent_dim)
        )
    
    def forward(self, x1, x2):
        return self.encoder1(x1), self.encoder2(x2)

model = DeepCCAModel(50, 30, 10)
optimizer = torch.optim.Adam(model.parameters())

for epoch in range(100):
    z1, z2 = model(X1_batch, X2_batch)
    # Maximize correlation between z1 and z2
    loss = -torch.trace(z1.T @ z2) / len(z1)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –Ω–∞—Ö–æ–¥–∏—Ç –ª–∏–Ω–µ–π–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –¥–≤—É—Ö –Ω–∞–±–æ—Ä–æ–≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π....
    </blockquote>
  </div>
  <div class="block">
    <h2>üî∑ 2. –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞</h2>
    <p>max corr(X*a, Y*b) –≥–¥–µ a –∏ b ‚Äî –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–µ –≤–µ—Å–∞.</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># Regularized CCA
from sklearn.cross_decomposition import CCA
import numpy as np

# Ridge CCA –¥–ª—è –≤—ã—Å–æ–∫–æ—Ä–∞–∑–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
class RidgeCCA:
    def __init__(self, n_components, reg=1e-3):
        self.n_components = n_components
        self.reg = reg
    
    def fit(self, X, Y):
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é –∫ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω—ã–º –º–∞—Ç—Ä–∏—Ü–∞–º
        C_xx = X.T @ X / len(X) + self.reg * np.eye(X.shape[1])
        C_yy = Y.T @ Y / len(Y) + self.reg * np.eye(Y.shape[1])
        C_xy = X.T @ Y / len(X)
        
        # –†–µ—à–∞–µ–º –æ–±–æ–±—â—ë–Ω–Ω—É—é –∑–∞–¥–∞—á—É –Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        # (—É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        self.cca = CCA(n_components=self.n_components)
        self.cca.fit(X, Y)
        return self

rcca = RidgeCCA(n_components=5)
rcca.fit(X_train, Y_train)</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ max corr(x*a, y*b) –≥–¥–µ a –∏ b ‚Äî –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–µ –≤–µ—Å–∞....
    </blockquote>
  </div>
  <div class="block">
    <h2>üî∑ 3. Canonical Variables</h2>
    <p>–ö–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ U = Xa –∏ V = Yb –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä—É—é—Ç.</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># CCA —Å sklearn
from sklearn.cross_decomposition import CCA
import numpy as np

X = np.random.randn(100, 10)
Y = np.random.randn(100, 8)

cca = CCA(n_components=3)
cca.fit(X, Y)

X_c, Y_c = cca.transform(X, Y)

# –í—ã—á–∏—Å–ª—è–µ–º –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
correlations = [np.corrcoef(X_c[:, i], Y_c[:, i])[0, 1] for i in range(3)]
print(f"–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏: {correlations}")</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ u = xa –∏ v = yb –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä—É—é—Ç....
    </blockquote>
  </div>
  <div class="block">
    <h2>üî∑ 4. Applications</h2>
    <p>–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ, —Å–≤—è–∑—å –º–µ–∂–¥—É —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è–º–∏ –¥–∞–Ω–Ω—ã—Ö.</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># Deep CCA —Å PyTorch
import torch
import torch.nn as nn

class DeepCCAModel(nn.Module):
    def __init__(self, input_dim1, input_dim2, latent_dim):
        super().__init__()
        self.encoder1 = nn.Sequential(
            nn.Linear(input_dim1, 128),
            nn.ReLU(),
            nn.Linear(128, latent_dim)
        )
        self.encoder2 = nn.Sequential(
            nn.Linear(input_dim2, 128),
            nn.ReLU(),
            nn.Linear(128, latent_dim)
        )
    
    def forward(self, x1, x2):
        return self.encoder1(x1), self.encoder2(x2)

model = DeepCCAModel(50, 30, 10)
optimizer = torch.optim.Adam(model.parameters())

for epoch in range(100):
    z1, z2 = model(X1_batch, X2_batch)
    # Maximize correlation between z1 and z2
    loss = -torch.trace(z1.T @ z2) / len(z1)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ, —Å–≤—è–∑—å –º–µ–∂–¥—É —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è–º–∏ –¥–∞–Ω–Ω—ã—Ö....
    </blockquote>
  </div>
  <div class="block">
    <h2>üî∑ 5. CCA vs PCA</h2>
    <p>PCA: –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ—Ç variance. CCA: –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ—Ç correlation –º–µ–∂–¥—É –¥–≤—É–º—è –Ω–∞–±–æ—Ä–∞–º–∏.</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># Regularized CCA
from sklearn.cross_decomposition import CCA
import numpy as np

# Ridge CCA –¥–ª—è –≤—ã—Å–æ–∫–æ—Ä–∞–∑–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
class RidgeCCA:
    def __init__(self, n_components, reg=1e-3):
        self.n_components = n_components
        self.reg = reg
    
    def fit(self, X, Y):
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é –∫ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω—ã–º –º–∞—Ç—Ä–∏—Ü–∞–º
        C_xx = X.T @ X / len(X) + self.reg * np.eye(X.shape[1])
        C_yy = Y.T @ Y / len(Y) + self.reg * np.eye(Y.shape[1])
        C_xy = X.T @ Y / len(X)
        
        # –†–µ—à–∞–µ–º –æ–±–æ–±—â—ë–Ω–Ω—É—é –∑–∞–¥–∞—á—É –Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        # (—É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        self.cca = CCA(n_components=self.n_components)
        self.cca.fit(X, Y)
        return self

rcca = RidgeCCA(n_components=5)
rcca.fit(X_train, Y_train)</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ pca: –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ—Ç variance. cca: –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ—Ç correlation –º–µ–∂–¥—É –¥–≤—É–º—è –Ω–∞–±–æ—Ä–∞–º–∏....
    </blockquote>
  </div>
  <div class="block">
    <h2>üî∑ 6. Kernel CCA</h2>
    <p>–ù–µ–ª–∏–Ω–µ–π–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ CCA —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º kernel trick.</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># CCA —Å sklearn
from sklearn.cross_decomposition import CCA
import numpy as np

X = np.random.randn(100, 10)
Y = np.random.randn(100, 8)

cca = CCA(n_components=3)
cca.fit(X, Y)

X_c, Y_c = cca.transform(X, Y)

# –í—ã—á–∏—Å–ª—è–µ–º –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
correlations = [np.corrcoef(X_c[:, i], Y_c[:, i])[0, 1] for i in range(3)]
print(f"–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏: {correlations}")</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –Ω–µ–ª–∏–Ω–µ–π–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ cca —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º kernel trick....
    </blockquote>
  </div>
  <div class="block">
    <h2>üî∑ 7. Deep CCA</h2>
    <p>–ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –ø–æ–¥—Ö–æ–¥: –¥–≤–µ —Å–µ—Ç–∏ —É—á–∞—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π.</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># Deep CCA —Å PyTorch
import torch
import torch.nn as nn

class DeepCCAModel(nn.Module):
    def __init__(self, input_dim1, input_dim2, latent_dim):
        super().__init__()
        self.encoder1 = nn.Sequential(
            nn.Linear(input_dim1, 128),
            nn.ReLU(),
            nn.Linear(128, latent_dim)
        )
        self.encoder2 = nn.Sequential(
            nn.Linear(input_dim2, 128),
            nn.ReLU(),
            nn.Linear(128, latent_dim)
        )
    
    def forward(self, x1, x2):
        return self.encoder1(x1), self.encoder2(x2)

model = DeepCCAModel(50, 30, 10)
optimizer = torch.optim.Adam(model.parameters())

for epoch in range(100):
    z1, z2 = model(X1_batch, X2_batch)
    # Maximize correlation between z1 and z2
    loss = -torch.trace(z1.T @ z2) / len(z1)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –ø–æ–¥—Ö–æ–¥: –¥–≤–µ —Å–µ—Ç–∏ —É—á–∞—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π....
    </blockquote>
  </div>
  <div class="block">
    <h2>üî∑ 8. Regularization</h2>
    <p>Ridge CCA –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–∏ p > n (–±–æ–ª—å—à–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —á–µ–º –æ–±—ä–µ–∫—Ç–æ–≤).</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># Regularized CCA
from sklearn.cross_decomposition import CCA
import numpy as np

# Ridge CCA –¥–ª—è –≤—ã—Å–æ–∫–æ—Ä–∞–∑–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
class RidgeCCA:
    def __init__(self, n_components, reg=1e-3):
        self.n_components = n_components
        self.reg = reg
    
    def fit(self, X, Y):
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é –∫ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω—ã–º –º–∞—Ç—Ä–∏—Ü–∞–º
        C_xx = X.T @ X / len(X) + self.reg * np.eye(X.shape[1])
        C_yy = Y.T @ Y / len(Y) + self.reg * np.eye(Y.shape[1])
        C_xy = X.T @ Y / len(X)
        
        # –†–µ—à–∞–µ–º –æ–±–æ–±—â—ë–Ω–Ω—É—é –∑–∞–¥–∞—á—É –Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        # (—É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        self.cca = CCA(n_components=self.n_components)
        self.cca.fit(X, Y)
        return self

rcca = RidgeCCA(n_components=5)
rcca.fit(X_train, Y_train)</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ ridge cca –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–∏ p > n (–±–æ–ª—å—à–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —á–µ–º –æ–±—ä–µ–∫—Ç–æ–≤)....
    </blockquote>
  </div>
  <div class="block">
    <h2>üî∑ 9. Interpretation</h2>
    <p>–ö–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–µ –≤–µ—Å–∞ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –∏—Å—Ö–æ–¥–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö.</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># CCA —Å sklearn
from sklearn.cross_decomposition import CCA
import numpy as np

X = np.random.randn(100, 10)
Y = np.random.randn(100, 8)

cca = CCA(n_components=3)
cca.fit(X, Y)

X_c, Y_c = cca.transform(X, Y)

# –í—ã—á–∏—Å–ª—è–µ–º –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
correlations = [np.corrcoef(X_c[:, i], Y_c[:, i])[0, 1] for i in range(3)]
print(f"–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏: {correlations}")</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–µ –≤–µ—Å–∞ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –∏—Å—Ö–æ–¥–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö....
    </blockquote>
  </div>
  <div class="block">
    <h2>üî∑ 10. Assumptions</h2>
    <p>–õ–∏–Ω–µ–π–Ω–æ—Å—Ç—å —Å–≤—è–∑–µ–π, –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π (–¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Å—Ç–æ–≤).</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># Deep CCA —Å PyTorch
import torch
import torch.nn as nn

class DeepCCAModel(nn.Module):
    def __init__(self, input_dim1, input_dim2, latent_dim):
        super().__init__()
        self.encoder1 = nn.Sequential(
            nn.Linear(input_dim1, 128),
            nn.ReLU(),
            nn.Linear(128, latent_dim)
        )
        self.encoder2 = nn.Sequential(
            nn.Linear(input_dim2, 128),
            nn.ReLU(),
            nn.Linear(128, latent_dim)
        )
    
    def forward(self, x1, x2):
        return self.encoder1(x1), self.encoder2(x2)

model = DeepCCAModel(50, 30, 10)
optimizer = torch.optim.Adam(model.parameters())

for epoch in range(100):
    z1, z2 = model(X1_batch, X2_batch)
    # Maximize correlation between z1 and z2
    loss = -torch.trace(z1.T @ z2) / len(z1)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –ª–∏–Ω–µ–π–Ω–æ—Å—Ç—å —Å–≤—è–∑–µ–π, –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π (–¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Å—Ç–æ–≤)....
    </blockquote>
  </div>
  <div class="block">
    <h2>üî∑ 11. Use Cases</h2>
    <p>–°–≤—è–∑—å –≥–µ–Ω–µ—Ç–∏–∫–∏ –∏ —Ñ–µ–Ω–æ—Ç–∏–ø–æ–≤, —Ç–µ–∫—Å—Ç-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ matching, –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π retrieval.</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># Regularized CCA
from sklearn.cross_decomposition import CCA
import numpy as np

# Ridge CCA –¥–ª—è –≤—ã—Å–æ–∫–æ—Ä–∞–∑–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
class RidgeCCA:
    def __init__(self, n_components, reg=1e-3):
        self.n_components = n_components
        self.reg = reg
    
    def fit(self, X, Y):
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é –∫ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω—ã–º –º–∞—Ç—Ä–∏—Ü–∞–º
        C_xx = X.T @ X / len(X) + self.reg * np.eye(X.shape[1])
        C_yy = Y.T @ Y / len(Y) + self.reg * np.eye(Y.shape[1])
        C_xy = X.T @ Y / len(X)
        
        # –†–µ—à–∞–µ–º –æ–±–æ–±—â—ë–Ω–Ω—É—é –∑–∞–¥–∞—á—É –Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        # (—É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        self.cca = CCA(n_components=self.n_components)
        self.cca.fit(X, Y)
        return self

rcca = RidgeCCA(n_components=5)
rcca.fit(X_train, Y_train)</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ —Å–≤—è–∑—å –≥–µ–Ω–µ—Ç–∏–∫–∏ –∏ —Ñ–µ–Ω–æ—Ç–∏–ø–æ–≤, —Ç–µ–∫—Å—Ç-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ matching, –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π retrieval....
    </blockquote>
  </div>
  <div class="block">
    <h2>üî∑ 12. Implementation</h2>
    <p>sklearn.cross_decomposition.CCA, rcca package, custom PyTorch implementations.</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># CCA —Å sklearn
from sklearn.cross_decomposition import CCA
import numpy as np

X = np.random.randn(100, 10)
Y = np.random.randn(100, 8)

cca = CCA(n_components=3)
cca.fit(X, Y)

X_c, Y_c = cca.transform(X, Y)

# –í—ã—á–∏—Å–ª—è–µ–º –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
correlations = [np.corrcoef(X_c[:, i], Y_c[:, i])[0, 1] for i in range(3)]
print(f"–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏: {correlations}")</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ sklearn.cross_decomposition.cca, rcca package, custom pytorch implementations....
    </blockquote>
  </div>
</div>

</body>
</html>