<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>–î–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –ü—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

        .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>üîí Differential Privacy</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –°—É—Ç—å</h2>
    <ul>
      <li><strong>–¶–µ–ª—å</strong>: –∑–∞—â–∏—Ç–∞ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –¥–∞–Ω–Ω—ã—Ö</li>
      <li><strong>–ì–∞—Ä–∞–Ω—Ç–∏—è</strong>: –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —É—á–∞—Å—Ç–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–ø–∏—Å–∏</li>
      <li><strong>–§–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å</strong>: –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–æ–∫–∞–∑—É–µ–º–∞—è –∑–∞—â–∏—Ç–∞</li>
      <li><strong>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</strong>: –ø–µ—Ä–µ–ø–∏—Å–∏, –º–µ–¥–∏—Ü–∏–Ω–∞, ML –Ω–∞ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö</li>
      <li><strong>Trade-off</strong>: –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å vs —Ç–æ—á–Ω–æ—Å—Ç—å</li>
    </ul>
    <blockquote>–î–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—á—Ç–∏ –Ω–µ –∏–∑–º–µ–Ω–∏—Ç—Å—è –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏/—É–¥–∞–ª–µ–Ω–∏–∏ –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å–∏</blockquote>

  <div class="block">
    <h2>üî∑ 2. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ (Œµ-DP)</h2>
    <p><strong>–ú–µ—Ö–∞–Ω–∏–∑–º M —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—è–µ—Ç Œµ-–¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏:</strong></p>
    <pre><code>P(M(D) ‚àà S) ‚â§ e^Œµ ¬∑ P(M(D') ‚àà S)

–≥–¥–µ:
- D –∏ D' —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å—å—é
- S - –ª—é–±–æ–µ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –≤—ã—Ö–æ–¥–æ–≤
- Œµ (epsilon) - –ø–∞—Ä–∞–º–µ—Ç—Ä –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏</code></pre>
    
    <p><strong>–ò–Ω—Ç—É–∏—Ü–∏—è Œµ:</strong></p>
    <ul>
      <li><code>Œµ = 0</code>: –∏–¥–µ–∞–ª—å–Ω–∞—è –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å (–±–µ—Å–ø–æ–ª–µ–∑–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç)</li>
      <li><code>Œµ = 0.1</code>: –æ—á–µ–Ω—å —Å–∏–ª—å–Ω–∞—è –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å</li>
      <li><code>Œµ = 1</code>: —Å–∏–ª—å–Ω–∞—è –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å (–æ–±—ã—á–Ω—ã–π –≤—ã–±–æ—Ä)</li>
      <li><code>Œµ = 10</code>: —Å–ª–∞–±–∞—è –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 3. Laplace –º–µ—Ö–∞–Ω–∏–∑–º</h2>
    <pre><code>import numpy as np

def laplace_mechanism(true_answer, sensitivity, epsilon):
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç —à—É–º –õ–∞–ø–ª–∞—Å–∞ –¥–ª—è DP
    
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    - true_answer: –∏—Å—Ç–∏–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å
    - sensitivity: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å–∏
    - epsilon: –ø–∞—Ä–∞–º–µ—Ç—Ä –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏
    """
    scale = sensitivity / epsilon
    noise = np.random.laplace(0, scale)
    return true_answer + noise

# –ü—Ä–∏–º–µ—Ä: –ø–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
true_count = len(data)
sensitivity = 1  # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ/—É–¥–∞–ª–µ–Ω–∏–µ –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å–∏ –º–µ–Ω—è–µ—Ç count –Ω–∞ 1
epsilon = 1.0

dp_count = laplace_mechanism(true_count, sensitivity, epsilon)
print(f"True count: {true_count}, DP count: {dp_count:.2f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. Gaussian –º–µ—Ö–∞–Ω–∏–∑–º</h2>
    <p><strong>–î–ª—è (Œµ, Œ¥)-DP:</strong></p>
    <pre><code>def gaussian_mechanism(true_answer, sensitivity, epsilon, delta):
    """
    Gaussian –º–µ—Ö–∞–Ω–∏–∑–º –¥–ª—è (Œµ, Œ¥)-DP
    –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ Laplace –¥–ª—è —á–∏—Å–ª–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    """
    sigma = np.sqrt(2 * np.log(1.25 / delta)) * sensitivity / epsilon
    noise = np.random.normal(0, sigma)
    return true_answer + noise

# –ü—Ä–∏–º–µ—Ä
dp_mean = gaussian_mechanism(
    true_answer=np.mean(data),
    sensitivity=max(data) - min(data),  # Range / n
    epsilon=1.0,
    delta=1e-5
)</code></pre>
    
    <p><strong>(Œµ, Œ¥)-DP –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:</strong></p>
    <pre><code>P(M(D) ‚àà S) ‚â§ e^Œµ ¬∑ P(M(D') ‚àà S) + Œ¥

Œ¥ - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–æ–≤–∞–ª–∞ –≥–∞—Ä–∞–Ω—Ç–∏–∏ (–æ–±—ã—á–Ω–æ 10^-5)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (Sensitivity)</h2>
    <table>
      <tr>
        <th>–ó–∞–ø—Ä–æ—Å</th>
        <th>L1 Sensitivity</th>
        <th>L2 Sensitivity</th>
      </tr>
      <tr>
        <td>Count</td>
        <td>1</td>
        <td>1</td>
      </tr>
      <tr>
        <td>Sum (bounded)</td>
        <td>max_value</td>
        <td>max_value</td>
      </tr>
      <tr>
        <td>Mean (bounded)</td>
        <td>range / n</td>
        <td>range / n</td>
      </tr>
      <tr>
        <td>Max/Min</td>
        <td>range</td>
        <td>range</td>
      </tr>
      <tr>
        <td>Histogram</td>
        <td>1 per bin</td>
        <td>‚àök (k bins)</td>
      </tr>
    </table>
    
    <pre><code>def compute_sensitivity(query_type, data_properties):
    """
    –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–∞
    """
    if query_type == "count":
        return 1
    elif query_type == "sum":
        return data_properties["max_value"]
    elif query_type == "mean":
        n = data_properties["n"]
        r = data_properties["range"]
        return r / n
    elif query_type == "histogram":
        return 1  # L1 –¥–ª—è –æ–¥–Ω–æ–≥–æ –±–∏–Ω–∞</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. –ö–æ–º–ø–æ–∑–∏—Ü–∏—è</h2>
    <p><strong>–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –∫–æ–º–ø–æ–∑–∏—Ü–∏—è:</strong></p>
    <pre><code># –ï—Å–ª–∏ M1 —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—è–µ—Ç Œµ1-DP –∏ M2 —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—è–µ—Ç Œµ2-DP
# —Ç–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ M1 –∏ M2 —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—è–µ—Ç (Œµ1 + Œµ2)-DP

total_epsilon = 0
privacy_budget = 1.0

def check_budget(epsilon_needed):
    global total_epsilon
    if total_epsilon + epsilon_needed > privacy_budget:
        raise ValueError("Privacy budget exceeded!")
    total_epsilon += epsilon_needed

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
check_budget(0.3)  # –ó–∞–ø—Ä–æ—Å 1
result1 = laplace_mechanism(count1, 1, 0.3)

check_budget(0.3)  # –ó–∞–ø—Ä–æ—Å 2
result2 = laplace_mechanism(count2, 1, 0.3)

print(f"Total epsilon used: {total_epsilon}")</code></pre>
    
    <p><strong>–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∫–æ–º–ø–æ–∑–∏—Ü–∏—è:</strong></p>
    <ul>
      <li>–ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ –Ω–µ–ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏—Ö—Å—è –¥–∞–Ω–Ω—ã—Ö</li>
      <li>–¢–æ–≥–¥–∞ Œµ –Ω–µ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è</li>
      <li>–ü—Ä–∏–º–µ—Ä: –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ (–∫–∞–∂–¥—ã–π –±–∏–Ω –Ω–µ–∑–∞–≤–∏—Å–∏–º)</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 7. DP-SGD (Machine Learning)</h2>
    <pre><code>import torch
import torch.nn as nn
from opacus import PrivacyEngine

# –ú–æ–¥–µ–ª—å
model = nn.Sequential(
    nn.Linear(784, 128),
    nn.ReLU(),
    nn.Linear(128, 10)
)

optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Privacy Engine
privacy_engine = PrivacyEngine()

model, optimizer, train_loader = privacy_engine.make_private(
    module=model,
    optimizer=optimizer,
    data_loader=train_loader,
    noise_multiplier=1.1,  # –£—Ä–æ–≤–µ–Ω—å —à—É–º–∞
    max_grad_norm=1.0,     # –ö–ª–∏–ø–ø–∏–Ω–≥ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
)

# –û–±—ã—á–Ω—ã–π training loop
for images, labels in train_loader:
    optimizer.zero_grad()
    output = model(images)
    loss = nn.CrossEntropyLoss()(output, labels)
    loss.backward()
    optimizer.step()

# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–æ—Ç—Ä–∞—á–µ–Ω–Ω–æ–≥–æ epsilon
epsilon = privacy_engine.get_epsilon(delta=1e-5)
print(f"(Œµ = {epsilon:.2f}, Œ¥ = 1e-5)-DP")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. –ö–ª–∏–ø–ø–∏–Ω–≥ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤</h2>
    <pre><code>def clip_gradients(gradients, max_norm):
    """
    –ö–ª–∏–ø–ø–∏–Ω–≥ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è DP-SGD
    –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –≤–ª–∏—è–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞
    """
    total_norm = torch.sqrt(sum(
        torch.sum(g ** 2) for g in gradients
    ))
    
    clip_coef = max_norm / (total_norm + 1e-6)
    clip_coef = min(clip_coef, 1.0)
    
    return [g * clip_coef for g in gradients]

# –í training loop
for param in model.parameters():
    if param.grad is not None:
        # –ö–ª–∏–ø–ø–∏–Ω–≥ per-sample
        param.grad = clip_gradients([param.grad], max_norm=1.0)[0]
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —à—É–º–∞
        noise_scale = noise_multiplier * max_norm / batch_size
        param.grad += torch.randn_like(param.grad) * noise_scale</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. –ú–æ–º–µ–Ω—Ç —É—á–µ—Ç–∞ –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏</h2>
    <pre><code>from opacus.accountants import RDPAccountant

def compute_privacy_spent(
    noise_multiplier,
    batch_size,
    dataset_size,
    epochs,
    delta
):
    """
    –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–æ—Ç—Ä–∞—á–µ–Ω–Ω–æ–π –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏
    """
    steps = int(epochs * dataset_size / batch_size)
    sampling_probability = batch_size / dataset_size
    
    accountant = RDPAccountant()
    
    for _ in range(steps):
        accountant.step(
            noise_multiplier=noise_multiplier,
            sample_rate=sampling_probability
        )
    
    epsilon = accountant.get_epsilon(delta=delta)
    return epsilon

# –ü—Ä–∏–º–µ—Ä
epsilon = compute_privacy_spent(
    noise_multiplier=1.1,
    batch_size=256,
    dataset_size=60000,
    epochs=10,
    delta=1e-5
)
print(f"Privacy cost: Œµ = {epsilon:.2f}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. Federated Learning —Å DP</h2>
    <pre><code>class DPFederatedLearning:
    def __init__(self, model, epsilon, delta, max_grad_norm):
        self.model = model
        self.epsilon = epsilon
        self.delta = delta
        self.max_grad_norm = max_grad_norm
        self.noise_multiplier = self._compute_noise_multiplier()
    
    def _compute_noise_multiplier(self):
        # –£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ
        return self.max_grad_norm / self.epsilon
    
    def aggregate_gradients(self, client_gradients):
        """
        –ê–≥—Ä–µ–≥–∞—Ü–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –æ—Ç –∫–ª–∏–µ–Ω—Ç–æ–≤ —Å DP
        """
        clipped_gradients = []
        
        # –ö–ª–∏–ø–ø–∏–Ω–≥ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –æ—Ç –∫–∞–∂–¥–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞
        for grad in client_gradients:
            norm = torch.norm(grad)
            clip_coef = min(1.0, self.max_grad_norm / norm)
            clipped_gradients.append(grad * clip_coef)
        
        # –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ
        avg_gradient = sum(clipped_gradients) / len(clipped_gradients)
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —à—É–º–∞
        noise = torch.randn_like(avg_gradient) * self.noise_multiplier
        dp_gradient = avg_gradient + noise
        
        return dp_gradient
    
    def train_round(self, clients):
        """
        –û–¥–∏–Ω —Ä–∞—É–Ω–¥ federated –æ–±—É—á–µ–Ω–∏—è
        """
        client_gradients = []
        
        for client in clients:
            # –õ–æ–∫–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –∫–ª–∏–µ–Ω—Ç–µ
            gradient = client.compute_gradient(self.model)
            client_gradients.append(gradient)
        
        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è —Å DP
        global_gradient = self.aggregate_gradients(client_gradients)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
        with torch.no_grad():
            for param in self.model.parameters():
                param -= 0.01 * global_gradient</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úì –•–æ—Ä–æ—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏</h3>
        <ul>
          <li>–ù–∞—á–∏–Ω–∞–π—Ç–µ —Å Œµ = 1.0</li>
          <li>–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–æ–º–µ–Ω—Ç —É—á–µ—Ç–∞ (RDP)</li>
          <li>–ö–ª–∏–ø–ø–∏–Ω–≥ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω</li>
          <li>–ë–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö ‚Üí –º–µ–Ω—å—à–µ —à—É–º–∞</li>
          <li>Batch —Ä–∞–∑–º–µ—Ä –≤–ª–∏—è–µ—Ç –Ω–∞ –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚úó –ò–∑–±–µ–≥–∞–π—Ç–µ</h3>
        <ul>
          <li>–°–ª–∏—à–∫–æ–º –º–∞–ª–æ–µ Œµ (–±–µ—Å–ø–æ–ª–µ–∑–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)</li>
          <li>–ó–∞–±—ã–≤–∞—Ç—å –ø—Ä–æ –∫–æ–º–ø–æ–∑–∏—Ü–∏—é</li>
          <li>–ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å</li>
          <li>–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –±–µ–∑ —É—á–µ—Ç–∞</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 12. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è</h2>
    <ul>
      <li><strong>–ü–µ—Ä–µ–ø–∏—Å–∏</strong>: Census 2020 (–°–®–ê) –∏—Å–ø–æ–ª—å–∑—É–µ—Ç DP</li>
      <li><strong>–ú–µ–¥–∏—Ü–∏–Ω–∞</strong>: –∞–Ω–∞–ª–∏–∑ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö</li>
      <li><strong>ML –º–æ–¥–µ–ª–∏</strong>: –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–≤–∞—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö</li>
      <li><strong>–†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã</strong>: –∑–∞—â–∏—Ç–∞ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π</li>
      <li><strong>–ì–µ–æ–ª–æ–∫–∞—Ü–∏—è</strong>: –∞–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ–¥–≤–∏–∂–µ–Ω–∏–π</li>
      <li><strong>–§–∏–Ω–∞–Ω—Å—ã</strong>: –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –±–µ–∑ —Ä–∞—Å–∫—Ä—ã—Ç–∏—è –¥–∞–Ω–Ω—ã—Ö</li>
    </ul>
    
    <blockquote>Apple, Google, Microsoft –∞–∫—Ç–∏–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç DP –¥–ª—è —Å–±–æ—Ä–∞ —Ç–µ–ª–µ–º–µ—Ç—Ä–∏–∏</blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 13. –í—ã–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤</h2>
    <table>
      <tr>
        <th>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</th>
        <th>Œµ</th>
        <th>Œ¥</th>
      </tr>
      <tr>
        <td>–í—ã—Å–æ–∫–∞—è –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å</td>
        <td>0.1 - 1</td>
        <td>10^-6</td>
      </tr>
      <tr>
        <td>–°—Ä–µ–¥–Ω—è—è –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å</td>
        <td>1 - 3</td>
        <td>10^-5</td>
      </tr>
      <tr>
        <td>–†–µ–ª–∞–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è</td>
        <td>3 - 10</td>
        <td>10^-4</td>
      </tr>
    </table>
    
    <p><strong>–ü—Ä–∞–≤–∏–ª–æ –±–æ–ª—å—à–æ–≥–æ –ø–∞–ª—å—Ü–∞:</strong></p>
    <ul>
      <li>Œ¥ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å < 1/n (—Ä–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞)</li>
      <li>–û–±—ã—á–Ω–æ Œ¥ = 10^-5 –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤</li>
      <li>Œµ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 14. –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏</h2>
    <pre><code># Opacus (PyTorch)
from opacus import PrivacyEngine

# TensorFlow Privacy
import tensorflow_privacy

# Diffprivlib (IBM)
from diffprivlib import models

# –ü—Ä–∏–º–µ—Ä —Å diffprivlib
from diffprivlib.models import LogisticRegression

clf = LogisticRegression(epsilon=1.0)
clf.fit(X_train, y_train)
predictions = clf.predict(X_test)</code></pre>
  </div>

</div>

</div>
</body>
</html>
