<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>–û—Ü–µ–Ω–∫–∞ –ø–æ–∑—ã —á–µ–ª–æ–≤–µ–∫–∞ (Pose Estimation) Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen { body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif; color: #333; background: #fafcff; padding: 10px; } }
    @media print { body { background: white; padding: 0; } @page { size: A4 landscape; margin: 10mm; } }
    .container { column-count: 3; column-gap: 20px; max-width: 100%; }
    .block { break-inside: avoid; margin-bottom: 1.2em; padding: 12px; background: white; border-radius: 6px; box-shadow: 0 1px 3px rgba(0,0,0,0.05); }
    h1 { font-size: 1.6em; font-weight: 700; color: #1a5fb4; text-align: center; margin: 0 0 8px; column-span: all; }
    .subtitle { text-align: center; color: #666; font-size: 0.9em; margin-bottom: 12px; column-span: all; }
    h2 { font-size: 1.15em; font-weight: 700; color: #1a5fb4; margin: 0 0 8px; padding-bottom: 4px; border-bottom: 1px solid #e0e7ff; }
    p, ul, ol { font-size: 0.92em; margin: 0.6em 0; }
    ul, ol { padding-left: 18px; }
    li { margin-bottom: 4px; }
    code { font-family: 'Consolas', 'Courier New', monospace; background-color: #f0f4ff; padding: 1px 4px; border-radius: 3px; font-size: 0.88em; }
    pre { background-color: #f0f4ff; padding: 8px; border-radius: 4px; overflow-x: auto; font-size: 0.84em; margin: 6px 0; }
    pre code { padding: 0; background: none; white-space: pre-wrap; }
    table { width: 100%; border-collapse: collapse; font-size: 0.82em; margin: 6px 0; }
    th { background-color: #e6f0ff; text-align: left; padding: 4px 6px; font-weight: 600; }
    td { padding: 4px 6px; border-bottom: 1px solid #f0f4ff; }
    tr:nth-child(even) { background-color: #f8fbff; }
    blockquote { font-style: italic; margin: 8px 0; padding: 6px 10px; background: #f8fbff; border-left: 2px solid #1a5fb4; font-size: 0.88em; }
  </style>
</head>
<body>
<div class="container">
  <h1>ü§∏ –û—Ü–µ–Ω–∫–∞ –ø–æ–∑—ã —á–µ–ª–æ–≤–µ–∫–∞ (Pose Estimation)</h1>
  <div class="subtitle">–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ñ–æ–∫—É—Å ‚Ä¢ –Ø–Ω–≤–∞—Ä—å 2026</div>
  
  <div class="block">
    <h2>üî∑ 1. –°—É—Ç—å –∑–∞–¥–∞—á–∏</h2>
    <ul>
      <li><strong>–¶–µ–ª—å</strong>: –Ω–∞–π—Ç–∏ –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏ —Ç–µ–ª–∞ —á–µ–ª–æ–≤–µ–∫–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏</li>
      <li><strong>Keypoints</strong>: –Ω–æ—Å, –≥–ª–∞–∑–∞, –ø–ª–µ—á–∏, –ª–æ–∫—Ç–∏, –∑–∞–ø—è—Å—Ç—å—è, –±–µ–¥—Ä–∞, –∫–æ–ª–µ–Ω–∏, –ª–æ–¥—ã–∂–∫–∏</li>
      <li><strong>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</strong>: —Å–ø–æ—Ä—Ç, AR, –º–µ–¥–∏—Ü–∏–Ω–∞, –∞–Ω–∏–º–∞—Ü–∏—è</li>
      <li><strong>2D vs 3D</strong>: 2D ‚Äî –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏, 3D ‚Äî –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 2. OpenPose</h2>
    <pre><code># OpenPose ‚Äî –ø–æ–ø—É–ª—è—Ä–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞
# –¢—Ä–µ–±—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–∏

import cv2
import numpy as np

# Load model
net = cv2.dnn.readNetFromCaffe('pose_deploy.prototxt',
                               'pose_iter.caffemodel')

# Read image
img = cv2.imread('person.jpg')
H, W = img.shape[:2]

# Prepare input
blob = cv2.dnn.blobFromImage(img, 1.0/255, (368, 368),
                             (0, 0, 0), swapRB=False, crop=False)

net.setInput(blob)
output = net.forward()

# Extract keypoints
keypoints = []
for i in range(18):  # 18 body parts
    prob_map = output[0, i, :, :]
    min_val, conf, min_loc, point = cv2.minMaxLoc(prob_map)
    
    x = int((W * point[0]) / output.shape[3])
    y = int((H * point[1]) / output.shape[2])
    
    keypoints.append((x, y) if conf > 0.1 else None)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 3. MediaPipe Pose</h2>
    <pre><code>import mediapipe as mp
import cv2

mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

pose = mp_pose.Pose(
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)

# Process video or webcam
cap = cv2.VideoCapture('video.mp4')

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    
    # Convert to RGB
    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = pose.process(image)
    
    # Draw landmarks
    if results.pose_landmarks:
        mp_drawing.draw_landmarks(
            frame,
            results.pose_landmarks,
            mp_pose.POSE_CONNECTIONS
        )
    
    cv2.imshow('Pose', frame)
    if cv2.waitKey(5) & 0xFF == 27:
        break

cap.release()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. Keypoints —Å—Ç—Ä—É–∫—Ç—É—Ä–∞</h2>
    <table>
      <tr><th>ID</th><th>–¢–æ—á–∫–∞</th><th>ID</th><th>–¢–æ—á–∫–∞</th></tr>
      <tr><td>0</td><td>–ù–æ—Å</td><td>9</td><td>–ü—Ä–∞–≤–æ–µ –±–µ–¥—Ä–æ</td></tr>
      <tr><td>1</td><td>–®–µ—è</td><td>10</td><td>–ü—Ä–∞–≤–æ–µ –∫–æ–ª–µ–Ω–æ</td></tr>
      <tr><td>2</td><td>–ü—Ä–∞–≤–æ–µ –ø–ª–µ—á–æ</td><td>11</td><td>–ü—Ä–∞–≤–∞—è –ª–æ–¥—ã–∂–∫–∞</td></tr>
      <tr><td>3</td><td>–ü—Ä–∞–≤—ã–π –ª–æ–∫–æ—Ç—å</td><td>12</td><td>–õ–µ–≤–æ–µ –±–µ–¥—Ä–æ</td></tr>
      <tr><td>4</td><td>–ü—Ä–∞–≤–æ–µ –∑–∞–ø—è—Å—Ç—å–µ</td><td>13</td><td>–õ–µ–≤–æ–µ –∫–æ–ª–µ–Ω–æ</td></tr>
      <tr><td>5</td><td>–õ–µ–≤–æ–µ –ø–ª–µ—á–æ</td><td>14</td><td>–õ–µ–≤–∞—è –ª–æ–¥—ã–∂–∫–∞</td></tr>
      <tr><td>6</td><td>–õ–µ–≤—ã–π –ª–æ–∫–æ—Ç—å</td><td>15</td><td>–ü—Ä–∞–≤—ã–π –≥–ª–∞–∑</td></tr>
      <tr><td>7</td><td>–õ–µ–≤–æ–µ –∑–∞–ø—è—Å—Ç—å–µ</td><td>16</td><td>–õ–µ–≤—ã–π –≥–ª–∞–∑</td></tr>
      <tr><td>8</td><td>–ü—Ä–∞–≤—ã–π –≥–ª–∞–∑</td><td>17</td><td>–ü—Ä–∞–≤–æ–µ —É—Ö–æ</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 5. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —É–≥–ª–æ–≤</h2>
    <pre><code>import numpy as np

def calculate_angle(a, b, c):
    """
    –í—ã—á–∏—Å–ª–∏—Ç—å —É–≥–æ–ª –º–µ–∂–¥—É —Ç—Ä–µ–º—è —Ç–æ—á–∫–∞–º–∏
    b - –≤–µ—Ä—à–∏–Ω–∞ —É–≥–ª–∞
    """
    a = np.array(a)  # First point
    b = np.array(b)  # Mid point
    c = np.array(c)  # End point
    
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)
    
    if angle > 180.0:
        angle = 360-angle
    
    return angle

# –ü—Ä–∏–º–µ—Ä: —É–≥–æ–ª –≤ –ª–æ–∫—Ç–µ
shoulder = keypoints[2]
elbow = keypoints[3]
wrist = keypoints[4]

elbow_angle = calculate_angle(shoulder, elbow, wrist)
print(f"Elbow angle: {elbow_angle:.1f}¬∞")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. Multi-person Pose</h2>
    <pre><code># OpenPose –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç multi-person –∏–∑ –∫–æ—Ä–æ–±–∫–∏
# MediaPipe —Ç—Ä–µ–±—É–µ—Ç detection + tracking

import mediapipe as mp

# Multi-person approach: detect each person first
mp_pose = mp.solutions.pose
mp_detection = mp.solutions.person_detection

detector = mp_detection.PersonDetection()
pose = mp_pose.Pose()

# Detect persons
detections = detector.process(image)

for detection in detections.detections:
    # Crop person
    bbox = detection.location_data.relative_bounding_box
    x, y, w, h = bbox.xmin, bbox.ymin, bbox.width, bbox.height
    
    person_img = image[int(y*H):int((y+h)*H),
                       int(x*W):int((x+w)*W)]
    
    # Estimate pose
    results = pose.process(person_img)
    # Draw landmarks...</code></pre>
  </div>

  <div class="block">
    <h2>ÔøΩÔøΩ 7. 3D Pose Estimation</h2>
    <pre><code># MediaPipe –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç 3D landmarks
pose_3d = mp_pose.Pose(model_complexity=2)

results = pose_3d.process(image)

if results.pose_world_landmarks:
    # 3D coordinates –≤ –º–µ—Ç—Ä–∞—Ö
    for landmark in results.pose_world_landmarks.landmark:
        print(f"x: {landmark.x:.3f}, "
              f"y: {landmark.y:.3f}, "
              f"z: {landmark.z:.3f}")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤ 3D
from mpl_toolkits.mplot3d import Axes3D

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')

xs = [lm.x for lm in results.pose_world_landmarks.landmark]
ys = [lm.y for lm in results.pose_world_landmarks.landmark]
zs = [lm.z for lm in results.pose_world_landmarks.landmark]

ax.scatter(xs, ys, zs)
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è</h2>
    <ul>
      <li><strong>Fitness tracking</strong>: –ø–æ–¥—Å—á–µ—Ç –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π, –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º—ã</li>
      <li><strong>–°–ø–æ—Ä—Ç–∏–≤–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞</strong>: –∞–Ω–∞–ª–∏–∑ —Ç–µ—Ö–Ω–∏–∫–∏</li>
      <li><strong>AR —Ñ–∏–ª—å—Ç—Ä—ã</strong>: –Ω–∞–ª–æ–∂–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ —Ç–µ–ª–æ</li>
      <li><strong>–ê–Ω–∏–º–∞—Ü–∏—è</strong>: motion capture –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π</li>
      <li><strong>–ú–µ–¥–∏—Ü–∏–Ω–∞</strong>: —Ä–µ–∞–±–∏–ª–∏—Ç–∞—Ü–∏—è, –∞–Ω–∞–ª–∏–∑ –ø–æ—Ö–æ–¥–∫–∏</li>
      <li><strong>–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å</strong>: –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–∞–¥–µ–Ω–∏–π</li>
    </ul>
    <pre><code># –ü—Ä–∏–º–µ—Ä: —Å—á–µ—Ç—á–∏–∫ –ø—Ä–∏—Å–µ–¥–∞–Ω–∏–π
squat_count = 0
stage = None

while True:
    # Get landmarks
    hip_angle = calculate_angle(shoulder, hip, knee)
    
    if hip_angle > 160:
        stage = "up"
    if hip_angle < 90 and stage == "up":
        stage = "down"
        squat_count += 1
        print(f"Squats: {squat_count}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. Optimization</h2>
    <pre><code># –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è real-time
pose = mp_pose.Pose(
    static_image_mode=False,  # Video mode
    model_complexity=0,  # 0=Lite, 1=Full, 2=Heavy
    smooth_landmarks=True,  # Temporal smoothing
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)

# Resize –¥–ª—è speed
import cv2
target_width = 640
scale = target_width / frame.shape[1]
frame_resized = cv2.resize(frame, None, fx=scale, fy=scale)

# Process –º–µ–Ω—å—à–∏–π frame
results = pose.process(frame_resized)

# Scale landmarks –æ–±—Ä–∞—Ç–Ω–æ
if results.pose_landmarks:
    for landmark in results.pose_landmarks.landmark:
        landmark.x /= scale
        landmark.y /= scale</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É (MediaPipe, OpenPose)</li>
      <li>[ ] –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω—É–∂–Ω—ã–µ keypoints</li>
      <li>[ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å confidence thresholds</li>
      <li>[ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å angle calculation</li>
      <li>[ ] –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è real-time</li>
      <li>[ ] –û–±—Ä–∞–±–æ—Ç–∞—Ç—å missing keypoints</li>
      <li>[ ] –î–æ–±–∞–≤–∏—Ç—å temporal smoothing</li>
      <li>[ ] –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å skeleton</li>
      <li>[ ] –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –ø–æ–∑–∞—Ö</li>
      <li>[ ] –û–±—Ä–∞–±–æ—Ç–∞—Ç—å multi-person —Å–ª—É—á–∞–∏</li>
    </ul>
    <blockquote>
      ¬´Pose estimation ‚Äî —ç—Ç–æ –∫–∞–∫ –Ω–∞–π—Ç–∏ "—Å–∫–µ–ª–µ—Ç" —á–µ–ª–æ–≤–µ–∫–∞ –Ω–∞ —Ñ–æ—Ç–æ. –ú—ã –æ–ø—Ä–µ–¥–µ–ª—è–µ–º, –≥–¥–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è —Å—É—Å—Ç–∞–≤—ã, –∏ –º–æ–∂–µ–º –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–≤–∏–∂–µ–Ω–∏—è, –ø–æ–∑—ã, –¥–∞–∂–µ —ç–º–æ—Ü–∏–∏ –ø–æ —è–∑—ã–∫—É —Ç–µ–ª–∞¬ª.
    </blockquote>
  </div>


</div>
</body>
</html>
