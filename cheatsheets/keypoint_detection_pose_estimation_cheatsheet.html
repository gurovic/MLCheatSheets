<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Keypoint Detection –∏ Pose Estimation ‚Äî Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      
        min-width: 900px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

        .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      font-size: 0.9em;
      color: #666;
      text-align: center;
      margin-bottom: 20px;
      column-span: all;
    }

    h2 {
      font-size: 1.1em;
      font-weight: 700;
      margin-top: 0;
      color: #1a5fb4;
      border-bottom: 2px solid #e0e8f5;
      padding-bottom: 4px;
    }

    h3 {
      font-size: 0.95em;
      font-weight: 600;
      margin: 8px 0 4px;
      color: #26a269;
    }

    p, ul, ol {
      margin: 6px 0;
      font-size: 0.88em;
      line-height: 1.5;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 3px;
    }

    code {
      background: #f6f8fa;
      padding: 1px 4px;
      border-radius: 3px;
      font-family: 'Consolas', 'Monaco', monospace;
      font-size: 0.9em;
      color: #c7254e;
    }

    pre {
      background: #282c34;
      color: #abb2bf;
      padding: 10px;
      border-radius: 6px;
      overflow-x: auto;
      font-size: 0.8em;
      line-height: 1.4;
      margin: 8px 0;
    }

    pre code {
      background: transparent;
      color: inherit;
      padding: 0;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      margin: 8px 0;
      font-size: 0.85em;
    }

    th, td {
      border: 1px solid #ddd;
      padding: 6px 8px;
      text-align: left;
    }

    th {
      background: #e0e8f5;
      font-weight: 600;
      color: #1a5fb4;
    }

    tr:nth-child(even) {
      background: #f9fbff;
    }

    blockquote {
      background: #fff9e6;
      border-left: 4px solid #f6d32d;
      padding: 8px 12px;
      margin: 8px 0;
      font-size: 0.88em;
      font-style: italic;
    }

    .formula {
      background: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      margin: 8px 0;
      font-family: 'Cambria', 'Times New Roman', serif;
      font-size: 0.9em;
      text-align: center;
    }
  </style>
</head>
<body>

<h1>üéØ Keypoint Detection –∏ Pose Estimation</h1>
<div class="subtitle"></div>

<div class="container">

  <div class="block">
    <h2>üî∑ 1. –û—Å–Ω–æ–≤—ã Keypoint Detection</h2>
    <p>–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã—Ö —Ç–æ—á–µ–∫ –Ω–∞ –æ–±—ä–µ–∫—Ç–∞—Ö: —Å—É—Å—Ç–∞–≤—ã —á–µ–ª–æ–≤–µ–∫–∞, —É–≥–ª—ã –∑–¥–∞–Ω–∏–π, —á–µ—Ä—Ç—ã –ª–∏—Ü–∞.</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># –î–µ—Ç–µ–∫—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
import torch
from torchvision.models.detection import keypointrcnn_resnet50_fpn
import numpy as np

model = keypointrcnn_resnet50_fpn(weights="DEFAULT")
model.eval()

image = torch.rand(3, 224, 224)
with torch.no_grad():
    outputs = model([image])

pred_keypoints = outputs[0]["keypoints"][0, :, :2].cpu().numpy()
gt_keypoints = pred_keypoints + np.random.normal(scale=2.0, size=pred_keypoints.shape)

def pck(pred, gt, thr=0.05, img_size=224):
    dists = np.linalg.norm(pred - gt, axis=1)
    correct = dists < thr * img_size
    return correct.sum() / len(pred)

score = pck(pred_keypoints, gt_keypoints)
print(f"PCK: {score:.3f}")</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã—Ö —Ç–æ—á–µ–∫ –Ω–∞ –æ–±—ä–µ–∫—Ç–∞—Ö: —Å—É—Å—Ç–∞–≤—ã —á–µ–ª–æ–≤–µ–∫–∞, —É–≥–ª—ã –∑–¥–∞–Ω–∏–π, —á–µ—Ä—Ç—ã –ª–∏—Ü–∞....
    </blockquote>
  <div class="block">
    <h2>üî∑ 2. Pose Estimation Overview</h2>
    <p>–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–∑—ã —á–µ–ª–æ–≤–µ–∫–∞ –ø–æ 2D/3D –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ (—Å–∫–µ–ª–µ—Ç).</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># –î–µ—Ç–µ–∫—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
import torch
from torchvision.models.detection import keypointrcnn_resnet50_fpn
import numpy as np

model = keypointrcnn_resnet50_fpn(weights="DEFAULT")
model.eval()

image = torch.rand(3, 224, 224)
with torch.no_grad():
    outputs = model([image])

pred_keypoints = outputs[0]["keypoints"][0, :, :2].cpu().numpy()
gt_keypoints = pred_keypoints + np.random.normal(scale=2.0, size=pred_keypoints.shape)

def pck(pred, gt, thr=0.05, img_size=224):
    dists = np.linalg.norm(pred - gt, axis=1)
    correct = dists < thr * img_size
    return correct.sum() / len(pred)

score = pck(pred_keypoints, gt_keypoints)
print(f"PCK: {score:.3f}")</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–∑—ã —á–µ–ª–æ–≤–µ–∫–∞ –ø–æ 2d/3d –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ (—Å–∫–µ–ª–µ—Ç)....
    </blockquote>
  </div>
  <div class="block">
    <h2>üî∑ 3. Top-down vs Bottom-up</h2>
    <p>Top-down: —Å–Ω–∞—á–∞–ª–∞ –¥–µ—Ç–µ–∫—Ü–∏—è –ª—é–¥–µ–π, –∑–∞—Ç–µ–º keypoints. Bottom-up: –≤—Å–µ keypoints, –∑–∞—Ç–µ–º –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞.</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># –î–µ—Ç–µ–∫—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
import torch
from torchvision.models.detection import keypointrcnn_resnet50_fpn
import numpy as np

model = keypointrcnn_resnet50_fpn(weights="DEFAULT")
model.eval()

image = torch.rand(3, 224, 224)
with torch.no_grad():
    outputs = model([image])

pred_keypoints = outputs[0]["keypoints"][0, :, :2].cpu().numpy()
gt_keypoints = pred_keypoints + np.random.normal(scale=2.0, size=pred_keypoints.shape)

def pck(pred, gt, thr=0.05, img_size=224):
    dists = np.linalg.norm(pred - gt, axis=1)
    correct = dists < thr * img_size
    return correct.sum() / len(pred)

score = pck(pred_keypoints, gt_keypoints)
print(f"PCK: {score:.3f}")</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ top-down: —Å–Ω–∞—á–∞–ª–∞ –¥–µ—Ç–µ–∫—Ü–∏—è –ª—é–¥–µ–π, –∑–∞—Ç–µ–º keypoints. bottom-up: –≤—Å–µ keypoints, –∑–∞—Ç–µ–º –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞....
    </blockquote>
  </div>
  <div class="block">
    <h2>üî∑ 4. OpenPose Architecture</h2>
    <p>Bottom-up –ø–æ–¥—Ö–æ–¥ —Å Part Affinity Fields (PAFs) –¥–ª—è —Å–≤—è–∑—ã–≤–∞–Ω–∏—è keypoints.</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># –î–µ—Ç–µ–∫—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
import torch
from torchvision.models.detection import keypointrcnn_resnet50_fpn
import numpy as np

model = keypointrcnn_resnet50_fpn(weights="DEFAULT")
model.eval()

image = torch.rand(3, 224, 224)
with torch.no_grad():
    outputs = model([image])

pred_keypoints = outputs[0]["keypoints"][0, :, :2].cpu().numpy()
gt_keypoints = pred_keypoints + np.random.normal(scale=2.0, size=pred_keypoints.shape)

def pck(pred, gt, thr=0.05, img_size=224):
    dists = np.linalg.norm(pred - gt, axis=1)
    correct = dists < thr * img_size
    return correct.sum() / len(pred)

score = pck(pred_keypoints, gt_keypoints)
print(f"PCK: {score:.3f}")</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ bottom-up –ø–æ–¥—Ö–æ–¥ —Å part affinity fields (pafs) –¥–ª—è —Å–≤—è–∑—ã–≤–∞–Ω–∏—è keypoints....
    </blockquote>
  </div>
  <div class="block">
    <h2>üî∑ 5. HRNet (High-Resolution Net)</h2>
    <p>–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—ã—Å–æ–∫–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –≤—Å–µ —Å–ª–æ–∏, –ª—É—á—à–µ –¥–ª—è –º–µ–ª–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π.</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># –î–µ—Ç–µ–∫—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
import torch
from torchvision.models.detection import keypointrcnn_resnet50_fpn
import numpy as np

model = keypointrcnn_resnet50_fpn(weights="DEFAULT")
model.eval()

image = torch.rand(3, 224, 224)
with torch.no_grad():
    outputs = model([image])

pred_keypoints = outputs[0]["keypoints"][0, :, :2].cpu().numpy()
gt_keypoints = pred_keypoints + np.random.normal(scale=2.0, size=pred_keypoints.shape)

def pck(pred, gt, thr=0.05, img_size=224):
    dists = np.linalg.norm(pred - gt, axis=1)
    correct = dists < thr * img_size
    return correct.sum() / len(pred)

score = pck(pred_keypoints, gt_keypoints)
print(f"PCK: {score:.3f}")</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—ã—Å–æ–∫–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –≤—Å–µ —Å–ª–æ–∏, –ª—É—á—à–µ –¥–ª—è –º–µ–ª–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π....
    </blockquote>
  </div>
  <div class="block">
    <h2>üî∑ 6. MediaPipe Pose</h2>
    <p>–õ–µ–≥–∫–æ–≤–µ—Å–Ω–æ–µ real-time —Ä–µ—à–µ–Ω–∏–µ –æ—Ç Google –¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤.</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># –î–µ—Ç–µ–∫—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
import torch
from torchvision.models.detection import keypointrcnn_resnet50_fpn
import numpy as np

model = keypointrcnn_resnet50_fpn(weights="DEFAULT")
model.eval()

image = torch.rand(3, 224, 224)
with torch.no_grad():
    outputs = model([image])

pred_keypoints = outputs[0]["keypoints"][0, :, :2].cpu().numpy()
gt_keypoints = pred_keypoints + np.random.normal(scale=2.0, size=pred_keypoints.shape)

def pck(pred, gt, thr=0.05, img_size=224):
    dists = np.linalg.norm(pred - gt, axis=1)
    correct = dists < thr * img_size
    return correct.sum() / len(pred)

score = pck(pred_keypoints, gt_keypoints)
print(f"PCK: {score:.3f}")</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –ª–µ–≥–∫–æ–≤–µ—Å–Ω–æ–µ real-time —Ä–µ—à–µ–Ω–∏–µ –æ—Ç google –¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤....
    </blockquote>
  </div>
  <div class="block">
    <h2>üî∑ 7. Dataset Annotations</h2>
    <p>COCO Keypoints (17 —Ç–æ—á–µ–∫), MPII Human Pose (16 —Ç–æ—á–µ–∫), —Ñ–æ—Ä–º–∞—Ç—ã –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π.</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># –î–µ—Ç–µ–∫—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
import torch
from torchvision.models.detection import keypointrcnn_resnet50_fpn
import numpy as np

model = keypointrcnn_resnet50_fpn(weights="DEFAULT")
model.eval()

image = torch.rand(3, 224, 224)
with torch.no_grad():
    outputs = model([image])

pred_keypoints = outputs[0]["keypoints"][0, :, :2].cpu().numpy()
gt_keypoints = pred_keypoints + np.random.normal(scale=2.0, size=pred_keypoints.shape)

def pck(pred, gt, thr=0.05, img_size=224):
    dists = np.linalg.norm(pred - gt, axis=1)
    correct = dists < thr * img_size
    return correct.sum() / len(pred)

score = pck(pred_keypoints, gt_keypoints)
print(f"PCK: {score:.3f}")</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ coco keypoints (17 —Ç–æ—á–µ–∫), mpii human pose (16 —Ç–æ—á–µ–∫), —Ñ–æ—Ä–º–∞—Ç—ã –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π....
    </blockquote>
  </div>
  <div class="block">
    <h2>üî∑ 8. Loss Functions</h2>
    <p>MSE –¥–ª—è heatmaps, OKS (Object Keypoint Similarity) metric.</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># –î–µ—Ç–µ–∫—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
import torch
from torchvision.models.detection import keypointrcnn_resnet50_fpn
import numpy as np

model = keypointrcnn_resnet50_fpn(weights="DEFAULT")
model.eval()

image = torch.rand(3, 224, 224)
with torch.no_grad():
    outputs = model([image])

pred_keypoints = outputs[0]["keypoints"][0, :, :2].cpu().numpy()
gt_keypoints = pred_keypoints + np.random.normal(scale=2.0, size=pred_keypoints.shape)

def pck(pred, gt, thr=0.05, img_size=224):
    dists = np.linalg.norm(pred - gt, axis=1)
    correct = dists < thr * img_size
    return correct.sum() / len(pred)

score = pck(pred_keypoints, gt_keypoints)
print(f"PCK: {score:.3f}")</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ mse –¥–ª—è heatmaps, oks (object keypoint similarity) metric....
    </blockquote>
  </div>
  <div class="block">
    <h2>üî∑ 9. 3D Pose Estimation</h2>
    <p>–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ 3D –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –∏–∑ 2D –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, depth estimation.</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># –î–µ—Ç–µ–∫—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
import torch
from torchvision.models.detection import keypointrcnn_resnet50_fpn
import numpy as np

model = keypointrcnn_resnet50_fpn(weights="DEFAULT")
model.eval()

image = torch.rand(3, 224, 224)
with torch.no_grad():
    outputs = model([image])

pred_keypoints = outputs[0]["keypoints"][0, :, :2].cpu().numpy()
gt_keypoints = pred_keypoints + np.random.normal(scale=2.0, size=pred_keypoints.shape)

def pck(pred, gt, thr=0.05, img_size=224):
    dists = np.linalg.norm(pred - gt, axis=1)
    correct = dists < thr * img_size
    return correct.sum() / len(pred)

score = pck(pred_keypoints, gt_keypoints)
print(f"PCK: {score:.3f}")</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ 3d –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –∏–∑ 2d –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, depth estimation....
    </blockquote>
  </div>
  <div class="block">
    <h2>üî∑ 10. Multi-person Pose</h2>
    <p>–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ü–µ–Ω —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ª—é–¥—å–º–∏, non-maximum suppression.</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># –î–µ—Ç–µ–∫—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
import torch
from torchvision.models.detection import keypointrcnn_resnet50_fpn
import numpy as np

model = keypointrcnn_resnet50_fpn(weights="DEFAULT")
model.eval()

image = torch.rand(3, 224, 224)
with torch.no_grad():
    outputs = model([image])

pred_keypoints = outputs[0]["keypoints"][0, :, :2].cpu().numpy()
gt_keypoints = pred_keypoints + np.random.normal(scale=2.0, size=pred_keypoints.shape)

def pck(pred, gt, thr=0.05, img_size=224):
    dists = np.linalg.norm(pred - gt, axis=1)
    correct = dists < thr * img_size
    return correct.sum() / len(pred)

score = pck(pred_keypoints, gt_keypoints)
print(f"PCK: {score:.3f}")</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ü–µ–Ω —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ª—é–¥—å–º–∏, non-maximum suppression....
    </blockquote>
  </div>
  <div class="block">
    <h2>üî∑ 11. Real-time Applications</h2>
    <p>–°–ø–æ—Ä—Ç –∞–Ω–∞–ª–∏—Ç–∏–∫–∞, AR/VR, —Ñ–∏—Ç–Ω–µ—Å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –∂–µ—Å—Ç–æ–≤–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ.</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># –î–µ—Ç–µ–∫—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
import torch
from torchvision.models.detection import keypointrcnn_resnet50_fpn
import numpy as np

model = keypointrcnn_resnet50_fpn(weights="DEFAULT")
model.eval()

image = torch.rand(3, 224, 224)
with torch.no_grad():
    outputs = model([image])

pred_keypoints = outputs[0]["keypoints"][0, :, :2].cpu().numpy()
gt_keypoints = pred_keypoints + np.random.normal(scale=2.0, size=pred_keypoints.shape)

def pck(pred, gt, thr=0.05, img_size=224):
    dists = np.linalg.norm(pred - gt, axis=1)
    correct = dists < thr * img_size
    return correct.sum() / len(pred)

score = pck(pred_keypoints, gt_keypoints)
print(f"PCK: {score:.3f}")</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ —Å–ø–æ—Ä—Ç –∞–Ω–∞–ª–∏—Ç–∏–∫–∞, ar/vr, —Ñ–∏—Ç–Ω–µ—Å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –∂–µ—Å—Ç–æ–≤–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ....
    </blockquote>
  </div>
  <div class="block">
    <h2>üî∑ 12. Implementation Tips</h2>
    <p>Data augmentation –¥–ª—è robustness, post-processing heatmaps, temporal smoothing –¥–ª—è –≤–∏–¥–µ–æ.</p>
    <h3>–î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:</h3>
    <ul>
      <li>–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏ —Ñ–æ—Ä–º—É–ª—ã</li>
      <li>–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è</li>
      <li>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç</li>
      <li>–¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è</li>
      <li>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏</li>
    </ul>
    <pre><code># –î–µ—Ç–µ–∫—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
import torch
from torchvision.models.detection import keypointrcnn_resnet50_fpn
import numpy as np

model = keypointrcnn_resnet50_fpn(weights="DEFAULT")
model.eval()

image = torch.rand(3, 224, 224)
with torch.no_grad():
    outputs = model([image])

pred_keypoints = outputs[0]["keypoints"][0, :, :2].cpu().numpy()
gt_keypoints = pred_keypoints + np.random.normal(scale=2.0, size=pred_keypoints.shape)

def pck(pred, gt, thr=0.05, img_size=224):
    dists = np.linalg.norm(pred - gt, axis=1)
    correct = dists < thr * img_size
    return correct.sum() / len(pred)

score = pck(pred_keypoints, gt_keypoints)
print(f"PCK: {score:.3f}")</code></pre>
    <h3>üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</h3>
    <blockquote>
      –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ data augmentation –¥–ª—è robustness, post-processing heatmaps, temporal smoothing –¥–ª—è –≤–∏–¥–µ–æ....
    </blockquote>
  </div>
</div>

</div>
</body>
</html>