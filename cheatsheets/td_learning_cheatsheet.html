<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>–í—Ä–µ–º–µ–Ω–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ (TD-learning) Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

        .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>‚è±Ô∏è –í—Ä–µ–º–µ–Ω–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ (TD-learning)</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –°—É—Ç—å TD-learning</h2>
    <ul>
      <li><strong>TD</strong>: Temporal Difference ‚Äî —Ä–∞–∑–Ω–∏—Ü–∞ –≤–æ –≤—Ä–µ–º–µ–Ω–∏</li>
      <li><strong>–ö–æ–º–±–∏–Ω–∞—Ü–∏—è</strong>: MC + Dynamic Programming</li>
      <li><strong>Bootstrapping</strong>: –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ü–µ–Ω–æ–∫</li>
      <li><strong>Online</strong>: –æ–±—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞</li>
    </ul>
    <p><strong>–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:</strong></p>
    <ul>
      <li>–ù–µ –Ω—É–∂–Ω–æ –∂–¥–∞—Ç—å –∫–æ–Ω—Ü–∞ —ç–ø–∏–∑–æ–¥–∞</li>
      <li>–†–∞–±–æ—Ç–∞–µ—Ç –≤ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö</li>
      <li>–ú–µ–Ω—å—à–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è —á–µ–º MC</li>
    </ul>

  <div class="block">
    <h2>üî∑ 2. TD(0) ‚Äî –æ—Å–Ω–æ–≤–∞</h2>
    <p><strong>–§–æ—Ä–º—É–ª–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è:</strong></p>
    <pre><code>V(s_t) ‚Üê V(s_t) + Œ±[R_{t+1} + Œ≥V(s_{t+1}) - V(s_t)]

–≥–¥–µ:
Œ± - learning rate
Œ≥ - discount factor
TD error = R_{t+1} + Œ≥V(s_{t+1}) - V(s_t)</code></pre>

    <p><strong>–ê–ª–≥–æ—Ä–∏—Ç–º:</strong></p>
    <pre><code>def td0_learning(env, episodes=1000, alpha=0.1, gamma=0.9):
    V = defaultdict(float)
    
    for episode in range(episodes):
        state = env.reset()
        
        while True:
            action = policy(state)
            next_state, reward, done = env.step(action)
            
            # TD(0) update
            td_error = reward + gamma * V[next_state] - V[state]
            V[state] += alpha * td_error
            
            if done:
                break
            state = next_state
    
    return V</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 3. MC vs TD —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ</h2>
    <table>
      <tr><th>–ö—Ä–∏—Ç–µ—Ä–∏–π</th><th>Monte Carlo</th><th>TD-learning</th></tr>
      <tr><td><strong>–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ</strong></td><td>–ö–æ–Ω–µ—Ü —ç–ø–∏–∑–æ–¥–∞</td><td>–ö–∞–∂–¥—ã–π —à–∞–≥</td></tr>
      <tr><td><strong>Bias</strong></td><td>–ù–µ—Ç</td><td>–ï—Å—Ç—å</td></tr>
      <tr><td><strong>Variance</strong></td><td>–í—ã—Å–æ–∫–∞—è</td><td>–ù–∏–∑–∫–∞—è</td></tr>
      <tr><td><strong>–°—Ö–æ–¥–∏–º–æ—Å—Ç—å</strong></td><td>–ú–µ–¥–ª–µ–Ω–Ω–∞—è</td><td>–ë—ã—Å—Ç—Ä–∞—è</td></tr>
      <tr><td><strong>Episodic</strong></td><td>–¢—Ä–µ–±—É–µ—Ç—Å—è</td><td>–ù–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 4. TD(Œª) ‚Äî –æ–±–æ–±—â–µ–Ω–∏–µ</h2>
    <p><strong>Eligibility Traces:</strong></p>
    <pre><code>e(s) ‚Üê Œ≥Œªe(s) + 1  # –µ—Å–ª–∏ s –ø–æ—Å–µ—â–µ–Ω–æ
e(s) ‚Üê Œ≥Œªe(s)      # –∏–Ω–∞—á–µ

V(s) ‚Üê V(s) + Œ± * Œ¥_t * e(s)

–≥–¥–µ:
Œª ‚àà [0,1] - trace decay parameter
Œ¥_t - TD error
e(s) - eligibility trace</code></pre>

    <p><strong>–†–µ–∞–ª–∏–∑–∞—Ü–∏—è:</strong></p>
    <pre><code>def td_lambda(env, episodes, alpha=0.1, gamma=0.9, lambda_=0.9):
    V = defaultdict(float)
    
    for episode in range(episodes):
        e = defaultdict(float)  # eligibility traces
        state = env.reset()
        
        while True:
            action = policy(state)
            next_state, reward, done = env.step(action)
            
            delta = reward + gamma * V[next_state] - V[state]
            e[state] += 1
            
            # Update all states
            for s in e.keys():
                V[s] += alpha * delta * e[s]
                e[s] *= gamma * lambda_
            
            if done:
                break
            state = next_state
    
    return V</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. n-step TD</h2>
    <p><strong>n-step return:</strong></p>
    <pre><code>G_t^(n) = R_{t+1} + Œ≥R_{t+2} + ... + Œ≥^{n-1}R_{t+n} + Œ≥^n V(s_{t+n})

V(s_t) ‚Üê V(s_t) + Œ±[G_t^(n) - V(s_t)]</code></pre>

    <p><strong>–†–µ–∞–ª–∏–∑–∞—Ü–∏—è:</strong></p>
    <pre><code>def n_step_td(env, n=3, alpha=0.1, gamma=0.9):
    V = defaultdict(float)
    
    for episode in range(episodes):
        states = []
        rewards = []
        state = env.reset()
        
        while True:
            states.append(state)
            action = policy(state)
            next_state, reward, done = env.step(action)
            rewards.append(reward)
            
            # Update after n steps
            if len(states) >= n:
                G = sum([gamma**i * rewards[i] 
                        for i in range(n)])
                G += gamma**n * V[next_state]
                
                s_update = states[0]
                V[s_update] += alpha * (G - V[s_update])
                
                states.pop(0)
                rewards.pop(0)
            
            if done:
                break
            state = next_state
    
    return V</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. TD Error –∏–Ω—Ç—É–∏—Ü–∏—è</h2>
    <pre><code>TD Error = Œ¥_t = R_{t+1} + Œ≥V(s_{t+1}) - V(s_t)
           = [Target] - [Prediction]</code></pre>

    <p><strong>–ó–Ω–∞—á–µ–Ω–∏—è:</strong></p>
    <ul>
      <li><strong>Œ¥ > 0</strong>: –Ω–µ–¥–æ–æ—Ü–µ–Ω–∏–ª–∏ V(s), —É–≤–µ–ª–∏—á–∏—Ç—å</li>
      <li><strong>Œ¥ < 0</strong>: –ø–µ—Ä–µ–æ—Ü–µ–Ω–∏–ª–∏ V(s), —É–º–µ–Ω—å—à–∏—Ç—å</li>
      <li><strong>Œ¥ = 0</strong>: –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞</li>
    </ul>

    <p><strong>–ü—Ä–∏–º–µ—Ä:</strong></p>
    <pre><code># –°–æ—Å—Ç–æ—è–Ω–∏–µ s: V(s) = 10
# –ü–æ–ª—É—á–∏–ª–∏ reward = 5
# –°–ª–µ–¥—É—é—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ s': V(s') = 8
# Œ≥ = 0.9

Œ¥ = 5 + 0.9 * 8 - 10 = 2.2

# V(s) —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º!</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∏</h2>
    <p><strong>Learning rate (Œ±):</strong></p>
    <ul>
      <li><strong>0.01-0.1</strong>: –º–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ</li>
      <li><strong>0.1-0.3</strong>: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ</li>
      <li><strong>0.3-0.5</strong>: –±—ã—Å—Ç—Ä–æ–µ, –Ω–æ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ–µ</li>
    </ul>

    <p><strong>Discount factor (Œ≥):</strong></p>
    <ul>
      <li><strong>0.9</strong>: –±–ª–∏–∑–∫–∏–µ –Ω–∞–≥—Ä–∞–¥—ã –≤–∞–∂–Ω–µ–µ</li>
      <li><strong>0.95-0.99</strong>: –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ</li>
      <li><strong>0.999</strong>: –æ—á–µ–Ω—å –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–µ</li>
    </ul>

    <p><strong>Lambda (Œª):</strong></p>
    <ul>
      <li><strong>Œª = 0</strong>: TD(0)</li>
      <li><strong>Œª = 0.5-0.9</strong>: –∫–æ–º–ø—Ä–æ–º–∏—Å—Å</li>
      <li><strong>Œª = 1</strong>: Monte Carlo</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 8. Eligibility Traces</h2>
    <p><strong>–ò–¥–µ—è:</strong> –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å "–∑–∞—Å–ª—É–≥–∏" —Å–æ—Å—Ç–æ—è–Ω–∏–π</p>
    <pre><code># Forward view (—Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–µ)
V(s) ‚Üê V(s) + Œ±[G_t^Œª - V(s)]

# Backward view (–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ)
e(s) ‚Üê Œ≥Œªe(s) + 1
V(s) ‚Üê V(s) + Œ± * Œ¥_t * e(s)</code></pre>

    <p><strong>–¢–∏–ø—ã:</strong></p>
    <ul>
      <li><strong>Accumulating</strong>: e(s) += 1</li>
      <li><strong>Replacing</strong>: e(s) = 1</li>
      <li><strong>Dutch</strong>: e(s) = (1-Œ±)e(s) + 1</li>
    </ul>

    <p><strong>–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è:</strong></p>
    <pre><code>t=0: s1 ‚Üí s2 ‚Üí s3 ‚Üí s4 (reward=10)
                         ‚Üë
                    TD error –∑–¥–µ—Å—å

Eligibility:
e(s1) = 0.729 ‚Üí –æ–±–Ω–æ–≤–∏—Ç—å –Ω–∞ 72.9% –æ—Ç TD error
e(s2) = 0.81  ‚Üí –æ–±–Ω–æ–≤–∏—Ç—å –Ω–∞ 81% –æ—Ç TD error
e(s3) = 0.9   ‚Üí –æ–±–Ω–æ–≤–∏—Ç—å –Ω–∞ 90% –æ—Ç TD error
e(s4) = 1.0   ‚Üí –æ–±–Ω–æ–≤–∏—Ç—å –Ω–∞ 100% –æ—Ç TD error</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã</h2>
    <ul>
      <li><strong>–ù–∞—á–Ω–∏—Ç–µ —Å TD(0)</strong>: –ø—Ä–æ—â–µ –ø–æ–Ω—è—Ç—å –∏ –æ—Ç–ª–∞–¥–∏—Ç—å</li>
      <li><strong>–£–º–µ–Ω—å—à–∞–π—Ç–µ Œ±</strong>: Œ± = Œ±‚ÇÄ/(1 + episode/1000)</li>
      <li><strong>–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Œª=0.9</strong>: —Ö–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å</li>
      <li><strong>–ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ TD error</strong>: –¥–æ–ª–∂–µ–Ω —É–º–µ–Ω—å—à–∞—Ç—å—Å—è</li>
      <li><strong>–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ V(s)</strong>: –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—É—á–µ–Ω–∏—è</li>
      <li><strong>–°—Ä–∞–≤–Ω–∏—Ç–µ —Å MC</strong>: baseline –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 10. –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –•–æ—Ä–æ—à–æ</h3>
        <ul>
          <li>–ù—É–∂–Ω–æ –æ–Ω–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏–µ</li>
          <li>–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏ –±–µ–∑ —ç–ø–∏–∑–æ–¥–æ–≤</li>
          <li>–ë—ã—Å—Ç—Ä–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å –≤–∞–∂–Ω–∞</li>
          <li>–°—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–∞—è —Å—Ä–µ–¥–∞</li>
          <li>–ú–∞–ª–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è –∫—Ä–∏—Ç–∏—á–Ω–∞</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ùå –ü–ª–æ—Ö–æ</h3>
        <ul>
          <li>–ù—É–∂–Ω—ã –≥–∞—Ä–∞–Ω—Ç–∏–∏ –Ω–µ—Å–º–µ—â—ë–Ω–Ω–æ—Å—Ç–∏</li>
          <li>–û—á–µ–Ω—å –ø—Ä–æ—Å—Ç–∞—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ä–µ–¥–∞</li>
          <li>–î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–¥–Ω–æ–≥–æ —ç–ø–∏–∑–æ–¥–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 11. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å V(s) = 0</li>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å Œ± = 0.1 –¥–ª—è –Ω–∞—á–∞–ª–∞</li>
      <li>[ ] –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Œ≥ = 0.9-0.99</li>
      <li>[ ] –î–ª—è TD(Œª) –≤—ã–±—Ä–∞—Ç—å Œª = 0.9</li>
      <li>[ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å TD error –ø–æ–¥—Å—á—ë—Ç</li>
      <li>[ ] –î–æ–±–∞–≤–∏—Ç—å eligibility traces –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è</li>
      <li>[ ] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ GridWorld</li>
      <li>[ ] –°—Ä–∞–≤–Ω–∏—Ç—å —Å Monte Carlo</li>
      <li>[ ] –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å learned values</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´TD-learning ‚Äî —ç—Ç–æ –∫–∞–∫ —É—á–∏—Ç—å—Å—è –Ω–∞ —Å–≤–æ–∏—Ö –æ—à–∏–±–∫–∞—Ö —Å—Ä–∞–∑—É, –Ω–µ –¥–æ–∂–∏–¥–∞—è—Å—å –∫–æ–Ω—Ü–∞ –∏–≥—Ä—ã. –ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ, —á—Ç–æ –≤—ã –∏–≥—Ä–∞–µ—Ç–µ –≤ —à–∞—Ö–º–∞—Ç—ã –∏ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —Ö–æ–¥–∞ —Å—Ä–∞–∑—É –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç–µ, –Ω–∞—Å–∫–æ–ª—å–∫–æ –æ–Ω –±—ã–ª —Ö–æ—Ä–æ—à –∏–ª–∏ –ø–ª–æ—Ö, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –Ω–æ–≤–æ–π –ø–æ–∑–∏—Ü–∏–∏¬ª.
    </blockquote>
  </div>

</div>

</div>
</body>
</html>
