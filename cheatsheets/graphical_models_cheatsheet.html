<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>–ì—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏ Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen { body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif; color: #333; background: #fafcff; padding: 10px; 
        min-width: 900px;
      } }
    @media print { body { background: white; padding: 0; } @page { size: A4 landscape; margin: 10mm; } }
        .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }
    .block { break-inside: avoid; margin-bottom: 1.2em; padding: 12px; background: white; border-radius: 6px; box-shadow: 0 1px 3px rgba(0,0,0,0.05); }
    h1 { font-size: 1.6em; font-weight: 700; color: #1a5fb4; text-align: center; margin: 0 0 8px; column-span: all; }
    .subtitle { text-align: center; color: #666; font-size: 0.9em; margin-bottom: 12px; column-span: all; }
    h2 { font-size: 1.15em; font-weight: 700; color: #1a5fb4; margin: 0 0 8px; padding-bottom: 4px; border-bottom: 1px solid #e0e7ff; }
    p, ul, ol { font-size: 0.92em; margin: 0.6em 0; }
    ul, ol { padding-left: 18px; }
    li { margin-bottom: 4px; }
    code { font-family: 'Consolas', 'Courier New', monospace; background-color: #f0f4ff; padding: 1px 4px; border-radius: 3px; font-size: 0.88em; }
    pre { background-color: #f0f4ff; padding: 8px; border-radius: 4px; overflow-x: auto; font-size: 0.84em; margin: 6px 0; }
    pre code { padding: 0; background: none; white-space: pre-wrap; }
    blockquote { font-style: italic; margin: 8px 0; padding: 6px 10px; background: #f8fbff; border-left: 2px solid #1a5fb4; font-size: 0.88em; }
    table { width: 100%; border-collapse: collapse; font-size: 0.88em; margin: 6px 0; }
    th, td { padding: 6px 8px; text-align: left; border: 1px solid #e0e7ff; }
    th { background-color: #1a5fb4; color: white; font-weight: 700; }
    tr:nth-child(even) { background-color: #f8fbff; }
    @media print { .container { column-gap: 12px; } .block { box-shadow: none; } code, pre { font-size: 0.78em; } h1 { font-size: 1.4em; } h2 { font-size: 1em; } }
  </style>
</head>
<body>
<div class="container">
  <h1>üï∏Ô∏è –ì—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –û—Å–Ω–æ–≤—ã –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π</h2>
    <p><strong>–ì—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏</strong>: –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ—ã</p>
    <ul>
      <li><strong>–£–∑–ª—ã (nodes)</strong>: —Å–ª—É—á–∞–π–Ω—ã–µ –≤–µ–ª–∏—á–∏–Ω—ã</li>
      <li><strong>–†–µ–±—Ä–∞ (edges)</strong>: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏</li>
      <li><strong>–¢–∏–ø—ã</strong>: –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ (Bayesian networks) –∏ –Ω–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ (Markov networks)</li>
      <li><strong>–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞</strong>: –∏–Ω—Ç—É–∏—Ç–∏–≤–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è, –º–æ–¥—É–ª—å–Ω–æ—Å—Ç—å, —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –≤—ã–≤–æ–¥</li>
      <li><strong>–§–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è</strong>: —Ä–∞–∑–ª–æ–∂–µ–Ω–∏–µ —Å–æ–≤–º–µ—Å—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è</li>
    </ul>
    <blockquote>üí° –ì—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏ - –º–æ—â–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Å–ª–æ–∂–Ω—ã—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π</blockquote>

  <div class="block">
    <h2>üî∑ 2. –ë–∞–π–µ—Å–æ–≤—Å–∫–∏–µ —Å–µ—Ç–∏</h2>
    <p><strong>Directed Acyclic Graph (DAG)</strong>: P(X‚ÇÅ, ..., X‚Çô) = ‚àè·µ¢ P(X·µ¢ | Parents(X·µ¢))</p>
    <pre><code>from pgmpy.models import BayesianNetwork
from pgmpy.factors.discrete import TabularCPD

# –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
model = BayesianNetwork([
    ('Rain', 'Sprinkler'),
    ('Rain', 'Grass_Wet'),
    ('Sprinkler', 'Grass_Wet')
])

# CPD –¥–ª—è Rain
cpd_rain = TabularCPD(
    variable='Rain',
    variable_card=2,
    values=[[0.8], [0.2]]
)

# CPD –¥–ª—è Sprinkler | Rain
cpd_sprinkler = TabularCPD(
    variable='Sprinkler',
    variable_card=2,
    values=[[0.6, 0.99], [0.4, 0.01]],
    evidence=['Rain'],
    evidence_card=[2]
)

model.add_cpds(cpd_rain, cpd_sprinkler)
model.check_model()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 3. –ú–∞—Ä–∫–æ–≤—Å–∫–∏–µ —Å–µ—Ç–∏</h2>
    <p><strong>Undirected graphical models</strong>: P(X) = (1/Z) ‚àè_c œà_c(X_c)</p>
    <pre><code>from pgmpy.models import MarkovNetwork
from pgmpy.factors.discrete import DiscreteFactor

# –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Ç–∏
model = MarkovNetwork([
    ('A', 'B'), ('B', 'C'), ('A', 'C')
])

# –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
factor_ab = DiscreteFactor(
    variables=['A', 'B'],
    cardinality=[2, 2],
    values=[1.0, 2.0, 2.0, 1.0]
)

model.add_factors(factor_ab)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. –£—Å–ª–æ–≤–Ω–∞—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å</h2>
    <table>
      <tr><th>–°—Ç—Ä—É–∫—Ç—É—Ä–∞</th><th>–ù–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å</th><th>–ù–∞–∑–≤–∞–Ω–∏–µ</th></tr>
      <tr><td>A ‚Üí B ‚Üí C</td><td>A ‚ä• C | B</td><td>Chain</td></tr>
      <tr><td>A ‚Üê B ‚Üí C</td><td>A ‚ä• C | B</td><td>Fork</td></tr>
      <tr><td>A ‚Üí B ‚Üê C</td><td>A ‚ä• C (–±–µ–∑ B)</td><td>Collider</td></tr>
    </table>
    <p><strong>D-separation</strong>: –ø—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–Ω–æ–π –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≤ DAG</p>
    <pre><code>from pgmpy.base import DAG

dag = DAG([('A', 'B'), ('B', 'C')])
is_dsep = dag.is_dconnected('A', 'C', observed=['B'])
print(f"A d-separated from C given B: {not is_dsep}")</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. –ê–ª–≥–æ—Ä–∏—Ç–º—ã –≤—ã–≤–æ–¥–∞</h2>
    <pre><code>from pgmpy.inference import VariableElimination

# Variable Elimination
infer = VariableElimination(model)

# –ú–∞—Ä–≥–∏–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
result = infer.query(variables=['Grass_Wet'])

# –£—Å–ª–æ–≤–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
result = infer.query(
    variables=['Grass_Wet'],
    evidence={'Rain': 1}
)

# MAP inference
result = infer.map_query(
    variables=['Sprinkler'],
    evidence={'Grass_Wet': 1}
)

# Belief Propagation
from pgmpy.inference import BeliefPropagation

bp = BeliefPropagation(model)
bp.calibrate()
result = bp.query(variables=['Grass_Wet'])</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. Hidden Markov Models</h2>
    <pre><code>from hmmlearn import hmm

# Discrete HMM
model = hmm.MultinomialHMM(n_components=3)

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
model.startprob_ = np.array([0.6, 0.3, 0.1])
model.transmat_ = np.array([
    [0.7, 0.2, 0.1],
    [0.1, 0.8, 0.1],
    [0.1, 0.1, 0.8]
])
model.emissionprob_ = np.array([
    [0.7, 0.3],
    [0.4, 0.6],
    [0.1, 0.9]
])

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
X, Z = model.sample(100)

# –û–±—É—á–µ–Ω–∏–µ
model.fit(X)

# –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ (Viterbi)
log_prob, states = model.decode(X)

# Forward-backward
posteriors = model.predict_proba(X)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. Conditional Random Fields</h2>
    <pre><code>import sklearn_crfsuite

def word2features(sent, i):
    word = sent[i][0]
    return {
        'bias': 1.0,
        'word.lower()': word.lower(),
        'word[-3:]': word[-3:],
        'word.isupper()': word.isupper(),
        'word.istitle()': word.istitle(),
    }

# Training CRF
crf = sklearn_crfsuite.CRF(
    algorithm='lbfgs',
    c1=0.1,
    c2=0.1,
    max_iterations=100
)

X_train = [
    [word2features(s, i) for i in range(len(s))]
    for s in train_sents
]
y_train = [[label for _, label in s] for s in train_sents]

crf.fit(X_train, y_train)
y_pred = crf.predict(X_test)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 8. Factor Graphs</h2>
    <p><strong>Factor graphs</strong>: —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ</p>
    <ul>
      <li><strong>Variable nodes</strong>: —Å–ª—É—á–∞–π–Ω—ã–µ –≤–µ–ª–∏—á–∏–Ω—ã (–∫—Ä—É–≥–∏)</li>
      <li><strong>Factor nodes</strong>: —Ñ—É–Ω–∫—Ü–∏–∏ (–∫–≤–∞–¥—Ä–∞—Ç—ã)</li>
      <li><strong>Sum-Product algorithm</strong>: –æ–±—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –≤—ã–≤–æ–¥–∞</li>
    </ul>
    <pre><code># P(x‚ÇÅ,x‚ÇÇ,x‚ÇÉ) = f_A(x‚ÇÅ,x‚ÇÇ) ¬∑ f_B(x‚ÇÇ,x‚ÇÉ)

class FactorGraph:
    def __init__(self):
        self.variables = {}
        self.factors = {}
    
    def add_variable(self, name, cardinality):
        self.variables[name] = {
            'card': cardinality,
            'neighbors': []
        }
    
    def add_factor(self, name, variables, values):
        self.factors[name] = {
            'vars': variables,
            'values': np.array(values)
        }</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 9. –°—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ</h2>
    <pre><code>from pgmpy.estimators import HillClimbSearch, BicScore

# Hill climbing —Å BIC score
hc = HillClimbSearch(data)
best_model = hc.estimate(
    scoring_method=BicScore(data)
)

# Constraint-based (PC algorithm)
from pgmpy.estimators import PC

pc = PC(data)
model = pc.estimate(
    variant='stable',
    ci_test='chi_square',
    significance_level=0.05
)

# –û–±—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
from pgmpy.estimators import MaximumLikelihoodEstimator

bn = BayesianNetwork(best_model.edges())
bn.fit(data, estimator=MaximumLikelihoodEstimator)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. Dynamic Bayesian Networks</h2>
    <pre><code>from pgmpy.models import DynamicBayesianNetwork as DBN

# 2-Time-Slice BN
dbn = DBN()

# Intra-slice edges
dbn.add_edges_from([('X_0', 'Y_0')])

# Inter-slice edges
dbn.add_edges_from([
    (('X', 0), ('X', 1)),  # X_{t-1} ‚Üí X_t
    (('Y', 0), ('Y', 1)),  # Y_{t-1} ‚Üí Y_t
    (('X', 1), ('Y', 1'))  # X_t ‚Üí Y_t
])

# Inference
from pgmpy.inference import DBNInference

dbn_infer = DBNInference(dbn)
result = dbn_infer.forward_inference(['X'])</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏</h2>
    <ul>
      <li>‚úÖ <strong>–í—ã–±–æ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã</strong>: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ domain knowledge</li>
      <li>‚úÖ <strong>Conditional independence</strong>: —É–ø—Ä–æ—â–∞–µ—Ç –º–æ–¥–µ–ª—å</li>
      <li>‚úÖ <strong>–í–∞–ª–∏–¥–∞—Ü–∏—è</strong>: –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ d-separation</li>
      <li>‚úÖ <strong>–°–ª–æ–∂–Ω–æ—Å—Ç—å –≤—ã–≤–æ–¥–∞</strong>: –∑–∞–≤–∏—Å–∏—Ç –æ—Ç tree-width</li>
      <li>‚úÖ <strong>Approximate inference</strong>: –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π</li>
      <li>‚úÖ <strong>–ë–∏–±–ª–∏–æ—Ç–µ–∫–∏</strong>: pgmpy (Python), bnlearn (R)</li>
      <li>‚úÖ <strong>–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è</strong>: –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–Ω—è—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏</li>
    </ul>
    <blockquote>üí° –ì—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ–ª–µ–∑–Ω—ã –∫–æ–≥–¥–∞ –≤–∞–∂–Ω–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å</blockquote>
  </div>

  <div class="block">
    <h2>üî∑ 12. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</h2>
    <ul>
      <li>üéØ <strong>–ú–µ–¥–∏—Ü–∏–Ω–∞</strong>: –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–µ —Å–∏—Å—Ç–µ–º—ã</li>
      <li>üéØ <strong>NLP</strong>: POS tagging, NER, parsing</li>
      <li>üéØ <strong>Computer vision</strong>: segmentation</li>
      <li>üéØ <strong>–ë–∏–æ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞</strong>: gene networks</li>
      <li>üéØ <strong>Recommendation</strong>: user modeling</li>
      <li>üéØ <strong>Speech recognition</strong>: HMM –¥–ª—è —Ñ–æ–Ω–µ–º</li>
      <li>üéØ <strong>Robotics</strong>: SLAM</li>
      <li>üéØ <strong>Finance</strong>: risk modeling</li>
    </ul>
  </div>

</div>
</div>
</body>
</html>