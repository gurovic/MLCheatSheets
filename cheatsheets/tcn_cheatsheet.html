<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>Temporal Convolutional Networks (TCN) Cheatsheet ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏</title>
  <style>
    @media screen {
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
        color: #333;
        background: #fafcff;
        padding: 10px;
      }
    }
    @media print {
      body {
        background: white;
        padding: 0;
      }
      @page {
        size: A4 landscape;
        margin: 10mm;
      }
    }

        .container {
      max-width: 100%;
    }

    /* Responsive columns: 3 columns on wide screens, fewer on narrow */
    @media (min-width: 900px) {
      .container {
        column-count: 3;
        column-gap: 20px;
      }
    }
    
    @media (min-width: 600px) and (max-width: 899px) {
      .container {
        column-count: 2;
        column-gap: 20px;
      }
    }
    
    @media (max-width: 599px) {
      .container {
        column-count: 1;
      }
    }

    .block {
      break-inside: avoid;
      margin-bottom: 1.2em;
      padding: 12px;
      background: white;
      border-radius: 6px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    h1 {
      font-size: 1.6em;
      font-weight: 700;
      color: #1a5fb4;
      text-align: center;
      margin: 0 0 8px;
      column-span: all;
    }

    .subtitle {
      text-align: center;
      color: #666;
      font-size: 0.9em;
      margin-bottom: 12px;
      column-span: all;
    }

    h2 {
      font-size: 1.15em;
      font-weight: 700;
      color: #1a5fb4;
      margin: 0 0 8px;
      padding-bottom: 4px;
      border-bottom: 1px solid #e0e7ff;
    }

    p, ul, ol {
      font-size: 0.92em;
      margin: 0.6em 0;
    }

    ul, ol {
      padding-left: 18px;
    }

    li {
      margin-bottom: 4px;
    }

    code {
      font-family: 'Consolas', 'Courier New', monospace;
      background-color: #f0f4ff;
      padding: 1px 4px;
      border-radius: 3px;
      font-size: 0.88em;
    }

    pre {
      background-color: #f0f4ff;
      padding: 8px;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.84em;
      margin: 6px 0;
    }

    pre code {
      padding: 0;
      background: none;
      white-space: pre-wrap;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82em;
      margin: 6px 0;
    }

    th {
      background-color: #e6f0ff;
      text-align: left;
      padding: 4px 6px;
      font-weight: 600;
    }

    td {
      padding: 4px 6px;
      border-bottom: 1px solid #f0f4ff;
    }

    tr:nth-child(even) {
      background-color: #f8fbff;
    }

    .good-vs-bad {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .good-vs-bad div {
      flex: 1;
      padding: 6px 8px;
      border-radius: 4px;
    }

    .good {
      background-color: #f0f9f4;
      border-left: 3px solid #2e8b57;
    }

    .bad {
      background-color: #fdf0f2;
      border-left: 3px solid #d32f2f;
    }

    .good h3, .bad h3 {
      margin: 0 0 4px;
      font-size: 1em;
      font-weight: 700;
    }

    .good ul, .bad ul {
      padding-left: 20px;
      margin: 0;
    }

    .good li::before { content: "‚úÖ "; font-weight: bold; }
    .bad li::before { content: "‚ùå "; font-weight: bold; }

    blockquote {
      font-style: italic;
      margin: 8px 0;
      padding: 6px 10px;
      background: #f8fbff;
      border-left: 2px solid #1a5fb4;
      font-size: 0.88em;
    }

    @media print {
      .container { column-gap: 12px; }
      .block { box-shadow: none; }
      code, pre, table { font-size: 0.78em; }
      h1 { font-size: 1.4em; }
      h2 { font-size: 1em; }
    }
  </style>
</head>
<body>

<div class="container">

  <h1>‚è±Ô∏è Temporal Convolutional Networks (TCN)</h1>
  <div class="subtitle">üìÖ –Ø–Ω–≤–∞—Ä—å 2026</div>

  <div class="block">
    <h2>üî∑ 1. –ß—Ç–æ —Ç–∞–∫–æ–µ TCN</h2>
    <ul>
      <li><strong>–¶–µ–ª—å</strong>: –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Å –ø–æ–º–æ—â—å—é CNN</li>
      <li><strong>–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ</strong>: –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º + –¥–ª–∏–Ω–Ω–∞—è –ø–∞–º—è—Ç—å</li>
      <li><strong>–ö–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã</strong>: causal convolution + dilation</li>
      <li><strong>–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ</strong>: –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã, –∞—É–¥–∏–æ, —Ç–µ–∫—Å—Ç</li>
      <li><strong>Vs RNN</strong>: –±—ã—Å—Ç—Ä–µ–µ –æ–±—É—á–∞–µ—Ç—Å—è, –ª—É—á—à–µ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è</li>
    </ul>

  <div class="block">
    <h2>üî∑ 2. –ö–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏</h2>
    <p><strong>1. Causal Convolution</strong>:</p>
    <ul>
      <li>–ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –±—É–¥—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ</li>
      <li>–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ t –∑–∞–≤–∏—Å–∏—Ç —Ç–æ–ª—å–∫–æ –æ—Ç t –∏ –ø—Ä–æ—à–ª–æ–≥–æ</li>
      <li>Padding —Å–ª–µ–≤–∞ (–Ω–µ —Å–ø—Ä–∞–≤–∞)</li>
    </ul>
    <p><strong>2. Dilated Convolution</strong>:</p>
    <ul>
      <li>–£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–µ—Ü–µ–ø—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–ª—è</li>
      <li>Dilation rate: 1, 2, 4, 8, 16...</li>
      <li>–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π —Ä–æ—Å—Ç –æ—Ö–≤–∞—Ç–∞</li>
    </ul>
    <p><strong>3. Residual Connections</strong>:</p>
    <ul>
      <li>Skip connections –¥–ª—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤</li>
      <li>–°—Ç–∞–±–∏–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –≥–ª—É–±–æ–∫–∏—Ö —Å–µ—Ç–µ–π</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 3. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ TCN</h2>
    <pre><code>import torch
import torch.nn as nn

class CausalConv1d(nn.Module):
    def __init__(self, in_channels, out_channels, 
                 kernel_size, dilation=1):
        super().__init__()
        self.padding = (kernel_size - 1) * dilation
        self.conv = nn.Conv1d(
            in_channels, out_channels,
            kernel_size, padding=self.padding,
            dilation=dilation
        )
    
    def forward(self, x):
        x = self.conv(x)
        # –£–¥–∞–ª—è–µ–º –ø—Ä–∞–≤—ã–π padding (–±—É–¥—É—â–µ–µ)
        return x[:, :, :-self.padding]


class ResidualBlock(nn.Module):
    def __init__(self, channels, kernel_size, dilation):
        super().__init__()
        self.conv1 = CausalConv1d(
            channels, channels, kernel_size, dilation
        )
        self.conv2 = CausalConv1d(
            channels, channels, kernel_size, dilation
        )
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.2)
        
    def forward(self, x):
        residual = x
        out = self.relu(self.conv1(x))
        out = self.dropout(out)
        out = self.relu(self.conv2(out))
        out = self.dropout(out)
        return self.relu(out + residual)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 4. –ü–æ–ª–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è TCN</h2>
    <pre><code>class TCN(nn.Module):
    def __init__(self, input_size, output_size, 
                 num_channels, kernel_size=3, dropout=0.2):
        super().__init__()
        layers = []
        num_levels = len(num_channels)
        
        for i in range(num_levels):
            dilation_size = 2 ** i
            in_channels = input_size if i == 0 else num_channels[i-1]
            out_channels = num_channels[i]
            
            layers.append(ResidualBlock(
                out_channels if i > 0 else in_channels,
                kernel_size,
                dilation_size
            ))
            
            if i == 0:
                layers.insert(0, nn.Conv1d(
                    input_size, out_channels, 1
                ))
        
        self.network = nn.Sequential(*layers)
        self.linear = nn.Linear(num_channels[-1], output_size)
    
    def forward(self, x):
        # x: (batch, seq_len, features)
        x = x.transpose(1, 2)  # (batch, features, seq_len)
        x = self.network(x)
        x = x.transpose(1, 2)  # (batch, seq_len, features)
        return self.linear(x[:, -1, :])  # –ü–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–≥


# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
model = TCN(
    input_size=10,        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    output_size=1,        # –†–µ–≥—Ä–µ—Å—Å–∏—è
    num_channels=[25, 25, 25, 25],  # –ö–∞–Ω–∞–ª—ã –Ω–∞ —É—Ä–æ–≤–Ω—è—Ö
    kernel_size=3,
    dropout=0.2
)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 5. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏</h2>
    <pre><code>import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
X_train_tensor = torch.FloatTensor(X_train)
y_train_tensor = torch.FloatTensor(y_train)

train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
train_loader = DataLoader(train_dataset, batch_size=32, 
                          shuffle=True)

# –ú–æ–¥–µ–ª—å, –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä, —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
model = TCN(input_size=10, output_size=1, 
            num_channels=[32, 32, 32, 32])
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.MSELoss()

# –û–±—É—á–µ–Ω–∏–µ
num_epochs = 50
model.train()

for epoch in range(num_epochs):
    total_loss = 0
    for batch_x, batch_y in train_loader:
        optimizer.zero_grad()
        
        # Forward pass
        outputs = model(batch_x)
        loss = criterion(outputs.squeeze(), batch_y)
        
        # Backward pass
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
    
    if (epoch + 1) % 10 == 0:
        avg_loss = total_loss / len(train_loader)
        print(f'Epoch [{epoch+1}/{num_epochs}], '
              f'Loss: {avg_loss:.4f}')</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 6. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ</h2>
    <pre><code># –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
model.eval()
with torch.no_grad():
    X_test_tensor = torch.FloatTensor(X_test)
    predictions = model(X_test_tensor)
    predictions = predictions.squeeze().numpy()

# –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
from sklearn.metrics import mean_squared_error, r2_score

mse = mean_squared_error(y_test, predictions)
r2 = r2_score(y_test, predictions)

print(f'MSE: {mse:.4f}')
print(f'R¬≤: {r2:.4f}')

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
plt.plot(y_test[:100], label='–ò—Å—Ç–∏–Ω–∞', alpha=0.7)
plt.plot(predictions[:100], label='–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ', alpha=0.7)
plt.xlabel('–í—Ä–µ–º—è')
plt.ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ')
plt.title('TCN: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è vs –ò—Å—Ç–∏–Ω–∞')
plt.legend()
plt.grid(True)
plt.show()</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 7. –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã TCN</h2>
    <table>
      <tr><th>–ü–∞—Ä–∞–º–µ—Ç—Ä</th><th>–û–ø–∏—Å–∞–Ω–∏–µ</th><th>–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏</th></tr>
      <tr><td><code>num_channels</code></td><td>–ö–∞–Ω–∞–ª—ã –Ω–∞ —É—Ä–æ–≤–Ω—è—Ö</td><td>[25, 25, 25] - [64, 64, 64]</td></tr>
      <tr><td><code>kernel_size</code></td><td>–†–∞–∑–º–µ—Ä —è–¥—Ä–∞</td><td>3-7 (–æ–±—ã—á–Ω–æ 3)</td></tr>
      <tr><td><code>dropout</code></td><td>–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è</td><td>0.1-0.3</td></tr>
      <tr><td><code>num_levels</code></td><td>–ì–ª—É–±–∏–Ω–∞ —Å–µ—Ç–∏</td><td>3-8 —É—Ä–æ–≤–Ω–µ–π</td></tr>
      <tr><td><code>learning_rate</code></td><td>–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è</td><td>0.001-0.01</td></tr>
    </table>
    <p><strong>–†–µ—Ü–µ–ø—Ç–∏–≤–Ω–æ–µ –ø–æ–ª–µ</strong>:</p>
    <ul>
      <li>RF = 1 + 2 √ó (kernel_size - 1) √ó Œ£(2^i) –¥–ª—è i=0..L-1</li>
      <li>–ü—Ä–∏–º–µ—Ä: kernel_size=3, L=4 ‚Üí RF = 31</li>
    </ul>
  </div>

  <div class="block">
    <h2>üî∑ 8. TCN vs RNN/LSTM</h2>
    <table>
      <tr><th>–ö—Ä–∏—Ç–µ—Ä–∏–π</th><th>TCN</th><th>LSTM</th></tr>
      <tr><td><strong>–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è</strong></td><td>‚úÖ –ë—ã—Å—Ç—Ä–µ–µ</td><td>–ú–µ–¥–ª–µ–Ω–Ω–µ–µ</td></tr>
      <tr><td><strong>–ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º</strong></td><td>‚úÖ –ü–æ–ª–Ω—ã–π</td><td>‚ùå –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π</td></tr>
      <tr><td><strong>–î–ª–∏–Ω–Ω–∞—è –ø–∞–º—è—Ç—å</strong></td><td>‚úÖ –° dilations</td><td>‚úÖ –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è</td></tr>
      <tr><td><strong>–ì—Ä–∞–¥–∏–µ–Ω—Ç—ã</strong></td><td>‚úÖ –°—Ç–∞–±–∏–ª—å–Ω—ã–µ</td><td>‚ö†Ô∏è –ú–æ–≥—É—Ç –∏—Å—á–µ–∑–∞—Ç—å</td></tr>
      <tr><td><strong>–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏</strong></td><td>–ë–æ–ª—å—à–µ</td><td>–ú–µ–Ω—å—à–µ</td></tr>
      <tr><td><strong>Inference</strong></td><td>‚ö° –ë—ã—Å—Ç—Ä—ã–π</td><td>–ú–µ–¥–ª–µ–Ω–Ω–µ–µ</td></tr>
    </table>
  </div>

  <div class="block">
    <h2>üî∑ 9. –ì–æ—Ç–æ–≤–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞</h2>
    <pre><code># –£—Å—Ç–∞–Ω–æ–≤–∫–∞
# pip install torch-tcn

from tcn import TCN as TCNLayer

class SimpleTCN(nn.Module):
    def __init__(self, input_size, output_size, 
                 num_channels, kernel_size=3):
        super().__init__()
        self.tcn = TCNLayer(
            num_inputs=input_size,
            num_channels=num_channels,
            kernel_size=kernel_size,
            dropout=0.2
        )
        self.linear = nn.Linear(num_channels[-1], output_size)
    
    def forward(self, x):
        # x: (batch, seq_len, features)
        x = x.transpose(1, 2)
        y = self.tcn(x)
        y = y.transpose(1, 2)
        return self.linear(y[:, -1, :])

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
model = SimpleTCN(
    input_size=10,
    output_size=1,
    num_channels=[32, 32, 32, 32],
    kernel_size=3
)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 10. –ú–Ω–æ–≥–æ—à–∞–≥–æ–≤–æ–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ</h2>
    <pre><code>class MultiStepTCN(nn.Module):
    def __init__(self, input_size, horizon, num_channels):
        super().__init__()
        self.horizon = horizon
        self.tcn = TCN(
            input_size=input_size,
            output_size=horizon,  # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ —à–∞–≥–∏
            num_channels=num_channels
        )
    
    def forward(self, x):
        # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (batch, horizon)
        return self.tcn(x)

# –û–±—É—á–µ–Ω–∏–µ
model = MultiStepTCN(
    input_size=10, 
    horizon=24,  # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º 24 —à–∞–≥–∞ –≤–ø–µ—Ä–µ–¥
    num_channels=[64, 64, 64, 64]
)

# –ü—Ä–∏–º–µ—Ä: –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 24 —á–∞—Å–∞ –≤–ø–µ—Ä–µ–¥
with torch.no_grad():
    predictions = model(X_test_tensor)
    # predictions: (batch_size, 24)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 11. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è TCN</h2>
    <div class="good-vs-bad">
      <div class="good">
        <h3>‚úÖ –•–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç</h3>
        <ul>
          <li>–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤</li>
          <li>–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π</li>
          <li>–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ —Å–∏–≥–Ω–∞–ª–æ–≤</li>
          <li>–î–µ—Ç–µ–∫—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π –≤ –ø–æ—Ç–æ–∫–∞—Ö</li>
          <li>–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏–π (video)</li>
          <li>–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–µ–Ω—Å–æ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö IoT</li>
        </ul>
      </div>
      <div class="bad">
        <h3>‚ùå –ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è</h3>
        <ul>
          <li>–û—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (>10k)</li>
          <li>–ó–∞–¥–∞—á–∏ —Ç—Ä–µ–±—É—é—â–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª–∏–Ω—É</li>
          <li>–ú–∞–ª—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã (–ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ)</li>
          <li>–ö–æ–≥–¥–∞ –≤–∞–∂–Ω–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="block">
    <h2>üî∑ 12. Weight Normalization</h2>
    <p>–°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è:</p>
    <pre><code>from torch.nn.utils import weight_norm

class ImprovedTCN(nn.Module):
    def __init__(self, input_size, output_size, 
                 num_channels):
        super().__init__()
        
        layers = []
        for i, channels in enumerate(num_channels):
            dilation = 2 ** i
            in_ch = input_size if i == 0 else num_channels[i-1]
            
            # Weight normalization –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            conv = weight_norm(nn.Conv1d(
                in_ch, channels, kernel_size=3,
                padding=(3-1)*dilation, dilation=dilation
            ))
            layers.append(conv)
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(0.2))
        
        self.network = nn.Sequential(*layers)
        self.fc = nn.Linear(num_channels[-1], output_size)
    
    def forward(self, x):
        x = x.transpose(1, 2)
        x = self.network(x)
        x = x[:, :, -1]  # –ü–æ—Å–ª–µ–¥–Ω–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥
        return self.fc(x)</code></pre>
  </div>

  <div class="block">
    <h2>üî∑ 13. –ß–µ–∫-–ª–∏—Å—Ç</h2>
    <ul>
      <li>[ ] –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å/–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ</li>
      <li>[ ] –í—ã–±—Ä–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π kernel_size (–æ–±—ã—á–Ω–æ 3)</li>
      <li>[ ] –†–∞—Å—Å—á–∏—Ç–∞—Ç—å –Ω—É–∂–Ω–æ–µ —Ä–µ—Ü–µ–ø—Ç–∏–≤–Ω–æ–µ –ø–æ–ª–µ</li>
      <li>[ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å weight normalization</li>
      <li>[ ] –î–æ–±–∞–≤–∏—Ç—å dropout –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏</li>
      <li>[ ] –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ</li>
      <li>[ ] –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∫–∞–Ω–∞–ª–æ–≤</li>
      <li>[ ] –°—Ä–∞–≤–Ω–∏—Ç—å —Å LSTM baseline</li>
      <li>[ ] –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è</li>
      <li>[ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö</li>
    </ul>

    <h3>üí° –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫—É:</h3>
    <blockquote>
      ¬´TCN ‚Äî —ç—Ç–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ LSTM –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤, –∫–æ—Ç–æ—Ä–∞—è —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–µ–µ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ –±–ª–∞–≥–æ–¥–∞—Ä—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –≤–º–µ—Å—Ç–æ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö¬ª.
    </blockquote>
  </div>

</div>

</div>
</body>
</html>
